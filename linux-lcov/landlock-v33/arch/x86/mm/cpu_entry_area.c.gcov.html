<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - landlock.info - arch/x86/mm/cpu_entry_area.c</title>
  <link rel="stylesheet" type="text/css" href="../../../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../../../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../../../index.html">top level</a> - <a href="index.html">arch/x86/mm</a> - cpu_entry_area.c<span style="font-size: 80%;"> (source / <a href="cpu_entry_area.c.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">landlock.info</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">65</td>
            <td class="headerCovTableEntry">66</td>
            <td class="headerCovTableEntryHi">98.5 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2021-04-07 12:34:12</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">7</td>
            <td class="headerCovTableEntry">7</td>
            <td class="headerCovTableEntryHi">100.0 %</td>
          </tr>
          <tr><td><img src="../../../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../../../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : // SPDX-License-Identifier: GPL-2.0</a>
<a name="2"><span class="lineNum">       2 </span>            : </a>
<a name="3"><span class="lineNum">       3 </span>            : #include &lt;linux/spinlock.h&gt;</a>
<a name="4"><span class="lineNum">       4 </span>            : #include &lt;linux/percpu.h&gt;</a>
<a name="5"><span class="lineNum">       5 </span>            : #include &lt;linux/kallsyms.h&gt;</a>
<a name="6"><span class="lineNum">       6 </span>            : #include &lt;linux/kcore.h&gt;</a>
<a name="7"><span class="lineNum">       7 </span>            : #include &lt;linux/pgtable.h&gt;</a>
<a name="8"><span class="lineNum">       8 </span>            : </a>
<a name="9"><span class="lineNum">       9 </span>            : #include &lt;asm/cpu_entry_area.h&gt;</a>
<a name="10"><span class="lineNum">      10 </span>            : #include &lt;asm/fixmap.h&gt;</a>
<a name="11"><span class="lineNum">      11 </span>            : #include &lt;asm/desc.h&gt;</a>
<a name="12"><span class="lineNum">      12 </span>            : </a>
<a name="13"><span class="lineNum">      13 </span>            : static DEFINE_PER_CPU_PAGE_ALIGNED(struct entry_stack_page, entry_stack_storage);</a>
<a name="14"><span class="lineNum">      14 </span>            : </a>
<a name="15"><span class="lineNum">      15 </span>            : #ifdef CONFIG_X86_64</a>
<a name="16"><span class="lineNum">      16 </span>            : static DEFINE_PER_CPU_PAGE_ALIGNED(struct exception_stacks, exception_stacks);</a>
<a name="17"><span class="lineNum">      17 </span>            : DEFINE_PER_CPU(struct cea_exception_stacks*, cea_exception_stacks);</a>
<a name="18"><span class="lineNum">      18 </span>            : #endif</a>
<a name="19"><span class="lineNum">      19 </span>            : </a>
<a name="20"><span class="lineNum">      20 </span>            : #ifdef CONFIG_X86_32</a>
<a name="21"><span class="lineNum">      21 </span>            : DECLARE_PER_CPU_PAGE_ALIGNED(struct doublefault_stack, doublefault_stack);</a>
<a name="22"><span class="lineNum">      22 </span>            : #endif</a>
<a name="23"><span class="lineNum">      23 </span>            : </a>
<a name="24"><span class="lineNum">      24 </span>            : /* Is called from entry code, so must be noinstr */</a>
<a name="25"><span class="lineNum">      25 </span><span class="lineCov">         38 : noinstr struct cpu_entry_area *get_cpu_entry_area(int cpu)</span></a>
<a name="26"><span class="lineNum">      26 </span>            : {</a>
<a name="27"><span class="lineNum">      27 </span><span class="lineCov">         38 :         unsigned long va = CPU_ENTRY_AREA_PER_CPU + cpu * CPU_ENTRY_AREA_SIZE;</span></a>
<a name="28"><span class="lineNum">      28 </span><span class="lineCov">         38 :         BUILD_BUG_ON(sizeof(struct cpu_entry_area) % PAGE_SIZE != 0);</span></a>
<a name="29"><span class="lineNum">      29 </span>            : </a>
<a name="30"><span class="lineNum">      30 </span><span class="lineCov">         38 :         return (struct cpu_entry_area *) va;</span></a>
<a name="31"><span class="lineNum">      31 </span>            : }</a>
<a name="32"><span class="lineNum">      32 </span>            : EXPORT_SYMBOL(get_cpu_entry_area);</a>
<a name="33"><span class="lineNum">      33 </span>            : </a>
<a name="34"><span class="lineNum">      34 </span><span class="lineCov">        193 : void cea_set_pte(void *cea_vaddr, phys_addr_t pa, pgprot_t flags)</span></a>
<a name="35"><span class="lineNum">      35 </span>            : {</a>
<a name="36"><span class="lineNum">      36 </span><span class="lineCov">        193 :         unsigned long va = (unsigned long) cea_vaddr;</span></a>
<a name="37"><span class="lineNum">      37 </span><span class="lineCov">        193 :         pte_t pte = pfn_pte(pa &gt;&gt; PAGE_SHIFT, flags);</span></a>
<a name="38"><span class="lineNum">      38 </span>            : </a>
<a name="39"><span class="lineNum">      39 </span>            :         /*</a>
<a name="40"><span class="lineNum">      40 </span>            :          * The cpu_entry_area is shared between the user and kernel</a>
<a name="41"><span class="lineNum">      41 </span>            :          * page tables.  All of its ptes can safely be global.</a>
<a name="42"><span class="lineNum">      42 </span>            :          * _PAGE_GLOBAL gets reused to help indicate PROT_NONE for</a>
<a name="43"><span class="lineNum">      43 </span>            :          * non-present PTEs, so be careful not to set it in that</a>
<a name="44"><span class="lineNum">      44 </span>            :          * case to avoid confusion.</a>
<a name="45"><span class="lineNum">      45 </span>            :          */</a>
<a name="46"><span class="lineNum">      46 </span><span class="lineCov">        193 :         if (boot_cpu_has(X86_FEATURE_PGE) &amp;&amp;</span></a>
<a name="47"><span class="lineNum">      47 </span><span class="lineCov">        193 :             (pgprot_val(flags) &amp; _PAGE_PRESENT))</span></a>
<a name="48"><span class="lineNum">      48 </span><span class="lineCov">         65 :                 pte = pte_set_flags(pte, _PAGE_GLOBAL);</span></a>
<a name="49"><span class="lineNum">      49 </span>            : </a>
<a name="50"><span class="lineNum">      50 </span><span class="lineCov">        193 :         set_pte_vaddr(va, pte);</span></a>
<a name="51"><span class="lineNum">      51 </span><span class="lineCov">        193 : }</span></a>
<a name="52"><span class="lineNum">      52 </span>            : </a>
<a name="53"><span class="lineNum">      53 </span>            : static void __init</a>
<a name="54"><span class="lineNum">      54 </span><span class="lineCov">         28 : cea_map_percpu_pages(void *cea_vaddr, void *ptr, int pages, pgprot_t prot)</span></a>
<a name="55"><span class="lineNum">      55 </span>            : {</a>
<a name="56"><span class="lineNum">      56 </span><span class="lineCov">         88 :         for ( ; pages; pages--, cea_vaddr+= PAGE_SIZE, ptr += PAGE_SIZE)</span></a>
<a name="57"><span class="lineNum">      57 </span><span class="lineCov">         60 :                 cea_set_pte(cea_vaddr, per_cpu_ptr_to_phys(ptr), prot);</span></a>
<a name="58"><span class="lineNum">      58 </span><span class="lineCov">         28 : }</span></a>
<a name="59"><span class="lineNum">      59 </span>            : </a>
<a name="60"><span class="lineNum">      60 </span><span class="lineCov">          4 : static void __init percpu_setup_debug_store(unsigned int cpu)</span></a>
<a name="61"><span class="lineNum">      61 </span>            : {</a>
<a name="62"><span class="lineNum">      62 </span>            : #ifdef CONFIG_CPU_SUP_INTEL</a>
<a name="63"><span class="lineNum">      63 </span><span class="lineCov">          4 :         unsigned int npages;</span></a>
<a name="64"><span class="lineNum">      64 </span><span class="lineCov">          4 :         void *cea;</span></a>
<a name="65"><span class="lineNum">      65 </span>            : </a>
<a name="66"><span class="lineNum">      66 </span><span class="lineCov">          4 :         if (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL)</span></a>
<a name="67"><span class="lineNum">      67 </span><span class="lineNoCov">          0 :                 return;</span></a>
<a name="68"><span class="lineNum">      68 </span>            : </a>
<a name="69"><span class="lineNum">      69 </span><span class="lineCov">          4 :         cea = &amp;get_cpu_entry_area(cpu)-&gt;cpu_debug_store;</span></a>
<a name="70"><span class="lineNum">      70 </span><span class="lineCov">          4 :         npages = sizeof(struct debug_store) / PAGE_SIZE;</span></a>
<a name="71"><span class="lineNum">      71 </span><span class="lineCov">          4 :         BUILD_BUG_ON(sizeof(struct debug_store) % PAGE_SIZE != 0);</span></a>
<a name="72"><span class="lineNum">      72 </span><span class="lineCov">          4 :         cea_map_percpu_pages(cea, &amp;per_cpu(cpu_debug_store, cpu), npages,</span></a>
<a name="73"><span class="lineNum">      73 </span><span class="lineCov">          4 :                              PAGE_KERNEL);</span></a>
<a name="74"><span class="lineNum">      74 </span>            : </a>
<a name="75"><span class="lineNum">      75 </span><span class="lineCov">          4 :         cea = &amp;get_cpu_entry_area(cpu)-&gt;cpu_debug_buffers;</span></a>
<a name="76"><span class="lineNum">      76 </span>            :         /*</a>
<a name="77"><span class="lineNum">      77 </span>            :          * Force the population of PMDs for not yet allocated per cpu</a>
<a name="78"><span class="lineNum">      78 </span>            :          * memory like debug store buffers.</a>
<a name="79"><span class="lineNum">      79 </span>            :          */</a>
<a name="80"><span class="lineNum">      80 </span><span class="lineCov">          4 :         npages = sizeof(struct debug_store_buffers) / PAGE_SIZE;</span></a>
<a name="81"><span class="lineNum">      81 </span><span class="lineCov">        132 :         for (; npages; npages--, cea += PAGE_SIZE)</span></a>
<a name="82"><span class="lineNum">      82 </span><span class="lineCov">        128 :                 cea_set_pte(cea, 0, PAGE_NONE);</span></a>
<a name="83"><span class="lineNum">      83 </span>            : #endif</a>
<a name="84"><span class="lineNum">      84 </span>            : }</a>
<a name="85"><span class="lineNum">      85 </span>            : </a>
<a name="86"><span class="lineNum">      86 </span>            : #ifdef CONFIG_X86_64</a>
<a name="87"><span class="lineNum">      87 </span>            : </a>
<a name="88"><span class="lineNum">      88 </span>            : #define cea_map_stack(name) do {                                        \</a>
<a name="89"><span class="lineNum">      89 </span>            :         npages = sizeof(estacks-&gt;name## _stack) / PAGE_SIZE;         \</a>
<a name="90"><span class="lineNum">      90 </span>            :         cea_map_percpu_pages(cea-&gt;estacks.name## _stack,             \</a>
<a name="91"><span class="lineNum">      91 </span>            :                         estacks-&gt;name## _stack, npages, PAGE_KERNEL);        \</a>
<a name="92"><span class="lineNum">      92 </span>            :         } while (0)</a>
<a name="93"><span class="lineNum">      93 </span>            : </a>
<a name="94"><span class="lineNum">      94 </span><span class="lineCov">          4 : static void __init percpu_setup_exception_stacks(unsigned int cpu)</span></a>
<a name="95"><span class="lineNum">      95 </span>            : {</a>
<a name="96"><span class="lineNum">      96 </span><span class="lineCov">          4 :         struct exception_stacks *estacks = per_cpu_ptr(&amp;exception_stacks, cpu);</span></a>
<a name="97"><span class="lineNum">      97 </span><span class="lineCov">          4 :         struct cpu_entry_area *cea = get_cpu_entry_area(cpu);</span></a>
<a name="98"><span class="lineNum">      98 </span><span class="lineCov">          4 :         unsigned int npages;</span></a>
<a name="99"><span class="lineNum">      99 </span>            : </a>
<a name="100"><span class="lineNum">     100 </span><span class="lineCov">          4 :         BUILD_BUG_ON(sizeof(exception_stacks) % PAGE_SIZE != 0);</span></a>
<a name="101"><span class="lineNum">     101 </span>            : </a>
<a name="102"><span class="lineNum">     102 </span><span class="lineCov">          4 :         per_cpu(cea_exception_stacks, cpu) = &amp;cea-&gt;estacks;</span></a>
<a name="103"><span class="lineNum">     103 </span>            : </a>
<a name="104"><span class="lineNum">     104 </span>            :         /*</a>
<a name="105"><span class="lineNum">     105 </span>            :          * The exceptions stack mappings in the per cpu area are protected</a>
<a name="106"><span class="lineNum">     106 </span>            :          * by guard pages so each stack must be mapped separately. DB2 is</a>
<a name="107"><span class="lineNum">     107 </span>            :          * not mapped; it just exists to catch triple nesting of #DB.</a>
<a name="108"><span class="lineNum">     108 </span>            :          */</a>
<a name="109"><span class="lineNum">     109 </span><span class="lineCov">          4 :         cea_map_stack(DF);</span></a>
<a name="110"><span class="lineNum">     110 </span><span class="lineCov">          4 :         cea_map_stack(NMI);</span></a>
<a name="111"><span class="lineNum">     111 </span><span class="lineCov">          4 :         cea_map_stack(DB);</span></a>
<a name="112"><span class="lineNum">     112 </span><span class="lineCov">          4 :         cea_map_stack(MCE);</span></a>
<a name="113"><span class="lineNum">     113 </span><span class="lineCov">          4 : }</span></a>
<a name="114"><span class="lineNum">     114 </span>            : #else</a>
<a name="115"><span class="lineNum">     115 </span>            : static inline void percpu_setup_exception_stacks(unsigned int cpu)</a>
<a name="116"><span class="lineNum">     116 </span>            : {</a>
<a name="117"><span class="lineNum">     117 </span>            :         struct cpu_entry_area *cea = get_cpu_entry_area(cpu);</a>
<a name="118"><span class="lineNum">     118 </span>            : </a>
<a name="119"><span class="lineNum">     119 </span>            :         cea_map_percpu_pages(&amp;cea-&gt;doublefault_stack,</a>
<a name="120"><span class="lineNum">     120 </span>            :                              &amp;per_cpu(doublefault_stack, cpu), 1, PAGE_KERNEL);</a>
<a name="121"><span class="lineNum">     121 </span>            : }</a>
<a name="122"><span class="lineNum">     122 </span>            : #endif</a>
<a name="123"><span class="lineNum">     123 </span>            : </a>
<a name="124"><span class="lineNum">     124 </span>            : /* Setup the fixmap mappings only once per-processor */</a>
<a name="125"><span class="lineNum">     125 </span><span class="lineCov">          4 : static void __init setup_cpu_entry_area(unsigned int cpu)</span></a>
<a name="126"><span class="lineNum">     126 </span>            : {</a>
<a name="127"><span class="lineNum">     127 </span><span class="lineCov">          4 :         struct cpu_entry_area *cea = get_cpu_entry_area(cpu);</span></a>
<a name="128"><span class="lineNum">     128 </span>            : #ifdef CONFIG_X86_64</a>
<a name="129"><span class="lineNum">     129 </span>            :         /* On 64-bit systems, we use a read-only fixmap GDT and TSS. */</a>
<a name="130"><span class="lineNum">     130 </span><span class="lineCov">          4 :         pgprot_t gdt_prot = PAGE_KERNEL_RO;</span></a>
<a name="131"><span class="lineNum">     131 </span><span class="lineCov">          4 :         pgprot_t tss_prot = PAGE_KERNEL_RO;</span></a>
<a name="132"><span class="lineNum">     132 </span>            : #else</a>
<a name="133"><span class="lineNum">     133 </span>            :         /*</a>
<a name="134"><span class="lineNum">     134 </span>            :          * On native 32-bit systems, the GDT cannot be read-only because</a>
<a name="135"><span class="lineNum">     135 </span>            :          * our double fault handler uses a task gate, and entering through</a>
<a name="136"><span class="lineNum">     136 </span>            :          * a task gate needs to change an available TSS to busy.  If the</a>
<a name="137"><span class="lineNum">     137 </span>            :          * GDT is read-only, that will triple fault.  The TSS cannot be</a>
<a name="138"><span class="lineNum">     138 </span>            :          * read-only because the CPU writes to it on task switches.</a>
<a name="139"><span class="lineNum">     139 </span>            :          *</a>
<a name="140"><span class="lineNum">     140 </span>            :          * On Xen PV, the GDT must be read-only because the hypervisor</a>
<a name="141"><span class="lineNum">     141 </span>            :          * requires it.</a>
<a name="142"><span class="lineNum">     142 </span>            :          */</a>
<a name="143"><span class="lineNum">     143 </span>            :         pgprot_t gdt_prot = boot_cpu_has(X86_FEATURE_XENPV) ?</a>
<a name="144"><span class="lineNum">     144 </span>            :                 PAGE_KERNEL_RO : PAGE_KERNEL;</a>
<a name="145"><span class="lineNum">     145 </span>            :         pgprot_t tss_prot = PAGE_KERNEL;</a>
<a name="146"><span class="lineNum">     146 </span>            : #endif</a>
<a name="147"><span class="lineNum">     147 </span>            : </a>
<a name="148"><span class="lineNum">     148 </span><span class="lineCov">          4 :         cea_set_pte(&amp;cea-&gt;gdt, get_cpu_gdt_paddr(cpu), gdt_prot);</span></a>
<a name="149"><span class="lineNum">     149 </span>            : </a>
<a name="150"><span class="lineNum">     150 </span><span class="lineCov">          4 :         cea_map_percpu_pages(&amp;cea-&gt;entry_stack_page,</span></a>
<a name="151"><span class="lineNum">     151 </span><span class="lineCov">          4 :                              per_cpu_ptr(&amp;entry_stack_storage, cpu), 1,</span></a>
<a name="152"><span class="lineNum">     152 </span><span class="lineCov">          4 :                              PAGE_KERNEL);</span></a>
<a name="153"><span class="lineNum">     153 </span>            : </a>
<a name="154"><span class="lineNum">     154 </span>            :         /*</a>
<a name="155"><span class="lineNum">     155 </span>            :          * The Intel SDM says (Volume 3, 7.2.1):</a>
<a name="156"><span class="lineNum">     156 </span>            :          *</a>
<a name="157"><span class="lineNum">     157 </span>            :          *  Avoid placing a page boundary in the part of the TSS that the</a>
<a name="158"><span class="lineNum">     158 </span>            :          *  processor reads during a task switch (the first 104 bytes). The</a>
<a name="159"><span class="lineNum">     159 </span>            :          *  processor may not correctly perform address translations if a</a>
<a name="160"><span class="lineNum">     160 </span>            :          *  boundary occurs in this area. During a task switch, the processor</a>
<a name="161"><span class="lineNum">     161 </span>            :          *  reads and writes into the first 104 bytes of each TSS (using</a>
<a name="162"><span class="lineNum">     162 </span>            :          *  contiguous physical addresses beginning with the physical address</a>
<a name="163"><span class="lineNum">     163 </span>            :          *  of the first byte of the TSS). So, after TSS access begins, if</a>
<a name="164"><span class="lineNum">     164 </span>            :          *  part of the 104 bytes is not physically contiguous, the processor</a>
<a name="165"><span class="lineNum">     165 </span>            :          *  will access incorrect information without generating a page-fault</a>
<a name="166"><span class="lineNum">     166 </span>            :          *  exception.</a>
<a name="167"><span class="lineNum">     167 </span>            :          *</a>
<a name="168"><span class="lineNum">     168 </span>            :          * There are also a lot of errata involving the TSS spanning a page</a>
<a name="169"><span class="lineNum">     169 </span>            :          * boundary.  Assert that we're not doing that.</a>
<a name="170"><span class="lineNum">     170 </span>            :          */</a>
<a name="171"><span class="lineNum">     171 </span><span class="lineCov">          4 :         BUILD_BUG_ON((offsetof(struct tss_struct, x86_tss) ^</span></a>
<a name="172"><span class="lineNum">     172 </span>            :                       offsetofend(struct tss_struct, x86_tss)) &amp; PAGE_MASK);</a>
<a name="173"><span class="lineNum">     173 </span><span class="lineCov">          4 :         BUILD_BUG_ON(sizeof(struct tss_struct) % PAGE_SIZE != 0);</span></a>
<a name="174"><span class="lineNum">     174 </span>            :         /*</a>
<a name="175"><span class="lineNum">     175 </span>            :          * VMX changes the host TR limit to 0x67 after a VM exit. This is</a>
<a name="176"><span class="lineNum">     176 </span>            :          * okay, since 0x67 covers the size of struct x86_hw_tss. Make sure</a>
<a name="177"><span class="lineNum">     177 </span>            :          * that this is correct.</a>
<a name="178"><span class="lineNum">     178 </span>            :          */</a>
<a name="179"><span class="lineNum">     179 </span><span class="lineCov">          4 :         BUILD_BUG_ON(offsetof(struct tss_struct, x86_tss) != 0);</span></a>
<a name="180"><span class="lineNum">     180 </span><span class="lineCov">          4 :         BUILD_BUG_ON(sizeof(struct x86_hw_tss) != 0x68);</span></a>
<a name="181"><span class="lineNum">     181 </span>            : </a>
<a name="182"><span class="lineNum">     182 </span><span class="lineCov">          4 :         cea_map_percpu_pages(&amp;cea-&gt;tss, &amp;per_cpu(cpu_tss_rw, cpu),</span></a>
<a name="183"><span class="lineNum">     183 </span>            :                              sizeof(struct tss_struct) / PAGE_SIZE, tss_prot);</a>
<a name="184"><span class="lineNum">     184 </span>            : </a>
<a name="185"><span class="lineNum">     185 </span>            : #ifdef CONFIG_X86_32</a>
<a name="186"><span class="lineNum">     186 </span>            :         per_cpu(cpu_entry_area, cpu) = cea;</a>
<a name="187"><span class="lineNum">     187 </span>            : #endif</a>
<a name="188"><span class="lineNum">     188 </span>            : </a>
<a name="189"><span class="lineNum">     189 </span><span class="lineCov">          4 :         percpu_setup_exception_stacks(cpu);</span></a>
<a name="190"><span class="lineNum">     190 </span>            : </a>
<a name="191"><span class="lineNum">     191 </span><span class="lineCov">          4 :         percpu_setup_debug_store(cpu);</span></a>
<a name="192"><span class="lineNum">     192 </span><span class="lineCov">          4 : }</span></a>
<a name="193"><span class="lineNum">     193 </span>            : </a>
<a name="194"><span class="lineNum">     194 </span><span class="lineCov">          1 : static __init void setup_cpu_entry_area_ptes(void)</span></a>
<a name="195"><span class="lineNum">     195 </span>            : {</a>
<a name="196"><span class="lineNum">     196 </span>            : #ifdef CONFIG_X86_32</a>
<a name="197"><span class="lineNum">     197 </span>            :         unsigned long start, end;</a>
<a name="198"><span class="lineNum">     198 </span>            : </a>
<a name="199"><span class="lineNum">     199 </span>            :         /* The +1 is for the readonly IDT: */</a>
<a name="200"><span class="lineNum">     200 </span>            :         BUILD_BUG_ON((CPU_ENTRY_AREA_PAGES+1)*PAGE_SIZE != CPU_ENTRY_AREA_MAP_SIZE);</a>
<a name="201"><span class="lineNum">     201 </span>            :         BUILD_BUG_ON(CPU_ENTRY_AREA_TOTAL_SIZE != CPU_ENTRY_AREA_MAP_SIZE);</a>
<a name="202"><span class="lineNum">     202 </span>            :         BUG_ON(CPU_ENTRY_AREA_BASE &amp; ~PMD_MASK);</a>
<a name="203"><span class="lineNum">     203 </span>            : </a>
<a name="204"><span class="lineNum">     204 </span>            :         start = CPU_ENTRY_AREA_BASE;</a>
<a name="205"><span class="lineNum">     205 </span>            :         end = start + CPU_ENTRY_AREA_MAP_SIZE;</a>
<a name="206"><span class="lineNum">     206 </span>            : </a>
<a name="207"><span class="lineNum">     207 </span>            :         /* Careful here: start + PMD_SIZE might wrap around */</a>
<a name="208"><span class="lineNum">     208 </span>            :         for (; start &lt; end &amp;&amp; start &gt;= CPU_ENTRY_AREA_BASE; start += PMD_SIZE)</a>
<a name="209"><span class="lineNum">     209 </span>            :                 populate_extra_pte(start);</a>
<a name="210"><span class="lineNum">     210 </span>            : #endif</a>
<a name="211"><span class="lineNum">     211 </span><span class="lineCov">          1 : }</span></a>
<a name="212"><span class="lineNum">     212 </span>            : </a>
<a name="213"><span class="lineNum">     213 </span><span class="lineCov">          1 : void __init setup_cpu_entry_areas(void)</span></a>
<a name="214"><span class="lineNum">     214 </span>            : {</a>
<a name="215"><span class="lineNum">     215 </span><span class="lineCov">          1 :         unsigned int cpu;</span></a>
<a name="216"><span class="lineNum">     216 </span>            : </a>
<a name="217"><span class="lineNum">     217 </span><span class="lineCov">          1 :         setup_cpu_entry_area_ptes();</span></a>
<a name="218"><span class="lineNum">     218 </span>            : </a>
<a name="219"><span class="lineNum">     219 </span><span class="lineCov">          5 :         for_each_possible_cpu(cpu)</span></a>
<a name="220"><span class="lineNum">     220 </span><span class="lineCov">          4 :                 setup_cpu_entry_area(cpu);</span></a>
<a name="221"><span class="lineNum">     221 </span>            : </a>
<a name="222"><span class="lineNum">     222 </span>            :         /*</a>
<a name="223"><span class="lineNum">     223 </span>            :          * This is the last essential update to swapper_pgdir which needs</a>
<a name="224"><span class="lineNum">     224 </span>            :          * to be synchronized to initial_page_table on 32bit.</a>
<a name="225"><span class="lineNum">     225 </span>            :          */</a>
<a name="226"><span class="lineNum">     226 </span><span class="lineCov">          1 :         sync_initial_page_table();</span></a>
<a name="227"><span class="lineNum">     227 </span><span class="lineCov">          1 : }</span></a>
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../../../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="http://ltp.sourceforge.net/coverage/lcov.php" target="_parent">LCOV version 1.14</a></td></tr>
  </table>
  <br>

</body>
</html>
