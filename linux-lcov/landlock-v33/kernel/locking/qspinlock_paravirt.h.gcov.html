<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - landlock.info - kernel/locking/qspinlock_paravirt.h</title>
  <link rel="stylesheet" type="text/css" href="../../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../../index.html">top level</a> - <a href="index.html">kernel/locking</a> - qspinlock_paravirt.h<span style="font-size: 80%;"> (source / <a href="qspinlock_paravirt.h.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">landlock.info</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">105</td>
            <td class="headerCovTableEntry">110</td>
            <td class="headerCovTableEntryHi">95.5 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2021-04-07 12:34:12</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">8</td>
            <td class="headerCovTableEntry">8</td>
            <td class="headerCovTableEntryHi">100.0 %</td>
          </tr>
          <tr><td><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : /* SPDX-License-Identifier: GPL-2.0 */</a>
<a name="2"><span class="lineNum">       2 </span>            : #ifndef _GEN_PV_LOCK_SLOWPATH</a>
<a name="3"><span class="lineNum">       3 </span>            : #error &quot;do not include this file&quot;</a>
<a name="4"><span class="lineNum">       4 </span>            : #endif</a>
<a name="5"><span class="lineNum">       5 </span>            : </a>
<a name="6"><span class="lineNum">       6 </span>            : #include &lt;linux/hash.h&gt;</a>
<a name="7"><span class="lineNum">       7 </span>            : #include &lt;linux/memblock.h&gt;</a>
<a name="8"><span class="lineNum">       8 </span>            : #include &lt;linux/debug_locks.h&gt;</a>
<a name="9"><span class="lineNum">       9 </span>            : </a>
<a name="10"><span class="lineNum">      10 </span>            : /*</a>
<a name="11"><span class="lineNum">      11 </span>            :  * Implement paravirt qspinlocks; the general idea is to halt the vcpus instead</a>
<a name="12"><span class="lineNum">      12 </span>            :  * of spinning them.</a>
<a name="13"><span class="lineNum">      13 </span>            :  *</a>
<a name="14"><span class="lineNum">      14 </span>            :  * This relies on the architecture to provide two paravirt hypercalls:</a>
<a name="15"><span class="lineNum">      15 </span>            :  *</a>
<a name="16"><span class="lineNum">      16 </span>            :  *   pv_wait(u8 *ptr, u8 val) -- suspends the vcpu if *ptr == val</a>
<a name="17"><span class="lineNum">      17 </span>            :  *   pv_kick(cpu)             -- wakes a suspended vcpu</a>
<a name="18"><span class="lineNum">      18 </span>            :  *</a>
<a name="19"><span class="lineNum">      19 </span>            :  * Using these we implement __pv_queued_spin_lock_slowpath() and</a>
<a name="20"><span class="lineNum">      20 </span>            :  * __pv_queued_spin_unlock() to replace native_queued_spin_lock_slowpath() and</a>
<a name="21"><span class="lineNum">      21 </span>            :  * native_queued_spin_unlock().</a>
<a name="22"><span class="lineNum">      22 </span>            :  */</a>
<a name="23"><span class="lineNum">      23 </span>            : </a>
<a name="24"><span class="lineNum">      24 </span>            : #define _Q_SLOW_VAL     (3U &lt;&lt; _Q_LOCKED_OFFSET)</a>
<a name="25"><span class="lineNum">      25 </span>            : </a>
<a name="26"><span class="lineNum">      26 </span>            : /*</a>
<a name="27"><span class="lineNum">      27 </span>            :  * Queue Node Adaptive Spinning</a>
<a name="28"><span class="lineNum">      28 </span>            :  *</a>
<a name="29"><span class="lineNum">      29 </span>            :  * A queue node vCPU will stop spinning if the vCPU in the previous node is</a>
<a name="30"><span class="lineNum">      30 </span>            :  * not running. The one lock stealing attempt allowed at slowpath entry</a>
<a name="31"><span class="lineNum">      31 </span>            :  * mitigates the slight slowdown for non-overcommitted guest with this</a>
<a name="32"><span class="lineNum">      32 </span>            :  * aggressive wait-early mechanism.</a>
<a name="33"><span class="lineNum">      33 </span>            :  *</a>
<a name="34"><span class="lineNum">      34 </span>            :  * The status of the previous node will be checked at fixed interval</a>
<a name="35"><span class="lineNum">      35 </span>            :  * controlled by PV_PREV_CHECK_MASK. This is to ensure that we won't</a>
<a name="36"><span class="lineNum">      36 </span>            :  * pound on the cacheline of the previous node too heavily.</a>
<a name="37"><span class="lineNum">      37 </span>            :  */</a>
<a name="38"><span class="lineNum">      38 </span>            : #define PV_PREV_CHECK_MASK      0xff</a>
<a name="39"><span class="lineNum">      39 </span>            : </a>
<a name="40"><span class="lineNum">      40 </span>            : /*</a>
<a name="41"><span class="lineNum">      41 </span>            :  * Queue node uses: vcpu_running &amp; vcpu_halted.</a>
<a name="42"><span class="lineNum">      42 </span>            :  * Queue head uses: vcpu_running &amp; vcpu_hashed.</a>
<a name="43"><span class="lineNum">      43 </span>            :  */</a>
<a name="44"><span class="lineNum">      44 </span>            : enum vcpu_state {</a>
<a name="45"><span class="lineNum">      45 </span>            :         vcpu_running = 0,</a>
<a name="46"><span class="lineNum">      46 </span>            :         vcpu_halted,            /* Used only in pv_wait_node */</a>
<a name="47"><span class="lineNum">      47 </span>            :         vcpu_hashed,            /* = pv_hash'ed + vcpu_halted */</a>
<a name="48"><span class="lineNum">      48 </span>            : };</a>
<a name="49"><span class="lineNum">      49 </span>            : </a>
<a name="50"><span class="lineNum">      50 </span>            : struct pv_node {</a>
<a name="51"><span class="lineNum">      51 </span>            :         struct mcs_spinlock     mcs;</a>
<a name="52"><span class="lineNum">      52 </span>            :         int                     cpu;</a>
<a name="53"><span class="lineNum">      53 </span>            :         u8                      state;</a>
<a name="54"><span class="lineNum">      54 </span>            : };</a>
<a name="55"><span class="lineNum">      55 </span>            : </a>
<a name="56"><span class="lineNum">      56 </span>            : /*</a>
<a name="57"><span class="lineNum">      57 </span>            :  * Hybrid PV queued/unfair lock</a>
<a name="58"><span class="lineNum">      58 </span>            :  *</a>
<a name="59"><span class="lineNum">      59 </span>            :  * By replacing the regular queued_spin_trylock() with the function below,</a>
<a name="60"><span class="lineNum">      60 </span>            :  * it will be called once when a lock waiter enter the PV slowpath before</a>
<a name="61"><span class="lineNum">      61 </span>            :  * being queued.</a>
<a name="62"><span class="lineNum">      62 </span>            :  *</a>
<a name="63"><span class="lineNum">      63 </span>            :  * The pending bit is set by the queue head vCPU of the MCS wait queue in</a>
<a name="64"><span class="lineNum">      64 </span>            :  * pv_wait_head_or_lock() to signal that it is ready to spin on the lock.</a>
<a name="65"><span class="lineNum">      65 </span>            :  * When that bit becomes visible to the incoming waiters, no lock stealing</a>
<a name="66"><span class="lineNum">      66 </span>            :  * is allowed. The function will return immediately to make the waiters</a>
<a name="67"><span class="lineNum">      67 </span>            :  * enter the MCS wait queue. So lock starvation shouldn't happen as long</a>
<a name="68"><span class="lineNum">      68 </span>            :  * as the queued mode vCPUs are actively running to set the pending bit</a>
<a name="69"><span class="lineNum">      69 </span>            :  * and hence disabling lock stealing.</a>
<a name="70"><span class="lineNum">      70 </span>            :  *</a>
<a name="71"><span class="lineNum">      71 </span>            :  * When the pending bit isn't set, the lock waiters will stay in the unfair</a>
<a name="72"><span class="lineNum">      72 </span>            :  * mode spinning on the lock unless the MCS wait queue is empty. In this</a>
<a name="73"><span class="lineNum">      73 </span>            :  * case, the lock waiters will enter the queued mode slowpath trying to</a>
<a name="74"><span class="lineNum">      74 </span>            :  * become the queue head and set the pending bit.</a>
<a name="75"><span class="lineNum">      75 </span>            :  *</a>
<a name="76"><span class="lineNum">      76 </span>            :  * This hybrid PV queued/unfair lock combines the best attributes of a</a>
<a name="77"><span class="lineNum">      77 </span>            :  * queued lock (no lock starvation) and an unfair lock (good performance</a>
<a name="78"><span class="lineNum">      78 </span>            :  * on not heavily contended locks).</a>
<a name="79"><span class="lineNum">      79 </span>            :  */</a>
<a name="80"><span class="lineNum">      80 </span>            : #define queued_spin_trylock(l)  pv_hybrid_queued_unfair_trylock(l)</a>
<a name="81"><span class="lineNum">      81 </span><span class="lineCov">     146144 : static inline bool pv_hybrid_queued_unfair_trylock(struct qspinlock *lock)</span></a>
<a name="82"><span class="lineNum">      82 </span>            : {</a>
<a name="83"><span class="lineNum">      83 </span>            :         /*</a>
<a name="84"><span class="lineNum">      84 </span>            :          * Stay in unfair lock mode as long as queued mode waiters are</a>
<a name="85"><span class="lineNum">      85 </span>            :          * present in the MCS wait queue but the pending bit isn't set.</a>
<a name="86"><span class="lineNum">      86 </span>            :          */</a>
<a name="87"><span class="lineNum">      87 </span><span class="lineCov">     494231 :         for (;;) {</span></a>
<a name="88"><span class="lineNum">      88 </span><span class="lineCov">     494231 :                 int val = atomic_read(&amp;lock-&gt;val);</span></a>
<a name="89"><span class="lineNum">      89 </span>            : </a>
<a name="90"><span class="lineNum">      90 </span><span class="lineCov">     493979 :                 if (!(val &amp; _Q_LOCKED_PENDING_MASK) &amp;&amp;</span></a>
<a name="91"><span class="lineNum">      91 </span><span class="lineCov">      11237 :                    (cmpxchg_acquire(&amp;lock-&gt;locked, 0, _Q_LOCKED_VAL) == 0)) {</span></a>
<a name="92"><span class="lineNum">      92 </span>            :                         lockevent_inc(pv_lock_stealing);</a>
<a name="93"><span class="lineNum">      93 </span>            :                         return true;</a>
<a name="94"><span class="lineNum">      94 </span>            :                 }</a>
<a name="95"><span class="lineNum">      95 </span><span class="lineCov">     484283 :                 if (!(val &amp; _Q_TAIL_MASK) || (val &amp; _Q_PENDING_MASK))</span></a>
<a name="96"><span class="lineNum">      96 </span>            :                         break;</a>
<a name="97"><span class="lineNum">      97 </span>            : </a>
<a name="98"><span class="lineNum">      98 </span><span class="lineCov">     347830 :                 cpu_relax();</span></a>
<a name="99"><span class="lineNum">      99 </span>            :         }</a>
<a name="100"><span class="lineNum">     100 </span>            : </a>
<a name="101"><span class="lineNum">     101 </span>            :         return false;</a>
<a name="102"><span class="lineNum">     102 </span>            : }</a>
<a name="103"><span class="lineNum">     103 </span>            : </a>
<a name="104"><span class="lineNum">     104 </span>            : /*</a>
<a name="105"><span class="lineNum">     105 </span>            :  * The pending bit is used by the queue head vCPU to indicate that it</a>
<a name="106"><span class="lineNum">     106 </span>            :  * is actively spinning on the lock and no lock stealing is allowed.</a>
<a name="107"><span class="lineNum">     107 </span>            :  */</a>
<a name="108"><span class="lineNum">     108 </span>            : #if _Q_PENDING_BITS == 8</a>
<a name="109"><span class="lineNum">     109 </span><span class="lineCov">     136583 : static __always_inline void set_pending(struct qspinlock *lock)</span></a>
<a name="110"><span class="lineNum">     110 </span>            : {</a>
<a name="111"><span class="lineNum">     111 </span><span class="lineCov">     136583 :         WRITE_ONCE(lock-&gt;pending, 1);</span></a>
<a name="112"><span class="lineNum">     112 </span>            : }</a>
<a name="113"><span class="lineNum">     113 </span>            : </a>
<a name="114"><span class="lineNum">     114 </span>            : /*</a>
<a name="115"><span class="lineNum">     115 </span>            :  * The pending bit check in pv_queued_spin_steal_lock() isn't a memory</a>
<a name="116"><span class="lineNum">     116 </span>            :  * barrier. Therefore, an atomic cmpxchg_acquire() is used to acquire the</a>
<a name="117"><span class="lineNum">     117 </span>            :  * lock just to be sure that it will get it.</a>
<a name="118"><span class="lineNum">     118 </span>            :  */</a>
<a name="119"><span class="lineNum">     119 </span><span class="lineCov">    9099650 : static __always_inline int trylock_clear_pending(struct qspinlock *lock)</span></a>
<a name="120"><span class="lineNum">     120 </span>            : {</a>
<a name="121"><span class="lineNum">     121 </span><span class="lineCov">    9236196 :         return !READ_ONCE(lock-&gt;locked) &amp;&amp;</span></a>
<a name="122"><span class="lineNum">     122 </span><span class="lineCov">     136546 :                (cmpxchg_acquire(&amp;lock-&gt;locked_pending, _Q_PENDING_VAL,</span></a>
<a name="123"><span class="lineNum">     123 </span>            :                                 _Q_LOCKED_VAL) == _Q_PENDING_VAL);</a>
<a name="124"><span class="lineNum">     124 </span>            : }</a>
<a name="125"><span class="lineNum">     125 </span>            : #else /* _Q_PENDING_BITS == 8 */</a>
<a name="126"><span class="lineNum">     126 </span>            : static __always_inline void set_pending(struct qspinlock *lock)</a>
<a name="127"><span class="lineNum">     127 </span>            : {</a>
<a name="128"><span class="lineNum">     128 </span>            :         atomic_or(_Q_PENDING_VAL, &amp;lock-&gt;val);</a>
<a name="129"><span class="lineNum">     129 </span>            : }</a>
<a name="130"><span class="lineNum">     130 </span>            : </a>
<a name="131"><span class="lineNum">     131 </span>            : static __always_inline int trylock_clear_pending(struct qspinlock *lock)</a>
<a name="132"><span class="lineNum">     132 </span>            : {</a>
<a name="133"><span class="lineNum">     133 </span>            :         int val = atomic_read(&amp;lock-&gt;val);</a>
<a name="134"><span class="lineNum">     134 </span>            : </a>
<a name="135"><span class="lineNum">     135 </span>            :         for (;;) {</a>
<a name="136"><span class="lineNum">     136 </span>            :                 int old, new;</a>
<a name="137"><span class="lineNum">     137 </span>            : </a>
<a name="138"><span class="lineNum">     138 </span>            :                 if (val  &amp; _Q_LOCKED_MASK)</a>
<a name="139"><span class="lineNum">     139 </span>            :                         break;</a>
<a name="140"><span class="lineNum">     140 </span>            : </a>
<a name="141"><span class="lineNum">     141 </span>            :                 /*</a>
<a name="142"><span class="lineNum">     142 </span>            :                  * Try to clear pending bit &amp; set locked bit</a>
<a name="143"><span class="lineNum">     143 </span>            :                  */</a>
<a name="144"><span class="lineNum">     144 </span>            :                 old = val;</a>
<a name="145"><span class="lineNum">     145 </span>            :                 new = (val &amp; ~_Q_PENDING_MASK) | _Q_LOCKED_VAL;</a>
<a name="146"><span class="lineNum">     146 </span>            :                 val = atomic_cmpxchg_acquire(&amp;lock-&gt;val, old, new);</a>
<a name="147"><span class="lineNum">     147 </span>            : </a>
<a name="148"><span class="lineNum">     148 </span>            :                 if (val == old)</a>
<a name="149"><span class="lineNum">     149 </span>            :                         return 1;</a>
<a name="150"><span class="lineNum">     150 </span>            :         }</a>
<a name="151"><span class="lineNum">     151 </span>            :         return 0;</a>
<a name="152"><span class="lineNum">     152 </span>            : }</a>
<a name="153"><span class="lineNum">     153 </span>            : #endif /* _Q_PENDING_BITS == 8 */</a>
<a name="154"><span class="lineNum">     154 </span>            : </a>
<a name="155"><span class="lineNum">     155 </span>            : /*</a>
<a name="156"><span class="lineNum">     156 </span>            :  * Lock and MCS node addresses hash table for fast lookup</a>
<a name="157"><span class="lineNum">     157 </span>            :  *</a>
<a name="158"><span class="lineNum">     158 </span>            :  * Hashing is done on a per-cacheline basis to minimize the need to access</a>
<a name="159"><span class="lineNum">     159 </span>            :  * more than one cacheline.</a>
<a name="160"><span class="lineNum">     160 </span>            :  *</a>
<a name="161"><span class="lineNum">     161 </span>            :  * Dynamically allocate a hash table big enough to hold at least 4X the</a>
<a name="162"><span class="lineNum">     162 </span>            :  * number of possible cpus in the system. Allocation is done on page</a>
<a name="163"><span class="lineNum">     163 </span>            :  * granularity. So the minimum number of hash buckets should be at least</a>
<a name="164"><span class="lineNum">     164 </span>            :  * 256 (64-bit) or 512 (32-bit) to fully utilize a 4k page.</a>
<a name="165"><span class="lineNum">     165 </span>            :  *</a>
<a name="166"><span class="lineNum">     166 </span>            :  * Since we should not be holding locks from NMI context (very rare indeed) the</a>
<a name="167"><span class="lineNum">     167 </span>            :  * max load factor is 0.75, which is around the point where open addressing</a>
<a name="168"><span class="lineNum">     168 </span>            :  * breaks down.</a>
<a name="169"><span class="lineNum">     169 </span>            :  *</a>
<a name="170"><span class="lineNum">     170 </span>            :  */</a>
<a name="171"><span class="lineNum">     171 </span>            : struct pv_hash_entry {</a>
<a name="172"><span class="lineNum">     172 </span>            :         struct qspinlock *lock;</a>
<a name="173"><span class="lineNum">     173 </span>            :         struct pv_node   *node;</a>
<a name="174"><span class="lineNum">     174 </span>            : };</a>
<a name="175"><span class="lineNum">     175 </span>            : </a>
<a name="176"><span class="lineNum">     176 </span>            : #define PV_HE_PER_LINE  (SMP_CACHE_BYTES / sizeof(struct pv_hash_entry))</a>
<a name="177"><span class="lineNum">     177 </span>            : #define PV_HE_MIN       (PAGE_SIZE / sizeof(struct pv_hash_entry))</a>
<a name="178"><span class="lineNum">     178 </span>            : </a>
<a name="179"><span class="lineNum">     179 </span>            : static struct pv_hash_entry *pv_lock_hash;</a>
<a name="180"><span class="lineNum">     180 </span>            : static unsigned int pv_lock_hash_bits __read_mostly;</a>
<a name="181"><span class="lineNum">     181 </span>            : </a>
<a name="182"><span class="lineNum">     182 </span>            : /*</a>
<a name="183"><span class="lineNum">     183 </span>            :  * Allocate memory for the PV qspinlock hash buckets</a>
<a name="184"><span class="lineNum">     184 </span>            :  *</a>
<a name="185"><span class="lineNum">     185 </span>            :  * This function should be called from the paravirt spinlock initialization</a>
<a name="186"><span class="lineNum">     186 </span>            :  * routine.</a>
<a name="187"><span class="lineNum">     187 </span>            :  */</a>
<a name="188"><span class="lineNum">     188 </span><span class="lineCov">          1 : void __init __pv_init_lock_hash(void)</span></a>
<a name="189"><span class="lineNum">     189 </span>            : {</a>
<a name="190"><span class="lineNum">     190 </span><span class="lineCov">          1 :         int pv_hash_size = ALIGN(4 * num_possible_cpus(), PV_HE_PER_LINE);</span></a>
<a name="191"><span class="lineNum">     191 </span>            : </a>
<a name="192"><span class="lineNum">     192 </span><span class="lineCov">          1 :         if (pv_hash_size &lt; PV_HE_MIN)</span></a>
<a name="193"><span class="lineNum">     193 </span><span class="lineCov">          1 :                 pv_hash_size = PV_HE_MIN;</span></a>
<a name="194"><span class="lineNum">     194 </span>            : </a>
<a name="195"><span class="lineNum">     195 </span>            :         /*</a>
<a name="196"><span class="lineNum">     196 </span>            :          * Allocate space from bootmem which should be page-size aligned</a>
<a name="197"><span class="lineNum">     197 </span>            :          * and hence cacheline aligned.</a>
<a name="198"><span class="lineNum">     198 </span>            :          */</a>
<a name="199"><span class="lineNum">     199 </span><span class="lineCov">          1 :         pv_lock_hash = alloc_large_system_hash(&quot;PV qspinlock&quot;,</span></a>
<a name="200"><span class="lineNum">     200 </span>            :                                                sizeof(struct pv_hash_entry),</a>
<a name="201"><span class="lineNum">     201 </span>            :                                                pv_hash_size, 0,</a>
<a name="202"><span class="lineNum">     202 </span>            :                                                HASH_EARLY | HASH_ZERO,</a>
<a name="203"><span class="lineNum">     203 </span>            :                                                &amp;pv_lock_hash_bits, NULL,</a>
<a name="204"><span class="lineNum">     204 </span>            :                                                pv_hash_size, pv_hash_size);</a>
<a name="205"><span class="lineNum">     205 </span><span class="lineCov">          1 : }</span></a>
<a name="206"><span class="lineNum">     206 </span>            : </a>
<a name="207"><span class="lineNum">     207 </span>            : #define for_each_hash_entry(he, offset, hash)                                           \</a>
<a name="208"><span class="lineNum">     208 </span>            :         for (hash &amp;= ~(PV_HE_PER_LINE - 1), he = &amp;pv_lock_hash[hash], offset = 0;       \</a>
<a name="209"><span class="lineNum">     209 </span>            :              offset &lt; (1 &lt;&lt; pv_lock_hash_bits);                                                \</a>
<a name="210"><span class="lineNum">     210 </span>            :              offset++, he = &amp;pv_lock_hash[(hash + offset) &amp; ((1 &lt;&lt; pv_lock_hash_bits) - 1)])</a>
<a name="211"><span class="lineNum">     211 </span>            : </a>
<a name="212"><span class="lineNum">     212 </span><span class="lineCov">        102 : static struct qspinlock **pv_hash(struct qspinlock *lock, struct pv_node *node)</span></a>
<a name="213"><span class="lineNum">     213 </span>            : {</a>
<a name="214"><span class="lineNum">     214 </span><span class="lineCov">        102 :         unsigned long offset, hash = hash_ptr(lock, pv_lock_hash_bits);</span></a>
<a name="215"><span class="lineNum">     215 </span><span class="lineCov">        102 :         struct pv_hash_entry *he;</span></a>
<a name="216"><span class="lineNum">     216 </span><span class="lineCov">        102 :         int hopcnt = 0;</span></a>
<a name="217"><span class="lineNum">     217 </span>            : </a>
<a name="218"><span class="lineNum">     218 </span><span class="lineCov">        102 :         for_each_hash_entry(he, offset, hash) {</span></a>
<a name="219"><span class="lineNum">     219 </span><span class="lineCov">        102 :                 hopcnt++;</span></a>
<a name="220"><span class="lineNum">     220 </span><span class="lineCov">        102 :                 if (!cmpxchg(&amp;he-&gt;lock, NULL, lock)) {</span></a>
<a name="221"><span class="lineNum">     221 </span><span class="lineCov">        102 :                         WRITE_ONCE(he-&gt;node, node);</span></a>
<a name="222"><span class="lineNum">     222 </span><span class="lineCov">        102 :                         lockevent_pv_hop(hopcnt);</span></a>
<a name="223"><span class="lineNum">     223 </span><span class="lineCov">        102 :                         return &amp;he-&gt;lock;</span></a>
<a name="224"><span class="lineNum">     224 </span>            :                 }</a>
<a name="225"><span class="lineNum">     225 </span>            :         }</a>
<a name="226"><span class="lineNum">     226 </span>            :         /*</a>
<a name="227"><span class="lineNum">     227 </span>            :          * Hard assume there is a free entry for us.</a>
<a name="228"><span class="lineNum">     228 </span>            :          *</a>
<a name="229"><span class="lineNum">     229 </span>            :          * This is guaranteed by ensuring every blocked lock only ever consumes</a>
<a name="230"><span class="lineNum">     230 </span>            :          * a single entry, and since we only have 4 nesting levels per CPU</a>
<a name="231"><span class="lineNum">     231 </span>            :          * and allocated 4*nr_possible_cpus(), this must be so.</a>
<a name="232"><span class="lineNum">     232 </span>            :          *</a>
<a name="233"><span class="lineNum">     233 </span>            :          * The single entry is guaranteed by having the lock owner unhash</a>
<a name="234"><span class="lineNum">     234 </span>            :          * before it releases.</a>
<a name="235"><span class="lineNum">     235 </span>            :          */</a>
<a name="236"><span class="lineNum">     236 </span><span class="lineCov">        102 :         BUG();</span></a>
<a name="237"><span class="lineNum">     237 </span>            : }</a>
<a name="238"><span class="lineNum">     238 </span>            : </a>
<a name="239"><span class="lineNum">     239 </span><span class="lineCov">        102 : static struct pv_node *pv_unhash(struct qspinlock *lock)</span></a>
<a name="240"><span class="lineNum">     240 </span>            : {</a>
<a name="241"><span class="lineNum">     241 </span><span class="lineCov">        102 :         unsigned long offset, hash = hash_ptr(lock, pv_lock_hash_bits);</span></a>
<a name="242"><span class="lineNum">     242 </span><span class="lineCov">        102 :         struct pv_hash_entry *he;</span></a>
<a name="243"><span class="lineNum">     243 </span><span class="lineCov">        102 :         struct pv_node *node;</span></a>
<a name="244"><span class="lineNum">     244 </span>            : </a>
<a name="245"><span class="lineNum">     245 </span><span class="lineCov">        102 :         for_each_hash_entry(he, offset, hash) {</span></a>
<a name="246"><span class="lineNum">     246 </span><span class="lineCov">        102 :                 if (READ_ONCE(he-&gt;lock) == lock) {</span></a>
<a name="247"><span class="lineNum">     247 </span><span class="lineCov">        102 :                         node = READ_ONCE(he-&gt;node);</span></a>
<a name="248"><span class="lineNum">     248 </span><span class="lineCov">        102 :                         WRITE_ONCE(he-&gt;lock, NULL);</span></a>
<a name="249"><span class="lineNum">     249 </span><span class="lineCov">        102 :                         return node;</span></a>
<a name="250"><span class="lineNum">     250 </span>            :                 }</a>
<a name="251"><span class="lineNum">     251 </span>            :         }</a>
<a name="252"><span class="lineNum">     252 </span>            :         /*</a>
<a name="253"><span class="lineNum">     253 </span>            :          * Hard assume we'll find an entry.</a>
<a name="254"><span class="lineNum">     254 </span>            :          *</a>
<a name="255"><span class="lineNum">     255 </span>            :          * This guarantees a limited lookup time and is itself guaranteed by</a>
<a name="256"><span class="lineNum">     256 </span>            :          * having the lock owner do the unhash -- IFF the unlock sees the</a>
<a name="257"><span class="lineNum">     257 </span>            :          * SLOW flag, there MUST be a hash entry.</a>
<a name="258"><span class="lineNum">     258 </span>            :          */</a>
<a name="259"><span class="lineNum">     259 </span><span class="lineCov">        102 :         BUG();</span></a>
<a name="260"><span class="lineNum">     260 </span>            : }</a>
<a name="261"><span class="lineNum">     261 </span>            : </a>
<a name="262"><span class="lineNum">     262 </span>            : /*</a>
<a name="263"><span class="lineNum">     263 </span>            :  * Return true if when it is time to check the previous node which is not</a>
<a name="264"><span class="lineNum">     264 </span>            :  * in a running state.</a>
<a name="265"><span class="lineNum">     265 </span>            :  */</a>
<a name="266"><span class="lineNum">     266 </span>            : static inline bool</a>
<a name="267"><span class="lineNum">     267 </span><span class="lineCov">    1793144 : pv_wait_early(struct pv_node *prev, int loop)</span></a>
<a name="268"><span class="lineNum">     268 </span>            : {</a>
<a name="269"><span class="lineNum">     269 </span><span class="lineCov">    1793144 :         if ((loop &amp; PV_PREV_CHECK_MASK) != 0)</span></a>
<a name="270"><span class="lineNum">     270 </span>            :                 return false;</a>
<a name="271"><span class="lineNum">     271 </span>            : </a>
<a name="272"><span class="lineNum">     272 </span><span class="lineCov">      16289 :         return READ_ONCE(prev-&gt;state) != vcpu_running;</span></a>
<a name="273"><span class="lineNum">     273 </span>            : }</a>
<a name="274"><span class="lineNum">     274 </span>            : </a>
<a name="275"><span class="lineNum">     275 </span>            : /*</a>
<a name="276"><span class="lineNum">     276 </span>            :  * Initialize the PV part of the mcs_spinlock node.</a>
<a name="277"><span class="lineNum">     277 </span>            :  */</a>
<a name="278"><span class="lineNum">     278 </span><span class="lineCov">     146147 : static void pv_init_node(struct mcs_spinlock *node)</span></a>
<a name="279"><span class="lineNum">     279 </span>            : {</a>
<a name="280"><span class="lineNum">     280 </span><span class="lineCov">     146147 :         struct pv_node *pn = (struct pv_node *)node;</span></a>
<a name="281"><span class="lineNum">     281 </span>            : </a>
<a name="282"><span class="lineNum">     282 </span><span class="lineCov">     146147 :         BUILD_BUG_ON(sizeof(struct pv_node) &gt; sizeof(struct qnode));</span></a>
<a name="283"><span class="lineNum">     283 </span>            : </a>
<a name="284"><span class="lineNum">     284 </span><span class="lineCov">     146147 :         pn-&gt;cpu = smp_processor_id();</span></a>
<a name="285"><span class="lineNum">     285 </span><span class="lineCov">     146147 :         pn-&gt;state = vcpu_running;</span></a>
<a name="286"><span class="lineNum">     286 </span>            : }</a>
<a name="287"><span class="lineNum">     287 </span>            : </a>
<a name="288"><span class="lineNum">     288 </span>            : /*</a>
<a name="289"><span class="lineNum">     289 </span>            :  * Wait for node-&gt;locked to become true, halt the vcpu after a short spin.</a>
<a name="290"><span class="lineNum">     290 </span>            :  * pv_kick_node() is used to set _Q_SLOW_VAL and fill in hash table on its</a>
<a name="291"><span class="lineNum">     291 </span>            :  * behalf.</a>
<a name="292"><span class="lineNum">     292 </span>            :  */</a>
<a name="293"><span class="lineNum">     293 </span><span class="lineCov">       6612 : static void pv_wait_node(struct mcs_spinlock *node, struct mcs_spinlock *prev)</span></a>
<a name="294"><span class="lineNum">     294 </span>            : {</a>
<a name="295"><span class="lineNum">     295 </span><span class="lineCov">       6612 :         struct pv_node *pn = (struct pv_node *)node;</span></a>
<a name="296"><span class="lineNum">     296 </span><span class="lineCov">       6612 :         struct pv_node *pp = (struct pv_node *)prev;</span></a>
<a name="297"><span class="lineNum">     297 </span><span class="lineCov">       6648 :         int loop;</span></a>
<a name="298"><span class="lineNum">     298 </span><span class="lineCov">       6648 :         bool wait_early;</span></a>
<a name="299"><span class="lineNum">     299 </span>            : </a>
<a name="300"><span class="lineNum">     300 </span><span class="lineCov">       6684 :         for (;;) {</span></a>
<a name="301"><span class="lineNum">     301 </span><span class="lineCov">    1799776 :                 for (wait_early = false, loop = SPIN_THRESHOLD; loop; loop--) {</span></a>
<a name="302"><span class="lineNum">     302 </span><span class="lineCov">    1799757 :                         if (READ_ONCE(node-&gt;locked))</span></a>
<a name="303"><span class="lineNum">     303 </span><span class="lineCov">       6613 :                                 return;</span></a>
<a name="304"><span class="lineNum">     304 </span><span class="lineCov">    1793144 :                         if (pv_wait_early(pp, loop)) {</span></a>
<a name="305"><span class="lineNum">     305 </span><span class="lineCov">         36 :                                 wait_early = true;</span></a>
<a name="306"><span class="lineNum">     306 </span>            :                                 break;</a>
<a name="307"><span class="lineNum">     307 </span>            :                         }</a>
<a name="308"><span class="lineNum">     308 </span><span class="lineCov">    1793127 :                         cpu_relax();</span></a>
<a name="309"><span class="lineNum">     309 </span>            :                 }</a>
<a name="310"><span class="lineNum">     310 </span>            : </a>
<a name="311"><span class="lineNum">     311 </span>            :                 /*</a>
<a name="312"><span class="lineNum">     312 </span>            :                  * Order pn-&gt;state vs pn-&gt;locked thusly:</a>
<a name="313"><span class="lineNum">     313 </span>            :                  *</a>
<a name="314"><span class="lineNum">     314 </span>            :                  * [S] pn-&gt;state = vcpu_halted         [S] next-&gt;locked = 1</a>
<a name="315"><span class="lineNum">     315 </span>            :                  *     MB                             MB</a>
<a name="316"><span class="lineNum">     316 </span>            :                  * [L] pn-&gt;locked            [RmW] pn-&gt;state = vcpu_hashed</a>
<a name="317"><span class="lineNum">     317 </span>            :                  *</a>
<a name="318"><span class="lineNum">     318 </span>            :                  * Matches the cmpxchg() from pv_kick_node().</a>
<a name="319"><span class="lineNum">     319 </span>            :                  */</a>
<a name="320"><span class="lineNum">     320 </span><span class="lineCov">         36 :                 smp_store_mb(pn-&gt;state, vcpu_halted);</span></a>
<a name="321"><span class="lineNum">     321 </span>            : </a>
<a name="322"><span class="lineNum">     322 </span><span class="lineCov">         36 :                 if (!READ_ONCE(node-&gt;locked)) {</span></a>
<a name="323"><span class="lineNum">     323 </span><span class="lineCov">         35 :                         lockevent_inc(pv_wait_node);</span></a>
<a name="324"><span class="lineNum">     324 </span><span class="lineCov">         35 :                         lockevent_cond_inc(pv_wait_early, wait_early);</span></a>
<a name="325"><span class="lineNum">     325 </span><span class="lineCov">         35 :                         pv_wait(&amp;pn-&gt;state, vcpu_halted);</span></a>
<a name="326"><span class="lineNum">     326 </span>            :                 }</a>
<a name="327"><span class="lineNum">     327 </span>            : </a>
<a name="328"><span class="lineNum">     328 </span>            :                 /*</a>
<a name="329"><span class="lineNum">     329 </span>            :                  * If pv_kick_node() changed us to vcpu_hashed, retain that</a>
<a name="330"><span class="lineNum">     330 </span>            :                  * value so that pv_wait_head_or_lock() knows to not also try</a>
<a name="331"><span class="lineNum">     331 </span>            :                  * to hash this lock.</a>
<a name="332"><span class="lineNum">     332 </span>            :                  */</a>
<a name="333"><span class="lineNum">     333 </span><span class="lineCov">         36 :                 cmpxchg(&amp;pn-&gt;state, vcpu_halted, vcpu_running);</span></a>
<a name="334"><span class="lineNum">     334 </span>            : </a>
<a name="335"><span class="lineNum">     335 </span>            :                 /*</a>
<a name="336"><span class="lineNum">     336 </span>            :                  * If the locked flag is still not set after wakeup, it is a</a>
<a name="337"><span class="lineNum">     337 </span>            :                  * spurious wakeup and the vCPU should wait again. However,</a>
<a name="338"><span class="lineNum">     338 </span>            :                  * there is a pretty high overhead for CPU halting and kicking.</a>
<a name="339"><span class="lineNum">     339 </span>            :                  * So it is better to spin for a while in the hope that the</a>
<a name="340"><span class="lineNum">     340 </span>            :                  * MCS lock will be released soon.</a>
<a name="341"><span class="lineNum">     341 </span>            :                  */</a>
<a name="342"><span class="lineNum">     342 </span>            :                 lockevent_cond_inc(pv_spurious_wakeup,</a>
<a name="343"><span class="lineNum">     343 </span><span class="lineCov">         36 :                                   !READ_ONCE(node-&gt;locked));</span></a>
<a name="344"><span class="lineNum">     344 </span>            :         }</a>
<a name="345"><span class="lineNum">     345 </span>            : </a>
<a name="346"><span class="lineNum">     346 </span>            :         /*</a>
<a name="347"><span class="lineNum">     347 </span>            :          * By now our node-&gt;locked should be 1 and our caller will not actually</a>
<a name="348"><span class="lineNum">     348 </span>            :          * spin-wait for it. We do however rely on our caller to do a</a>
<a name="349"><span class="lineNum">     349 </span>            :          * load-acquire for us.</a>
<a name="350"><span class="lineNum">     350 </span>            :          */</a>
<a name="351"><span class="lineNum">     351 </span>            : }</a>
<a name="352"><span class="lineNum">     352 </span>            : </a>
<a name="353"><span class="lineNum">     353 </span>            : /*</a>
<a name="354"><span class="lineNum">     354 </span>            :  * Called after setting next-&gt;locked = 1 when we're the lock owner.</a>
<a name="355"><span class="lineNum">     355 </span>            :  *</a>
<a name="356"><span class="lineNum">     356 </span>            :  * Instead of waking the waiters stuck in pv_wait_node() advance their state</a>
<a name="357"><span class="lineNum">     357 </span>            :  * such that they're waiting in pv_wait_head_or_lock(), this avoids a</a>
<a name="358"><span class="lineNum">     358 </span>            :  * wake/sleep cycle.</a>
<a name="359"><span class="lineNum">     359 </span>            :  */</a>
<a name="360"><span class="lineNum">     360 </span><span class="lineCov">       6613 : static void pv_kick_node(struct qspinlock *lock, struct mcs_spinlock *node)</span></a>
<a name="361"><span class="lineNum">     361 </span>            : {</a>
<a name="362"><span class="lineNum">     362 </span><span class="lineCov">       6613 :         struct pv_node *pn = (struct pv_node *)node;</span></a>
<a name="363"><span class="lineNum">     363 </span>            : </a>
<a name="364"><span class="lineNum">     364 </span>            :         /*</a>
<a name="365"><span class="lineNum">     365 </span>            :          * If the vCPU is indeed halted, advance its state to match that of</a>
<a name="366"><span class="lineNum">     366 </span>            :          * pv_wait_node(). If OTOH this fails, the vCPU was running and will</a>
<a name="367"><span class="lineNum">     367 </span>            :          * observe its next-&gt;locked value and advance itself.</a>
<a name="368"><span class="lineNum">     368 </span>            :          *</a>
<a name="369"><span class="lineNum">     369 </span>            :          * Matches with smp_store_mb() and cmpxchg() in pv_wait_node()</a>
<a name="370"><span class="lineNum">     370 </span>            :          *</a>
<a name="371"><span class="lineNum">     371 </span>            :          * The write to next-&gt;locked in arch_mcs_spin_unlock_contended()</a>
<a name="372"><span class="lineNum">     372 </span>            :          * must be ordered before the read of pn-&gt;state in the cmpxchg()</a>
<a name="373"><span class="lineNum">     373 </span>            :          * below for the code to work correctly. To guarantee full ordering</a>
<a name="374"><span class="lineNum">     374 </span>            :          * irrespective of the success or failure of the cmpxchg(),</a>
<a name="375"><span class="lineNum">     375 </span>            :          * a relaxed version with explicit barrier is used. The control</a>
<a name="376"><span class="lineNum">     376 </span>            :          * dependency will order the reading of pn-&gt;state before any</a>
<a name="377"><span class="lineNum">     377 </span>            :          * subsequent writes.</a>
<a name="378"><span class="lineNum">     378 </span>            :          */</a>
<a name="379"><span class="lineNum">     379 </span><span class="lineCov">       6613 :         smp_mb__before_atomic();</span></a>
<a name="380"><span class="lineNum">     380 </span><span class="lineCov">       6613 :         if (cmpxchg_relaxed(&amp;pn-&gt;state, vcpu_halted, vcpu_hashed)</span></a>
<a name="381"><span class="lineNum">     381 </span>            :             != vcpu_halted)</a>
<a name="382"><span class="lineNum">     382 </span>            :                 return;</a>
<a name="383"><span class="lineNum">     383 </span>            : </a>
<a name="384"><span class="lineNum">     384 </span>            :         /*</a>
<a name="385"><span class="lineNum">     385 </span>            :          * Put the lock into the hash table and set the _Q_SLOW_VAL.</a>
<a name="386"><span class="lineNum">     386 </span>            :          *</a>
<a name="387"><span class="lineNum">     387 </span>            :          * As this is the same vCPU that will check the _Q_SLOW_VAL value and</a>
<a name="388"><span class="lineNum">     388 </span>            :          * the hash table later on at unlock time, no atomic instruction is</a>
<a name="389"><span class="lineNum">     389 </span>            :          * needed.</a>
<a name="390"><span class="lineNum">     390 </span>            :          */</a>
<a name="391"><span class="lineNum">     391 </span><span class="lineCov">         36 :         WRITE_ONCE(lock-&gt;locked, _Q_SLOW_VAL);</span></a>
<a name="392"><span class="lineNum">     392 </span><span class="lineCov">         36 :         (void)pv_hash(lock, pn);</span></a>
<a name="393"><span class="lineNum">     393 </span>            : }</a>
<a name="394"><span class="lineNum">     394 </span>            : </a>
<a name="395"><span class="lineNum">     395 </span>            : /*</a>
<a name="396"><span class="lineNum">     396 </span>            :  * Wait for l-&gt;locked to become clear and acquire the lock;</a>
<a name="397"><span class="lineNum">     397 </span>            :  * halt the vcpu after a short spin.</a>
<a name="398"><span class="lineNum">     398 </span>            :  * __pv_queued_spin_unlock() will wake us.</a>
<a name="399"><span class="lineNum">     399 </span>            :  *</a>
<a name="400"><span class="lineNum">     400 </span>            :  * The current value of the lock will be returned for additional processing.</a>
<a name="401"><span class="lineNum">     401 </span>            :  */</a>
<a name="402"><span class="lineNum">     402 </span>            : static u32</a>
<a name="403"><span class="lineNum">     403 </span><span class="lineCov">     136514 : pv_wait_head_or_lock(struct qspinlock *lock, struct mcs_spinlock *node)</span></a>
<a name="404"><span class="lineNum">     404 </span>            : {</a>
<a name="405"><span class="lineNum">     405 </span><span class="lineCov">     136514 :         struct pv_node *pn = (struct pv_node *)node;</span></a>
<a name="406"><span class="lineNum">     406 </span><span class="lineCov">     136514 :         struct qspinlock **lp = NULL;</span></a>
<a name="407"><span class="lineNum">     407 </span><span class="lineCov">     136514 :         int waitcnt = 0;</span></a>
<a name="408"><span class="lineNum">     408 </span><span class="lineCov">     136514 :         int loop;</span></a>
<a name="409"><span class="lineNum">     409 </span>            : </a>
<a name="410"><span class="lineNum">     410 </span>            :         /*</a>
<a name="411"><span class="lineNum">     411 </span>            :          * If pv_kick_node() already advanced our state, we don't need to</a>
<a name="412"><span class="lineNum">     412 </span>            :          * insert ourselves into the hash table anymore.</a>
<a name="413"><span class="lineNum">     413 </span>            :          */</a>
<a name="414"><span class="lineNum">     414 </span><span class="lineCov">     136514 :         if (READ_ONCE(pn-&gt;state) == vcpu_hashed)</span></a>
<a name="415"><span class="lineNum">     415 </span><span class="lineCov">         36 :                 lp = (struct qspinlock **)1;</span></a>
<a name="416"><span class="lineNum">     416 </span>            : </a>
<a name="417"><span class="lineNum">     417 </span>            :         /*</a>
<a name="418"><span class="lineNum">     418 </span>            :          * Tracking # of slowpath locking operations</a>
<a name="419"><span class="lineNum">     419 </span>            :          */</a>
<a name="420"><span class="lineNum">     420 </span><span class="lineCov">     136583 :         lockevent_inc(lock_slowpath);</span></a>
<a name="421"><span class="lineNum">     421 </span>            : </a>
<a name="422"><span class="lineNum">     422 </span><span class="lineCov">         69 :         for (;; waitcnt++) {</span></a>
<a name="423"><span class="lineNum">     423 </span>            :                 /*</a>
<a name="424"><span class="lineNum">     424 </span>            :                  * Set correct vCPU state to be used by queue node wait-early</a>
<a name="425"><span class="lineNum">     425 </span>            :                  * mechanism.</a>
<a name="426"><span class="lineNum">     426 </span>            :                  */</a>
<a name="427"><span class="lineNum">     427 </span><span class="lineCov">         69 :                 WRITE_ONCE(pn-&gt;state, vcpu_running);</span></a>
<a name="428"><span class="lineNum">     428 </span>            : </a>
<a name="429"><span class="lineNum">     429 </span>            :                 /*</a>
<a name="430"><span class="lineNum">     430 </span>            :                  * Set the pending bit in the active lock spinning loop to</a>
<a name="431"><span class="lineNum">     431 </span>            :                  * disable lock stealing before attempting to acquire the lock.</a>
<a name="432"><span class="lineNum">     432 </span>            :                  */</a>
<a name="433"><span class="lineNum">     433 </span><span class="lineCov">     136583 :                 set_pending(lock);</span></a>
<a name="434"><span class="lineNum">     434 </span><span class="lineCov">    9099719 :                 for (loop = SPIN_THRESHOLD; loop; loop--) {</span></a>
<a name="435"><span class="lineNum">     435 </span><span class="lineCov">    9099650 :                         if (trylock_clear_pending(lock))</span></a>
<a name="436"><span class="lineNum">     436 </span><span class="lineCov">     136514 :                                 goto gotlock;</span></a>
<a name="437"><span class="lineNum">     437 </span><span class="lineCov">    8963136 :                         cpu_relax();</span></a>
<a name="438"><span class="lineNum">     438 </span>            :                 }</a>
<a name="439"><span class="lineNum">     439 </span><span class="lineCov">         69 :                 clear_pending(lock);</span></a>
<a name="440"><span class="lineNum">     440 </span>            : </a>
<a name="441"><span class="lineNum">     441 </span>            : </a>
<a name="442"><span class="lineNum">     442 </span><span class="lineCov">         69 :                 if (!lp) { /* ONCE */</span></a>
<a name="443"><span class="lineNum">     443 </span><span class="lineCov">         66 :                         lp = pv_hash(lock, pn);</span></a>
<a name="444"><span class="lineNum">     444 </span>            : </a>
<a name="445"><span class="lineNum">     445 </span>            :                         /*</a>
<a name="446"><span class="lineNum">     446 </span>            :                          * We must hash before setting _Q_SLOW_VAL, such that</a>
<a name="447"><span class="lineNum">     447 </span>            :                          * when we observe _Q_SLOW_VAL in __pv_queued_spin_unlock()</a>
<a name="448"><span class="lineNum">     448 </span>            :                          * we'll be sure to be able to observe our hash entry.</a>
<a name="449"><span class="lineNum">     449 </span>            :                          *</a>
<a name="450"><span class="lineNum">     450 </span>            :                          *   [S] &lt;hash&gt;                 [Rmw] l-&gt;locked == _Q_SLOW_VAL</a>
<a name="451"><span class="lineNum">     451 </span>            :                          *       MB                           RMB</a>
<a name="452"><span class="lineNum">     452 </span>            :                          * [RmW] l-&gt;locked = _Q_SLOW_VAL  [L] &lt;unhash&gt;</a>
<a name="453"><span class="lineNum">     453 </span>            :                          *</a>
<a name="454"><span class="lineNum">     454 </span>            :                          * Matches the smp_rmb() in __pv_queued_spin_unlock().</a>
<a name="455"><span class="lineNum">     455 </span>            :                          */</a>
<a name="456"><span class="lineNum">     456 </span><span class="lineCov">         66 :                         if (xchg(&amp;lock-&gt;locked, _Q_SLOW_VAL) == 0) {</span></a>
<a name="457"><span class="lineNum">     457 </span>            :                                 /*</a>
<a name="458"><span class="lineNum">     458 </span>            :                                  * The lock was free and now we own the lock.</a>
<a name="459"><span class="lineNum">     459 </span>            :                                  * Change the lock value back to _Q_LOCKED_VAL</a>
<a name="460"><span class="lineNum">     460 </span>            :                                  * and unhash the table.</a>
<a name="461"><span class="lineNum">     461 </span>            :                                  */</a>
<a name="462"><span class="lineNum">     462 </span><span class="lineNoCov">          0 :                                 WRITE_ONCE(lock-&gt;locked, _Q_LOCKED_VAL);</span></a>
<a name="463"><span class="lineNum">     463 </span><span class="lineNoCov">          0 :                                 WRITE_ONCE(*lp, NULL);</span></a>
<a name="464"><span class="lineNum">     464 </span><span class="lineNoCov">          0 :                                 goto gotlock;</span></a>
<a name="465"><span class="lineNum">     465 </span>            :                         }</a>
<a name="466"><span class="lineNum">     466 </span>            :                 }</a>
<a name="467"><span class="lineNum">     467 </span><span class="lineCov">         69 :                 WRITE_ONCE(pn-&gt;state, vcpu_hashed);</span></a>
<a name="468"><span class="lineNum">     468 </span><span class="lineCov">         69 :                 lockevent_inc(pv_wait_head);</span></a>
<a name="469"><span class="lineNum">     469 </span><span class="lineCov">         69 :                 lockevent_cond_inc(pv_wait_again, waitcnt);</span></a>
<a name="470"><span class="lineNum">     470 </span><span class="lineCov">         69 :                 pv_wait(&amp;lock-&gt;locked, _Q_SLOW_VAL);</span></a>
<a name="471"><span class="lineNum">     471 </span>            : </a>
<a name="472"><span class="lineNum">     472 </span>            :                 /*</a>
<a name="473"><span class="lineNum">     473 </span>            :                  * Because of lock stealing, the queue head vCPU may not be</a>
<a name="474"><span class="lineNum">     474 </span>            :                  * able to acquire the lock before it has to wait again.</a>
<a name="475"><span class="lineNum">     475 </span>            :                  */</a>
<a name="476"><span class="lineNum">     476 </span>            :         }</a>
<a name="477"><span class="lineNum">     477 </span>            : </a>
<a name="478"><span class="lineNum">     478 </span>            :         /*</a>
<a name="479"><span class="lineNum">     479 </span>            :          * The cmpxchg() or xchg() call before coming here provides the</a>
<a name="480"><span class="lineNum">     480 </span>            :          * acquire semantics for locking. The dummy ORing of _Q_LOCKED_VAL</a>
<a name="481"><span class="lineNum">     481 </span>            :          * here is to indicate to the compiler that the value will always</a>
<a name="482"><span class="lineNum">     482 </span>            :          * be nozero to enable better code optimization.</a>
<a name="483"><span class="lineNum">     483 </span>            :          */</a>
<a name="484"><span class="lineNum">     484 </span><span class="lineCov">     136514 : gotlock:</span></a>
<a name="485"><span class="lineNum">     485 </span><span class="lineCov">     136514 :         return (u32)(atomic_read(&amp;lock-&gt;val) | _Q_LOCKED_VAL);</span></a>
<a name="486"><span class="lineNum">     486 </span>            : }</a>
<a name="487"><span class="lineNum">     487 </span>            : </a>
<a name="488"><span class="lineNum">     488 </span>            : /*</a>
<a name="489"><span class="lineNum">     489 </span>            :  * PV versions of the unlock fastpath and slowpath functions to be used</a>
<a name="490"><span class="lineNum">     490 </span>            :  * instead of queued_spin_unlock().</a>
<a name="491"><span class="lineNum">     491 </span>            :  */</a>
<a name="492"><span class="lineNum">     492 </span>            : __visible void</a>
<a name="493"><span class="lineNum">     493 </span><span class="lineCov">        102 : __pv_queued_spin_unlock_slowpath(struct qspinlock *lock, u8 locked)</span></a>
<a name="494"><span class="lineNum">     494 </span>            : {</a>
<a name="495"><span class="lineNum">     495 </span><span class="lineCov">        102 :         struct pv_node *node;</span></a>
<a name="496"><span class="lineNum">     496 </span>            : </a>
<a name="497"><span class="lineNum">     497 </span><span class="lineCov">        102 :         if (unlikely(locked != _Q_SLOW_VAL)) {</span></a>
<a name="498"><span class="lineNum">     498 </span><span class="lineNoCov">          0 :                 WARN(!debug_locks_silent,</span></a>
<a name="499"><span class="lineNum">     499 </span>            :                      &quot;pvqspinlock: lock 0x%lx has corrupted value 0x%x!\n&quot;,</a>
<a name="500"><span class="lineNum">     500 </span>            :                      (unsigned long)lock, atomic_read(&amp;lock-&gt;val));</a>
<a name="501"><span class="lineNum">     501 </span><span class="lineNoCov">          0 :                 return;</span></a>
<a name="502"><span class="lineNum">     502 </span>            :         }</a>
<a name="503"><span class="lineNum">     503 </span>            : </a>
<a name="504"><span class="lineNum">     504 </span>            :         /*</a>
<a name="505"><span class="lineNum">     505 </span>            :          * A failed cmpxchg doesn't provide any memory-ordering guarantees,</a>
<a name="506"><span class="lineNum">     506 </span>            :          * so we need a barrier to order the read of the node data in</a>
<a name="507"><span class="lineNum">     507 </span>            :          * pv_unhash *after* we've read the lock being _Q_SLOW_VAL.</a>
<a name="508"><span class="lineNum">     508 </span>            :          *</a>
<a name="509"><span class="lineNum">     509 </span>            :          * Matches the cmpxchg() in pv_wait_head_or_lock() setting _Q_SLOW_VAL.</a>
<a name="510"><span class="lineNum">     510 </span>            :          */</a>
<a name="511"><span class="lineNum">     511 </span><span class="lineCov">        102 :         smp_rmb();</span></a>
<a name="512"><span class="lineNum">     512 </span>            : </a>
<a name="513"><span class="lineNum">     513 </span>            :         /*</a>
<a name="514"><span class="lineNum">     514 </span>            :          * Since the above failed to release, this must be the SLOW path.</a>
<a name="515"><span class="lineNum">     515 </span>            :          * Therefore start by looking up the blocked node and unhashing it.</a>
<a name="516"><span class="lineNum">     516 </span>            :          */</a>
<a name="517"><span class="lineNum">     517 </span><span class="lineCov">        102 :         node = pv_unhash(lock);</span></a>
<a name="518"><span class="lineNum">     518 </span>            : </a>
<a name="519"><span class="lineNum">     519 </span>            :         /*</a>
<a name="520"><span class="lineNum">     520 </span>            :          * Now that we have a reference to the (likely) blocked pv_node,</a>
<a name="521"><span class="lineNum">     521 </span>            :          * release the lock.</a>
<a name="522"><span class="lineNum">     522 </span>            :          */</a>
<a name="523"><span class="lineNum">     523 </span><span class="lineCov">        102 :         smp_store_release(&amp;lock-&gt;locked, 0);</span></a>
<a name="524"><span class="lineNum">     524 </span>            : </a>
<a name="525"><span class="lineNum">     525 </span>            :         /*</a>
<a name="526"><span class="lineNum">     526 </span>            :          * At this point the memory pointed at by lock can be freed/reused,</a>
<a name="527"><span class="lineNum">     527 </span>            :          * however we can still use the pv_node to kick the CPU.</a>
<a name="528"><span class="lineNum">     528 </span>            :          * The other vCPU may not really be halted, but kicking an active</a>
<a name="529"><span class="lineNum">     529 </span>            :          * vCPU is harmless other than the additional latency in completing</a>
<a name="530"><span class="lineNum">     530 </span>            :          * the unlock.</a>
<a name="531"><span class="lineNum">     531 </span>            :          */</a>
<a name="532"><span class="lineNum">     532 </span><span class="lineCov">        102 :         lockevent_inc(pv_kick_unlock);</span></a>
<a name="533"><span class="lineNum">     533 </span><span class="lineCov">        102 :         pv_kick(node-&gt;cpu);</span></a>
<a name="534"><span class="lineNum">     534 </span>            : }</a>
<a name="535"><span class="lineNum">     535 </span>            : </a>
<a name="536"><span class="lineNum">     536 </span>            : /*</a>
<a name="537"><span class="lineNum">     537 </span>            :  * Include the architecture specific callee-save thunk of the</a>
<a name="538"><span class="lineNum">     538 </span>            :  * __pv_queued_spin_unlock(). This thunk is put together with</a>
<a name="539"><span class="lineNum">     539 </span>            :  * __pv_queued_spin_unlock() to make the callee-save thunk and the real unlock</a>
<a name="540"><span class="lineNum">     540 </span>            :  * function close to each other sharing consecutive instruction cachelines.</a>
<a name="541"><span class="lineNum">     541 </span>            :  * Alternatively, architecture specific version of __pv_queued_spin_unlock()</a>
<a name="542"><span class="lineNum">     542 </span>            :  * can be defined.</a>
<a name="543"><span class="lineNum">     543 </span>            :  */</a>
<a name="544"><span class="lineNum">     544 </span>            : #include &lt;asm/qspinlock_paravirt.h&gt;</a>
<a name="545"><span class="lineNum">     545 </span>            : </a>
<a name="546"><span class="lineNum">     546 </span>            : #ifndef __pv_queued_spin_unlock</a>
<a name="547"><span class="lineNum">     547 </span>            : __visible void __pv_queued_spin_unlock(struct qspinlock *lock)</a>
<a name="548"><span class="lineNum">     548 </span>            : {</a>
<a name="549"><span class="lineNum">     549 </span>            :         u8 locked;</a>
<a name="550"><span class="lineNum">     550 </span>            : </a>
<a name="551"><span class="lineNum">     551 </span>            :         /*</a>
<a name="552"><span class="lineNum">     552 </span>            :          * We must not unlock if SLOW, because in that case we must first</a>
<a name="553"><span class="lineNum">     553 </span>            :          * unhash. Otherwise it would be possible to have multiple @lock</a>
<a name="554"><span class="lineNum">     554 </span>            :          * entries, which would be BAD.</a>
<a name="555"><span class="lineNum">     555 </span>            :          */</a>
<a name="556"><span class="lineNum">     556 </span>            :         locked = cmpxchg_release(&amp;lock-&gt;locked, _Q_LOCKED_VAL, 0);</a>
<a name="557"><span class="lineNum">     557 </span>            :         if (likely(locked == _Q_LOCKED_VAL))</a>
<a name="558"><span class="lineNum">     558 </span>            :                 return;</a>
<a name="559"><span class="lineNum">     559 </span>            : </a>
<a name="560"><span class="lineNum">     560 </span>            :         __pv_queued_spin_unlock_slowpath(lock, locked);</a>
<a name="561"><span class="lineNum">     561 </span>            : }</a>
<a name="562"><span class="lineNum">     562 </span>            : #endif /* __pv_queued_spin_unlock */</a>
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="http://ltp.sourceforge.net/coverage/lcov.php" target="_parent">LCOV version 1.14</a></td></tr>
  </table>
  <br>

</body>
</html>
