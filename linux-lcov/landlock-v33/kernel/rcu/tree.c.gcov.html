<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - landlock.info - kernel/rcu/tree.c</title>
  <link rel="stylesheet" type="text/css" href="../../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../../index.html">top level</a> - <a href="index.html">kernel/rcu</a> - tree.c<span style="font-size: 80%;"> (source / <a href="tree.c.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">landlock.info</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">1280</td>
            <td class="headerCovTableEntry">1779</td>
            <td class="headerCovTableEntryLo">72.0 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2021-04-07 12:34:12</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">82</td>
            <td class="headerCovTableEntry">117</td>
            <td class="headerCovTableEntryLo">70.1 %</td>
          </tr>
          <tr><td><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : // SPDX-License-Identifier: GPL-2.0+</a>
<a name="2"><span class="lineNum">       2 </span>            : /*</a>
<a name="3"><span class="lineNum">       3 </span>            :  * Read-Copy Update mechanism for mutual exclusion (tree-based version)</a>
<a name="4"><span class="lineNum">       4 </span>            :  *</a>
<a name="5"><span class="lineNum">       5 </span>            :  * Copyright IBM Corporation, 2008</a>
<a name="6"><span class="lineNum">       6 </span>            :  *</a>
<a name="7"><span class="lineNum">       7 </span>            :  * Authors: Dipankar Sarma &lt;dipankar@in.ibm.com&gt;</a>
<a name="8"><span class="lineNum">       8 </span>            :  *          Manfred Spraul &lt;manfred@colorfullife.com&gt;</a>
<a name="9"><span class="lineNum">       9 </span>            :  *          Paul E. McKenney &lt;paulmck@linux.ibm.com&gt;</a>
<a name="10"><span class="lineNum">      10 </span>            :  *</a>
<a name="11"><span class="lineNum">      11 </span>            :  * Based on the original work by Paul McKenney &lt;paulmck@linux.ibm.com&gt;</a>
<a name="12"><span class="lineNum">      12 </span>            :  * and inputs from Rusty Russell, Andrea Arcangeli and Andi Kleen.</a>
<a name="13"><span class="lineNum">      13 </span>            :  *</a>
<a name="14"><span class="lineNum">      14 </span>            :  * For detailed explanation of Read-Copy Update mechanism see -</a>
<a name="15"><span class="lineNum">      15 </span>            :  *      Documentation/RCU</a>
<a name="16"><span class="lineNum">      16 </span>            :  */</a>
<a name="17"><span class="lineNum">      17 </span>            : </a>
<a name="18"><span class="lineNum">      18 </span>            : #define pr_fmt(fmt) &quot;rcu: &quot; fmt</a>
<a name="19"><span class="lineNum">      19 </span>            : </a>
<a name="20"><span class="lineNum">      20 </span>            : #include &lt;linux/types.h&gt;</a>
<a name="21"><span class="lineNum">      21 </span>            : #include &lt;linux/kernel.h&gt;</a>
<a name="22"><span class="lineNum">      22 </span>            : #include &lt;linux/init.h&gt;</a>
<a name="23"><span class="lineNum">      23 </span>            : #include &lt;linux/spinlock.h&gt;</a>
<a name="24"><span class="lineNum">      24 </span>            : #include &lt;linux/smp.h&gt;</a>
<a name="25"><span class="lineNum">      25 </span>            : #include &lt;linux/rcupdate_wait.h&gt;</a>
<a name="26"><span class="lineNum">      26 </span>            : #include &lt;linux/interrupt.h&gt;</a>
<a name="27"><span class="lineNum">      27 </span>            : #include &lt;linux/sched.h&gt;</a>
<a name="28"><span class="lineNum">      28 </span>            : #include &lt;linux/sched/debug.h&gt;</a>
<a name="29"><span class="lineNum">      29 </span>            : #include &lt;linux/nmi.h&gt;</a>
<a name="30"><span class="lineNum">      30 </span>            : #include &lt;linux/atomic.h&gt;</a>
<a name="31"><span class="lineNum">      31 </span>            : #include &lt;linux/bitops.h&gt;</a>
<a name="32"><span class="lineNum">      32 </span>            : #include &lt;linux/export.h&gt;</a>
<a name="33"><span class="lineNum">      33 </span>            : #include &lt;linux/completion.h&gt;</a>
<a name="34"><span class="lineNum">      34 </span>            : #include &lt;linux/moduleparam.h&gt;</a>
<a name="35"><span class="lineNum">      35 </span>            : #include &lt;linux/percpu.h&gt;</a>
<a name="36"><span class="lineNum">      36 </span>            : #include &lt;linux/notifier.h&gt;</a>
<a name="37"><span class="lineNum">      37 </span>            : #include &lt;linux/cpu.h&gt;</a>
<a name="38"><span class="lineNum">      38 </span>            : #include &lt;linux/mutex.h&gt;</a>
<a name="39"><span class="lineNum">      39 </span>            : #include &lt;linux/time.h&gt;</a>
<a name="40"><span class="lineNum">      40 </span>            : #include &lt;linux/kernel_stat.h&gt;</a>
<a name="41"><span class="lineNum">      41 </span>            : #include &lt;linux/wait.h&gt;</a>
<a name="42"><span class="lineNum">      42 </span>            : #include &lt;linux/kthread.h&gt;</a>
<a name="43"><span class="lineNum">      43 </span>            : #include &lt;uapi/linux/sched/types.h&gt;</a>
<a name="44"><span class="lineNum">      44 </span>            : #include &lt;linux/prefetch.h&gt;</a>
<a name="45"><span class="lineNum">      45 </span>            : #include &lt;linux/delay.h&gt;</a>
<a name="46"><span class="lineNum">      46 </span>            : #include &lt;linux/random.h&gt;</a>
<a name="47"><span class="lineNum">      47 </span>            : #include &lt;linux/trace_events.h&gt;</a>
<a name="48"><span class="lineNum">      48 </span>            : #include &lt;linux/suspend.h&gt;</a>
<a name="49"><span class="lineNum">      49 </span>            : #include &lt;linux/ftrace.h&gt;</a>
<a name="50"><span class="lineNum">      50 </span>            : #include &lt;linux/tick.h&gt;</a>
<a name="51"><span class="lineNum">      51 </span>            : #include &lt;linux/sysrq.h&gt;</a>
<a name="52"><span class="lineNum">      52 </span>            : #include &lt;linux/kprobes.h&gt;</a>
<a name="53"><span class="lineNum">      53 </span>            : #include &lt;linux/gfp.h&gt;</a>
<a name="54"><span class="lineNum">      54 </span>            : #include &lt;linux/oom.h&gt;</a>
<a name="55"><span class="lineNum">      55 </span>            : #include &lt;linux/smpboot.h&gt;</a>
<a name="56"><span class="lineNum">      56 </span>            : #include &lt;linux/jiffies.h&gt;</a>
<a name="57"><span class="lineNum">      57 </span>            : #include &lt;linux/slab.h&gt;</a>
<a name="58"><span class="lineNum">      58 </span>            : #include &lt;linux/sched/isolation.h&gt;</a>
<a name="59"><span class="lineNum">      59 </span>            : #include &lt;linux/sched/clock.h&gt;</a>
<a name="60"><span class="lineNum">      60 </span>            : #include &lt;linux/vmalloc.h&gt;</a>
<a name="61"><span class="lineNum">      61 </span>            : #include &lt;linux/mm.h&gt;</a>
<a name="62"><span class="lineNum">      62 </span>            : #include &lt;linux/kasan.h&gt;</a>
<a name="63"><span class="lineNum">      63 </span>            : #include &quot;../time/tick-internal.h&quot;</a>
<a name="64"><span class="lineNum">      64 </span>            : </a>
<a name="65"><span class="lineNum">      65 </span>            : #include &quot;tree.h&quot;</a>
<a name="66"><span class="lineNum">      66 </span>            : #include &quot;rcu.h&quot;</a>
<a name="67"><span class="lineNum">      67 </span>            : </a>
<a name="68"><span class="lineNum">      68 </span>            : #ifdef MODULE_PARAM_PREFIX</a>
<a name="69"><span class="lineNum">      69 </span>            : #undef MODULE_PARAM_PREFIX</a>
<a name="70"><span class="lineNum">      70 </span>            : #endif</a>
<a name="71"><span class="lineNum">      71 </span>            : #define MODULE_PARAM_PREFIX &quot;rcutree.&quot;</a>
<a name="72"><span class="lineNum">      72 </span>            : </a>
<a name="73"><span class="lineNum">      73 </span>            : /* Data structures. */</a>
<a name="74"><span class="lineNum">      74 </span>            : </a>
<a name="75"><span class="lineNum">      75 </span>            : /*</a>
<a name="76"><span class="lineNum">      76 </span>            :  * Steal a bit from the bottom of -&gt;dynticks for idle entry/exit</a>
<a name="77"><span class="lineNum">      77 </span>            :  * control.  Initially this is for TLB flushing.</a>
<a name="78"><span class="lineNum">      78 </span>            :  */</a>
<a name="79"><span class="lineNum">      79 </span>            : #define RCU_DYNTICK_CTRL_MASK 0x1</a>
<a name="80"><span class="lineNum">      80 </span>            : #define RCU_DYNTICK_CTRL_CTR  (RCU_DYNTICK_CTRL_MASK + 1)</a>
<a name="81"><span class="lineNum">      81 </span>            : </a>
<a name="82"><span class="lineNum">      82 </span>            : static DEFINE_PER_CPU_SHARED_ALIGNED(struct rcu_data, rcu_data) = {</a>
<a name="83"><span class="lineNum">      83 </span>            :         .dynticks_nesting = 1,</a>
<a name="84"><span class="lineNum">      84 </span>            :         .dynticks_nmi_nesting = DYNTICK_IRQ_NONIDLE,</a>
<a name="85"><span class="lineNum">      85 </span>            :         .dynticks = ATOMIC_INIT(RCU_DYNTICK_CTRL_CTR),</a>
<a name="86"><span class="lineNum">      86 </span>            : #ifdef CONFIG_RCU_NOCB_CPU</a>
<a name="87"><span class="lineNum">      87 </span>            :         .cblist.flags = SEGCBLIST_SOFTIRQ_ONLY,</a>
<a name="88"><span class="lineNum">      88 </span>            : #endif</a>
<a name="89"><span class="lineNum">      89 </span>            : };</a>
<a name="90"><span class="lineNum">      90 </span>            : static struct rcu_state rcu_state = {</a>
<a name="91"><span class="lineNum">      91 </span>            :         .level = { &amp;rcu_state.node[0] },</a>
<a name="92"><span class="lineNum">      92 </span>            :         .gp_state = RCU_GP_IDLE,</a>
<a name="93"><span class="lineNum">      93 </span>            :         .gp_seq = (0UL - 300UL) &lt;&lt; RCU_SEQ_CTR_SHIFT,</a>
<a name="94"><span class="lineNum">      94 </span>            :         .barrier_mutex = __MUTEX_INITIALIZER(rcu_state.barrier_mutex),</a>
<a name="95"><span class="lineNum">      95 </span>            :         .name = RCU_NAME,</a>
<a name="96"><span class="lineNum">      96 </span>            :         .abbr = RCU_ABBR,</a>
<a name="97"><span class="lineNum">      97 </span>            :         .exp_mutex = __MUTEX_INITIALIZER(rcu_state.exp_mutex),</a>
<a name="98"><span class="lineNum">      98 </span>            :         .exp_wake_mutex = __MUTEX_INITIALIZER(rcu_state.exp_wake_mutex),</a>
<a name="99"><span class="lineNum">      99 </span>            :         .ofl_lock = __RAW_SPIN_LOCK_UNLOCKED(rcu_state.ofl_lock),</a>
<a name="100"><span class="lineNum">     100 </span>            : };</a>
<a name="101"><span class="lineNum">     101 </span>            : </a>
<a name="102"><span class="lineNum">     102 </span>            : /* Dump rcu_node combining tree at boot to verify correct setup. */</a>
<a name="103"><span class="lineNum">     103 </span>            : static bool dump_tree;</a>
<a name="104"><span class="lineNum">     104 </span>            : module_param(dump_tree, bool, 0444);</a>
<a name="105"><span class="lineNum">     105 </span>            : /* By default, use RCU_SOFTIRQ instead of rcuc kthreads. */</a>
<a name="106"><span class="lineNum">     106 </span>            : static bool use_softirq = !IS_ENABLED(CONFIG_PREEMPT_RT);</a>
<a name="107"><span class="lineNum">     107 </span>            : #ifndef CONFIG_PREEMPT_RT</a>
<a name="108"><span class="lineNum">     108 </span>            : module_param(use_softirq, bool, 0444);</a>
<a name="109"><span class="lineNum">     109 </span>            : #endif</a>
<a name="110"><span class="lineNum">     110 </span>            : /* Control rcu_node-tree auto-balancing at boot time. */</a>
<a name="111"><span class="lineNum">     111 </span>            : static bool rcu_fanout_exact;</a>
<a name="112"><span class="lineNum">     112 </span>            : module_param(rcu_fanout_exact, bool, 0444);</a>
<a name="113"><span class="lineNum">     113 </span>            : /* Increase (but not decrease) the RCU_FANOUT_LEAF at boot time. */</a>
<a name="114"><span class="lineNum">     114 </span>            : static int rcu_fanout_leaf = RCU_FANOUT_LEAF;</a>
<a name="115"><span class="lineNum">     115 </span>            : module_param(rcu_fanout_leaf, int, 0444);</a>
<a name="116"><span class="lineNum">     116 </span>            : int rcu_num_lvls __read_mostly = RCU_NUM_LVLS;</a>
<a name="117"><span class="lineNum">     117 </span>            : /* Number of rcu_nodes at specified level. */</a>
<a name="118"><span class="lineNum">     118 </span>            : int num_rcu_lvl[] = NUM_RCU_LVL_INIT;</a>
<a name="119"><span class="lineNum">     119 </span>            : int rcu_num_nodes __read_mostly = NUM_RCU_NODES; /* Total # rcu_nodes in use. */</a>
<a name="120"><span class="lineNum">     120 </span>            : </a>
<a name="121"><span class="lineNum">     121 </span>            : /*</a>
<a name="122"><span class="lineNum">     122 </span>            :  * The rcu_scheduler_active variable is initialized to the value</a>
<a name="123"><span class="lineNum">     123 </span>            :  * RCU_SCHEDULER_INACTIVE and transitions RCU_SCHEDULER_INIT just before the</a>
<a name="124"><span class="lineNum">     124 </span>            :  * first task is spawned.  So when this variable is RCU_SCHEDULER_INACTIVE,</a>
<a name="125"><span class="lineNum">     125 </span>            :  * RCU can assume that there is but one task, allowing RCU to (for example)</a>
<a name="126"><span class="lineNum">     126 </span>            :  * optimize synchronize_rcu() to a simple barrier().  When this variable</a>
<a name="127"><span class="lineNum">     127 </span>            :  * is RCU_SCHEDULER_INIT, RCU must actually do all the hard work required</a>
<a name="128"><span class="lineNum">     128 </span>            :  * to detect real grace periods.  This variable is also used to suppress</a>
<a name="129"><span class="lineNum">     129 </span>            :  * boot-time false positives from lockdep-RCU error checking.  Finally, it</a>
<a name="130"><span class="lineNum">     130 </span>            :  * transitions from RCU_SCHEDULER_INIT to RCU_SCHEDULER_RUNNING after RCU</a>
<a name="131"><span class="lineNum">     131 </span>            :  * is fully initialized, including all of its kthreads having been spawned.</a>
<a name="132"><span class="lineNum">     132 </span>            :  */</a>
<a name="133"><span class="lineNum">     133 </span>            : int rcu_scheduler_active __read_mostly;</a>
<a name="134"><span class="lineNum">     134 </span>            : EXPORT_SYMBOL_GPL(rcu_scheduler_active);</a>
<a name="135"><span class="lineNum">     135 </span>            : </a>
<a name="136"><span class="lineNum">     136 </span>            : /*</a>
<a name="137"><span class="lineNum">     137 </span>            :  * The rcu_scheduler_fully_active variable transitions from zero to one</a>
<a name="138"><span class="lineNum">     138 </span>            :  * during the early_initcall() processing, which is after the scheduler</a>
<a name="139"><span class="lineNum">     139 </span>            :  * is capable of creating new tasks.  So RCU processing (for example,</a>
<a name="140"><span class="lineNum">     140 </span>            :  * creating tasks for RCU priority boosting) must be delayed until after</a>
<a name="141"><span class="lineNum">     141 </span>            :  * rcu_scheduler_fully_active transitions from zero to one.  We also</a>
<a name="142"><span class="lineNum">     142 </span>            :  * currently delay invocation of any RCU callbacks until after this point.</a>
<a name="143"><span class="lineNum">     143 </span>            :  *</a>
<a name="144"><span class="lineNum">     144 </span>            :  * It might later prove better for people registering RCU callbacks during</a>
<a name="145"><span class="lineNum">     145 </span>            :  * early boot to take responsibility for these callbacks, but one step at</a>
<a name="146"><span class="lineNum">     146 </span>            :  * a time.</a>
<a name="147"><span class="lineNum">     147 </span>            :  */</a>
<a name="148"><span class="lineNum">     148 </span>            : static int rcu_scheduler_fully_active __read_mostly;</a>
<a name="149"><span class="lineNum">     149 </span>            : </a>
<a name="150"><span class="lineNum">     150 </span>            : static void rcu_report_qs_rnp(unsigned long mask, struct rcu_node *rnp,</a>
<a name="151"><span class="lineNum">     151 </span>            :                               unsigned long gps, unsigned long flags);</a>
<a name="152"><span class="lineNum">     152 </span>            : static void rcu_init_new_rnp(struct rcu_node *rnp_leaf);</a>
<a name="153"><span class="lineNum">     153 </span>            : static void rcu_cleanup_dead_rnp(struct rcu_node *rnp_leaf);</a>
<a name="154"><span class="lineNum">     154 </span>            : static void rcu_boost_kthread_setaffinity(struct rcu_node *rnp, int outgoingcpu);</a>
<a name="155"><span class="lineNum">     155 </span>            : static void invoke_rcu_core(void);</a>
<a name="156"><span class="lineNum">     156 </span>            : static void rcu_report_exp_rdp(struct rcu_data *rdp);</a>
<a name="157"><span class="lineNum">     157 </span>            : static void sync_sched_exp_online_cleanup(int cpu);</a>
<a name="158"><span class="lineNum">     158 </span>            : static void check_cb_ovld_locked(struct rcu_data *rdp, struct rcu_node *rnp);</a>
<a name="159"><span class="lineNum">     159 </span>            : </a>
<a name="160"><span class="lineNum">     160 </span>            : /* rcuc/rcub kthread realtime priority */</a>
<a name="161"><span class="lineNum">     161 </span>            : static int kthread_prio = IS_ENABLED(CONFIG_RCU_BOOST) ? 1 : 0;</a>
<a name="162"><span class="lineNum">     162 </span>            : module_param(kthread_prio, int, 0444);</a>
<a name="163"><span class="lineNum">     163 </span>            : </a>
<a name="164"><span class="lineNum">     164 </span>            : /* Delay in jiffies for grace-period initialization delays, debug only. */</a>
<a name="165"><span class="lineNum">     165 </span>            : </a>
<a name="166"><span class="lineNum">     166 </span>            : static int gp_preinit_delay;</a>
<a name="167"><span class="lineNum">     167 </span>            : module_param(gp_preinit_delay, int, 0444);</a>
<a name="168"><span class="lineNum">     168 </span>            : static int gp_init_delay;</a>
<a name="169"><span class="lineNum">     169 </span>            : module_param(gp_init_delay, int, 0444);</a>
<a name="170"><span class="lineNum">     170 </span>            : static int gp_cleanup_delay;</a>
<a name="171"><span class="lineNum">     171 </span>            : module_param(gp_cleanup_delay, int, 0444);</a>
<a name="172"><span class="lineNum">     172 </span>            : </a>
<a name="173"><span class="lineNum">     173 </span>            : // Add delay to rcu_read_unlock() for strict grace periods.</a>
<a name="174"><span class="lineNum">     174 </span>            : static int rcu_unlock_delay;</a>
<a name="175"><span class="lineNum">     175 </span>            : #ifdef CONFIG_RCU_STRICT_GRACE_PERIOD</a>
<a name="176"><span class="lineNum">     176 </span>            : module_param(rcu_unlock_delay, int, 0444);</a>
<a name="177"><span class="lineNum">     177 </span>            : #endif</a>
<a name="178"><span class="lineNum">     178 </span>            : </a>
<a name="179"><span class="lineNum">     179 </span>            : /*</a>
<a name="180"><span class="lineNum">     180 </span>            :  * This rcu parameter is runtime-read-only. It reflects</a>
<a name="181"><span class="lineNum">     181 </span>            :  * a minimum allowed number of objects which can be cached</a>
<a name="182"><span class="lineNum">     182 </span>            :  * per-CPU. Object size is equal to one page. This value</a>
<a name="183"><span class="lineNum">     183 </span>            :  * can be changed at boot time.</a>
<a name="184"><span class="lineNum">     184 </span>            :  */</a>
<a name="185"><span class="lineNum">     185 </span>            : static int rcu_min_cached_objs = 5;</a>
<a name="186"><span class="lineNum">     186 </span>            : module_param(rcu_min_cached_objs, int, 0444);</a>
<a name="187"><span class="lineNum">     187 </span>            : </a>
<a name="188"><span class="lineNum">     188 </span>            : /* Retrieve RCU kthreads priority for rcutorture */</a>
<a name="189"><span class="lineNum">     189 </span><span class="lineNoCov">          0 : int rcu_get_gp_kthreads_prio(void)</span></a>
<a name="190"><span class="lineNum">     190 </span>            : {</a>
<a name="191"><span class="lineNum">     191 </span><span class="lineNoCov">          0 :         return kthread_prio;</span></a>
<a name="192"><span class="lineNum">     192 </span>            : }</a>
<a name="193"><span class="lineNum">     193 </span>            : EXPORT_SYMBOL_GPL(rcu_get_gp_kthreads_prio);</a>
<a name="194"><span class="lineNum">     194 </span>            : </a>
<a name="195"><span class="lineNum">     195 </span>            : /*</a>
<a name="196"><span class="lineNum">     196 </span>            :  * Number of grace periods between delays, normalized by the duration of</a>
<a name="197"><span class="lineNum">     197 </span>            :  * the delay.  The longer the delay, the more the grace periods between</a>
<a name="198"><span class="lineNum">     198 </span>            :  * each delay.  The reason for this normalization is that it means that,</a>
<a name="199"><span class="lineNum">     199 </span>            :  * for non-zero delays, the overall slowdown of grace periods is constant</a>
<a name="200"><span class="lineNum">     200 </span>            :  * regardless of the duration of the delay.  This arrangement balances</a>
<a name="201"><span class="lineNum">     201 </span>            :  * the need for long delays to increase some race probabilities with the</a>
<a name="202"><span class="lineNum">     202 </span>            :  * need for fast grace periods to increase other race probabilities.</a>
<a name="203"><span class="lineNum">     203 </span>            :  */</a>
<a name="204"><span class="lineNum">     204 </span>            : #define PER_RCU_NODE_PERIOD 3   /* Number of grace periods between delays. */</a>
<a name="205"><span class="lineNum">     205 </span>            : </a>
<a name="206"><span class="lineNum">     206 </span>            : /*</a>
<a name="207"><span class="lineNum">     207 </span>            :  * Compute the mask of online CPUs for the specified rcu_node structure.</a>
<a name="208"><span class="lineNum">     208 </span>            :  * This will not be stable unless the rcu_node structure's -&gt;lock is</a>
<a name="209"><span class="lineNum">     209 </span>            :  * held, but the bit corresponding to the current CPU will be stable</a>
<a name="210"><span class="lineNum">     210 </span>            :  * in most contexts.</a>
<a name="211"><span class="lineNum">     211 </span>            :  */</a>
<a name="212"><span class="lineNum">     212 </span><span class="lineCov">   35067552 : static unsigned long rcu_rnp_online_cpus(struct rcu_node *rnp)</span></a>
<a name="213"><span class="lineNum">     213 </span>            : {</a>
<a name="214"><span class="lineNum">     214 </span><span class="lineCov">   35067552 :         return READ_ONCE(rnp-&gt;qsmaskinitnext);</span></a>
<a name="215"><span class="lineNum">     215 </span>            : }</a>
<a name="216"><span class="lineNum">     216 </span>            : </a>
<a name="217"><span class="lineNum">     217 </span>            : /*</a>
<a name="218"><span class="lineNum">     218 </span>            :  * Return true if an RCU grace period is in progress.  The READ_ONCE()s</a>
<a name="219"><span class="lineNum">     219 </span>            :  * permit this function to be invoked without holding the root rcu_node</a>
<a name="220"><span class="lineNum">     220 </span>            :  * structure's -&gt;lock, but of course results can be subject to change.</a>
<a name="221"><span class="lineNum">     221 </span>            :  */</a>
<a name="222"><span class="lineNum">     222 </span><span class="lineCov">     169060 : static int rcu_gp_in_progress(void)</span></a>
<a name="223"><span class="lineNum">     223 </span>            : {</a>
<a name="224"><span class="lineNum">     224 </span><span class="lineCov">      82194 :         return rcu_seq_state(rcu_seq_current(&amp;rcu_state.gp_seq));</span></a>
<a name="225"><span class="lineNum">     225 </span>            : }</a>
<a name="226"><span class="lineNum">     226 </span>            : </a>
<a name="227"><span class="lineNum">     227 </span>            : /*</a>
<a name="228"><span class="lineNum">     228 </span>            :  * Return the number of callbacks queued on the specified CPU.</a>
<a name="229"><span class="lineNum">     229 </span>            :  * Handles both the nocbs and normal cases.</a>
<a name="230"><span class="lineNum">     230 </span>            :  */</a>
<a name="231"><span class="lineNum">     231 </span><span class="lineNoCov">          0 : static long rcu_get_n_cbs_cpu(int cpu)</span></a>
<a name="232"><span class="lineNum">     232 </span>            : {</a>
<a name="233"><span class="lineNum">     233 </span><span class="lineNoCov">          0 :         struct rcu_data *rdp = per_cpu_ptr(&amp;rcu_data, cpu);</span></a>
<a name="234"><span class="lineNum">     234 </span>            : </a>
<a name="235"><span class="lineNum">     235 </span><span class="lineNoCov">          0 :         if (rcu_segcblist_is_enabled(&amp;rdp-&gt;cblist))</span></a>
<a name="236"><span class="lineNum">     236 </span><span class="lineNoCov">          0 :                 return rcu_segcblist_n_cbs(&amp;rdp-&gt;cblist);</span></a>
<a name="237"><span class="lineNum">     237 </span>            :         return 0;</a>
<a name="238"><span class="lineNum">     238 </span>            : }</a>
<a name="239"><span class="lineNum">     239 </span>            : </a>
<a name="240"><span class="lineNum">     240 </span><span class="lineCov">      32234 : void rcu_softirq_qs(void)</span></a>
<a name="241"><span class="lineNum">     241 </span>            : {</a>
<a name="242"><span class="lineNum">     242 </span><span class="lineCov">      32234 :         rcu_qs();</span></a>
<a name="243"><span class="lineNum">     243 </span><span class="lineCov">      32233 :         rcu_preempt_deferred_qs(current);</span></a>
<a name="244"><span class="lineNum">     244 </span><span class="lineCov">      32233 : }</span></a>
<a name="245"><span class="lineNum">     245 </span>            : </a>
<a name="246"><span class="lineNum">     246 </span>            : /*</a>
<a name="247"><span class="lineNum">     247 </span>            :  * Record entry into an extended quiescent state.  This is only to be</a>
<a name="248"><span class="lineNum">     248 </span>            :  * called when not already in an extended quiescent state, that is,</a>
<a name="249"><span class="lineNum">     249 </span>            :  * RCU is watching prior to the call to this function and is no longer</a>
<a name="250"><span class="lineNum">     250 </span>            :  * watching upon return.</a>
<a name="251"><span class="lineNum">     251 </span>            :  */</a>
<a name="252"><span class="lineNum">     252 </span><span class="lineCov">      35514 : static noinstr void rcu_dynticks_eqs_enter(void)</span></a>
<a name="253"><span class="lineNum">     253 </span>            : {</a>
<a name="254"><span class="lineNum">     254 </span><span class="lineCov">      35514 :         struct rcu_data *rdp = this_cpu_ptr(&amp;rcu_data);</span></a>
<a name="255"><span class="lineNum">     255 </span><span class="lineCov">      35517 :         int seq;</span></a>
<a name="256"><span class="lineNum">     256 </span>            : </a>
<a name="257"><span class="lineNum">     257 </span>            :         /*</a>
<a name="258"><span class="lineNum">     258 </span>            :          * CPUs seeing atomic_add_return() must see prior RCU read-side</a>
<a name="259"><span class="lineNum">     259 </span>            :          * critical sections, and we also must force ordering with the</a>
<a name="260"><span class="lineNum">     260 </span>            :          * next idle sojourn.</a>
<a name="261"><span class="lineNum">     261 </span>            :          */</a>
<a name="262"><span class="lineNum">     262 </span><span class="lineCov">      35517 :         rcu_dynticks_task_trace_enter();  // Before -&gt;dynticks update!</span></a>
<a name="263"><span class="lineNum">     263 </span><span class="lineCov">      35517 :         seq = arch_atomic_add_return(RCU_DYNTICK_CTRL_CTR, &amp;rdp-&gt;dynticks);</span></a>
<a name="264"><span class="lineNum">     264 </span>            :         // RCU is no longer watching.  Better be in extended quiescent state!</a>
<a name="265"><span class="lineNum">     265 </span><span class="lineCov">      35572 :         WARN_ON_ONCE(IS_ENABLED(CONFIG_RCU_EQS_DEBUG) &amp;&amp;</span></a>
<a name="266"><span class="lineNum">     266 </span>            :                      (seq &amp; RCU_DYNTICK_CTRL_CTR));</a>
<a name="267"><span class="lineNum">     267 </span>            :         /* Better not have special action (TLB flush) pending! */</a>
<a name="268"><span class="lineNum">     268 </span><span class="lineCov">      35572 :         WARN_ON_ONCE(IS_ENABLED(CONFIG_RCU_EQS_DEBUG) &amp;&amp;</span></a>
<a name="269"><span class="lineNum">     269 </span>            :                      (seq &amp; RCU_DYNTICK_CTRL_MASK));</a>
<a name="270"><span class="lineNum">     270 </span><span class="lineCov">      35572 : }</span></a>
<a name="271"><span class="lineNum">     271 </span>            : </a>
<a name="272"><span class="lineNum">     272 </span>            : /*</a>
<a name="273"><span class="lineNum">     273 </span>            :  * Record exit from an extended quiescent state.  This is only to be</a>
<a name="274"><span class="lineNum">     274 </span>            :  * called from an extended quiescent state, that is, RCU is not watching</a>
<a name="275"><span class="lineNum">     275 </span>            :  * prior to the call to this function and is watching upon return.</a>
<a name="276"><span class="lineNum">     276 </span>            :  */</a>
<a name="277"><span class="lineNum">     277 </span><span class="lineCov">      35000 : static noinstr void rcu_dynticks_eqs_exit(void)</span></a>
<a name="278"><span class="lineNum">     278 </span>            : {</a>
<a name="279"><span class="lineNum">     279 </span><span class="lineCov">      35000 :         struct rcu_data *rdp = this_cpu_ptr(&amp;rcu_data);</span></a>
<a name="280"><span class="lineNum">     280 </span><span class="lineCov">      35198 :         int seq;</span></a>
<a name="281"><span class="lineNum">     281 </span>            : </a>
<a name="282"><span class="lineNum">     282 </span>            :         /*</a>
<a name="283"><span class="lineNum">     283 </span>            :          * CPUs seeing atomic_add_return() must see prior idle sojourns,</a>
<a name="284"><span class="lineNum">     284 </span>            :          * and we also must force ordering with the next RCU read-side</a>
<a name="285"><span class="lineNum">     285 </span>            :          * critical section.</a>
<a name="286"><span class="lineNum">     286 </span>            :          */</a>
<a name="287"><span class="lineNum">     287 </span><span class="lineCov">      35198 :         seq = arch_atomic_add_return(RCU_DYNTICK_CTRL_CTR, &amp;rdp-&gt;dynticks);</span></a>
<a name="288"><span class="lineNum">     288 </span>            :         // RCU is now watching.  Better not be in an extended quiescent state!</a>
<a name="289"><span class="lineNum">     289 </span><span class="lineCov">      35524 :         rcu_dynticks_task_trace_exit();  // After -&gt;dynticks update!</span></a>
<a name="290"><span class="lineNum">     290 </span><span class="lineCov">      35524 :         WARN_ON_ONCE(IS_ENABLED(CONFIG_RCU_EQS_DEBUG) &amp;&amp;</span></a>
<a name="291"><span class="lineNum">     291 </span>            :                      !(seq &amp; RCU_DYNTICK_CTRL_CTR));</a>
<a name="292"><span class="lineNum">     292 </span><span class="lineCov">      35524 :         if (seq &amp; RCU_DYNTICK_CTRL_MASK) {</span></a>
<a name="293"><span class="lineNum">     293 </span><span class="lineNoCov">          0 :                 arch_atomic_andnot(RCU_DYNTICK_CTRL_MASK, &amp;rdp-&gt;dynticks);</span></a>
<a name="294"><span class="lineNum">     294 </span><span class="lineCov">      35524 :                 smp_mb__after_atomic(); /* _exit after clearing mask. */</span></a>
<a name="295"><span class="lineNum">     295 </span>            :         }</a>
<a name="296"><span class="lineNum">     296 </span><span class="lineCov">      35524 : }</span></a>
<a name="297"><span class="lineNum">     297 </span>            : </a>
<a name="298"><span class="lineNum">     298 </span>            : /*</a>
<a name="299"><span class="lineNum">     299 </span>            :  * Reset the current CPU's -&gt;dynticks counter to indicate that the</a>
<a name="300"><span class="lineNum">     300 </span>            :  * newly onlined CPU is no longer in an extended quiescent state.</a>
<a name="301"><span class="lineNum">     301 </span>            :  * This will either leave the counter unchanged, or increment it</a>
<a name="302"><span class="lineNum">     302 </span>            :  * to the next non-quiescent value.</a>
<a name="303"><span class="lineNum">     303 </span>            :  *</a>
<a name="304"><span class="lineNum">     304 </span>            :  * The non-atomic test/increment sequence works because the upper bits</a>
<a name="305"><span class="lineNum">     305 </span>            :  * of the -&gt;dynticks counter are manipulated only by the corresponding CPU,</a>
<a name="306"><span class="lineNum">     306 </span>            :  * or when the corresponding CPU is offline.</a>
<a name="307"><span class="lineNum">     307 </span>            :  */</a>
<a name="308"><span class="lineNum">     308 </span><span class="lineCov">          4 : static void rcu_dynticks_eqs_online(void)</span></a>
<a name="309"><span class="lineNum">     309 </span>            : {</a>
<a name="310"><span class="lineNum">     310 </span><span class="lineCov">          4 :         struct rcu_data *rdp = this_cpu_ptr(&amp;rcu_data);</span></a>
<a name="311"><span class="lineNum">     311 </span>            : </a>
<a name="312"><span class="lineNum">     312 </span><span class="lineCov">          4 :         if (atomic_read(&amp;rdp-&gt;dynticks) &amp; RCU_DYNTICK_CTRL_CTR)</span></a>
<a name="313"><span class="lineNum">     313 </span>            :                 return;</a>
<a name="314"><span class="lineNum">     314 </span><span class="lineNoCov">          0 :         atomic_add(RCU_DYNTICK_CTRL_CTR, &amp;rdp-&gt;dynticks);</span></a>
<a name="315"><span class="lineNum">     315 </span>            : }</a>
<a name="316"><span class="lineNum">     316 </span>            : </a>
<a name="317"><span class="lineNum">     317 </span>            : /*</a>
<a name="318"><span class="lineNum">     318 </span>            :  * Is the current CPU in an extended quiescent state?</a>
<a name="319"><span class="lineNum">     319 </span>            :  *</a>
<a name="320"><span class="lineNum">     320 </span>            :  * No ordering, as we are sampling CPU-local information.</a>
<a name="321"><span class="lineNum">     321 </span>            :  */</a>
<a name="322"><span class="lineNum">     322 </span><span class="lineCov">   40681482 : static __always_inline bool rcu_dynticks_curr_cpu_in_eqs(void)</span></a>
<a name="323"><span class="lineNum">     323 </span>            : {</a>
<a name="324"><span class="lineNum">     324 </span><span class="lineNoCov">          0 :         struct rcu_data *rdp = this_cpu_ptr(&amp;rcu_data);</span></a>
<a name="325"><span class="lineNum">     325 </span>            : </a>
<a name="326"><span class="lineNum">     326 </span><span class="lineCov">   40720823 :         return !(arch_atomic_read(&amp;rdp-&gt;dynticks) &amp; RCU_DYNTICK_CTRL_CTR);</span></a>
<a name="327"><span class="lineNum">     327 </span>            : }</a>
<a name="328"><span class="lineNum">     328 </span>            : </a>
<a name="329"><span class="lineNum">     329 </span>            : /*</a>
<a name="330"><span class="lineNum">     330 </span>            :  * Snapshot the -&gt;dynticks counter with full ordering so as to allow</a>
<a name="331"><span class="lineNum">     331 </span>            :  * stable comparison of this counter with past and future snapshots.</a>
<a name="332"><span class="lineNum">     332 </span>            :  */</a>
<a name="333"><span class="lineNum">     333 </span><span class="lineCov">       4358 : static int rcu_dynticks_snap(struct rcu_data *rdp)</span></a>
<a name="334"><span class="lineNum">     334 </span>            : {</a>
<a name="335"><span class="lineNum">     335 </span><span class="lineCov">       4358 :         int snap = atomic_add_return(0, &amp;rdp-&gt;dynticks);</span></a>
<a name="336"><span class="lineNum">     336 </span>            : </a>
<a name="337"><span class="lineNum">     337 </span><span class="lineCov">       4358 :         return snap &amp; ~RCU_DYNTICK_CTRL_MASK;</span></a>
<a name="338"><span class="lineNum">     338 </span>            : }</a>
<a name="339"><span class="lineNum">     339 </span>            : </a>
<a name="340"><span class="lineNum">     340 </span>            : /*</a>
<a name="341"><span class="lineNum">     341 </span>            :  * Return true if the snapshot returned from rcu_dynticks_snap()</a>
<a name="342"><span class="lineNum">     342 </span>            :  * indicates that RCU is in an extended quiescent state.</a>
<a name="343"><span class="lineNum">     343 </span>            :  */</a>
<a name="344"><span class="lineNum">     344 </span><span class="lineCov">       3065 : static bool rcu_dynticks_in_eqs(int snap)</span></a>
<a name="345"><span class="lineNum">     345 </span>            : {</a>
<a name="346"><span class="lineNum">     346 </span><span class="lineCov">        483 :         return !(snap &amp; RCU_DYNTICK_CTRL_CTR);</span></a>
<a name="347"><span class="lineNum">     347 </span>            : }</a>
<a name="348"><span class="lineNum">     348 </span>            : </a>
<a name="349"><span class="lineNum">     349 </span>            : /* Return true if the specified CPU is currently idle from an RCU viewpoint.  */</a>
<a name="350"><span class="lineNum">     350 </span><span class="lineNoCov">          0 : bool rcu_is_idle_cpu(int cpu)</span></a>
<a name="351"><span class="lineNum">     351 </span>            : {</a>
<a name="352"><span class="lineNum">     352 </span><span class="lineNoCov">          0 :         struct rcu_data *rdp = per_cpu_ptr(&amp;rcu_data, cpu);</span></a>
<a name="353"><span class="lineNum">     353 </span>            : </a>
<a name="354"><span class="lineNum">     354 </span><span class="lineNoCov">          0 :         return rcu_dynticks_in_eqs(rcu_dynticks_snap(rdp));</span></a>
<a name="355"><span class="lineNum">     355 </span>            : }</a>
<a name="356"><span class="lineNum">     356 </span>            : </a>
<a name="357"><span class="lineNum">     357 </span>            : /*</a>
<a name="358"><span class="lineNum">     358 </span>            :  * Return true if the CPU corresponding to the specified rcu_data</a>
<a name="359"><span class="lineNum">     359 </span>            :  * structure has spent some time in an extended quiescent state since</a>
<a name="360"><span class="lineNum">     360 </span>            :  * rcu_dynticks_snap() returned the specified snapshot.</a>
<a name="361"><span class="lineNum">     361 </span>            :  */</a>
<a name="362"><span class="lineNum">     362 </span><span class="lineCov">       1293 : static bool rcu_dynticks_in_eqs_since(struct rcu_data *rdp, int snap)</span></a>
<a name="363"><span class="lineNum">     363 </span>            : {</a>
<a name="364"><span class="lineNum">     364 </span><span class="lineCov">        323 :         return snap != rcu_dynticks_snap(rdp);</span></a>
<a name="365"><span class="lineNum">     365 </span>            : }</a>
<a name="366"><span class="lineNum">     366 </span>            : </a>
<a name="367"><span class="lineNum">     367 </span>            : /*</a>
<a name="368"><span class="lineNum">     368 </span>            :  * Return true if the referenced integer is zero while the specified</a>
<a name="369"><span class="lineNum">     369 </span>            :  * CPU remains within a single extended quiescent state.</a>
<a name="370"><span class="lineNum">     370 </span>            :  */</a>
<a name="371"><span class="lineNum">     371 </span><span class="lineNoCov">          0 : bool rcu_dynticks_zero_in_eqs(int cpu, int *vp)</span></a>
<a name="372"><span class="lineNum">     372 </span>            : {</a>
<a name="373"><span class="lineNum">     373 </span><span class="lineNoCov">          0 :         struct rcu_data *rdp = per_cpu_ptr(&amp;rcu_data, cpu);</span></a>
<a name="374"><span class="lineNum">     374 </span><span class="lineNoCov">          0 :         int snap;</span></a>
<a name="375"><span class="lineNum">     375 </span>            : </a>
<a name="376"><span class="lineNum">     376 </span>            :         // If not quiescent, force back to earlier extended quiescent state.</a>
<a name="377"><span class="lineNum">     377 </span><span class="lineNoCov">          0 :         snap = atomic_read(&amp;rdp-&gt;dynticks) &amp; ~(RCU_DYNTICK_CTRL_MASK |</span></a>
<a name="378"><span class="lineNum">     378 </span>            :                                                RCU_DYNTICK_CTRL_CTR);</a>
<a name="379"><span class="lineNum">     379 </span>            : </a>
<a name="380"><span class="lineNum">     380 </span><span class="lineNoCov">          0 :         smp_rmb(); // Order -&gt;dynticks and *vp reads.</span></a>
<a name="381"><span class="lineNum">     381 </span><span class="lineNoCov">          0 :         if (READ_ONCE(*vp))</span></a>
<a name="382"><span class="lineNum">     382 </span>            :                 return false;  // Non-zero, so report failure;</a>
<a name="383"><span class="lineNum">     383 </span><span class="lineNoCov">          0 :         smp_rmb(); // Order *vp read and -&gt;dynticks re-read.</span></a>
<a name="384"><span class="lineNum">     384 </span>            : </a>
<a name="385"><span class="lineNum">     385 </span>            :         // If still in the same extended quiescent state, we are good!</a>
<a name="386"><span class="lineNum">     386 </span><span class="lineNoCov">          0 :         return snap == (atomic_read(&amp;rdp-&gt;dynticks) &amp; ~RCU_DYNTICK_CTRL_MASK);</span></a>
<a name="387"><span class="lineNum">     387 </span>            : }</a>
<a name="388"><span class="lineNum">     388 </span>            : </a>
<a name="389"><span class="lineNum">     389 </span>            : /*</a>
<a name="390"><span class="lineNum">     390 </span>            :  * Set the special (bottom) bit of the specified CPU so that it</a>
<a name="391"><span class="lineNum">     391 </span>            :  * will take special action (such as flushing its TLB) on the</a>
<a name="392"><span class="lineNum">     392 </span>            :  * next exit from an extended quiescent state.  Returns true if</a>
<a name="393"><span class="lineNum">     393 </span>            :  * the bit was successfully set, or false if the CPU was not in</a>
<a name="394"><span class="lineNum">     394 </span>            :  * an extended quiescent state.</a>
<a name="395"><span class="lineNum">     395 </span>            :  */</a>
<a name="396"><span class="lineNum">     396 </span><span class="lineNoCov">          0 : bool rcu_eqs_special_set(int cpu)</span></a>
<a name="397"><span class="lineNum">     397 </span>            : {</a>
<a name="398"><span class="lineNum">     398 </span><span class="lineNoCov">          0 :         int old;</span></a>
<a name="399"><span class="lineNum">     399 </span><span class="lineNoCov">          0 :         int new;</span></a>
<a name="400"><span class="lineNum">     400 </span><span class="lineNoCov">          0 :         int new_old;</span></a>
<a name="401"><span class="lineNum">     401 </span><span class="lineNoCov">          0 :         struct rcu_data *rdp = &amp;per_cpu(rcu_data, cpu);</span></a>
<a name="402"><span class="lineNum">     402 </span>            : </a>
<a name="403"><span class="lineNum">     403 </span><span class="lineNoCov">          0 :         new_old = atomic_read(&amp;rdp-&gt;dynticks);</span></a>
<a name="404"><span class="lineNum">     404 </span><span class="lineNoCov">          0 :         do {</span></a>
<a name="405"><span class="lineNum">     405 </span><span class="lineNoCov">          0 :                 old = new_old;</span></a>
<a name="406"><span class="lineNum">     406 </span><span class="lineNoCov">          0 :                 if (old &amp; RCU_DYNTICK_CTRL_CTR)</span></a>
<a name="407"><span class="lineNum">     407 </span>            :                         return false;</a>
<a name="408"><span class="lineNum">     408 </span><span class="lineNoCov">          0 :                 new = old | RCU_DYNTICK_CTRL_MASK;</span></a>
<a name="409"><span class="lineNum">     409 </span><span class="lineNoCov">          0 :                 new_old = atomic_cmpxchg(&amp;rdp-&gt;dynticks, old, new);</span></a>
<a name="410"><span class="lineNum">     410 </span><span class="lineNoCov">          0 :         } while (new_old != old);</span></a>
<a name="411"><span class="lineNum">     411 </span>            :         return true;</a>
<a name="412"><span class="lineNum">     412 </span>            : }</a>
<a name="413"><span class="lineNum">     413 </span>            : </a>
<a name="414"><span class="lineNum">     414 </span>            : /*</a>
<a name="415"><span class="lineNum">     415 </span>            :  * Let the RCU core know that this CPU has gone through the scheduler,</a>
<a name="416"><span class="lineNum">     416 </span>            :  * which is a quiescent state.  This is called when the need for a</a>
<a name="417"><span class="lineNum">     417 </span>            :  * quiescent state is urgent, so we burn an atomic operation and full</a>
<a name="418"><span class="lineNum">     418 </span>            :  * memory barriers to let the RCU core know about it, regardless of what</a>
<a name="419"><span class="lineNum">     419 </span>            :  * this CPU might (or might not) do in the near future.</a>
<a name="420"><span class="lineNum">     420 </span>            :  *</a>
<a name="421"><span class="lineNum">     421 </span>            :  * We inform the RCU core by emulating a zero-duration dyntick-idle period.</a>
<a name="422"><span class="lineNum">     422 </span>            :  *</a>
<a name="423"><span class="lineNum">     423 </span>            :  * The caller must have disabled interrupts and must not be idle.</a>
<a name="424"><span class="lineNum">     424 </span>            :  */</a>
<a name="425"><span class="lineNum">     425 </span><span class="lineCov">      45877 : notrace void rcu_momentary_dyntick_idle(void)</span></a>
<a name="426"><span class="lineNum">     426 </span>            : {</a>
<a name="427"><span class="lineNum">     427 </span><span class="lineCov">      45877 :         int special;</span></a>
<a name="428"><span class="lineNum">     428 </span>            : </a>
<a name="429"><span class="lineNum">     429 </span><span class="lineCov">      45877 :         raw_cpu_write(rcu_data.rcu_need_heavy_qs, false);</span></a>
<a name="430"><span class="lineNum">     430 </span><span class="lineCov">     144275 :         special = atomic_add_return(2 * RCU_DYNTICK_CTRL_CTR,</span></a>
<a name="431"><span class="lineNum">     431 </span><span class="lineCov">      45877 :                                     &amp;this_cpu_ptr(&amp;rcu_data)-&gt;dynticks);</span></a>
<a name="432"><span class="lineNum">     432 </span>            :         /* It is illegal to call this from idle state. */</a>
<a name="433"><span class="lineNum">     433 </span><span class="lineCov">      50826 :         WARN_ON_ONCE(!(special &amp; RCU_DYNTICK_CTRL_CTR));</span></a>
<a name="434"><span class="lineNum">     434 </span><span class="lineCov">      50826 :         rcu_preempt_deferred_qs(current);</span></a>
<a name="435"><span class="lineNum">     435 </span><span class="lineCov">      50826 : }</span></a>
<a name="436"><span class="lineNum">     436 </span>            : EXPORT_SYMBOL_GPL(rcu_momentary_dyntick_idle);</a>
<a name="437"><span class="lineNum">     437 </span>            : </a>
<a name="438"><span class="lineNum">     438 </span>            : /**</a>
<a name="439"><span class="lineNum">     439 </span>            :  * rcu_is_cpu_rrupt_from_idle - see if 'interrupted' from idle</a>
<a name="440"><span class="lineNum">     440 </span>            :  *</a>
<a name="441"><span class="lineNum">     441 </span>            :  * If the current CPU is idle and running at a first-level (not nested)</a>
<a name="442"><span class="lineNum">     442 </span>            :  * interrupt, or directly, from idle, return true.</a>
<a name="443"><span class="lineNum">     443 </span>            :  *</a>
<a name="444"><span class="lineNum">     444 </span>            :  * The caller must have at least disabled IRQs.</a>
<a name="445"><span class="lineNum">     445 </span>            :  */</a>
<a name="446"><span class="lineNum">     446 </span><span class="lineCov">      53622 : static int rcu_is_cpu_rrupt_from_idle(void)</span></a>
<a name="447"><span class="lineNum">     447 </span>            : {</a>
<a name="448"><span class="lineNum">     448 </span><span class="lineCov">      53622 :         long nesting;</span></a>
<a name="449"><span class="lineNum">     449 </span>            : </a>
<a name="450"><span class="lineNum">     450 </span>            :         /*</a>
<a name="451"><span class="lineNum">     451 </span>            :          * Usually called from the tick; but also used from smp_function_call()</a>
<a name="452"><span class="lineNum">     452 </span>            :          * for expedited grace periods. This latter can result in running from</a>
<a name="453"><span class="lineNum">     453 </span>            :          * the idle task, instead of an actual IPI.</a>
<a name="454"><span class="lineNum">     454 </span>            :          */</a>
<a name="455"><span class="lineNum">     455 </span><span class="lineCov">     107737 :         lockdep_assert_irqs_disabled();</span></a>
<a name="456"><span class="lineNum">     456 </span>            : </a>
<a name="457"><span class="lineNum">     457 </span>            :         /* Check for counter underflows */</a>
<a name="458"><span class="lineNum">     458 </span><span class="lineCov">      54248 :         RCU_LOCKDEP_WARN(__this_cpu_read(rcu_data.dynticks_nesting) &lt; 0,</span></a>
<a name="459"><span class="lineNum">     459 </span>            :                          &quot;RCU dynticks_nesting counter underflow!&quot;);</a>
<a name="460"><span class="lineNum">     460 </span><span class="lineCov">      54454 :         RCU_LOCKDEP_WARN(__this_cpu_read(rcu_data.dynticks_nmi_nesting) &lt;= 0,</span></a>
<a name="461"><span class="lineNum">     461 </span>            :                          &quot;RCU dynticks_nmi_nesting counter underflow/zero!&quot;);</a>
<a name="462"><span class="lineNum">     462 </span>            : </a>
<a name="463"><span class="lineNum">     463 </span>            :         /* Are we at first interrupt nesting level? */</a>
<a name="464"><span class="lineNum">     464 </span><span class="lineCov">      54954 :         nesting = __this_cpu_read(rcu_data.dynticks_nmi_nesting);</span></a>
<a name="465"><span class="lineNum">     465 </span><span class="lineCov">      54954 :         if (nesting &gt; 1)</span></a>
<a name="466"><span class="lineNum">     466 </span>            :                 return false;</a>
<a name="467"><span class="lineNum">     467 </span>            : </a>
<a name="468"><span class="lineNum">     468 </span>            :         /*</a>
<a name="469"><span class="lineNum">     469 </span>            :          * If we're not in an interrupt, we must be in the idle task!</a>
<a name="470"><span class="lineNum">     470 </span>            :          */</a>
<a name="471"><span class="lineNum">     471 </span><span class="lineCov">      23421 :         WARN_ON_ONCE(!nesting &amp;&amp; !is_idle_task(current));</span></a>
<a name="472"><span class="lineNum">     472 </span>            : </a>
<a name="473"><span class="lineNum">     473 </span>            :         /* Does CPU appear to be idle from an RCU standpoint? */</a>
<a name="474"><span class="lineNum">     474 </span><span class="lineCov">      23421 :         return __this_cpu_read(rcu_data.dynticks_nesting) == 0;</span></a>
<a name="475"><span class="lineNum">     475 </span>            : }</a>
<a name="476"><span class="lineNum">     476 </span>            : </a>
<a name="477"><span class="lineNum">     477 </span>            : #define DEFAULT_RCU_BLIMIT (IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD) ? 1000 : 10)</a>
<a name="478"><span class="lineNum">     478 </span>            :                                 // Maximum callbacks per rcu_do_batch ...</a>
<a name="479"><span class="lineNum">     479 </span>            : #define DEFAULT_MAX_RCU_BLIMIT 10000 // ... even during callback flood.</a>
<a name="480"><span class="lineNum">     480 </span>            : static long blimit = DEFAULT_RCU_BLIMIT;</a>
<a name="481"><span class="lineNum">     481 </span>            : #define DEFAULT_RCU_QHIMARK 10000 // If this many pending, ignore blimit.</a>
<a name="482"><span class="lineNum">     482 </span>            : static long qhimark = DEFAULT_RCU_QHIMARK;</a>
<a name="483"><span class="lineNum">     483 </span>            : #define DEFAULT_RCU_QLOMARK 100   // Once only this many pending, use blimit.</a>
<a name="484"><span class="lineNum">     484 </span>            : static long qlowmark = DEFAULT_RCU_QLOMARK;</a>
<a name="485"><span class="lineNum">     485 </span>            : #define DEFAULT_RCU_QOVLD_MULT 2</a>
<a name="486"><span class="lineNum">     486 </span>            : #define DEFAULT_RCU_QOVLD (DEFAULT_RCU_QOVLD_MULT * DEFAULT_RCU_QHIMARK)</a>
<a name="487"><span class="lineNum">     487 </span>            : static long qovld = DEFAULT_RCU_QOVLD; // If this many pending, hammer QS.</a>
<a name="488"><span class="lineNum">     488 </span>            : static long qovld_calc = -1;      // No pre-initialization lock acquisitions!</a>
<a name="489"><span class="lineNum">     489 </span>            : </a>
<a name="490"><span class="lineNum">     490 </span>            : module_param(blimit, long, 0444);</a>
<a name="491"><span class="lineNum">     491 </span>            : module_param(qhimark, long, 0444);</a>
<a name="492"><span class="lineNum">     492 </span>            : module_param(qlowmark, long, 0444);</a>
<a name="493"><span class="lineNum">     493 </span>            : module_param(qovld, long, 0444);</a>
<a name="494"><span class="lineNum">     494 </span>            : </a>
<a name="495"><span class="lineNum">     495 </span>            : static ulong jiffies_till_first_fqs = IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD) ? 0 : ULONG_MAX;</a>
<a name="496"><span class="lineNum">     496 </span>            : static ulong jiffies_till_next_fqs = ULONG_MAX;</a>
<a name="497"><span class="lineNum">     497 </span>            : static bool rcu_kick_kthreads;</a>
<a name="498"><span class="lineNum">     498 </span>            : static int rcu_divisor = 7;</a>
<a name="499"><span class="lineNum">     499 </span>            : module_param(rcu_divisor, int, 0644);</a>
<a name="500"><span class="lineNum">     500 </span>            : </a>
<a name="501"><span class="lineNum">     501 </span>            : /* Force an exit from rcu_do_batch() after 3 milliseconds. */</a>
<a name="502"><span class="lineNum">     502 </span>            : static long rcu_resched_ns = 3 * NSEC_PER_MSEC;</a>
<a name="503"><span class="lineNum">     503 </span>            : module_param(rcu_resched_ns, long, 0644);</a>
<a name="504"><span class="lineNum">     504 </span>            : </a>
<a name="505"><span class="lineNum">     505 </span>            : /*</a>
<a name="506"><span class="lineNum">     506 </span>            :  * How long the grace period must be before we start recruiting</a>
<a name="507"><span class="lineNum">     507 </span>            :  * quiescent-state help from rcu_note_context_switch().</a>
<a name="508"><span class="lineNum">     508 </span>            :  */</a>
<a name="509"><span class="lineNum">     509 </span>            : static ulong jiffies_till_sched_qs = ULONG_MAX;</a>
<a name="510"><span class="lineNum">     510 </span>            : module_param(jiffies_till_sched_qs, ulong, 0444);</a>
<a name="511"><span class="lineNum">     511 </span>            : static ulong jiffies_to_sched_qs; /* See adjust_jiffies_till_sched_qs(). */</a>
<a name="512"><span class="lineNum">     512 </span>            : module_param(jiffies_to_sched_qs, ulong, 0444); /* Display only! */</a>
<a name="513"><span class="lineNum">     513 </span>            : </a>
<a name="514"><span class="lineNum">     514 </span>            : /*</a>
<a name="515"><span class="lineNum">     515 </span>            :  * Make sure that we give the grace-period kthread time to detect any</a>
<a name="516"><span class="lineNum">     516 </span>            :  * idle CPUs before taking active measures to force quiescent states.</a>
<a name="517"><span class="lineNum">     517 </span>            :  * However, don't go below 100 milliseconds, adjusted upwards for really</a>
<a name="518"><span class="lineNum">     518 </span>            :  * large systems.</a>
<a name="519"><span class="lineNum">     519 </span>            :  */</a>
<a name="520"><span class="lineNum">     520 </span><span class="lineCov">          1 : static void adjust_jiffies_till_sched_qs(void)</span></a>
<a name="521"><span class="lineNum">     521 </span>            : {</a>
<a name="522"><span class="lineNum">     522 </span><span class="lineCov">          1 :         unsigned long j;</span></a>
<a name="523"><span class="lineNum">     523 </span>            : </a>
<a name="524"><span class="lineNum">     524 </span>            :         /* If jiffies_till_sched_qs was specified, respect the request. */</a>
<a name="525"><span class="lineNum">     525 </span><span class="lineCov">          1 :         if (jiffies_till_sched_qs != ULONG_MAX) {</span></a>
<a name="526"><span class="lineNum">     526 </span><span class="lineNoCov">          0 :                 WRITE_ONCE(jiffies_to_sched_qs, jiffies_till_sched_qs);</span></a>
<a name="527"><span class="lineNum">     527 </span><span class="lineNoCov">          0 :                 return;</span></a>
<a name="528"><span class="lineNum">     528 </span>            :         }</a>
<a name="529"><span class="lineNum">     529 </span>            :         /* Otherwise, set to third fqs scan, but bound below on large system. */</a>
<a name="530"><span class="lineNum">     530 </span><span class="lineCov">          1 :         j = READ_ONCE(jiffies_till_first_fqs) +</span></a>
<a name="531"><span class="lineNum">     531 </span><span class="lineCov">          1 :                       2 * READ_ONCE(jiffies_till_next_fqs);</span></a>
<a name="532"><span class="lineNum">     532 </span><span class="lineCov">          1 :         if (j &lt; HZ / 10 + nr_cpu_ids / RCU_JIFFIES_FQS_DIV)</span></a>
<a name="533"><span class="lineNum">     533 </span>            :                 j = HZ / 10 + nr_cpu_ids / RCU_JIFFIES_FQS_DIV;</a>
<a name="534"><span class="lineNum">     534 </span><span class="lineCov">          1 :         pr_info(&quot;RCU calculated value of scheduler-enlistment delay is %ld jiffies.\n&quot;, j);</span></a>
<a name="535"><span class="lineNum">     535 </span><span class="lineCov">          1 :         WRITE_ONCE(jiffies_to_sched_qs, j);</span></a>
<a name="536"><span class="lineNum">     536 </span>            : }</a>
<a name="537"><span class="lineNum">     537 </span>            : </a>
<a name="538"><span class="lineNum">     538 </span><span class="lineNoCov">          0 : static int param_set_first_fqs_jiffies(const char *val, const struct kernel_param *kp)</span></a>
<a name="539"><span class="lineNum">     539 </span>            : {</a>
<a name="540"><span class="lineNum">     540 </span><span class="lineNoCov">          0 :         ulong j;</span></a>
<a name="541"><span class="lineNum">     541 </span><span class="lineNoCov">          0 :         int ret = kstrtoul(val, 0, &amp;j);</span></a>
<a name="542"><span class="lineNum">     542 </span>            : </a>
<a name="543"><span class="lineNum">     543 </span><span class="lineNoCov">          0 :         if (!ret) {</span></a>
<a name="544"><span class="lineNum">     544 </span><span class="lineNoCov">          0 :                 WRITE_ONCE(*(ulong *)kp-&gt;arg, (j &gt; HZ) ? HZ : j);</span></a>
<a name="545"><span class="lineNum">     545 </span><span class="lineNoCov">          0 :                 adjust_jiffies_till_sched_qs();</span></a>
<a name="546"><span class="lineNum">     546 </span>            :         }</a>
<a name="547"><span class="lineNum">     547 </span><span class="lineNoCov">          0 :         return ret;</span></a>
<a name="548"><span class="lineNum">     548 </span>            : }</a>
<a name="549"><span class="lineNum">     549 </span>            : </a>
<a name="550"><span class="lineNum">     550 </span><span class="lineNoCov">          0 : static int param_set_next_fqs_jiffies(const char *val, const struct kernel_param *kp)</span></a>
<a name="551"><span class="lineNum">     551 </span>            : {</a>
<a name="552"><span class="lineNum">     552 </span><span class="lineNoCov">          0 :         ulong j;</span></a>
<a name="553"><span class="lineNum">     553 </span><span class="lineNoCov">          0 :         int ret = kstrtoul(val, 0, &amp;j);</span></a>
<a name="554"><span class="lineNum">     554 </span>            : </a>
<a name="555"><span class="lineNum">     555 </span><span class="lineNoCov">          0 :         if (!ret) {</span></a>
<a name="556"><span class="lineNum">     556 </span><span class="lineNoCov">          0 :                 WRITE_ONCE(*(ulong *)kp-&gt;arg, (j &gt; HZ) ? HZ : (j ?: 1));</span></a>
<a name="557"><span class="lineNum">     557 </span><span class="lineNoCov">          0 :                 adjust_jiffies_till_sched_qs();</span></a>
<a name="558"><span class="lineNum">     558 </span>            :         }</a>
<a name="559"><span class="lineNum">     559 </span><span class="lineNoCov">          0 :         return ret;</span></a>
<a name="560"><span class="lineNum">     560 </span>            : }</a>
<a name="561"><span class="lineNum">     561 </span>            : </a>
<a name="562"><span class="lineNum">     562 </span>            : static const struct kernel_param_ops first_fqs_jiffies_ops = {</a>
<a name="563"><span class="lineNum">     563 </span>            :         .set = param_set_first_fqs_jiffies,</a>
<a name="564"><span class="lineNum">     564 </span>            :         .get = param_get_ulong,</a>
<a name="565"><span class="lineNum">     565 </span>            : };</a>
<a name="566"><span class="lineNum">     566 </span>            : </a>
<a name="567"><span class="lineNum">     567 </span>            : static const struct kernel_param_ops next_fqs_jiffies_ops = {</a>
<a name="568"><span class="lineNum">     568 </span>            :         .set = param_set_next_fqs_jiffies,</a>
<a name="569"><span class="lineNum">     569 </span>            :         .get = param_get_ulong,</a>
<a name="570"><span class="lineNum">     570 </span>            : };</a>
<a name="571"><span class="lineNum">     571 </span>            : </a>
<a name="572"><span class="lineNum">     572 </span>            : module_param_cb(jiffies_till_first_fqs, &amp;first_fqs_jiffies_ops, &amp;jiffies_till_first_fqs, 0644);</a>
<a name="573"><span class="lineNum">     573 </span>            : module_param_cb(jiffies_till_next_fqs, &amp;next_fqs_jiffies_ops, &amp;jiffies_till_next_fqs, 0644);</a>
<a name="574"><span class="lineNum">     574 </span>            : module_param(rcu_kick_kthreads, bool, 0644);</a>
<a name="575"><span class="lineNum">     575 </span>            : </a>
<a name="576"><span class="lineNum">     576 </span>            : static void force_qs_rnp(int (*f)(struct rcu_data *rdp));</a>
<a name="577"><span class="lineNum">     577 </span>            : static int rcu_pending(int user);</a>
<a name="578"><span class="lineNum">     578 </span>            : </a>
<a name="579"><span class="lineNum">     579 </span>            : /*</a>
<a name="580"><span class="lineNum">     580 </span>            :  * Return the number of RCU GPs completed thus far for debug &amp; stats.</a>
<a name="581"><span class="lineNum">     581 </span>            :  */</a>
<a name="582"><span class="lineNum">     582 </span><span class="lineNoCov">          0 : unsigned long rcu_get_gp_seq(void)</span></a>
<a name="583"><span class="lineNum">     583 </span>            : {</a>
<a name="584"><span class="lineNum">     584 </span><span class="lineNoCov">          0 :         return READ_ONCE(rcu_state.gp_seq);</span></a>
<a name="585"><span class="lineNum">     585 </span>            : }</a>
<a name="586"><span class="lineNum">     586 </span>            : EXPORT_SYMBOL_GPL(rcu_get_gp_seq);</a>
<a name="587"><span class="lineNum">     587 </span>            : </a>
<a name="588"><span class="lineNum">     588 </span>            : /*</a>
<a name="589"><span class="lineNum">     589 </span>            :  * Return the number of RCU expedited batches completed thus far for</a>
<a name="590"><span class="lineNum">     590 </span>            :  * debug &amp; stats.  Odd numbers mean that a batch is in progress, even</a>
<a name="591"><span class="lineNum">     591 </span>            :  * numbers mean idle.  The value returned will thus be roughly double</a>
<a name="592"><span class="lineNum">     592 </span>            :  * the cumulative batches since boot.</a>
<a name="593"><span class="lineNum">     593 </span>            :  */</a>
<a name="594"><span class="lineNum">     594 </span><span class="lineNoCov">          0 : unsigned long rcu_exp_batches_completed(void)</span></a>
<a name="595"><span class="lineNum">     595 </span>            : {</a>
<a name="596"><span class="lineNum">     596 </span><span class="lineNoCov">          0 :         return rcu_state.expedited_sequence;</span></a>
<a name="597"><span class="lineNum">     597 </span>            : }</a>
<a name="598"><span class="lineNum">     598 </span>            : EXPORT_SYMBOL_GPL(rcu_exp_batches_completed);</a>
<a name="599"><span class="lineNum">     599 </span>            : </a>
<a name="600"><span class="lineNum">     600 </span>            : /*</a>
<a name="601"><span class="lineNum">     601 </span>            :  * Return the root node of the rcu_state structure.</a>
<a name="602"><span class="lineNum">     602 </span>            :  */</a>
<a name="603"><span class="lineNum">     603 </span><span class="lineCov">      83214 : static struct rcu_node *rcu_get_root(void)</span></a>
<a name="604"><span class="lineNum">     604 </span>            : {</a>
<a name="605"><span class="lineNum">     605 </span><span class="lineCov">      55141 :         return &amp;rcu_state.node[0];</span></a>
<a name="606"><span class="lineNum">     606 </span>            : }</a>
<a name="607"><span class="lineNum">     607 </span>            : </a>
<a name="608"><span class="lineNum">     608 </span>            : /*</a>
<a name="609"><span class="lineNum">     609 </span>            :  * Send along grace-period-related data for rcutorture diagnostics.</a>
<a name="610"><span class="lineNum">     610 </span>            :  */</a>
<a name="611"><span class="lineNum">     611 </span><span class="lineNoCov">          0 : void rcutorture_get_gp_data(enum rcutorture_type test_type, int *flags,</span></a>
<a name="612"><span class="lineNum">     612 </span>            :                             unsigned long *gp_seq)</a>
<a name="613"><span class="lineNum">     613 </span>            : {</a>
<a name="614"><span class="lineNum">     614 </span><span class="lineNoCov">          0 :         switch (test_type) {</span></a>
<a name="615"><span class="lineNum">     615 </span>            :         case RCU_FLAVOR:</a>
<a name="616"><span class="lineNum">     616 </span><span class="lineNoCov">          0 :                 *flags = READ_ONCE(rcu_state.gp_flags);</span></a>
<a name="617"><span class="lineNum">     617 </span><span class="lineNoCov">          0 :                 *gp_seq = rcu_seq_current(&amp;rcu_state.gp_seq);</span></a>
<a name="618"><span class="lineNum">     618 </span><span class="lineNoCov">          0 :                 break;</span></a>
<a name="619"><span class="lineNum">     619 </span>            :         default:</a>
<a name="620"><span class="lineNum">     620 </span>            :                 break;</a>
<a name="621"><span class="lineNum">     621 </span>            :         }</a>
<a name="622"><span class="lineNum">     622 </span><span class="lineNoCov">          0 : }</span></a>
<a name="623"><span class="lineNum">     623 </span>            : EXPORT_SYMBOL_GPL(rcutorture_get_gp_data);</a>
<a name="624"><span class="lineNum">     624 </span>            : </a>
<a name="625"><span class="lineNum">     625 </span>            : /*</a>
<a name="626"><span class="lineNum">     626 </span>            :  * Enter an RCU extended quiescent state, which can be either the</a>
<a name="627"><span class="lineNum">     627 </span>            :  * idle loop or adaptive-tickless usermode execution.</a>
<a name="628"><span class="lineNum">     628 </span>            :  *</a>
<a name="629"><span class="lineNum">     629 </span>            :  * We crowbar the -&gt;dynticks_nmi_nesting field to zero to allow for</a>
<a name="630"><span class="lineNum">     630 </span>            :  * the possibility of usermode upcalls having messed up our count</a>
<a name="631"><span class="lineNum">     631 </span>            :  * of interrupt nesting level during the prior busy period.</a>
<a name="632"><span class="lineNum">     632 </span>            :  */</a>
<a name="633"><span class="lineNum">     633 </span><span class="lineCov">      17628 : static noinstr void rcu_eqs_enter(bool user)</span></a>
<a name="634"><span class="lineNum">     634 </span>            : {</a>
<a name="635"><span class="lineNum">     635 </span><span class="lineCov">      17628 :         struct rcu_data *rdp = this_cpu_ptr(&amp;rcu_data);</span></a>
<a name="636"><span class="lineNum">     636 </span>            : </a>
<a name="637"><span class="lineNum">     637 </span><span class="lineCov">      17610 :         WARN_ON_ONCE(rdp-&gt;dynticks_nmi_nesting != DYNTICK_IRQ_NONIDLE);</span></a>
<a name="638"><span class="lineNum">     638 </span><span class="lineCov">      17610 :         WRITE_ONCE(rdp-&gt;dynticks_nmi_nesting, 0);</span></a>
<a name="639"><span class="lineNum">     639 </span><span class="lineCov">      17610 :         WARN_ON_ONCE(IS_ENABLED(CONFIG_RCU_EQS_DEBUG) &amp;&amp;</span></a>
<a name="640"><span class="lineNum">     640 </span>            :                      rdp-&gt;dynticks_nesting == 0);</a>
<a name="641"><span class="lineNum">     641 </span><span class="lineCov">      17610 :         if (rdp-&gt;dynticks_nesting != 1) {</span></a>
<a name="642"><span class="lineNum">     642 </span>            :                 // RCU will still be watching, so just do accounting and leave.</a>
<a name="643"><span class="lineNum">     643 </span><span class="lineNoCov">          0 :                 rdp-&gt;dynticks_nesting--;</span></a>
<a name="644"><span class="lineNum">     644 </span><span class="lineNoCov">          0 :                 return;</span></a>
<a name="645"><span class="lineNum">     645 </span>            :         }</a>
<a name="646"><span class="lineNum">     646 </span>            : </a>
<a name="647"><span class="lineNum">     647 </span><span class="lineCov">      35237 :         lockdep_assert_irqs_disabled();</span></a>
<a name="648"><span class="lineNum">     648 </span><span class="lineCov">      17621 :         instrumentation_begin();</span></a>
<a name="649"><span class="lineNum">     649 </span><span class="lineCov">      17621 :         trace_rcu_dyntick(TPS(&quot;Start&quot;), rdp-&gt;dynticks_nesting, 0, atomic_read(&amp;rdp-&gt;dynticks));</span></a>
<a name="650"><span class="lineNum">     650 </span><span class="lineCov">      17629 :         WARN_ON_ONCE(IS_ENABLED(CONFIG_RCU_EQS_DEBUG) &amp;&amp; !user &amp;&amp; !is_idle_task(current));</span></a>
<a name="651"><span class="lineNum">     651 </span><span class="lineCov">      17629 :         rdp = this_cpu_ptr(&amp;rcu_data);</span></a>
<a name="652"><span class="lineNum">     652 </span><span class="lineCov">      17634 :         rcu_prepare_for_idle();</span></a>
<a name="653"><span class="lineNum">     653 </span><span class="lineCov">      17634 :         rcu_preempt_deferred_qs(current);</span></a>
<a name="654"><span class="lineNum">     654 </span>            : </a>
<a name="655"><span class="lineNum">     655 </span>            :         // instrumentation for the noinstr rcu_dynticks_eqs_enter()</a>
<a name="656"><span class="lineNum">     656 </span><span class="lineCov">      17634 :         instrument_atomic_write(&amp;rdp-&gt;dynticks, sizeof(rdp-&gt;dynticks));</span></a>
<a name="657"><span class="lineNum">     657 </span>            : </a>
<a name="658"><span class="lineNum">     658 </span><span class="lineCov">      17650 :         instrumentation_end();</span></a>
<a name="659"><span class="lineNum">     659 </span><span class="lineCov">      17650 :         WRITE_ONCE(rdp-&gt;dynticks_nesting, 0); /* Avoid irq-access tearing. */</span></a>
<a name="660"><span class="lineNum">     660 </span>            :         // RCU is watching here ...</a>
<a name="661"><span class="lineNum">     661 </span><span class="lineCov">      17650 :         rcu_dynticks_eqs_enter();</span></a>
<a name="662"><span class="lineNum">     662 </span>            :         // ... but is no longer watching here.</a>
<a name="663"><span class="lineNum">     663 </span><span class="lineCov">      17650 :         rcu_dynticks_task_enter();</span></a>
<a name="664"><span class="lineNum">     664 </span>            : }</a>
<a name="665"><span class="lineNum">     665 </span>            : </a>
<a name="666"><span class="lineNum">     666 </span>            : /**</a>
<a name="667"><span class="lineNum">     667 </span>            :  * rcu_idle_enter - inform RCU that current CPU is entering idle</a>
<a name="668"><span class="lineNum">     668 </span>            :  *</a>
<a name="669"><span class="lineNum">     669 </span>            :  * Enter idle mode, in other words, -leave- the mode in which RCU</a>
<a name="670"><span class="lineNum">     670 </span>            :  * read-side critical sections can occur.  (Though RCU read-side</a>
<a name="671"><span class="lineNum">     671 </span>            :  * critical sections can occur in irq handlers in idle, a possibility</a>
<a name="672"><span class="lineNum">     672 </span>            :  * handled by irq_enter() and irq_exit().)</a>
<a name="673"><span class="lineNum">     673 </span>            :  *</a>
<a name="674"><span class="lineNum">     674 </span>            :  * If you add or remove a call to rcu_idle_enter(), be sure to test with</a>
<a name="675"><span class="lineNum">     675 </span>            :  * CONFIG_RCU_EQS_DEBUG=y.</a>
<a name="676"><span class="lineNum">     676 </span>            :  */</a>
<a name="677"><span class="lineNum">     677 </span><span class="lineCov">      17618 : void rcu_idle_enter(void)</span></a>
<a name="678"><span class="lineNum">     678 </span>            : {</a>
<a name="679"><span class="lineNum">     679 </span><span class="lineCov">      35255 :         lockdep_assert_irqs_disabled();</span></a>
<a name="680"><span class="lineNum">     680 </span><span class="lineCov">      17642 :         rcu_eqs_enter(false);</span></a>
<a name="681"><span class="lineNum">     681 </span><span class="lineCov">      17652 : }</span></a>
<a name="682"><span class="lineNum">     682 </span>            : EXPORT_SYMBOL_GPL(rcu_idle_enter);</a>
<a name="683"><span class="lineNum">     683 </span>            : </a>
<a name="684"><span class="lineNum">     684 </span>            : #ifdef CONFIG_NO_HZ_FULL</a>
<a name="685"><span class="lineNum">     685 </span>            : </a>
<a name="686"><span class="lineNum">     686 </span>            : #if !defined(CONFIG_GENERIC_ENTRY) || !defined(CONFIG_KVM_XFER_TO_GUEST_WORK)</a>
<a name="687"><span class="lineNum">     687 </span>            : /*</a>
<a name="688"><span class="lineNum">     688 </span>            :  * An empty function that will trigger a reschedule on</a>
<a name="689"><span class="lineNum">     689 </span>            :  * IRQ tail once IRQs get re-enabled on userspace/guest resume.</a>
<a name="690"><span class="lineNum">     690 </span>            :  */</a>
<a name="691"><span class="lineNum">     691 </span>            : static void late_wakeup_func(struct irq_work *work)</a>
<a name="692"><span class="lineNum">     692 </span>            : {</a>
<a name="693"><span class="lineNum">     693 </span>            : }</a>
<a name="694"><span class="lineNum">     694 </span>            : </a>
<a name="695"><span class="lineNum">     695 </span>            : static DEFINE_PER_CPU(struct irq_work, late_wakeup_work) =</a>
<a name="696"><span class="lineNum">     696 </span>            :         IRQ_WORK_INIT(late_wakeup_func);</a>
<a name="697"><span class="lineNum">     697 </span>            : </a>
<a name="698"><span class="lineNum">     698 </span>            : /*</a>
<a name="699"><span class="lineNum">     699 </span>            :  * If either:</a>
<a name="700"><span class="lineNum">     700 </span>            :  *</a>
<a name="701"><span class="lineNum">     701 </span>            :  * 1) the task is about to enter in guest mode and $ARCH doesn't support KVM generic work</a>
<a name="702"><span class="lineNum">     702 </span>            :  * 2) the task is about to enter in user mode and $ARCH doesn't support generic entry.</a>
<a name="703"><span class="lineNum">     703 </span>            :  *</a>
<a name="704"><span class="lineNum">     704 </span>            :  * In these cases the late RCU wake ups aren't supported in the resched loops and our</a>
<a name="705"><span class="lineNum">     705 </span>            :  * last resort is to fire a local irq_work that will trigger a reschedule once IRQs</a>
<a name="706"><span class="lineNum">     706 </span>            :  * get re-enabled again.</a>
<a name="707"><span class="lineNum">     707 </span>            :  */</a>
<a name="708"><span class="lineNum">     708 </span>            : noinstr static void rcu_irq_work_resched(void)</a>
<a name="709"><span class="lineNum">     709 </span>            : {</a>
<a name="710"><span class="lineNum">     710 </span>            :         struct rcu_data *rdp = this_cpu_ptr(&amp;rcu_data);</a>
<a name="711"><span class="lineNum">     711 </span>            : </a>
<a name="712"><span class="lineNum">     712 </span>            :         if (IS_ENABLED(CONFIG_GENERIC_ENTRY) &amp;&amp; !(current-&gt;flags &amp; PF_VCPU))</a>
<a name="713"><span class="lineNum">     713 </span>            :                 return;</a>
<a name="714"><span class="lineNum">     714 </span>            : </a>
<a name="715"><span class="lineNum">     715 </span>            :         if (IS_ENABLED(CONFIG_KVM_XFER_TO_GUEST_WORK) &amp;&amp; (current-&gt;flags &amp; PF_VCPU))</a>
<a name="716"><span class="lineNum">     716 </span>            :                 return;</a>
<a name="717"><span class="lineNum">     717 </span>            : </a>
<a name="718"><span class="lineNum">     718 </span>            :         instrumentation_begin();</a>
<a name="719"><span class="lineNum">     719 </span>            :         if (do_nocb_deferred_wakeup(rdp) &amp;&amp; need_resched()) {</a>
<a name="720"><span class="lineNum">     720 </span>            :                 irq_work_queue(this_cpu_ptr(&amp;late_wakeup_work));</a>
<a name="721"><span class="lineNum">     721 </span>            :         }</a>
<a name="722"><span class="lineNum">     722 </span>            :         instrumentation_end();</a>
<a name="723"><span class="lineNum">     723 </span>            : }</a>
<a name="724"><span class="lineNum">     724 </span>            : </a>
<a name="725"><span class="lineNum">     725 </span>            : #else</a>
<a name="726"><span class="lineNum">     726 </span>            : static inline void rcu_irq_work_resched(void) { }</a>
<a name="727"><span class="lineNum">     727 </span>            : #endif</a>
<a name="728"><span class="lineNum">     728 </span>            : </a>
<a name="729"><span class="lineNum">     729 </span>            : /**</a>
<a name="730"><span class="lineNum">     730 </span>            :  * rcu_user_enter - inform RCU that we are resuming userspace.</a>
<a name="731"><span class="lineNum">     731 </span>            :  *</a>
<a name="732"><span class="lineNum">     732 </span>            :  * Enter RCU idle mode right before resuming userspace.  No use of RCU</a>
<a name="733"><span class="lineNum">     733 </span>            :  * is permitted between this call and rcu_user_exit(). This way the</a>
<a name="734"><span class="lineNum">     734 </span>            :  * CPU doesn't need to maintain the tick for RCU maintenance purposes</a>
<a name="735"><span class="lineNum">     735 </span>            :  * when the CPU runs in userspace.</a>
<a name="736"><span class="lineNum">     736 </span>            :  *</a>
<a name="737"><span class="lineNum">     737 </span>            :  * If you add or remove a call to rcu_user_enter(), be sure to test with</a>
<a name="738"><span class="lineNum">     738 </span>            :  * CONFIG_RCU_EQS_DEBUG=y.</a>
<a name="739"><span class="lineNum">     739 </span>            :  */</a>
<a name="740"><span class="lineNum">     740 </span>            : noinstr void rcu_user_enter(void)</a>
<a name="741"><span class="lineNum">     741 </span>            : {</a>
<a name="742"><span class="lineNum">     742 </span>            :         lockdep_assert_irqs_disabled();</a>
<a name="743"><span class="lineNum">     743 </span>            : </a>
<a name="744"><span class="lineNum">     744 </span>            :         /*</a>
<a name="745"><span class="lineNum">     745 </span>            :          * Other than generic entry implementation, we may be past the last</a>
<a name="746"><span class="lineNum">     746 </span>            :          * rescheduling opportunity in the entry code. Trigger a self IPI</a>
<a name="747"><span class="lineNum">     747 </span>            :          * that will fire and reschedule once we resume in user/guest mode.</a>
<a name="748"><span class="lineNum">     748 </span>            :          */</a>
<a name="749"><span class="lineNum">     749 </span>            :         rcu_irq_work_resched();</a>
<a name="750"><span class="lineNum">     750 </span>            :         rcu_eqs_enter(true);</a>
<a name="751"><span class="lineNum">     751 </span>            : }</a>
<a name="752"><span class="lineNum">     752 </span>            : </a>
<a name="753"><span class="lineNum">     753 </span>            : #endif /* CONFIG_NO_HZ_FULL */</a>
<a name="754"><span class="lineNum">     754 </span>            : </a>
<a name="755"><span class="lineNum">     755 </span>            : /**</a>
<a name="756"><span class="lineNum">     756 </span>            :  * rcu_nmi_exit - inform RCU of exit from NMI context</a>
<a name="757"><span class="lineNum">     757 </span>            :  *</a>
<a name="758"><span class="lineNum">     758 </span>            :  * If we are returning from the outermost NMI handler that interrupted an</a>
<a name="759"><span class="lineNum">     759 </span>            :  * RCU-idle period, update rdp-&gt;dynticks and rdp-&gt;dynticks_nmi_nesting</a>
<a name="760"><span class="lineNum">     760 </span>            :  * to let the RCU grace-period handling know that the CPU is back to</a>
<a name="761"><span class="lineNum">     761 </span>            :  * being RCU-idle.</a>
<a name="762"><span class="lineNum">     762 </span>            :  *</a>
<a name="763"><span class="lineNum">     763 </span>            :  * If you add or remove a call to rcu_nmi_exit(), be sure to test</a>
<a name="764"><span class="lineNum">     764 </span>            :  * with CONFIG_RCU_EQS_DEBUG=y.</a>
<a name="765"><span class="lineNum">     765 </span>            :  */</a>
<a name="766"><span class="lineNum">     766 </span><span class="lineCov">      19536 : noinstr void rcu_nmi_exit(void)</span></a>
<a name="767"><span class="lineNum">     767 </span>            : {</a>
<a name="768"><span class="lineNum">     768 </span><span class="lineCov">      19536 :         struct rcu_data *rdp = this_cpu_ptr(&amp;rcu_data);</span></a>
<a name="769"><span class="lineNum">     769 </span>            : </a>
<a name="770"><span class="lineNum">     770 </span><span class="lineCov">      19555 :         instrumentation_begin();</span></a>
<a name="771"><span class="lineNum">     771 </span>            :         /*</a>
<a name="772"><span class="lineNum">     772 </span>            :          * Check for -&gt;dynticks_nmi_nesting underflow and bad -&gt;dynticks.</a>
<a name="773"><span class="lineNum">     773 </span>            :          * (We are exiting an NMI handler, so RCU better be paying attention</a>
<a name="774"><span class="lineNum">     774 </span>            :          * to us!)</a>
<a name="775"><span class="lineNum">     775 </span>            :          */</a>
<a name="776"><span class="lineNum">     776 </span><span class="lineCov">      19555 :         WARN_ON_ONCE(rdp-&gt;dynticks_nmi_nesting &lt;= 0);</span></a>
<a name="777"><span class="lineNum">     777 </span><span class="lineCov">      19555 :         WARN_ON_ONCE(rcu_dynticks_curr_cpu_in_eqs());</span></a>
<a name="778"><span class="lineNum">     778 </span>            : </a>
<a name="779"><span class="lineNum">     779 </span>            :         /*</a>
<a name="780"><span class="lineNum">     780 </span>            :          * If the nesting level is not 1, the CPU wasn't RCU-idle, so</a>
<a name="781"><span class="lineNum">     781 </span>            :          * leave it in non-RCU-idle state.</a>
<a name="782"><span class="lineNum">     782 </span>            :          */</a>
<a name="783"><span class="lineNum">     783 </span><span class="lineCov">      19548 :         if (rdp-&gt;dynticks_nmi_nesting != 1) {</span></a>
<a name="784"><span class="lineNum">     784 </span><span class="lineCov">       3394 :                 trace_rcu_dyntick(TPS(&quot;--=&quot;), rdp-&gt;dynticks_nmi_nesting, rdp-&gt;dynticks_nmi_nesting - 2,</span></a>
<a name="785"><span class="lineNum">     785 </span><span class="lineCov">       1697 :                                   atomic_read(&amp;rdp-&gt;dynticks));</span></a>
<a name="786"><span class="lineNum">     786 </span><span class="lineCov">       1697 :                 WRITE_ONCE(rdp-&gt;dynticks_nmi_nesting, /* No store tearing. */</span></a>
<a name="787"><span class="lineNum">     787 </span>            :                            rdp-&gt;dynticks_nmi_nesting - 2);</a>
<a name="788"><span class="lineNum">     788 </span><span class="lineCov">       1697 :                 instrumentation_end();</span></a>
<a name="789"><span class="lineNum">     789 </span><span class="lineCov">       1697 :                 return;</span></a>
<a name="790"><span class="lineNum">     790 </span>            :         }</a>
<a name="791"><span class="lineNum">     791 </span>            : </a>
<a name="792"><span class="lineNum">     792 </span>            :         /* This NMI interrupted an RCU-idle CPU, restore RCU-idleness. */</a>
<a name="793"><span class="lineNum">     793 </span><span class="lineCov">      17851 :         trace_rcu_dyntick(TPS(&quot;Startirq&quot;), rdp-&gt;dynticks_nmi_nesting, 0, atomic_read(&amp;rdp-&gt;dynticks));</span></a>
<a name="794"><span class="lineNum">     794 </span><span class="lineCov">      17862 :         WRITE_ONCE(rdp-&gt;dynticks_nmi_nesting, 0); /* Avoid store tearing. */</span></a>
<a name="795"><span class="lineNum">     795 </span>            : </a>
<a name="796"><span class="lineNum">     796 </span><span class="lineCov">      17862 :         if (!in_nmi())</span></a>
<a name="797"><span class="lineNum">     797 </span>            :                 rcu_prepare_for_idle();</a>
<a name="798"><span class="lineNum">     798 </span>            : </a>
<a name="799"><span class="lineNum">     799 </span>            :         // instrumentation for the noinstr rcu_dynticks_eqs_enter()</a>
<a name="800"><span class="lineNum">     800 </span><span class="lineCov">      17862 :         instrument_atomic_write(&amp;rdp-&gt;dynticks, sizeof(rdp-&gt;dynticks));</span></a>
<a name="801"><span class="lineNum">     801 </span><span class="lineCov">      17871 :         instrumentation_end();</span></a>
<a name="802"><span class="lineNum">     802 </span>            : </a>
<a name="803"><span class="lineNum">     803 </span>            :         // RCU is watching here ...</a>
<a name="804"><span class="lineNum">     804 </span><span class="lineCov">      17871 :         rcu_dynticks_eqs_enter();</span></a>
<a name="805"><span class="lineNum">     805 </span>            :         // ... but is no longer watching here.</a>
<a name="806"><span class="lineNum">     806 </span>            : </a>
<a name="807"><span class="lineNum">     807 </span><span class="lineCov">      17909 :         if (!in_nmi())</span></a>
<a name="808"><span class="lineNum">     808 </span>            :                 rcu_dynticks_task_enter();</a>
<a name="809"><span class="lineNum">     809 </span>            : }</a>
<a name="810"><span class="lineNum">     810 </span>            : </a>
<a name="811"><span class="lineNum">     811 </span>            : /**</a>
<a name="812"><span class="lineNum">     812 </span>            :  * rcu_irq_exit - inform RCU that current CPU is exiting irq towards idle</a>
<a name="813"><span class="lineNum">     813 </span>            :  *</a>
<a name="814"><span class="lineNum">     814 </span>            :  * Exit from an interrupt handler, which might possibly result in entering</a>
<a name="815"><span class="lineNum">     815 </span>            :  * idle mode, in other words, leaving the mode in which read-side critical</a>
<a name="816"><span class="lineNum">     816 </span>            :  * sections can occur.  The caller must have disabled interrupts.</a>
<a name="817"><span class="lineNum">     817 </span>            :  *</a>
<a name="818"><span class="lineNum">     818 </span>            :  * This code assumes that the idle loop never does anything that might</a>
<a name="819"><span class="lineNum">     819 </span>            :  * result in unbalanced calls to irq_enter() and irq_exit().  If your</a>
<a name="820"><span class="lineNum">     820 </span>            :  * architecture's idle loop violates this assumption, RCU will give you what</a>
<a name="821"><span class="lineNum">     821 </span>            :  * you deserve, good and hard.  But very infrequently and irreproducibly.</a>
<a name="822"><span class="lineNum">     822 </span>            :  *</a>
<a name="823"><span class="lineNum">     823 </span>            :  * Use things like work queues to work around this limitation.</a>
<a name="824"><span class="lineNum">     824 </span>            :  *</a>
<a name="825"><span class="lineNum">     825 </span>            :  * You have been warned.</a>
<a name="826"><span class="lineNum">     826 </span>            :  *</a>
<a name="827"><span class="lineNum">     827 </span>            :  * If you add or remove a call to rcu_irq_exit(), be sure to test with</a>
<a name="828"><span class="lineNum">     828 </span>            :  * CONFIG_RCU_EQS_DEBUG=y.</a>
<a name="829"><span class="lineNum">     829 </span>            :  */</a>
<a name="830"><span class="lineNum">     830 </span><span class="lineCov">      19537 : void noinstr rcu_irq_exit(void)</span></a>
<a name="831"><span class="lineNum">     831 </span>            : {</a>
<a name="832"><span class="lineNum">     832 </span><span class="lineCov">      39110 :         lockdep_assert_irqs_disabled();</span></a>
<a name="833"><span class="lineNum">     833 </span><span class="lineCov">      19573 :         rcu_nmi_exit();</span></a>
<a name="834"><span class="lineNum">     834 </span><span class="lineCov">      19604 : }</span></a>
<a name="835"><span class="lineNum">     835 </span>            : </a>
<a name="836"><span class="lineNum">     836 </span>            : /**</a>
<a name="837"><span class="lineNum">     837 </span>            :  * rcu_irq_exit_preempt - Inform RCU that current CPU is exiting irq</a>
<a name="838"><span class="lineNum">     838 </span>            :  *                        towards in kernel preemption</a>
<a name="839"><span class="lineNum">     839 </span>            :  *</a>
<a name="840"><span class="lineNum">     840 </span>            :  * Same as rcu_irq_exit() but has a sanity check that scheduling is safe</a>
<a name="841"><span class="lineNum">     841 </span>            :  * from RCU point of view. Invoked from return from interrupt before kernel</a>
<a name="842"><span class="lineNum">     842 </span>            :  * preemption.</a>
<a name="843"><span class="lineNum">     843 </span>            :  */</a>
<a name="844"><span class="lineNum">     844 </span><span class="lineNoCov">          0 : void rcu_irq_exit_preempt(void)</span></a>
<a name="845"><span class="lineNum">     845 </span>            : {</a>
<a name="846"><span class="lineNum">     846 </span><span class="lineNoCov">          0 :         lockdep_assert_irqs_disabled();</span></a>
<a name="847"><span class="lineNum">     847 </span><span class="lineNoCov">          0 :         rcu_nmi_exit();</span></a>
<a name="848"><span class="lineNum">     848 </span>            : </a>
<a name="849"><span class="lineNum">     849 </span><span class="lineNoCov">          0 :         RCU_LOCKDEP_WARN(__this_cpu_read(rcu_data.dynticks_nesting) &lt;= 0,</span></a>
<a name="850"><span class="lineNum">     850 </span>            :                          &quot;RCU dynticks_nesting counter underflow/zero!&quot;);</a>
<a name="851"><span class="lineNum">     851 </span><span class="lineNoCov">          0 :         RCU_LOCKDEP_WARN(__this_cpu_read(rcu_data.dynticks_nmi_nesting) !=</span></a>
<a name="852"><span class="lineNum">     852 </span>            :                          DYNTICK_IRQ_NONIDLE,</a>
<a name="853"><span class="lineNum">     853 </span>            :                          &quot;Bad RCU  dynticks_nmi_nesting counter\n&quot;);</a>
<a name="854"><span class="lineNum">     854 </span><span class="lineNoCov">          0 :         RCU_LOCKDEP_WARN(rcu_dynticks_curr_cpu_in_eqs(),</span></a>
<a name="855"><span class="lineNum">     855 </span>            :                          &quot;RCU in extended quiescent state!&quot;);</a>
<a name="856"><span class="lineNum">     856 </span><span class="lineNoCov">          0 : }</span></a>
<a name="857"><span class="lineNum">     857 </span>            : </a>
<a name="858"><span class="lineNum">     858 </span>            : #ifdef CONFIG_PROVE_RCU</a>
<a name="859"><span class="lineNum">     859 </span>            : /**</a>
<a name="860"><span class="lineNum">     860 </span>            :  * rcu_irq_exit_check_preempt - Validate that scheduling is possible</a>
<a name="861"><span class="lineNum">     861 </span>            :  */</a>
<a name="862"><span class="lineNum">     862 </span><span class="lineNoCov">          0 : void rcu_irq_exit_check_preempt(void)</span></a>
<a name="863"><span class="lineNum">     863 </span>            : {</a>
<a name="864"><span class="lineNum">     864 </span><span class="lineNoCov">          0 :         lockdep_assert_irqs_disabled();</span></a>
<a name="865"><span class="lineNum">     865 </span>            : </a>
<a name="866"><span class="lineNum">     866 </span><span class="lineNoCov">          0 :         RCU_LOCKDEP_WARN(__this_cpu_read(rcu_data.dynticks_nesting) &lt;= 0,</span></a>
<a name="867"><span class="lineNum">     867 </span>            :                          &quot;RCU dynticks_nesting counter underflow/zero!&quot;);</a>
<a name="868"><span class="lineNum">     868 </span><span class="lineNoCov">          0 :         RCU_LOCKDEP_WARN(__this_cpu_read(rcu_data.dynticks_nmi_nesting) !=</span></a>
<a name="869"><span class="lineNum">     869 </span>            :                          DYNTICK_IRQ_NONIDLE,</a>
<a name="870"><span class="lineNum">     870 </span>            :                          &quot;Bad RCU  dynticks_nmi_nesting counter\n&quot;);</a>
<a name="871"><span class="lineNum">     871 </span><span class="lineNoCov">          0 :         RCU_LOCKDEP_WARN(rcu_dynticks_curr_cpu_in_eqs(),</span></a>
<a name="872"><span class="lineNum">     872 </span>            :                          &quot;RCU in extended quiescent state!&quot;);</a>
<a name="873"><span class="lineNum">     873 </span><span class="lineNoCov">          0 : }</span></a>
<a name="874"><span class="lineNum">     874 </span>            : #endif /* #ifdef CONFIG_PROVE_RCU */</a>
<a name="875"><span class="lineNum">     875 </span>            : </a>
<a name="876"><span class="lineNum">     876 </span>            : /*</a>
<a name="877"><span class="lineNum">     877 </span>            :  * Wrapper for rcu_irq_exit() where interrupts are enabled.</a>
<a name="878"><span class="lineNum">     878 </span>            :  *</a>
<a name="879"><span class="lineNum">     879 </span>            :  * If you add or remove a call to rcu_irq_exit_irqson(), be sure to test</a>
<a name="880"><span class="lineNum">     880 </span>            :  * with CONFIG_RCU_EQS_DEBUG=y.</a>
<a name="881"><span class="lineNum">     881 </span>            :  */</a>
<a name="882"><span class="lineNum">     882 </span><span class="lineNoCov">          0 : void rcu_irq_exit_irqson(void)</span></a>
<a name="883"><span class="lineNum">     883 </span>            : {</a>
<a name="884"><span class="lineNum">     884 </span><span class="lineNoCov">          0 :         unsigned long flags;</span></a>
<a name="885"><span class="lineNum">     885 </span>            : </a>
<a name="886"><span class="lineNum">     886 </span><span class="lineNoCov">          0 :         local_irq_save(flags);</span></a>
<a name="887"><span class="lineNum">     887 </span><span class="lineNoCov">          0 :         rcu_irq_exit();</span></a>
<a name="888"><span class="lineNum">     888 </span><span class="lineNoCov">          0 :         local_irq_restore(flags);</span></a>
<a name="889"><span class="lineNum">     889 </span><span class="lineNoCov">          0 : }</span></a>
<a name="890"><span class="lineNum">     890 </span>            : </a>
<a name="891"><span class="lineNum">     891 </span>            : /*</a>
<a name="892"><span class="lineNum">     892 </span>            :  * Exit an RCU extended quiescent state, which can be either the</a>
<a name="893"><span class="lineNum">     893 </span>            :  * idle loop or adaptive-tickless usermode execution.</a>
<a name="894"><span class="lineNum">     894 </span>            :  *</a>
<a name="895"><span class="lineNum">     895 </span>            :  * We crowbar the -&gt;dynticks_nmi_nesting field to DYNTICK_IRQ_NONIDLE to</a>
<a name="896"><span class="lineNum">     896 </span>            :  * allow for the possibility of usermode upcalls messing up our count of</a>
<a name="897"><span class="lineNum">     897 </span>            :  * interrupt nesting level during the busy period that is just now starting.</a>
<a name="898"><span class="lineNum">     898 </span>            :  */</a>
<a name="899"><span class="lineNum">     899 </span><span class="lineCov">      17624 : static void noinstr rcu_eqs_exit(bool user)</span></a>
<a name="900"><span class="lineNum">     900 </span>            : {</a>
<a name="901"><span class="lineNum">     901 </span><span class="lineCov">      17624 :         struct rcu_data *rdp;</span></a>
<a name="902"><span class="lineNum">     902 </span><span class="lineCov">      17624 :         long oldval;</span></a>
<a name="903"><span class="lineNum">     903 </span>            : </a>
<a name="904"><span class="lineNum">     904 </span><span class="lineCov">      35254 :         lockdep_assert_irqs_disabled();</span></a>
<a name="905"><span class="lineNum">     905 </span><span class="lineCov">      17634 :         rdp = this_cpu_ptr(&amp;rcu_data);</span></a>
<a name="906"><span class="lineNum">     906 </span><span class="lineCov">      17636 :         oldval = rdp-&gt;dynticks_nesting;</span></a>
<a name="907"><span class="lineNum">     907 </span><span class="lineCov">      17636 :         WARN_ON_ONCE(IS_ENABLED(CONFIG_RCU_EQS_DEBUG) &amp;&amp; oldval &lt; 0);</span></a>
<a name="908"><span class="lineNum">     908 </span><span class="lineCov">      17636 :         if (oldval) {</span></a>
<a name="909"><span class="lineNum">     909 </span>            :                 // RCU was already watching, so just do accounting and leave.</a>
<a name="910"><span class="lineNum">     910 </span><span class="lineNoCov">          0 :                 rdp-&gt;dynticks_nesting++;</span></a>
<a name="911"><span class="lineNum">     911 </span><span class="lineNoCov">          0 :                 return;</span></a>
<a name="912"><span class="lineNum">     912 </span>            :         }</a>
<a name="913"><span class="lineNum">     913 </span><span class="lineCov">      17636 :         rcu_dynticks_task_exit();</span></a>
<a name="914"><span class="lineNum">     914 </span>            :         // RCU is not watching here ...</a>
<a name="915"><span class="lineNum">     915 </span><span class="lineCov">      17636 :         rcu_dynticks_eqs_exit();</span></a>
<a name="916"><span class="lineNum">     916 </span>            :         // ... but is watching here.</a>
<a name="917"><span class="lineNum">     917 </span><span class="lineCov">      17654 :         instrumentation_begin();</span></a>
<a name="918"><span class="lineNum">     918 </span>            : </a>
<a name="919"><span class="lineNum">     919 </span>            :         // instrumentation for the noinstr rcu_dynticks_eqs_exit()</a>
<a name="920"><span class="lineNum">     920 </span><span class="lineCov">      17654 :         instrument_atomic_write(&amp;rdp-&gt;dynticks, sizeof(rdp-&gt;dynticks));</span></a>
<a name="921"><span class="lineNum">     921 </span>            : </a>
<a name="922"><span class="lineNum">     922 </span><span class="lineCov">      17617 :         rcu_cleanup_after_idle();</span></a>
<a name="923"><span class="lineNum">     923 </span><span class="lineCov">      17617 :         trace_rcu_dyntick(TPS(&quot;End&quot;), rdp-&gt;dynticks_nesting, 1, atomic_read(&amp;rdp-&gt;dynticks));</span></a>
<a name="924"><span class="lineNum">     924 </span><span class="lineCov">      17633 :         WARN_ON_ONCE(IS_ENABLED(CONFIG_RCU_EQS_DEBUG) &amp;&amp; !user &amp;&amp; !is_idle_task(current));</span></a>
<a name="925"><span class="lineNum">     925 </span><span class="lineCov">      17633 :         WRITE_ONCE(rdp-&gt;dynticks_nesting, 1);</span></a>
<a name="926"><span class="lineNum">     926 </span><span class="lineCov">      17633 :         WARN_ON_ONCE(rdp-&gt;dynticks_nmi_nesting);</span></a>
<a name="927"><span class="lineNum">     927 </span><span class="lineCov">      17633 :         WRITE_ONCE(rdp-&gt;dynticks_nmi_nesting, DYNTICK_IRQ_NONIDLE);</span></a>
<a name="928"><span class="lineNum">     928 </span><span class="lineCov">      17633 :         instrumentation_end();</span></a>
<a name="929"><span class="lineNum">     929 </span>            : }</a>
<a name="930"><span class="lineNum">     930 </span>            : </a>
<a name="931"><span class="lineNum">     931 </span>            : /**</a>
<a name="932"><span class="lineNum">     932 </span>            :  * rcu_idle_exit - inform RCU that current CPU is leaving idle</a>
<a name="933"><span class="lineNum">     933 </span>            :  *</a>
<a name="934"><span class="lineNum">     934 </span>            :  * Exit idle mode, in other words, -enter- the mode in which RCU</a>
<a name="935"><span class="lineNum">     935 </span>            :  * read-side critical sections can occur.</a>
<a name="936"><span class="lineNum">     936 </span>            :  *</a>
<a name="937"><span class="lineNum">     937 </span>            :  * If you add or remove a call to rcu_idle_exit(), be sure to test with</a>
<a name="938"><span class="lineNum">     938 </span>            :  * CONFIG_RCU_EQS_DEBUG=y.</a>
<a name="939"><span class="lineNum">     939 </span>            :  */</a>
<a name="940"><span class="lineNum">     940 </span><span class="lineCov">      17569 : void rcu_idle_exit(void)</span></a>
<a name="941"><span class="lineNum">     941 </span>            : {</a>
<a name="942"><span class="lineNum">     942 </span><span class="lineCov">      17569 :         unsigned long flags;</span></a>
<a name="943"><span class="lineNum">     943 </span>            : </a>
<a name="944"><span class="lineNum">     944 </span><span class="lineCov">      35197 :         local_irq_save(flags);</span></a>
<a name="945"><span class="lineNum">     945 </span><span class="lineCov">      17628 :         rcu_eqs_exit(false);</span></a>
<a name="946"><span class="lineNum">     946 </span><span class="lineCov">      17634 :         local_irq_restore(flags);</span></a>
<a name="947"><span class="lineNum">     947 </span><span class="lineCov">      17637 : }</span></a>
<a name="948"><span class="lineNum">     948 </span>            : EXPORT_SYMBOL_GPL(rcu_idle_exit);</a>
<a name="949"><span class="lineNum">     949 </span>            : </a>
<a name="950"><span class="lineNum">     950 </span>            : #ifdef CONFIG_NO_HZ_FULL</a>
<a name="951"><span class="lineNum">     951 </span>            : /**</a>
<a name="952"><span class="lineNum">     952 </span>            :  * rcu_user_exit - inform RCU that we are exiting userspace.</a>
<a name="953"><span class="lineNum">     953 </span>            :  *</a>
<a name="954"><span class="lineNum">     954 </span>            :  * Exit RCU idle mode while entering the kernel because it can</a>
<a name="955"><span class="lineNum">     955 </span>            :  * run a RCU read side critical section anytime.</a>
<a name="956"><span class="lineNum">     956 </span>            :  *</a>
<a name="957"><span class="lineNum">     957 </span>            :  * If you add or remove a call to rcu_user_exit(), be sure to test with</a>
<a name="958"><span class="lineNum">     958 </span>            :  * CONFIG_RCU_EQS_DEBUG=y.</a>
<a name="959"><span class="lineNum">     959 </span>            :  */</a>
<a name="960"><span class="lineNum">     960 </span>            : void noinstr rcu_user_exit(void)</a>
<a name="961"><span class="lineNum">     961 </span>            : {</a>
<a name="962"><span class="lineNum">     962 </span>            :         rcu_eqs_exit(1);</a>
<a name="963"><span class="lineNum">     963 </span>            : }</a>
<a name="964"><span class="lineNum">     964 </span>            : </a>
<a name="965"><span class="lineNum">     965 </span>            : /**</a>
<a name="966"><span class="lineNum">     966 </span>            :  * __rcu_irq_enter_check_tick - Enable scheduler tick on CPU if RCU needs it.</a>
<a name="967"><span class="lineNum">     967 </span>            :  *</a>
<a name="968"><span class="lineNum">     968 </span>            :  * The scheduler tick is not normally enabled when CPUs enter the kernel</a>
<a name="969"><span class="lineNum">     969 </span>            :  * from nohz_full userspace execution.  After all, nohz_full userspace</a>
<a name="970"><span class="lineNum">     970 </span>            :  * execution is an RCU quiescent state and the time executing in the kernel</a>
<a name="971"><span class="lineNum">     971 </span>            :  * is quite short.  Except of course when it isn't.  And it is not hard to</a>
<a name="972"><span class="lineNum">     972 </span>            :  * cause a large system to spend tens of seconds or even minutes looping</a>
<a name="973"><span class="lineNum">     973 </span>            :  * in the kernel, which can cause a number of problems, include RCU CPU</a>
<a name="974"><span class="lineNum">     974 </span>            :  * stall warnings.</a>
<a name="975"><span class="lineNum">     975 </span>            :  *</a>
<a name="976"><span class="lineNum">     976 </span>            :  * Therefore, if a nohz_full CPU fails to report a quiescent state</a>
<a name="977"><span class="lineNum">     977 </span>            :  * in a timely manner, the RCU grace-period kthread sets that CPU's</a>
<a name="978"><span class="lineNum">     978 </span>            :  * -&gt;rcu_urgent_qs flag with the expectation that the next interrupt or</a>
<a name="979"><span class="lineNum">     979 </span>            :  * exception will invoke this function, which will turn on the scheduler</a>
<a name="980"><span class="lineNum">     980 </span>            :  * tick, which will enable RCU to detect that CPU's quiescent states,</a>
<a name="981"><span class="lineNum">     981 </span>            :  * for example, due to cond_resched() calls in CONFIG_PREEMPT=n kernels.</a>
<a name="982"><span class="lineNum">     982 </span>            :  * The tick will be disabled once a quiescent state is reported for</a>
<a name="983"><span class="lineNum">     983 </span>            :  * this CPU.</a>
<a name="984"><span class="lineNum">     984 </span>            :  *</a>
<a name="985"><span class="lineNum">     985 </span>            :  * Of course, in carefully tuned systems, there might never be an</a>
<a name="986"><span class="lineNum">     986 </span>            :  * interrupt or exception.  In that case, the RCU grace-period kthread</a>
<a name="987"><span class="lineNum">     987 </span>            :  * will eventually cause one to happen.  However, in less carefully</a>
<a name="988"><span class="lineNum">     988 </span>            :  * controlled environments, this function allows RCU to get what it</a>
<a name="989"><span class="lineNum">     989 </span>            :  * needs without creating otherwise useless interruptions.</a>
<a name="990"><span class="lineNum">     990 </span>            :  */</a>
<a name="991"><span class="lineNum">     991 </span>            : void __rcu_irq_enter_check_tick(void)</a>
<a name="992"><span class="lineNum">     992 </span>            : {</a>
<a name="993"><span class="lineNum">     993 </span>            :         struct rcu_data *rdp = this_cpu_ptr(&amp;rcu_data);</a>
<a name="994"><span class="lineNum">     994 </span>            : </a>
<a name="995"><span class="lineNum">     995 </span>            :         // If we're here from NMI there's nothing to do.</a>
<a name="996"><span class="lineNum">     996 </span>            :         if (in_nmi())</a>
<a name="997"><span class="lineNum">     997 </span>            :                 return;</a>
<a name="998"><span class="lineNum">     998 </span>            : </a>
<a name="999"><span class="lineNum">     999 </span>            :         RCU_LOCKDEP_WARN(rcu_dynticks_curr_cpu_in_eqs(),</a>
<a name="1000"><span class="lineNum">    1000 </span>            :                          &quot;Illegal rcu_irq_enter_check_tick() from extended quiescent state&quot;);</a>
<a name="1001"><span class="lineNum">    1001 </span>            : </a>
<a name="1002"><span class="lineNum">    1002 </span>            :         if (!tick_nohz_full_cpu(rdp-&gt;cpu) ||</a>
<a name="1003"><span class="lineNum">    1003 </span>            :             !READ_ONCE(rdp-&gt;rcu_urgent_qs) ||</a>
<a name="1004"><span class="lineNum">    1004 </span>            :             READ_ONCE(rdp-&gt;rcu_forced_tick)) {</a>
<a name="1005"><span class="lineNum">    1005 </span>            :                 // RCU doesn't need nohz_full help from this CPU, or it is</a>
<a name="1006"><span class="lineNum">    1006 </span>            :                 // already getting that help.</a>
<a name="1007"><span class="lineNum">    1007 </span>            :                 return;</a>
<a name="1008"><span class="lineNum">    1008 </span>            :         }</a>
<a name="1009"><span class="lineNum">    1009 </span>            : </a>
<a name="1010"><span class="lineNum">    1010 </span>            :         // We get here only when not in an extended quiescent state and</a>
<a name="1011"><span class="lineNum">    1011 </span>            :         // from interrupts (as opposed to NMIs).  Therefore, (1) RCU is</a>
<a name="1012"><span class="lineNum">    1012 </span>            :         // already watching and (2) The fact that we are in an interrupt</a>
<a name="1013"><span class="lineNum">    1013 </span>            :         // handler and that the rcu_node lock is an irq-disabled lock</a>
<a name="1014"><span class="lineNum">    1014 </span>            :         // prevents self-deadlock.  So we can safely recheck under the lock.</a>
<a name="1015"><span class="lineNum">    1015 </span>            :         // Note that the nohz_full state currently cannot change.</a>
<a name="1016"><span class="lineNum">    1016 </span>            :         raw_spin_lock_rcu_node(rdp-&gt;mynode);</a>
<a name="1017"><span class="lineNum">    1017 </span>            :         if (rdp-&gt;rcu_urgent_qs &amp;&amp; !rdp-&gt;rcu_forced_tick) {</a>
<a name="1018"><span class="lineNum">    1018 </span>            :                 // A nohz_full CPU is in the kernel and RCU needs a</a>
<a name="1019"><span class="lineNum">    1019 </span>            :                 // quiescent state.  Turn on the tick!</a>
<a name="1020"><span class="lineNum">    1020 </span>            :                 WRITE_ONCE(rdp-&gt;rcu_forced_tick, true);</a>
<a name="1021"><span class="lineNum">    1021 </span>            :                 tick_dep_set_cpu(rdp-&gt;cpu, TICK_DEP_BIT_RCU);</a>
<a name="1022"><span class="lineNum">    1022 </span>            :         }</a>
<a name="1023"><span class="lineNum">    1023 </span>            :         raw_spin_unlock_rcu_node(rdp-&gt;mynode);</a>
<a name="1024"><span class="lineNum">    1024 </span>            : }</a>
<a name="1025"><span class="lineNum">    1025 </span>            : #endif /* CONFIG_NO_HZ_FULL */</a>
<a name="1026"><span class="lineNum">    1026 </span>            : </a>
<a name="1027"><span class="lineNum">    1027 </span>            : /**</a>
<a name="1028"><span class="lineNum">    1028 </span>            :  * rcu_nmi_enter - inform RCU of entry to NMI context</a>
<a name="1029"><span class="lineNum">    1029 </span>            :  *</a>
<a name="1030"><span class="lineNum">    1030 </span>            :  * If the CPU was idle from RCU's viewpoint, update rdp-&gt;dynticks and</a>
<a name="1031"><span class="lineNum">    1031 </span>            :  * rdp-&gt;dynticks_nmi_nesting to let the RCU grace-period handling know</a>
<a name="1032"><span class="lineNum">    1032 </span>            :  * that the CPU is active.  This implementation permits nested NMIs, as</a>
<a name="1033"><span class="lineNum">    1033 </span>            :  * long as the nesting level does not overflow an int.  (You will probably</a>
<a name="1034"><span class="lineNum">    1034 </span>            :  * run out of stack space first.)</a>
<a name="1035"><span class="lineNum">    1035 </span>            :  *</a>
<a name="1036"><span class="lineNum">    1036 </span>            :  * If you add or remove a call to rcu_nmi_enter(), be sure to test</a>
<a name="1037"><span class="lineNum">    1037 </span>            :  * with CONFIG_RCU_EQS_DEBUG=y.</a>
<a name="1038"><span class="lineNum">    1038 </span>            :  */</a>
<a name="1039"><span class="lineNum">    1039 </span><span class="lineCov">      19341 : noinstr void rcu_nmi_enter(void)</span></a>
<a name="1040"><span class="lineNum">    1040 </span>            : {</a>
<a name="1041"><span class="lineNum">    1041 </span><span class="lineCov">      19341 :         long incby = 2;</span></a>
<a name="1042"><span class="lineNum">    1042 </span><span class="lineCov">      19341 :         struct rcu_data *rdp = this_cpu_ptr(&amp;rcu_data);</span></a>
<a name="1043"><span class="lineNum">    1043 </span>            : </a>
<a name="1044"><span class="lineNum">    1044 </span>            :         /* Complain about underflow. */</a>
<a name="1045"><span class="lineNum">    1045 </span><span class="lineCov">      19475 :         WARN_ON_ONCE(rdp-&gt;dynticks_nmi_nesting &lt; 0);</span></a>
<a name="1046"><span class="lineNum">    1046 </span>            : </a>
<a name="1047"><span class="lineNum">    1047 </span>            :         /*</a>
<a name="1048"><span class="lineNum">    1048 </span>            :          * If idle from RCU viewpoint, atomically increment -&gt;dynticks</a>
<a name="1049"><span class="lineNum">    1049 </span>            :          * to mark non-idle and increment -&gt;dynticks_nmi_nesting by one.</a>
<a name="1050"><span class="lineNum">    1050 </span>            :          * Otherwise, increment -&gt;dynticks_nmi_nesting by two.  This means</a>
<a name="1051"><span class="lineNum">    1051 </span>            :          * if -&gt;dynticks_nmi_nesting is equal to one, we are guaranteed</a>
<a name="1052"><span class="lineNum">    1052 </span>            :          * to be in the outermost NMI handler that interrupted an RCU-idle</a>
<a name="1053"><span class="lineNum">    1053 </span>            :          * period (observation due to Andy Lutomirski).</a>
<a name="1054"><span class="lineNum">    1054 </span>            :          */</a>
<a name="1055"><span class="lineNum">    1055 </span><span class="lineCov">      19475 :         if (rcu_dynticks_curr_cpu_in_eqs()) {</span></a>
<a name="1056"><span class="lineNum">    1056 </span>            : </a>
<a name="1057"><span class="lineNum">    1057 </span><span class="lineCov">      17866 :                 if (!in_nmi())</span></a>
<a name="1058"><span class="lineNum">    1058 </span>            :                         rcu_dynticks_task_exit();</a>
<a name="1059"><span class="lineNum">    1059 </span>            : </a>
<a name="1060"><span class="lineNum">    1060 </span>            :                 // RCU is not watching here ...</a>
<a name="1061"><span class="lineNum">    1061 </span><span class="lineCov">      17866 :                 rcu_dynticks_eqs_exit();</span></a>
<a name="1062"><span class="lineNum">    1062 </span>            :                 // ... but is watching here.</a>
<a name="1063"><span class="lineNum">    1063 </span>            : </a>
<a name="1064"><span class="lineNum">    1064 </span><span class="lineCov">      17815 :                 if (!in_nmi()) {</span></a>
<a name="1065"><span class="lineNum">    1065 </span>            :                         instrumentation_begin();</a>
<a name="1066"><span class="lineNum">    1066 </span>            :                         rcu_cleanup_after_idle();</a>
<a name="1067"><span class="lineNum">    1067 </span><span class="lineCov">      17815 :                         instrumentation_end();</span></a>
<a name="1068"><span class="lineNum">    1068 </span>            :                 }</a>
<a name="1069"><span class="lineNum">    1069 </span>            : </a>
<a name="1070"><span class="lineNum">    1070 </span><span class="lineCov">      17815 :                 instrumentation_begin();</span></a>
<a name="1071"><span class="lineNum">    1071 </span>            :                 // instrumentation for the noinstr rcu_dynticks_curr_cpu_in_eqs()</a>
<a name="1072"><span class="lineNum">    1072 </span><span class="lineCov">      17815 :                 instrument_atomic_read(&amp;rdp-&gt;dynticks, sizeof(rdp-&gt;dynticks));</span></a>
<a name="1073"><span class="lineNum">    1073 </span>            :                 // instrumentation for the noinstr rcu_dynticks_eqs_exit()</a>
<a name="1074"><span class="lineNum">    1074 </span><span class="lineCov">      17720 :                 instrument_atomic_write(&amp;rdp-&gt;dynticks, sizeof(rdp-&gt;dynticks));</span></a>
<a name="1075"><span class="lineNum">    1075 </span>            : </a>
<a name="1076"><span class="lineNum">    1076 </span><span class="lineCov">      17720 :                 incby = 1;</span></a>
<a name="1077"><span class="lineNum">    1077 </span><span class="lineCov">       1698 :         } else if (!in_nmi()) {</span></a>
<a name="1078"><span class="lineNum">    1078 </span>            :                 instrumentation_begin();</a>
<a name="1079"><span class="lineNum">    1079 </span>            :                 rcu_irq_enter_check_tick();</a>
<a name="1080"><span class="lineNum">    1080 </span>            :                 instrumentation_end();</a>
<a name="1081"><span class="lineNum">    1081 </span>            :         } else  {</a>
<a name="1082"><span class="lineNum">    1082 </span><span class="lineCov">      19538 :                 instrumentation_begin();</span></a>
<a name="1083"><span class="lineNum">    1083 </span>            :         }</a>
<a name="1084"><span class="lineNum">    1084 </span>            : </a>
<a name="1085"><span class="lineNum">    1085 </span><span class="lineCov">      38999 :         trace_rcu_dyntick(incby == 1 ? TPS(&quot;Endirq&quot;) : TPS(&quot;++=&quot;),</span></a>
<a name="1086"><span class="lineNum">    1086 </span>            :                           rdp-&gt;dynticks_nmi_nesting,</a>
<a name="1087"><span class="lineNum">    1087 </span><span class="lineCov">      19538 :                           rdp-&gt;dynticks_nmi_nesting + incby, atomic_read(&amp;rdp-&gt;dynticks));</span></a>
<a name="1088"><span class="lineNum">    1088 </span><span class="lineCov">      19461 :         instrumentation_end();</span></a>
<a name="1089"><span class="lineNum">    1089 </span><span class="lineCov">      19461 :         WRITE_ONCE(rdp-&gt;dynticks_nmi_nesting, /* Prevent store tearing. */</span></a>
<a name="1090"><span class="lineNum">    1090 </span>            :                    rdp-&gt;dynticks_nmi_nesting + incby);</a>
<a name="1091"><span class="lineNum">    1091 </span><span class="lineCov">      19461 :         barrier();</span></a>
<a name="1092"><span class="lineNum">    1092 </span><span class="lineCov">      19477 : }</span></a>
<a name="1093"><span class="lineNum">    1093 </span>            : </a>
<a name="1094"><span class="lineNum">    1094 </span>            : /**</a>
<a name="1095"><span class="lineNum">    1095 </span>            :  * rcu_irq_enter - inform RCU that current CPU is entering irq away from idle</a>
<a name="1096"><span class="lineNum">    1096 </span>            :  *</a>
<a name="1097"><span class="lineNum">    1097 </span>            :  * Enter an interrupt handler, which might possibly result in exiting</a>
<a name="1098"><span class="lineNum">    1098 </span>            :  * idle mode, in other words, entering the mode in which read-side critical</a>
<a name="1099"><span class="lineNum">    1099 </span>            :  * sections can occur.  The caller must have disabled interrupts.</a>
<a name="1100"><span class="lineNum">    1100 </span>            :  *</a>
<a name="1101"><span class="lineNum">    1101 </span>            :  * Note that the Linux kernel is fully capable of entering an interrupt</a>
<a name="1102"><span class="lineNum">    1102 </span>            :  * handler that it never exits, for example when doing upcalls to user mode!</a>
<a name="1103"><span class="lineNum">    1103 </span>            :  * This code assumes that the idle loop never does upcalls to user mode.</a>
<a name="1104"><span class="lineNum">    1104 </span>            :  * If your architecture's idle loop does do upcalls to user mode (or does</a>
<a name="1105"><span class="lineNum">    1105 </span>            :  * anything else that results in unbalanced calls to the irq_enter() and</a>
<a name="1106"><span class="lineNum">    1106 </span>            :  * irq_exit() functions), RCU will give you what you deserve, good and hard.</a>
<a name="1107"><span class="lineNum">    1107 </span>            :  * But very infrequently and irreproducibly.</a>
<a name="1108"><span class="lineNum">    1108 </span>            :  *</a>
<a name="1109"><span class="lineNum">    1109 </span>            :  * Use things like work queues to work around this limitation.</a>
<a name="1110"><span class="lineNum">    1110 </span>            :  *</a>
<a name="1111"><span class="lineNum">    1111 </span>            :  * You have been warned.</a>
<a name="1112"><span class="lineNum">    1112 </span>            :  *</a>
<a name="1113"><span class="lineNum">    1113 </span>            :  * If you add or remove a call to rcu_irq_enter(), be sure to test with</a>
<a name="1114"><span class="lineNum">    1114 </span>            :  * CONFIG_RCU_EQS_DEBUG=y.</a>
<a name="1115"><span class="lineNum">    1115 </span>            :  */</a>
<a name="1116"><span class="lineNum">    1116 </span><span class="lineCov">      19336 : noinstr void rcu_irq_enter(void)</span></a>
<a name="1117"><span class="lineNum">    1117 </span>            : {</a>
<a name="1118"><span class="lineNum">    1118 </span><span class="lineCov">      38690 :         lockdep_assert_irqs_disabled();</span></a>
<a name="1119"><span class="lineNum">    1119 </span><span class="lineCov">      19350 :         rcu_nmi_enter();</span></a>
<a name="1120"><span class="lineNum">    1120 </span><span class="lineCov">      19471 : }</span></a>
<a name="1121"><span class="lineNum">    1121 </span>            : </a>
<a name="1122"><span class="lineNum">    1122 </span>            : /*</a>
<a name="1123"><span class="lineNum">    1123 </span>            :  * Wrapper for rcu_irq_enter() where interrupts are enabled.</a>
<a name="1124"><span class="lineNum">    1124 </span>            :  *</a>
<a name="1125"><span class="lineNum">    1125 </span>            :  * If you add or remove a call to rcu_irq_enter_irqson(), be sure to test</a>
<a name="1126"><span class="lineNum">    1126 </span>            :  * with CONFIG_RCU_EQS_DEBUG=y.</a>
<a name="1127"><span class="lineNum">    1127 </span>            :  */</a>
<a name="1128"><span class="lineNum">    1128 </span><span class="lineNoCov">          0 : void rcu_irq_enter_irqson(void)</span></a>
<a name="1129"><span class="lineNum">    1129 </span>            : {</a>
<a name="1130"><span class="lineNum">    1130 </span><span class="lineNoCov">          0 :         unsigned long flags;</span></a>
<a name="1131"><span class="lineNum">    1131 </span>            : </a>
<a name="1132"><span class="lineNum">    1132 </span><span class="lineNoCov">          0 :         local_irq_save(flags);</span></a>
<a name="1133"><span class="lineNum">    1133 </span><span class="lineNoCov">          0 :         rcu_irq_enter();</span></a>
<a name="1134"><span class="lineNum">    1134 </span><span class="lineNoCov">          0 :         local_irq_restore(flags);</span></a>
<a name="1135"><span class="lineNum">    1135 </span><span class="lineNoCov">          0 : }</span></a>
<a name="1136"><span class="lineNum">    1136 </span>            : </a>
<a name="1137"><span class="lineNum">    1137 </span>            : /*</a>
<a name="1138"><span class="lineNum">    1138 </span>            :  * If any sort of urgency was applied to the current CPU (for example,</a>
<a name="1139"><span class="lineNum">    1139 </span>            :  * the scheduler-clock interrupt was enabled on a nohz_full CPU) in order</a>
<a name="1140"><span class="lineNum">    1140 </span>            :  * to get to a quiescent state, disable it.</a>
<a name="1141"><span class="lineNum">    1141 </span>            :  */</a>
<a name="1142"><span class="lineNum">    1142 </span><span class="lineCov">       8463 : static void rcu_disable_urgency_upon_qs(struct rcu_data *rdp)</span></a>
<a name="1143"><span class="lineNum">    1143 </span>            : {</a>
<a name="1144"><span class="lineNum">    1144 </span><span class="lineCov">      16926 :         raw_lockdep_assert_held_rcu_node(rdp-&gt;mynode);</span></a>
<a name="1145"><span class="lineNum">    1145 </span><span class="lineCov">       8463 :         WRITE_ONCE(rdp-&gt;rcu_urgent_qs, false);</span></a>
<a name="1146"><span class="lineNum">    1146 </span><span class="lineCov">       8463 :         WRITE_ONCE(rdp-&gt;rcu_need_heavy_qs, false);</span></a>
<a name="1147"><span class="lineNum">    1147 </span><span class="lineCov">       8463 :         if (tick_nohz_full_cpu(rdp-&gt;cpu) &amp;&amp; rdp-&gt;rcu_forced_tick) {</span></a>
<a name="1148"><span class="lineNum">    1148 </span>            :                 tick_dep_clear_cpu(rdp-&gt;cpu, TICK_DEP_BIT_RCU);</a>
<a name="1149"><span class="lineNum">    1149 </span><span class="lineCov">       8463 :                 WRITE_ONCE(rdp-&gt;rcu_forced_tick, false);</span></a>
<a name="1150"><span class="lineNum">    1150 </span>            :         }</a>
<a name="1151"><span class="lineNum">    1151 </span><span class="lineCov">       8463 : }</span></a>
<a name="1152"><span class="lineNum">    1152 </span>            : </a>
<a name="1153"><span class="lineNum">    1153 </span>            : /**</a>
<a name="1154"><span class="lineNum">    1154 </span>            :  * rcu_is_watching - see if RCU thinks that the current CPU is not idle</a>
<a name="1155"><span class="lineNum">    1155 </span>            :  *</a>
<a name="1156"><span class="lineNum">    1156 </span>            :  * Return true if RCU is watching the running CPU, which means that this</a>
<a name="1157"><span class="lineNum">    1157 </span>            :  * CPU can safely enter RCU read-side critical sections.  In other words,</a>
<a name="1158"><span class="lineNum">    1158 </span>            :  * if the current CPU is not in its idle loop or is in an interrupt or</a>
<a name="1159"><span class="lineNum">    1159 </span>            :  * NMI handler, return true.</a>
<a name="1160"><span class="lineNum">    1160 </span>            :  *</a>
<a name="1161"><span class="lineNum">    1161 </span>            :  * Make notrace because it can be called by the internal functions of</a>
<a name="1162"><span class="lineNum">    1162 </span>            :  * ftrace, and making this notrace removes unnecessary recursion calls.</a>
<a name="1163"><span class="lineNum">    1163 </span>            :  */</a>
<a name="1164"><span class="lineNum">    1164 </span><span class="lineCov">   40629246 : notrace bool rcu_is_watching(void)</span></a>
<a name="1165"><span class="lineNum">    1165 </span>            : {</a>
<a name="1166"><span class="lineNum">    1166 </span><span class="lineCov">   40629246 :         bool ret;</span></a>
<a name="1167"><span class="lineNum">    1167 </span>            : </a>
<a name="1168"><span class="lineNum">    1168 </span><span class="lineCov">   40002263 :         preempt_disable_notrace();</span></a>
<a name="1169"><span class="lineNum">    1169 </span><span class="lineCov">   40642452 :         ret = !rcu_dynticks_curr_cpu_in_eqs();</span></a>
<a name="1170"><span class="lineNum">    1170 </span><span class="lineCov">   40681711 :         preempt_enable_notrace();</span></a>
<a name="1171"><span class="lineNum">    1171 </span><span class="lineNoCov">          0 :         return ret;</span></a>
<a name="1172"><span class="lineNum">    1172 </span>            : }</a>
<a name="1173"><span class="lineNum">    1173 </span>            : EXPORT_SYMBOL_GPL(rcu_is_watching);</a>
<a name="1174"><span class="lineNum">    1174 </span>            : </a>
<a name="1175"><span class="lineNum">    1175 </span>            : /*</a>
<a name="1176"><span class="lineNum">    1176 </span>            :  * If a holdout task is actually running, request an urgent quiescent</a>
<a name="1177"><span class="lineNum">    1177 </span>            :  * state from its CPU.  This is unsynchronized, so migrations can cause</a>
<a name="1178"><span class="lineNum">    1178 </span>            :  * the request to go to the wrong CPU.  Which is OK, all that will happen</a>
<a name="1179"><span class="lineNum">    1179 </span>            :  * is that the CPU's next context switch will be a bit slower and next</a>
<a name="1180"><span class="lineNum">    1180 </span>            :  * time around this task will generate another request.</a>
<a name="1181"><span class="lineNum">    1181 </span>            :  */</a>
<a name="1182"><span class="lineNum">    1182 </span><span class="lineNoCov">          0 : void rcu_request_urgent_qs_task(struct task_struct *t)</span></a>
<a name="1183"><span class="lineNum">    1183 </span>            : {</a>
<a name="1184"><span class="lineNum">    1184 </span><span class="lineNoCov">          0 :         int cpu;</span></a>
<a name="1185"><span class="lineNum">    1185 </span>            : </a>
<a name="1186"><span class="lineNum">    1186 </span><span class="lineNoCov">          0 :         barrier();</span></a>
<a name="1187"><span class="lineNum">    1187 </span><span class="lineNoCov">          0 :         cpu = task_cpu(t);</span></a>
<a name="1188"><span class="lineNum">    1188 </span><span class="lineNoCov">          0 :         if (!task_curr(t))</span></a>
<a name="1189"><span class="lineNum">    1189 </span>            :                 return; /* This task is not running on that CPU. */</a>
<a name="1190"><span class="lineNum">    1190 </span><span class="lineNoCov">          0 :         smp_store_release(per_cpu_ptr(&amp;rcu_data.rcu_urgent_qs, cpu), true);</span></a>
<a name="1191"><span class="lineNum">    1191 </span>            : }</a>
<a name="1192"><span class="lineNum">    1192 </span>            : </a>
<a name="1193"><span class="lineNum">    1193 </span>            : #if defined(CONFIG_PROVE_RCU) &amp;&amp; defined(CONFIG_HOTPLUG_CPU)</a>
<a name="1194"><span class="lineNum">    1194 </span>            : </a>
<a name="1195"><span class="lineNum">    1195 </span>            : /*</a>
<a name="1196"><span class="lineNum">    1196 </span>            :  * Is the current CPU online as far as RCU is concerned?</a>
<a name="1197"><span class="lineNum">    1197 </span>            :  *</a>
<a name="1198"><span class="lineNum">    1198 </span>            :  * Disable preemption to avoid false positives that could otherwise</a>
<a name="1199"><span class="lineNum">    1199 </span>            :  * happen due to the current CPU number being sampled, this task being</a>
<a name="1200"><span class="lineNum">    1200 </span>            :  * preempted, its old CPU being taken offline, resuming on some other CPU,</a>
<a name="1201"><span class="lineNum">    1201 </span>            :  * then determining that its old CPU is now offline.</a>
<a name="1202"><span class="lineNum">    1202 </span>            :  *</a>
<a name="1203"><span class="lineNum">    1203 </span>            :  * Disable checking if in an NMI handler because we cannot safely</a>
<a name="1204"><span class="lineNum">    1204 </span>            :  * report errors from NMI handlers anyway.  In addition, it is OK to use</a>
<a name="1205"><span class="lineNum">    1205 </span>            :  * RCU on an offline processor during initial boot, hence the check for</a>
<a name="1206"><span class="lineNum">    1206 </span>            :  * rcu_scheduler_fully_active.</a>
<a name="1207"><span class="lineNum">    1207 </span>            :  */</a>
<a name="1208"><span class="lineNum">    1208 </span><span class="lineCov">   35061682 : bool rcu_lockdep_current_cpu_online(void)</span></a>
<a name="1209"><span class="lineNum">    1209 </span>            : {</a>
<a name="1210"><span class="lineNum">    1210 </span><span class="lineCov">   35061682 :         struct rcu_data *rdp;</span></a>
<a name="1211"><span class="lineNum">    1211 </span><span class="lineCov">   35061682 :         struct rcu_node *rnp;</span></a>
<a name="1212"><span class="lineNum">    1212 </span><span class="lineCov">   35061682 :         bool ret = false;</span></a>
<a name="1213"><span class="lineNum">    1213 </span>            : </a>
<a name="1214"><span class="lineNum">    1214 </span><span class="lineCov">   35061682 :         if (in_nmi() || !rcu_scheduler_fully_active)</span></a>
<a name="1215"><span class="lineNum">    1215 </span>            :                 return true;</a>
<a name="1216"><span class="lineNum">    1216 </span><span class="lineCov">   35057314 :         preempt_disable_notrace();</span></a>
<a name="1217"><span class="lineNum">    1217 </span><span class="lineCov">   35009728 :         rdp = this_cpu_ptr(&amp;rcu_data);</span></a>
<a name="1218"><span class="lineNum">    1218 </span><span class="lineCov">   35066630 :         rnp = rdp-&gt;mynode;</span></a>
<a name="1219"><span class="lineNum">    1219 </span><span class="lineCov">   35066630 :         if (rdp-&gt;grpmask &amp; rcu_rnp_online_cpus(rnp) || READ_ONCE(rnp-&gt;ofl_seq) &amp; 0x1)</span></a>
<a name="1220"><span class="lineNum">    1220 </span><span class="lineCov">   35066630 :                 ret = true;</span></a>
<a name="1221"><span class="lineNum">    1221 </span><span class="lineCov">   35066630 :         preempt_enable_notrace();</span></a>
<a name="1222"><span class="lineNum">    1222 </span><span class="lineCov">   35070479 :         return ret;</span></a>
<a name="1223"><span class="lineNum">    1223 </span>            : }</a>
<a name="1224"><span class="lineNum">    1224 </span>            : EXPORT_SYMBOL_GPL(rcu_lockdep_current_cpu_online);</a>
<a name="1225"><span class="lineNum">    1225 </span>            : </a>
<a name="1226"><span class="lineNum">    1226 </span>            : #endif /* #if defined(CONFIG_PROVE_RCU) &amp;&amp; defined(CONFIG_HOTPLUG_CPU) */</a>
<a name="1227"><span class="lineNum">    1227 </span>            : </a>
<a name="1228"><span class="lineNum">    1228 </span>            : /*</a>
<a name="1229"><span class="lineNum">    1229 </span>            :  * We are reporting a quiescent state on behalf of some other CPU, so</a>
<a name="1230"><span class="lineNum">    1230 </span>            :  * it is our responsibility to check for and handle potential overflow</a>
<a name="1231"><span class="lineNum">    1231 </span>            :  * of the rcu_node -&gt;gp_seq counter with respect to the rcu_data counters.</a>
<a name="1232"><span class="lineNum">    1232 </span>            :  * After all, the CPU might be in deep idle state, and thus executing no</a>
<a name="1233"><span class="lineNum">    1233 </span>            :  * code whatsoever.</a>
<a name="1234"><span class="lineNum">    1234 </span>            :  */</a>
<a name="1235"><span class="lineNum">    1235 </span><span class="lineCov">      10996 : static void rcu_gpnum_ovf(struct rcu_node *rnp, struct rcu_data *rdp)</span></a>
<a name="1236"><span class="lineNum">    1236 </span>            : {</a>
<a name="1237"><span class="lineNum">    1237 </span><span class="lineCov">      21992 :         raw_lockdep_assert_held_rcu_node(rnp);</span></a>
<a name="1238"><span class="lineNum">    1238 </span><span class="lineCov">      10996 :         if (ULONG_CMP_LT(rcu_seq_current(&amp;rdp-&gt;gp_seq) + ULONG_MAX / 4,</span></a>
<a name="1239"><span class="lineNum">    1239 </span>            :                          rnp-&gt;gp_seq))</a>
<a name="1240"><span class="lineNum">    1240 </span><span class="lineNoCov">          0 :                 WRITE_ONCE(rdp-&gt;gpwrap, true);</span></a>
<a name="1241"><span class="lineNum">    1241 </span><span class="lineCov">      10996 :         if (ULONG_CMP_LT(rdp-&gt;rcu_iw_gp_seq + ULONG_MAX / 4, rnp-&gt;gp_seq))</span></a>
<a name="1242"><span class="lineNum">    1242 </span><span class="lineNoCov">          0 :                 rdp-&gt;rcu_iw_gp_seq = rnp-&gt;gp_seq + ULONG_MAX / 4;</span></a>
<a name="1243"><span class="lineNum">    1243 </span><span class="lineCov">      10996 : }</span></a>
<a name="1244"><span class="lineNum">    1244 </span>            : </a>
<a name="1245"><span class="lineNum">    1245 </span>            : /*</a>
<a name="1246"><span class="lineNum">    1246 </span>            :  * Snapshot the specified CPU's dynticks counter so that we can later</a>
<a name="1247"><span class="lineNum">    1247 </span>            :  * credit them with an implicit quiescent state.  Return 1 if this CPU</a>
<a name="1248"><span class="lineNum">    1248 </span>            :  * is in dynticks idle mode, which is an extended quiescent state.</a>
<a name="1249"><span class="lineNum">    1249 </span>            :  */</a>
<a name="1250"><span class="lineNum">    1250 </span><span class="lineCov">       2578 : static int dyntick_save_progress_counter(struct rcu_data *rdp)</span></a>
<a name="1251"><span class="lineNum">    1251 </span>            : {</a>
<a name="1252"><span class="lineNum">    1252 </span><span class="lineCov">       2578 :         rdp-&gt;dynticks_snap = rcu_dynticks_snap(rdp);</span></a>
<a name="1253"><span class="lineNum">    1253 </span><span class="lineCov">       2578 :         if (rcu_dynticks_in_eqs(rdp-&gt;dynticks_snap)) {</span></a>
<a name="1254"><span class="lineNum">    1254 </span><span class="lineCov">        883 :                 trace_rcu_fqs(rcu_state.name, rdp-&gt;gp_seq, rdp-&gt;cpu, TPS(&quot;dti&quot;));</span></a>
<a name="1255"><span class="lineNum">    1255 </span><span class="lineCov">        883 :                 rcu_gpnum_ovf(rdp-&gt;mynode, rdp);</span></a>
<a name="1256"><span class="lineNum">    1256 </span><span class="lineCov">        883 :                 return 1;</span></a>
<a name="1257"><span class="lineNum">    1257 </span>            :         }</a>
<a name="1258"><span class="lineNum">    1258 </span>            :         return 0;</a>
<a name="1259"><span class="lineNum">    1259 </span>            : }</a>
<a name="1260"><span class="lineNum">    1260 </span>            : </a>
<a name="1261"><span class="lineNum">    1261 </span>            : /*</a>
<a name="1262"><span class="lineNum">    1262 </span>            :  * Return true if the specified CPU has passed through a quiescent</a>
<a name="1263"><span class="lineNum">    1263 </span>            :  * state by virtue of being in or having passed through an dynticks</a>
<a name="1264"><span class="lineNum">    1264 </span>            :  * idle state since the last call to dyntick_save_progress_counter()</a>
<a name="1265"><span class="lineNum">    1265 </span>            :  * for this same CPU, or by virtue of having been offline.</a>
<a name="1266"><span class="lineNum">    1266 </span>            :  */</a>
<a name="1267"><span class="lineNum">    1267 </span><span class="lineCov">        970 : static int rcu_implicit_dynticks_qs(struct rcu_data *rdp)</span></a>
<a name="1268"><span class="lineNum">    1268 </span>            : {</a>
<a name="1269"><span class="lineNum">    1269 </span><span class="lineCov">        970 :         unsigned long jtsq;</span></a>
<a name="1270"><span class="lineNum">    1270 </span><span class="lineCov">        970 :         bool *rnhqp;</span></a>
<a name="1271"><span class="lineNum">    1271 </span><span class="lineCov">        970 :         bool *ruqp;</span></a>
<a name="1272"><span class="lineNum">    1272 </span><span class="lineCov">        970 :         struct rcu_node *rnp = rdp-&gt;mynode;</span></a>
<a name="1273"><span class="lineNum">    1273 </span>            : </a>
<a name="1274"><span class="lineNum">    1274 </span>            :         /*</a>
<a name="1275"><span class="lineNum">    1275 </span>            :          * If the CPU passed through or entered a dynticks idle phase with</a>
<a name="1276"><span class="lineNum">    1276 </span>            :          * no active irq/NMI handlers, then we can safely pretend that the CPU</a>
<a name="1277"><span class="lineNum">    1277 </span>            :          * already acknowledged the request to pass through a quiescent</a>
<a name="1278"><span class="lineNum">    1278 </span>            :          * state.  Either way, that CPU cannot possibly be in an RCU</a>
<a name="1279"><span class="lineNum">    1279 </span>            :          * read-side critical section that started before the beginning</a>
<a name="1280"><span class="lineNum">    1280 </span>            :          * of the current RCU grace period.</a>
<a name="1281"><span class="lineNum">    1281 </span>            :          */</a>
<a name="1282"><span class="lineNum">    1282 </span><span class="lineCov">        970 :         if (rcu_dynticks_in_eqs_since(rdp, rdp-&gt;dynticks_snap)) {</span></a>
<a name="1283"><span class="lineNum">    1283 </span><span class="lineCov">         48 :                 trace_rcu_fqs(rcu_state.name, rdp-&gt;gp_seq, rdp-&gt;cpu, TPS(&quot;dti&quot;));</span></a>
<a name="1284"><span class="lineNum">    1284 </span><span class="lineCov">         48 :                 rcu_gpnum_ovf(rnp, rdp);</span></a>
<a name="1285"><span class="lineNum">    1285 </span><span class="lineCov">         48 :                 return 1;</span></a>
<a name="1286"><span class="lineNum">    1286 </span>            :         }</a>
<a name="1287"><span class="lineNum">    1287 </span>            : </a>
<a name="1288"><span class="lineNum">    1288 </span>            :         /*</a>
<a name="1289"><span class="lineNum">    1289 </span>            :          * Complain if a CPU that is considered to be offline from RCU's</a>
<a name="1290"><span class="lineNum">    1290 </span>            :          * perspective has not yet reported a quiescent state.  After all,</a>
<a name="1291"><span class="lineNum">    1291 </span>            :          * the offline CPU should have reported a quiescent state during</a>
<a name="1292"><span class="lineNum">    1292 </span>            :          * the CPU-offline process, or, failing that, by rcu_gp_init()</a>
<a name="1293"><span class="lineNum">    1293 </span>            :          * if it ran concurrently with either the CPU going offline or the</a>
<a name="1294"><span class="lineNum">    1294 </span>            :          * last task on a leaf rcu_node structure exiting its RCU read-side</a>
<a name="1295"><span class="lineNum">    1295 </span>            :          * critical section while all CPUs corresponding to that structure</a>
<a name="1296"><span class="lineNum">    1296 </span>            :          * are offline.  This added warning detects bugs in any of these</a>
<a name="1297"><span class="lineNum">    1297 </span>            :          * code paths.</a>
<a name="1298"><span class="lineNum">    1298 </span>            :          *</a>
<a name="1299"><span class="lineNum">    1299 </span>            :          * The rcu_node structure's -&gt;lock is held here, which excludes</a>
<a name="1300"><span class="lineNum">    1300 </span>            :          * the relevant portions the CPU-hotplug code, the grace-period</a>
<a name="1301"><span class="lineNum">    1301 </span>            :          * initialization code, and the rcu_read_unlock() code paths.</a>
<a name="1302"><span class="lineNum">    1302 </span>            :          *</a>
<a name="1303"><span class="lineNum">    1303 </span>            :          * For more detail, please refer to the &quot;Hotplug CPU&quot; section</a>
<a name="1304"><span class="lineNum">    1304 </span>            :          * of RCU's Requirements documentation.</a>
<a name="1305"><span class="lineNum">    1305 </span>            :          */</a>
<a name="1306"><span class="lineNum">    1306 </span><span class="lineCov">        922 :         if (WARN_ON_ONCE(!(rdp-&gt;grpmask &amp; rcu_rnp_online_cpus(rnp)))) {</span></a>
<a name="1307"><span class="lineNum">    1307 </span><span class="lineNoCov">          0 :                 bool onl;</span></a>
<a name="1308"><span class="lineNum">    1308 </span><span class="lineNoCov">          0 :                 struct rcu_node *rnp1;</span></a>
<a name="1309"><span class="lineNum">    1309 </span>            : </a>
<a name="1310"><span class="lineNum">    1310 </span><span class="lineNoCov">          0 :                 pr_info(&quot;%s: grp: %d-%d level: %d -&gt;gp_seq %ld -&gt;completedqs %ld\n&quot;,</span></a>
<a name="1311"><span class="lineNum">    1311 </span>            :                         __func__, rnp-&gt;grplo, rnp-&gt;grphi, rnp-&gt;level,</a>
<a name="1312"><span class="lineNum">    1312 </span>            :                         (long)rnp-&gt;gp_seq, (long)rnp-&gt;completedqs);</a>
<a name="1313"><span class="lineNum">    1313 </span><span class="lineNoCov">          0 :                 for (rnp1 = rnp; rnp1; rnp1 = rnp1-&gt;parent)</span></a>
<a name="1314"><span class="lineNum">    1314 </span><span class="lineNoCov">          0 :                         pr_info(&quot;%s: %d:%d -&gt;qsmask %#lx -&gt;qsmaskinit %#lx -&gt;qsmaskinitnext %#lx -&gt;rcu_gp_init_mask %#lx\n&quot;,</span></a>
<a name="1315"><span class="lineNum">    1315 </span>            :                                 __func__, rnp1-&gt;grplo, rnp1-&gt;grphi, rnp1-&gt;qsmask, rnp1-&gt;qsmaskinit, rnp1-&gt;qsmaskinitnext, rnp1-&gt;rcu_gp_init_mask);</a>
<a name="1316"><span class="lineNum">    1316 </span><span class="lineNoCov">          0 :                 onl = !!(rdp-&gt;grpmask &amp; rcu_rnp_online_cpus(rnp));</span></a>
<a name="1317"><span class="lineNum">    1317 </span><span class="lineNoCov">          0 :                 pr_info(&quot;%s %d: %c online: %ld(%d) offline: %ld(%d)\n&quot;,</span></a>
<a name="1318"><span class="lineNum">    1318 </span>            :                         __func__, rdp-&gt;cpu, &quot;.o&quot;[onl],</a>
<a name="1319"><span class="lineNum">    1319 </span>            :                         (long)rdp-&gt;rcu_onl_gp_seq, rdp-&gt;rcu_onl_gp_flags,</a>
<a name="1320"><span class="lineNum">    1320 </span>            :                         (long)rdp-&gt;rcu_ofl_gp_seq, rdp-&gt;rcu_ofl_gp_flags);</a>
<a name="1321"><span class="lineNum">    1321 </span><span class="lineNoCov">          0 :                 return 1; /* Break things loose after complaining. */</span></a>
<a name="1322"><span class="lineNum">    1322 </span>            :         }</a>
<a name="1323"><span class="lineNum">    1323 </span>            : </a>
<a name="1324"><span class="lineNum">    1324 </span>            :         /*</a>
<a name="1325"><span class="lineNum">    1325 </span>            :          * A CPU running for an extended time within the kernel can</a>
<a name="1326"><span class="lineNum">    1326 </span>            :          * delay RCU grace periods: (1) At age jiffies_to_sched_qs,</a>
<a name="1327"><span class="lineNum">    1327 </span>            :          * set .rcu_urgent_qs, (2) At age 2*jiffies_to_sched_qs, set</a>
<a name="1328"><span class="lineNum">    1328 </span>            :          * both .rcu_need_heavy_qs and .rcu_urgent_qs.  Note that the</a>
<a name="1329"><span class="lineNum">    1329 </span>            :          * unsynchronized assignments to the per-CPU rcu_need_heavy_qs</a>
<a name="1330"><span class="lineNum">    1330 </span>            :          * variable are safe because the assignments are repeated if this</a>
<a name="1331"><span class="lineNum">    1331 </span>            :          * CPU failed to pass through a quiescent state.  This code</a>
<a name="1332"><span class="lineNum">    1332 </span>            :          * also checks .jiffies_resched in case jiffies_to_sched_qs</a>
<a name="1333"><span class="lineNum">    1333 </span>            :          * is set way high.</a>
<a name="1334"><span class="lineNum">    1334 </span>            :          */</a>
<a name="1335"><span class="lineNum">    1335 </span><span class="lineCov">        922 :         jtsq = READ_ONCE(jiffies_to_sched_qs);</span></a>
<a name="1336"><span class="lineNum">    1336 </span><span class="lineCov">        922 :         ruqp = per_cpu_ptr(&amp;rcu_data.rcu_urgent_qs, rdp-&gt;cpu);</span></a>
<a name="1337"><span class="lineNum">    1337 </span><span class="lineCov">        922 :         rnhqp = &amp;per_cpu(rcu_data.rcu_need_heavy_qs, rdp-&gt;cpu);</span></a>
<a name="1338"><span class="lineNum">    1338 </span><span class="lineCov">        922 :         if (!READ_ONCE(*rnhqp) &amp;&amp;</span></a>
<a name="1339"><span class="lineNum">    1339 </span><span class="lineCov">        922 :             (time_after(jiffies, rcu_state.gp_start + jtsq * 2) ||</span></a>
<a name="1340"><span class="lineNum">    1340 </span><span class="lineCov">        922 :              time_after(jiffies, rcu_state.jiffies_resched) ||</span></a>
<a name="1341"><span class="lineNum">    1341 </span><span class="lineCov">        922 :              rcu_state.cbovld)) {</span></a>
<a name="1342"><span class="lineNum">    1342 </span><span class="lineNoCov">          0 :                 WRITE_ONCE(*rnhqp, true);</span></a>
<a name="1343"><span class="lineNum">    1343 </span>            :                 /* Store rcu_need_heavy_qs before rcu_urgent_qs. */</a>
<a name="1344"><span class="lineNum">    1344 </span><span class="lineNoCov">          0 :                 smp_store_release(ruqp, true);</span></a>
<a name="1345"><span class="lineNum">    1345 </span><span class="lineCov">        922 :         } else if (time_after(jiffies, rcu_state.gp_start + jtsq)) {</span></a>
<a name="1346"><span class="lineNum">    1346 </span><span class="lineCov">         14 :                 WRITE_ONCE(*ruqp, true);</span></a>
<a name="1347"><span class="lineNum">    1347 </span>            :         }</a>
<a name="1348"><span class="lineNum">    1348 </span>            : </a>
<a name="1349"><span class="lineNum">    1349 </span>            :         /*</a>
<a name="1350"><span class="lineNum">    1350 </span>            :          * NO_HZ_FULL CPUs can run in-kernel without rcu_sched_clock_irq!</a>
<a name="1351"><span class="lineNum">    1351 </span>            :          * The above code handles this, but only for straight cond_resched().</a>
<a name="1352"><span class="lineNum">    1352 </span>            :          * And some in-kernel loops check need_resched() before calling</a>
<a name="1353"><span class="lineNum">    1353 </span>            :          * cond_resched(), which defeats the above code for CPUs that are</a>
<a name="1354"><span class="lineNum">    1354 </span>            :          * running in-kernel with scheduling-clock interrupts disabled.</a>
<a name="1355"><span class="lineNum">    1355 </span>            :          * So hit them over the head with the resched_cpu() hammer!</a>
<a name="1356"><span class="lineNum">    1356 </span>            :          */</a>
<a name="1357"><span class="lineNum">    1357 </span><span class="lineCov">        922 :         if (tick_nohz_full_cpu(rdp-&gt;cpu) &amp;&amp;</span></a>
<a name="1358"><span class="lineNum">    1358 </span>            :             (time_after(jiffies, READ_ONCE(rdp-&gt;last_fqs_resched) + jtsq * 3) ||</a>
<a name="1359"><span class="lineNum">    1359 </span>            :              rcu_state.cbovld)) {</a>
<a name="1360"><span class="lineNum">    1360 </span>            :                 WRITE_ONCE(*ruqp, true);</a>
<a name="1361"><span class="lineNum">    1361 </span>            :                 resched_cpu(rdp-&gt;cpu);</a>
<a name="1362"><span class="lineNum">    1362 </span><span class="lineCov">        922 :                 WRITE_ONCE(rdp-&gt;last_fqs_resched, jiffies);</span></a>
<a name="1363"><span class="lineNum">    1363 </span>            :         }</a>
<a name="1364"><span class="lineNum">    1364 </span>            : </a>
<a name="1365"><span class="lineNum">    1365 </span>            :         /*</a>
<a name="1366"><span class="lineNum">    1366 </span>            :          * If more than halfway to RCU CPU stall-warning time, invoke</a>
<a name="1367"><span class="lineNum">    1367 </span>            :          * resched_cpu() more frequently to try to loosen things up a bit.</a>
<a name="1368"><span class="lineNum">    1368 </span>            :          * Also check to see if the CPU is getting hammered with interrupts,</a>
<a name="1369"><span class="lineNum">    1369 </span>            :          * but only once per grace period, just to keep the IPIs down to</a>
<a name="1370"><span class="lineNum">    1370 </span>            :          * a dull roar.</a>
<a name="1371"><span class="lineNum">    1371 </span>            :          */</a>
<a name="1372"><span class="lineNum">    1372 </span><span class="lineCov">        922 :         if (time_after(jiffies, rcu_state.jiffies_resched)) {</span></a>
<a name="1373"><span class="lineNum">    1373 </span><span class="lineNoCov">          0 :                 if (time_after(jiffies,</span></a>
<a name="1374"><span class="lineNum">    1374 </span>            :                                READ_ONCE(rdp-&gt;last_fqs_resched) + jtsq)) {</a>
<a name="1375"><span class="lineNum">    1375 </span><span class="lineNoCov">          0 :                         resched_cpu(rdp-&gt;cpu);</span></a>
<a name="1376"><span class="lineNum">    1376 </span><span class="lineNoCov">          0 :                         WRITE_ONCE(rdp-&gt;last_fqs_resched, jiffies);</span></a>
<a name="1377"><span class="lineNum">    1377 </span>            :                 }</a>
<a name="1378"><span class="lineNum">    1378 </span><span class="lineNoCov">          0 :                 if (IS_ENABLED(CONFIG_IRQ_WORK) &amp;&amp;</span></a>
<a name="1379"><span class="lineNum">    1379 </span><span class="lineNoCov">          0 :                     !rdp-&gt;rcu_iw_pending &amp;&amp; rdp-&gt;rcu_iw_gp_seq != rnp-&gt;gp_seq &amp;&amp;</span></a>
<a name="1380"><span class="lineNum">    1380 </span><span class="lineNoCov">          0 :                     (rnp-&gt;ffmask &amp; rdp-&gt;grpmask)) {</span></a>
<a name="1381"><span class="lineNum">    1381 </span><span class="lineNoCov">          0 :                         rdp-&gt;rcu_iw_pending = true;</span></a>
<a name="1382"><span class="lineNum">    1382 </span><span class="lineNoCov">          0 :                         rdp-&gt;rcu_iw_gp_seq = rnp-&gt;gp_seq;</span></a>
<a name="1383"><span class="lineNum">    1383 </span><span class="lineNoCov">          0 :                         irq_work_queue_on(&amp;rdp-&gt;rcu_iw, rdp-&gt;cpu);</span></a>
<a name="1384"><span class="lineNum">    1384 </span>            :                 }</a>
<a name="1385"><span class="lineNum">    1385 </span>            :         }</a>
<a name="1386"><span class="lineNum">    1386 </span>            : </a>
<a name="1387"><span class="lineNum">    1387 </span>            :         return 0;</a>
<a name="1388"><span class="lineNum">    1388 </span>            : }</a>
<a name="1389"><span class="lineNum">    1389 </span>            : </a>
<a name="1390"><span class="lineNum">    1390 </span>            : /* Trace-event wrapper function for trace_rcu_future_grace_period.  */</a>
<a name="1391"><span class="lineNum">    1391 </span><span class="lineCov">      28041 : static void trace_rcu_this_gp(struct rcu_node *rnp, struct rcu_data *rdp,</span></a>
<a name="1392"><span class="lineNum">    1392 </span>            :                               unsigned long gp_seq_req, const char *s)</a>
<a name="1393"><span class="lineNum">    1393 </span>            : {</a>
<a name="1394"><span class="lineNum">    1394 </span><span class="lineCov">      28041 :         trace_rcu_future_grace_period(rcu_state.name, READ_ONCE(rnp-&gt;gp_seq),</span></a>
<a name="1395"><span class="lineNum">    1395 </span><span class="lineCov">      28041 :                                       gp_seq_req, rnp-&gt;level,</span></a>
<a name="1396"><span class="lineNum">    1396 </span>            :                                       rnp-&gt;grplo, rnp-&gt;grphi, s);</a>
<a name="1397"><span class="lineNum">    1397 </span>            : }</a>
<a name="1398"><span class="lineNum">    1398 </span>            : </a>
<a name="1399"><span class="lineNum">    1399 </span>            : /*</a>
<a name="1400"><span class="lineNum">    1400 </span>            :  * rcu_start_this_gp - Request the start of a particular grace period</a>
<a name="1401"><span class="lineNum">    1401 </span>            :  * @rnp_start: The leaf node of the CPU from which to start.</a>
<a name="1402"><span class="lineNum">    1402 </span>            :  * @rdp: The rcu_data corresponding to the CPU from which to start.</a>
<a name="1403"><span class="lineNum">    1403 </span>            :  * @gp_seq_req: The gp_seq of the grace period to start.</a>
<a name="1404"><span class="lineNum">    1404 </span>            :  *</a>
<a name="1405"><span class="lineNum">    1405 </span>            :  * Start the specified grace period, as needed to handle newly arrived</a>
<a name="1406"><span class="lineNum">    1406 </span>            :  * callbacks.  The required future grace periods are recorded in each</a>
<a name="1407"><span class="lineNum">    1407 </span>            :  * rcu_node structure's -&gt;gp_seq_needed field.  Returns true if there</a>
<a name="1408"><span class="lineNum">    1408 </span>            :  * is reason to awaken the grace-period kthread.</a>
<a name="1409"><span class="lineNum">    1409 </span>            :  *</a>
<a name="1410"><span class="lineNum">    1410 </span>            :  * The caller must hold the specified rcu_node structure's -&gt;lock, which</a>
<a name="1411"><span class="lineNum">    1411 </span>            :  * is why the caller is responsible for waking the grace-period kthread.</a>
<a name="1412"><span class="lineNum">    1412 </span>            :  *</a>
<a name="1413"><span class="lineNum">    1413 </span>            :  * Returns true if the GP thread needs to be awakened else false.</a>
<a name="1414"><span class="lineNum">    1414 </span>            :  */</a>
<a name="1415"><span class="lineNum">    1415 </span><span class="lineCov">      12961 : static bool rcu_start_this_gp(struct rcu_node *rnp_start, struct rcu_data *rdp,</span></a>
<a name="1416"><span class="lineNum">    1416 </span>            :                               unsigned long gp_seq_req)</a>
<a name="1417"><span class="lineNum">    1417 </span>            : {</a>
<a name="1418"><span class="lineNum">    1418 </span><span class="lineCov">      12961 :         bool ret = false;</span></a>
<a name="1419"><span class="lineNum">    1419 </span><span class="lineCov">      12961 :         struct rcu_node *rnp;</span></a>
<a name="1420"><span class="lineNum">    1420 </span>            : </a>
<a name="1421"><span class="lineNum">    1421 </span>            :         /*</a>
<a name="1422"><span class="lineNum">    1422 </span>            :          * Use funnel locking to either acquire the root rcu_node</a>
<a name="1423"><span class="lineNum">    1423 </span>            :          * structure's lock or bail out if the need for this grace period</a>
<a name="1424"><span class="lineNum">    1424 </span>            :          * has already been recorded -- or if that grace period has in</a>
<a name="1425"><span class="lineNum">    1425 </span>            :          * fact already started.  If there is already a grace period in</a>
<a name="1426"><span class="lineNum">    1426 </span>            :          * progress in a non-leaf node, no recording is needed because the</a>
<a name="1427"><span class="lineNum">    1427 </span>            :          * end of the grace period will scan the leaf rcu_node structures.</a>
<a name="1428"><span class="lineNum">    1428 </span>            :          * Note that rnp_start-&gt;lock must not be released.</a>
<a name="1429"><span class="lineNum">    1429 </span>            :          */</a>
<a name="1430"><span class="lineNum">    1430 </span><span class="lineCov">      25922 :         raw_lockdep_assert_held_rcu_node(rnp_start);</span></a>
<a name="1431"><span class="lineNum">    1431 </span><span class="lineCov">      12961 :         trace_rcu_this_gp(rnp_start, rdp, gp_seq_req, TPS(&quot;Startleaf&quot;));</span></a>
<a name="1432"><span class="lineNum">    1432 </span><span class="lineCov">      12961 :         for (rnp = rnp_start; 1; rnp = rnp-&gt;parent) {</span></a>
<a name="1433"><span class="lineNum">    1433 </span><span class="lineCov">      12961 :                 if (rnp != rnp_start)</span></a>
<a name="1434"><span class="lineNum">    1434 </span><span class="lineNoCov">          0 :                         raw_spin_lock_rcu_node(rnp);</span></a>
<a name="1435"><span class="lineNum">    1435 </span><span class="lineCov">      12961 :                 if (ULONG_CMP_GE(rnp-&gt;gp_seq_needed, gp_seq_req) ||</span></a>
<a name="1436"><span class="lineNum">    1436 </span><span class="lineCov">       2119 :                     rcu_seq_started(&amp;rnp-&gt;gp_seq, gp_seq_req) ||</span></a>
<a name="1437"><span class="lineNum">    1437 </span><span class="lineNoCov">          0 :                     (rnp != rnp_start &amp;&amp;</span></a>
<a name="1438"><span class="lineNum">    1438 </span><span class="lineNoCov">          0 :                      rcu_seq_state(rcu_seq_current(&amp;rnp-&gt;gp_seq)))) {</span></a>
<a name="1439"><span class="lineNum">    1439 </span><span class="lineCov">      10842 :                         trace_rcu_this_gp(rnp, rdp, gp_seq_req,</span></a>
<a name="1440"><span class="lineNum">    1440 </span><span class="lineCov">      10842 :                                           TPS(&quot;Prestarted&quot;));</span></a>
<a name="1441"><span class="lineNum">    1441 </span><span class="lineCov">      10842 :                         goto unlock_out;</span></a>
<a name="1442"><span class="lineNum">    1442 </span>            :                 }</a>
<a name="1443"><span class="lineNum">    1443 </span><span class="lineCov">       2119 :                 WRITE_ONCE(rnp-&gt;gp_seq_needed, gp_seq_req);</span></a>
<a name="1444"><span class="lineNum">    1444 </span><span class="lineCov">       2119 :                 if (rcu_seq_state(rcu_seq_current(&amp;rnp-&gt;gp_seq))) {</span></a>
<a name="1445"><span class="lineNum">    1445 </span>            :                         /*</a>
<a name="1446"><span class="lineNum">    1446 </span>            :                          * We just marked the leaf or internal node, and a</a>
<a name="1447"><span class="lineNum">    1447 </span>            :                          * grace period is in progress, which means that</a>
<a name="1448"><span class="lineNum">    1448 </span>            :                          * rcu_gp_cleanup() will see the marking.  Bail to</a>
<a name="1449"><span class="lineNum">    1449 </span>            :                          * reduce contention.</a>
<a name="1450"><span class="lineNum">    1450 </span>            :                          */</a>
<a name="1451"><span class="lineNum">    1451 </span><span class="lineCov">       2084 :                         trace_rcu_this_gp(rnp_start, rdp, gp_seq_req,</span></a>
<a name="1452"><span class="lineNum">    1452 </span><span class="lineCov">       2084 :                                           TPS(&quot;Startedleaf&quot;));</span></a>
<a name="1453"><span class="lineNum">    1453 </span><span class="lineCov">       2084 :                         goto unlock_out;</span></a>
<a name="1454"><span class="lineNum">    1454 </span>            :                 }</a>
<a name="1455"><span class="lineNum">    1455 </span><span class="lineCov">         35 :                 if (rnp != rnp_start &amp;&amp; rnp-&gt;parent != NULL)</span></a>
<a name="1456"><span class="lineNum">    1456 </span><span class="lineNoCov">          0 :                         raw_spin_unlock_rcu_node(rnp);</span></a>
<a name="1457"><span class="lineNum">    1457 </span><span class="lineCov">         35 :                 if (!rnp-&gt;parent)</span></a>
<a name="1458"><span class="lineNum">    1458 </span>            :                         break;  /* At root, and perhaps also leaf. */</a>
<a name="1459"><span class="lineNum">    1459 </span>            :         }</a>
<a name="1460"><span class="lineNum">    1460 </span>            : </a>
<a name="1461"><span class="lineNum">    1461 </span>            :         /* If GP already in progress, just leave, otherwise start one. */</a>
<a name="1462"><span class="lineNum">    1462 </span><span class="lineCov">         35 :         if (rcu_gp_in_progress()) {</span></a>
<a name="1463"><span class="lineNum">    1463 </span><span class="lineCov">         21 :                 trace_rcu_this_gp(rnp, rdp, gp_seq_req, TPS(&quot;Startedleafroot&quot;));</span></a>
<a name="1464"><span class="lineNum">    1464 </span><span class="lineCov">         21 :                 goto unlock_out;</span></a>
<a name="1465"><span class="lineNum">    1465 </span>            :         }</a>
<a name="1466"><span class="lineNum">    1466 </span><span class="lineCov">         14 :         trace_rcu_this_gp(rnp, rdp, gp_seq_req, TPS(&quot;Startedroot&quot;));</span></a>
<a name="1467"><span class="lineNum">    1467 </span><span class="lineCov">         14 :         WRITE_ONCE(rcu_state.gp_flags, rcu_state.gp_flags | RCU_GP_FLAG_INIT);</span></a>
<a name="1468"><span class="lineNum">    1468 </span><span class="lineCov">         14 :         WRITE_ONCE(rcu_state.gp_req_activity, jiffies);</span></a>
<a name="1469"><span class="lineNum">    1469 </span><span class="lineCov">         14 :         if (!READ_ONCE(rcu_state.gp_kthread)) {</span></a>
<a name="1470"><span class="lineNum">    1470 </span><span class="lineCov">          1 :                 trace_rcu_this_gp(rnp, rdp, gp_seq_req, TPS(&quot;NoGPkthread&quot;));</span></a>
<a name="1471"><span class="lineNum">    1471 </span><span class="lineCov">          1 :                 goto unlock_out;</span></a>
<a name="1472"><span class="lineNum">    1472 </span>            :         }</a>
<a name="1473"><span class="lineNum">    1473 </span><span class="lineCov">      12961 :         trace_rcu_grace_period(rcu_state.name, data_race(rcu_state.gp_seq), TPS(&quot;newreq&quot;));</span></a>
<a name="1474"><span class="lineNum">    1474 </span><span class="lineCov">      12961 :         ret = true;  /* Caller must wake GP kthread. */</span></a>
<a name="1475"><span class="lineNum">    1475 </span><span class="lineCov">      12961 : unlock_out:</span></a>
<a name="1476"><span class="lineNum">    1476 </span>            :         /* Push furthest requested GP to leaf node and rcu_data structure. */</a>
<a name="1477"><span class="lineNum">    1477 </span><span class="lineCov">      12961 :         if (ULONG_CMP_LT(gp_seq_req, rnp-&gt;gp_seq_needed)) {</span></a>
<a name="1478"><span class="lineNum">    1478 </span><span class="lineNoCov">          0 :                 WRITE_ONCE(rnp_start-&gt;gp_seq_needed, rnp-&gt;gp_seq_needed);</span></a>
<a name="1479"><span class="lineNum">    1479 </span><span class="lineNoCov">          0 :                 WRITE_ONCE(rdp-&gt;gp_seq_needed, rnp-&gt;gp_seq_needed);</span></a>
<a name="1480"><span class="lineNum">    1480 </span>            :         }</a>
<a name="1481"><span class="lineNum">    1481 </span><span class="lineCov">      12961 :         if (rnp != rnp_start)</span></a>
<a name="1482"><span class="lineNum">    1482 </span><span class="lineNoCov">          0 :                 raw_spin_unlock_rcu_node(rnp);</span></a>
<a name="1483"><span class="lineNum">    1483 </span><span class="lineCov">      12961 :         return ret;</span></a>
<a name="1484"><span class="lineNum">    1484 </span>            : }</a>
<a name="1485"><span class="lineNum">    1485 </span>            : </a>
<a name="1486"><span class="lineNum">    1486 </span>            : /*</a>
<a name="1487"><span class="lineNum">    1487 </span>            :  * Clean up any old requests for the just-ended grace period.  Also return</a>
<a name="1488"><span class="lineNum">    1488 </span>            :  * whether any additional grace periods have been requested.</a>
<a name="1489"><span class="lineNum">    1489 </span>            :  */</a>
<a name="1490"><span class="lineNum">    1490 </span><span class="lineCov">       2118 : static bool rcu_future_gp_cleanup(struct rcu_node *rnp)</span></a>
<a name="1491"><span class="lineNum">    1491 </span>            : {</a>
<a name="1492"><span class="lineNum">    1492 </span><span class="lineCov">       2118 :         bool needmore;</span></a>
<a name="1493"><span class="lineNum">    1493 </span><span class="lineCov">       4236 :         struct rcu_data *rdp = this_cpu_ptr(&amp;rcu_data);</span></a>
<a name="1494"><span class="lineNum">    1494 </span>            : </a>
<a name="1495"><span class="lineNum">    1495 </span><span class="lineCov">       2118 :         needmore = ULONG_CMP_LT(rnp-&gt;gp_seq, rnp-&gt;gp_seq_needed);</span></a>
<a name="1496"><span class="lineNum">    1496 </span><span class="lineCov">       2118 :         if (!needmore)</span></a>
<a name="1497"><span class="lineNum">    1497 </span><span class="lineCov">         13 :                 rnp-&gt;gp_seq_needed = rnp-&gt;gp_seq; /* Avoid counter wrap. */</span></a>
<a name="1498"><span class="lineNum">    1498 </span><span class="lineCov">       2118 :         trace_rcu_this_gp(rnp, rdp, rnp-&gt;gp_seq,</span></a>
<a name="1499"><span class="lineNum">    1499 </span><span class="lineCov">       2118 :                           needmore ? TPS(&quot;CleanupMore&quot;) : TPS(&quot;Cleanup&quot;));</span></a>
<a name="1500"><span class="lineNum">    1500 </span><span class="lineCov">       2118 :         return needmore;</span></a>
<a name="1501"><span class="lineNum">    1501 </span>            : }</a>
<a name="1502"><span class="lineNum">    1502 </span>            : </a>
<a name="1503"><span class="lineNum">    1503 </span>            : /*</a>
<a name="1504"><span class="lineNum">    1504 </span>            :  * Awaken the grace-period kthread.  Don't do a self-awaken (unless in an</a>
<a name="1505"><span class="lineNum">    1505 </span>            :  * interrupt or softirq handler, in which case we just might immediately</a>
<a name="1506"><span class="lineNum">    1506 </span>            :  * sleep upon return, resulting in a grace-period hang), and don't bother</a>
<a name="1507"><span class="lineNum">    1507 </span>            :  * awakening when there is nothing for the grace-period kthread to do</a>
<a name="1508"><span class="lineNum">    1508 </span>            :  * (as in several CPUs raced to awaken, we lost), and finally don't try</a>
<a name="1509"><span class="lineNum">    1509 </span>            :  * to awaken a kthread that has not yet been created.  If all those checks</a>
<a name="1510"><span class="lineNum">    1510 </span>            :  * are passed, track some debug information and awaken.</a>
<a name="1511"><span class="lineNum">    1511 </span>            :  *</a>
<a name="1512"><span class="lineNum">    1512 </span>            :  * So why do the self-wakeup when in an interrupt or softirq handler</a>
<a name="1513"><span class="lineNum">    1513 </span>            :  * in the grace-period kthread's context?  Because the kthread might have</a>
<a name="1514"><span class="lineNum">    1514 </span>            :  * been interrupted just as it was going to sleep, and just after the final</a>
<a name="1515"><span class="lineNum">    1515 </span>            :  * pre-sleep check of the awaken condition.  In this case, a wakeup really</a>
<a name="1516"><span class="lineNum">    1516 </span>            :  * is required, and is therefore supplied.</a>
<a name="1517"><span class="lineNum">    1517 </span>            :  */</a>
<a name="1518"><span class="lineNum">    1518 </span><span class="lineCov">       2131 : static void rcu_gp_kthread_wake(void)</span></a>
<a name="1519"><span class="lineNum">    1519 </span>            : {</a>
<a name="1520"><span class="lineNum">    1520 </span><span class="lineCov">       2131 :         struct task_struct *t = READ_ONCE(rcu_state.gp_kthread);</span></a>
<a name="1521"><span class="lineNum">    1521 </span>            : </a>
<a name="1522"><span class="lineNum">    1522 </span><span class="lineCov">       2131 :         if ((current == t &amp;&amp; !in_irq() &amp;&amp; !in_serving_softirq()) ||</span></a>
<a name="1523"><span class="lineNum">    1523 </span><span class="lineCov">       1726 :             !READ_ONCE(rcu_state.gp_flags) || !t)</span></a>
<a name="1524"><span class="lineNum">    1524 </span>            :                 return;</a>
<a name="1525"><span class="lineNum">    1525 </span><span class="lineCov">       1726 :         WRITE_ONCE(rcu_state.gp_wake_time, jiffies);</span></a>
<a name="1526"><span class="lineNum">    1526 </span><span class="lineCov">       1726 :         WRITE_ONCE(rcu_state.gp_wake_seq, READ_ONCE(rcu_state.gp_seq));</span></a>
<a name="1527"><span class="lineNum">    1527 </span><span class="lineCov">       1726 :         swake_up_one(&amp;rcu_state.gp_wq);</span></a>
<a name="1528"><span class="lineNum">    1528 </span>            : }</a>
<a name="1529"><span class="lineNum">    1529 </span>            : </a>
<a name="1530"><span class="lineNum">    1530 </span>            : /*</a>
<a name="1531"><span class="lineNum">    1531 </span>            :  * If there is room, assign a -&gt;gp_seq number to any callbacks on this</a>
<a name="1532"><span class="lineNum">    1532 </span>            :  * CPU that have not already been assigned.  Also accelerate any callbacks</a>
<a name="1533"><span class="lineNum">    1533 </span>            :  * that were previously assigned a -&gt;gp_seq number that has since proven</a>
<a name="1534"><span class="lineNum">    1534 </span>            :  * to be too conservative, which can happen if callbacks get assigned a</a>
<a name="1535"><span class="lineNum">    1535 </span>            :  * -&gt;gp_seq number while RCU is idle, but with reference to a non-root</a>
<a name="1536"><span class="lineNum">    1536 </span>            :  * rcu_node structure.  This function is idempotent, so it does not hurt</a>
<a name="1537"><span class="lineNum">    1537 </span>            :  * to call it repeatedly.  Returns an flag saying that we should awaken</a>
<a name="1538"><span class="lineNum">    1538 </span>            :  * the RCU grace-period kthread.</a>
<a name="1539"><span class="lineNum">    1539 </span>            :  *</a>
<a name="1540"><span class="lineNum">    1540 </span>            :  * The caller must hold rnp-&gt;lock with interrupts disabled.</a>
<a name="1541"><span class="lineNum">    1541 </span>            :  */</a>
<a name="1542"><span class="lineNum">    1542 </span><span class="lineCov">      19401 : static bool rcu_accelerate_cbs(struct rcu_node *rnp, struct rcu_data *rdp)</span></a>
<a name="1543"><span class="lineNum">    1543 </span>            : {</a>
<a name="1544"><span class="lineNum">    1544 </span><span class="lineCov">      19401 :         unsigned long gp_seq_req;</span></a>
<a name="1545"><span class="lineNum">    1545 </span><span class="lineCov">      19401 :         bool ret = false;</span></a>
<a name="1546"><span class="lineNum">    1546 </span>            : </a>
<a name="1547"><span class="lineNum">    1547 </span><span class="lineCov">      19401 :         rcu_lockdep_assert_cblist_protected(rdp);</span></a>
<a name="1548"><span class="lineNum">    1548 </span><span class="lineCov">      38802 :         raw_lockdep_assert_held_rcu_node(rnp);</span></a>
<a name="1549"><span class="lineNum">    1549 </span>            : </a>
<a name="1550"><span class="lineNum">    1550 </span>            :         /* If no pending (not yet ready to invoke) callbacks, nothing to do. */</a>
<a name="1551"><span class="lineNum">    1551 </span><span class="lineCov">      19401 :         if (!rcu_segcblist_pend_cbs(&amp;rdp-&gt;cblist))</span></a>
<a name="1552"><span class="lineNum">    1552 </span>            :                 return false;</a>
<a name="1553"><span class="lineNum">    1553 </span>            : </a>
<a name="1554"><span class="lineNum">    1554 </span><span class="lineCov">      17362 :         trace_rcu_segcb_stats(&amp;rdp-&gt;cblist, TPS(&quot;SegCbPreAcc&quot;));</span></a>
<a name="1555"><span class="lineNum">    1555 </span>            : </a>
<a name="1556"><span class="lineNum">    1556 </span>            :         /*</a>
<a name="1557"><span class="lineNum">    1557 </span>            :          * Callbacks are often registered with incomplete grace-period</a>
<a name="1558"><span class="lineNum">    1558 </span>            :          * information.  Something about the fact that getting exact</a>
<a name="1559"><span class="lineNum">    1559 </span>            :          * information requires acquiring a global lock...  RCU therefore</a>
<a name="1560"><span class="lineNum">    1560 </span>            :          * makes a conservative estimate of the grace period number at which</a>
<a name="1561"><span class="lineNum">    1561 </span>            :          * a given callback will become ready to invoke.        The following</a>
<a name="1562"><span class="lineNum">    1562 </span>            :          * code checks this estimate and improves it when possible, thus</a>
<a name="1563"><span class="lineNum">    1563 </span>            :          * accelerating callback invocation to an earlier grace-period</a>
<a name="1564"><span class="lineNum">    1564 </span>            :          * number.</a>
<a name="1565"><span class="lineNum">    1565 </span>            :          */</a>
<a name="1566"><span class="lineNum">    1566 </span><span class="lineCov">      17362 :         gp_seq_req = rcu_seq_snap(&amp;rcu_state.gp_seq);</span></a>
<a name="1567"><span class="lineNum">    1567 </span><span class="lineCov">      17362 :         if (rcu_segcblist_accelerate(&amp;rdp-&gt;cblist, gp_seq_req))</span></a>
<a name="1568"><span class="lineNum">    1568 </span><span class="lineCov">      12961 :                 ret = rcu_start_this_gp(rnp, rdp, gp_seq_req);</span></a>
<a name="1569"><span class="lineNum">    1569 </span>            : </a>
<a name="1570"><span class="lineNum">    1570 </span>            :         /* Trace depending on how much we were able to accelerate. */</a>
<a name="1571"><span class="lineNum">    1571 </span><span class="lineCov">      17362 :         if (rcu_segcblist_restempty(&amp;rdp-&gt;cblist, RCU_WAIT_TAIL))</span></a>
<a name="1572"><span class="lineNum">    1572 </span><span class="lineCov">      19401 :                 trace_rcu_grace_period(rcu_state.name, gp_seq_req, TPS(&quot;AccWaitCB&quot;));</span></a>
<a name="1573"><span class="lineNum">    1573 </span>            :         else</a>
<a name="1574"><span class="lineNum">    1574 </span><span class="lineCov">      17362 :                 trace_rcu_grace_period(rcu_state.name, gp_seq_req, TPS(&quot;AccReadyCB&quot;));</span></a>
<a name="1575"><span class="lineNum">    1575 </span>            : </a>
<a name="1576"><span class="lineNum">    1576 </span><span class="lineCov">      19401 :         trace_rcu_segcb_stats(&amp;rdp-&gt;cblist, TPS(&quot;SegCbPostAcc&quot;));</span></a>
<a name="1577"><span class="lineNum">    1577 </span>            : </a>
<a name="1578"><span class="lineNum">    1578 </span>            :         return ret;</a>
<a name="1579"><span class="lineNum">    1579 </span>            : }</a>
<a name="1580"><span class="lineNum">    1580 </span>            : </a>
<a name="1581"><span class="lineNum">    1581 </span>            : /*</a>
<a name="1582"><span class="lineNum">    1582 </span>            :  * Similar to rcu_accelerate_cbs(), but does not require that the leaf</a>
<a name="1583"><span class="lineNum">    1583 </span>            :  * rcu_node structure's -&gt;lock be held.  It consults the cached value</a>
<a name="1584"><span class="lineNum">    1584 </span>            :  * of -&gt;gp_seq_needed in the rcu_data structure, and if that indicates</a>
<a name="1585"><span class="lineNum">    1585 </span>            :  * that a new grace-period request be made, invokes rcu_accelerate_cbs()</a>
<a name="1586"><span class="lineNum">    1586 </span>            :  * while holding the leaf rcu_node structure's -&gt;lock.</a>
<a name="1587"><span class="lineNum">    1587 </span>            :  */</a>
<a name="1588"><span class="lineNum">    1588 </span><span class="lineCov">         16 : static void rcu_accelerate_cbs_unlocked(struct rcu_node *rnp,</span></a>
<a name="1589"><span class="lineNum">    1589 </span>            :                                         struct rcu_data *rdp)</a>
<a name="1590"><span class="lineNum">    1590 </span>            : {</a>
<a name="1591"><span class="lineNum">    1591 </span><span class="lineCov">         16 :         unsigned long c;</span></a>
<a name="1592"><span class="lineNum">    1592 </span><span class="lineCov">         16 :         bool needwake;</span></a>
<a name="1593"><span class="lineNum">    1593 </span>            : </a>
<a name="1594"><span class="lineNum">    1594 </span><span class="lineCov">         16 :         rcu_lockdep_assert_cblist_protected(rdp);</span></a>
<a name="1595"><span class="lineNum">    1595 </span><span class="lineCov">         16 :         c = rcu_seq_snap(&amp;rcu_state.gp_seq);</span></a>
<a name="1596"><span class="lineNum">    1596 </span><span class="lineCov">         16 :         if (!READ_ONCE(rdp-&gt;gpwrap) &amp;&amp; ULONG_CMP_GE(rdp-&gt;gp_seq_needed, c)) {</span></a>
<a name="1597"><span class="lineNum">    1597 </span>            :                 /* Old request still live, so mark recent callbacks. */</a>
<a name="1598"><span class="lineNum">    1598 </span><span class="lineNoCov">          0 :                 (void)rcu_segcblist_accelerate(&amp;rdp-&gt;cblist, c);</span></a>
<a name="1599"><span class="lineNum">    1599 </span><span class="lineNoCov">          0 :                 return;</span></a>
<a name="1600"><span class="lineNum">    1600 </span>            :         }</a>
<a name="1601"><span class="lineNum">    1601 </span><span class="lineCov">         16 :         raw_spin_lock_rcu_node(rnp); /* irqs already disabled. */</span></a>
<a name="1602"><span class="lineNum">    1602 </span><span class="lineCov">         16 :         needwake = rcu_accelerate_cbs(rnp, rdp);</span></a>
<a name="1603"><span class="lineNum">    1603 </span><span class="lineCov">         32 :         raw_spin_unlock_rcu_node(rnp); /* irqs remain disabled. */</span></a>
<a name="1604"><span class="lineNum">    1604 </span><span class="lineCov">         16 :         if (needwake)</span></a>
<a name="1605"><span class="lineNum">    1605 </span><span class="lineCov">          9 :                 rcu_gp_kthread_wake();</span></a>
<a name="1606"><span class="lineNum">    1606 </span>            : }</a>
<a name="1607"><span class="lineNum">    1607 </span>            : </a>
<a name="1608"><span class="lineNum">    1608 </span>            : /*</a>
<a name="1609"><span class="lineNum">    1609 </span>            :  * Move any callbacks whose grace period has completed to the</a>
<a name="1610"><span class="lineNum">    1610 </span>            :  * RCU_DONE_TAIL sublist, then compact the remaining sublists and</a>
<a name="1611"><span class="lineNum">    1611 </span>            :  * assign -&gt;gp_seq numbers to any callbacks in the RCU_NEXT_TAIL</a>
<a name="1612"><span class="lineNum">    1612 </span>            :  * sublist.  This function is idempotent, so it does not hurt to</a>
<a name="1613"><span class="lineNum">    1613 </span>            :  * invoke it repeatedly.  As long as it is not invoked -too- often...</a>
<a name="1614"><span class="lineNum">    1614 </span>            :  * Returns true if the RCU grace-period kthread needs to be awakened.</a>
<a name="1615"><span class="lineNum">    1615 </span>            :  *</a>
<a name="1616"><span class="lineNum">    1616 </span>            :  * The caller must hold rnp-&gt;lock with interrupts disabled.</a>
<a name="1617"><span class="lineNum">    1617 </span>            :  */</a>
<a name="1618"><span class="lineNum">    1618 </span><span class="lineCov">       7900 : static bool rcu_advance_cbs(struct rcu_node *rnp, struct rcu_data *rdp)</span></a>
<a name="1619"><span class="lineNum">    1619 </span>            : {</a>
<a name="1620"><span class="lineNum">    1620 </span><span class="lineCov">       7900 :         rcu_lockdep_assert_cblist_protected(rdp);</span></a>
<a name="1621"><span class="lineNum">    1621 </span><span class="lineCov">      15800 :         raw_lockdep_assert_held_rcu_node(rnp);</span></a>
<a name="1622"><span class="lineNum">    1622 </span>            : </a>
<a name="1623"><span class="lineNum">    1623 </span>            :         /* If no pending (not yet ready to invoke) callbacks, nothing to do. */</a>
<a name="1624"><span class="lineNum">    1624 </span><span class="lineCov">       7900 :         if (!rcu_segcblist_pend_cbs(&amp;rdp-&gt;cblist))</span></a>
<a name="1625"><span class="lineNum">    1625 </span>            :                 return false;</a>
<a name="1626"><span class="lineNum">    1626 </span>            : </a>
<a name="1627"><span class="lineNum">    1627 </span>            :         /*</a>
<a name="1628"><span class="lineNum">    1628 </span>            :          * Find all callbacks whose -&gt;gp_seq numbers indicate that they</a>
<a name="1629"><span class="lineNum">    1629 </span>            :          * are ready to invoke, and put them into the RCU_DONE_TAIL sublist.</a>
<a name="1630"><span class="lineNum">    1630 </span>            :          */</a>
<a name="1631"><span class="lineNum">    1631 </span><span class="lineCov">       7574 :         rcu_segcblist_advance(&amp;rdp-&gt;cblist, rnp-&gt;gp_seq);</span></a>
<a name="1632"><span class="lineNum">    1632 </span>            : </a>
<a name="1633"><span class="lineNum">    1633 </span>            :         /* Classify any remaining callbacks. */</a>
<a name="1634"><span class="lineNum">    1634 </span><span class="lineCov">       7574 :         return rcu_accelerate_cbs(rnp, rdp);</span></a>
<a name="1635"><span class="lineNum">    1635 </span>            : }</a>
<a name="1636"><span class="lineNum">    1636 </span>            : </a>
<a name="1637"><span class="lineNum">    1637 </span>            : /*</a>
<a name="1638"><span class="lineNum">    1638 </span>            :  * Move and classify callbacks, but only if doing so won't require</a>
<a name="1639"><span class="lineNum">    1639 </span>            :  * that the RCU grace-period kthread be awakened.</a>
<a name="1640"><span class="lineNum">    1640 </span>            :  */</a>
<a name="1641"><span class="lineNum">    1641 </span>            : static void __maybe_unused rcu_advance_cbs_nowake(struct rcu_node *rnp,</a>
<a name="1642"><span class="lineNum">    1642 </span>            :                                                   struct rcu_data *rdp)</a>
<a name="1643"><span class="lineNum">    1643 </span>            : {</a>
<a name="1644"><span class="lineNum">    1644 </span>            :         rcu_lockdep_assert_cblist_protected(rdp);</a>
<a name="1645"><span class="lineNum">    1645 </span>            :         if (!rcu_seq_state(rcu_seq_current(&amp;rnp-&gt;gp_seq)) ||</a>
<a name="1646"><span class="lineNum">    1646 </span>            :             !raw_spin_trylock_rcu_node(rnp))</a>
<a name="1647"><span class="lineNum">    1647 </span>            :                 return;</a>
<a name="1648"><span class="lineNum">    1648 </span>            :         WARN_ON_ONCE(rcu_advance_cbs(rnp, rdp));</a>
<a name="1649"><span class="lineNum">    1649 </span>            :         raw_spin_unlock_rcu_node(rnp);</a>
<a name="1650"><span class="lineNum">    1650 </span>            : }</a>
<a name="1651"><span class="lineNum">    1651 </span>            : </a>
<a name="1652"><span class="lineNum">    1652 </span>            : /*</a>
<a name="1653"><span class="lineNum">    1653 </span>            :  * In CONFIG_RCU_STRICT_GRACE_PERIOD=y kernels, attempt to generate a</a>
<a name="1654"><span class="lineNum">    1654 </span>            :  * quiescent state.  This is intended to be invoked when the CPU notices</a>
<a name="1655"><span class="lineNum">    1655 </span>            :  * a new grace period.</a>
<a name="1656"><span class="lineNum">    1656 </span>            :  */</a>
<a name="1657"><span class="lineNum">    1657 </span><span class="lineCov">       5824 : static void rcu_strict_gp_check_qs(void)</span></a>
<a name="1658"><span class="lineNum">    1658 </span>            : {</a>
<a name="1659"><span class="lineNum">    1659 </span><span class="lineCov">       5824 :         if (IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD)) {</span></a>
<a name="1660"><span class="lineNum">    1660 </span>            :                 rcu_read_lock();</a>
<a name="1661"><span class="lineNum">    1661 </span>            :                 rcu_read_unlock();</a>
<a name="1662"><span class="lineNum">    1662 </span>            :         }</a>
<a name="1663"><span class="lineNum">    1663 </span>            : }</a>
<a name="1664"><span class="lineNum">    1664 </span>            : </a>
<a name="1665"><span class="lineNum">    1665 </span>            : /*</a>
<a name="1666"><span class="lineNum">    1666 </span>            :  * Update CPU-local rcu_data state to record the beginnings and ends of</a>
<a name="1667"><span class="lineNum">    1667 </span>            :  * grace periods.  The caller must hold the -&gt;lock of the leaf rcu_node</a>
<a name="1668"><span class="lineNum">    1668 </span>            :  * structure corresponding to the current CPU, and must have irqs disabled.</a>
<a name="1669"><span class="lineNum">    1669 </span>            :  * Returns true if the grace-period kthread needs to be awakened.</a>
<a name="1670"><span class="lineNum">    1670 </span>            :  */</a>
<a name="1671"><span class="lineNum">    1671 </span><span class="lineCov">      10061 : static bool __note_gp_changes(struct rcu_node *rnp, struct rcu_data *rdp)</span></a>
<a name="1672"><span class="lineNum">    1672 </span>            : {</a>
<a name="1673"><span class="lineNum">    1673 </span><span class="lineCov">      10061 :         bool ret = false;</span></a>
<a name="1674"><span class="lineNum">    1674 </span><span class="lineCov">      10061 :         bool need_qs;</span></a>
<a name="1675"><span class="lineNum">    1675 </span><span class="lineCov">      10061 :         const bool offloaded = rcu_segcblist_is_offloaded(&amp;rdp-&gt;cblist);</span></a>
<a name="1676"><span class="lineNum">    1676 </span>            : </a>
<a name="1677"><span class="lineNum">    1677 </span><span class="lineCov">      20122 :         raw_lockdep_assert_held_rcu_node(rnp);</span></a>
<a name="1678"><span class="lineNum">    1678 </span>            : </a>
<a name="1679"><span class="lineNum">    1679 </span><span class="lineCov">      10061 :         if (rdp-&gt;gp_seq == rnp-&gt;gp_seq)</span></a>
<a name="1680"><span class="lineNum">    1680 </span>            :                 return false; /* Nothing to do. */</a>
<a name="1681"><span class="lineNum">    1681 </span>            : </a>
<a name="1682"><span class="lineNum">    1682 </span>            :         /* Handle the ends of any preceding grace periods first. */</a>
<a name="1683"><span class="lineNum">    1683 </span><span class="lineCov">      10061 :         if (rcu_seq_completed_gp(rdp-&gt;gp_seq, rnp-&gt;gp_seq) ||</span></a>
<a name="1684"><span class="lineNum">    1684 </span><span class="lineCov">       2161 :             unlikely(READ_ONCE(rdp-&gt;gpwrap))) {</span></a>
<a name="1685"><span class="lineNum">    1685 </span><span class="lineCov">       7900 :                 if (!offloaded)</span></a>
<a name="1686"><span class="lineNum">    1686 </span><span class="lineCov">       7900 :                         ret = rcu_advance_cbs(rnp, rdp); /* Advance CBs. */</span></a>
<a name="1687"><span class="lineNum">    1687 </span><span class="lineCov">       7900 :                 rdp-&gt;core_needs_qs = false;</span></a>
<a name="1688"><span class="lineNum">    1688 </span><span class="lineCov">       7900 :                 trace_rcu_grace_period(rcu_state.name, rdp-&gt;gp_seq, TPS(&quot;cpuend&quot;));</span></a>
<a name="1689"><span class="lineNum">    1689 </span>            :         } else {</a>
<a name="1690"><span class="lineNum">    1690 </span><span class="lineCov">       2161 :                 if (!offloaded)</span></a>
<a name="1691"><span class="lineNum">    1691 </span><span class="lineCov">       2161 :                         ret = rcu_accelerate_cbs(rnp, rdp); /* Recent CBs. */</span></a>
<a name="1692"><span class="lineNum">    1692 </span><span class="lineCov">       2161 :                 if (rdp-&gt;core_needs_qs)</span></a>
<a name="1693"><span class="lineNum">    1693 </span><span class="lineNoCov">          0 :                         rdp-&gt;core_needs_qs = !!(rnp-&gt;qsmask &amp; rdp-&gt;grpmask);</span></a>
<a name="1694"><span class="lineNum">    1694 </span>            :         }</a>
<a name="1695"><span class="lineNum">    1695 </span>            : </a>
<a name="1696"><span class="lineNum">    1696 </span>            :         /* Now handle the beginnings of any new-to-this-CPU grace periods. */</a>
<a name="1697"><span class="lineNum">    1697 </span><span class="lineCov">      10061 :         if (rcu_seq_new_gp(rdp-&gt;gp_seq, rnp-&gt;gp_seq) ||</span></a>
<a name="1698"><span class="lineNum">    1698 </span><span class="lineCov">       2161 :             unlikely(READ_ONCE(rdp-&gt;gpwrap))) {</span></a>
<a name="1699"><span class="lineNum">    1699 </span>            :                 /*</a>
<a name="1700"><span class="lineNum">    1700 </span>            :                  * If the current grace period is waiting for this CPU,</a>
<a name="1701"><span class="lineNum">    1701 </span>            :                  * set up to detect a quiescent state, otherwise don't</a>
<a name="1702"><span class="lineNum">    1702 </span>            :                  * go looking for one.</a>
<a name="1703"><span class="lineNum">    1703 </span>            :                  */</a>
<a name="1704"><span class="lineNum">    1704 </span><span class="lineCov">       7900 :                 trace_rcu_grace_period(rcu_state.name, rnp-&gt;gp_seq, TPS(&quot;cpustart&quot;));</span></a>
<a name="1705"><span class="lineNum">    1705 </span><span class="lineCov">       7900 :                 need_qs = !!(rnp-&gt;qsmask &amp; rdp-&gt;grpmask);</span></a>
<a name="1706"><span class="lineNum">    1706 </span><span class="lineCov">       7900 :                 rdp-&gt;cpu_no_qs.b.norm = need_qs;</span></a>
<a name="1707"><span class="lineNum">    1707 </span><span class="lineCov">       7900 :                 rdp-&gt;core_needs_qs = need_qs;</span></a>
<a name="1708"><span class="lineNum">    1708 </span><span class="lineCov">       7900 :                 zero_cpu_stall_ticks(rdp);</span></a>
<a name="1709"><span class="lineNum">    1709 </span>            :         }</a>
<a name="1710"><span class="lineNum">    1710 </span><span class="lineCov">      10061 :         rdp-&gt;gp_seq = rnp-&gt;gp_seq;  /* Remember new grace-period state. */</span></a>
<a name="1711"><span class="lineNum">    1711 </span><span class="lineCov">      10061 :         if (ULONG_CMP_LT(rdp-&gt;gp_seq_needed, rnp-&gt;gp_seq_needed) || rdp-&gt;gpwrap)</span></a>
<a name="1712"><span class="lineNum">    1712 </span><span class="lineCov">       7232 :                 WRITE_ONCE(rdp-&gt;gp_seq_needed, rnp-&gt;gp_seq_needed);</span></a>
<a name="1713"><span class="lineNum">    1713 </span><span class="lineCov">      10061 :         WRITE_ONCE(rdp-&gt;gpwrap, false);</span></a>
<a name="1714"><span class="lineNum">    1714 </span><span class="lineCov">      10061 :         rcu_gpnum_ovf(rnp, rdp);</span></a>
<a name="1715"><span class="lineNum">    1715 </span><span class="lineCov">      10061 :         return ret;</span></a>
<a name="1716"><span class="lineNum">    1716 </span>            : }</a>
<a name="1717"><span class="lineNum">    1717 </span>            : </a>
<a name="1718"><span class="lineNum">    1718 </span><span class="lineCov">      54331 : static void note_gp_changes(struct rcu_data *rdp)</span></a>
<a name="1719"><span class="lineNum">    1719 </span>            : {</a>
<a name="1720"><span class="lineNum">    1720 </span><span class="lineCov">      54331 :         unsigned long flags;</span></a>
<a name="1721"><span class="lineNum">    1721 </span><span class="lineCov">      54331 :         bool needwake;</span></a>
<a name="1722"><span class="lineNum">    1722 </span><span class="lineCov">      54331 :         struct rcu_node *rnp;</span></a>
<a name="1723"><span class="lineNum">    1723 </span>            : </a>
<a name="1724"><span class="lineNum">    1724 </span><span class="lineCov">     108781 :         local_irq_save(flags);</span></a>
<a name="1725"><span class="lineNum">    1725 </span><span class="lineCov">      54435 :         rnp = rdp-&gt;mynode;</span></a>
<a name="1726"><span class="lineNum">    1726 </span><span class="lineCov">      54435 :         if ((rdp-&gt;gp_seq == rcu_seq_current(&amp;rnp-&gt;gp_seq) &amp;&amp;</span></a>
<a name="1727"><span class="lineNum">    1727 </span><span class="lineCov">      47925 :              !unlikely(READ_ONCE(rdp-&gt;gpwrap))) || /* w/out lock. */</span></a>
<a name="1728"><span class="lineNum">    1728 </span><span class="lineCov">       6510 :             !raw_spin_trylock_rcu_node(rnp)) { /* irqs already off, so later. */</span></a>
<a name="1729"><span class="lineNum">    1729 </span><span class="lineCov">      48692 :                 local_irq_restore(flags);</span></a>
<a name="1730"><span class="lineNum">    1730 </span><span class="lineCov">      48718 :                 return;</span></a>
<a name="1731"><span class="lineNum">    1731 </span>            :         }</a>
<a name="1732"><span class="lineNum">    1732 </span><span class="lineCov">       5824 :         needwake = __note_gp_changes(rnp, rdp);</span></a>
<a name="1733"><span class="lineNum">    1733 </span><span class="lineCov">      11648 :         raw_spin_unlock_irqrestore_rcu_node(rnp, flags);</span></a>
<a name="1734"><span class="lineNum">    1734 </span><span class="lineCov">       5824 :         rcu_strict_gp_check_qs();</span></a>
<a name="1735"><span class="lineNum">    1735 </span><span class="lineCov">       5824 :         if (needwake)</span></a>
<a name="1736"><span class="lineNum">    1736 </span><span class="lineCov">          4 :                 rcu_gp_kthread_wake();</span></a>
<a name="1737"><span class="lineNum">    1737 </span>            : }</a>
<a name="1738"><span class="lineNum">    1738 </span>            : </a>
<a name="1739"><span class="lineNum">    1739 </span><span class="lineCov">       6356 : static void rcu_gp_slow(int delay)</span></a>
<a name="1740"><span class="lineNum">    1740 </span>            : {</a>
<a name="1741"><span class="lineNum">    1741 </span><span class="lineCov">       6356 :         if (delay &gt; 0 &amp;&amp;</span></a>
<a name="1742"><span class="lineNum">    1742 </span><span class="lineNoCov">          0 :             !(rcu_seq_ctr(rcu_state.gp_seq) %</span></a>
<a name="1743"><span class="lineNum">    1743 </span><span class="lineNoCov">          0 :               (rcu_num_nodes * PER_RCU_NODE_PERIOD * delay)))</span></a>
<a name="1744"><span class="lineNum">    1744 </span><span class="lineNoCov">          0 :                 schedule_timeout_idle(delay);</span></a>
<a name="1745"><span class="lineNum">    1745 </span><span class="lineCov">       6356 : }</span></a>
<a name="1746"><span class="lineNum">    1746 </span>            : </a>
<a name="1747"><span class="lineNum">    1747 </span>            : static unsigned long sleep_duration;</a>
<a name="1748"><span class="lineNum">    1748 </span>            : </a>
<a name="1749"><span class="lineNum">    1749 </span>            : /* Allow rcutorture to stall the grace-period kthread. */</a>
<a name="1750"><span class="lineNum">    1750 </span><span class="lineNoCov">          0 : void rcu_gp_set_torture_wait(int duration)</span></a>
<a name="1751"><span class="lineNum">    1751 </span>            : {</a>
<a name="1752"><span class="lineNum">    1752 </span><span class="lineNoCov">          0 :         if (IS_ENABLED(CONFIG_RCU_TORTURE_TEST) &amp;&amp; duration &gt; 0)</span></a>
<a name="1753"><span class="lineNum">    1753 </span><span class="lineNoCov">          0 :                 WRITE_ONCE(sleep_duration, duration);</span></a>
<a name="1754"><span class="lineNum">    1754 </span><span class="lineNoCov">          0 : }</span></a>
<a name="1755"><span class="lineNum">    1755 </span>            : EXPORT_SYMBOL_GPL(rcu_gp_set_torture_wait);</a>
<a name="1756"><span class="lineNum">    1756 </span>            : </a>
<a name="1757"><span class="lineNum">    1757 </span>            : /* Actually implement the aforementioned wait. */</a>
<a name="1758"><span class="lineNum">    1758 </span><span class="lineCov">       6692 : static void rcu_gp_torture_wait(void)</span></a>
<a name="1759"><span class="lineNum">    1759 </span>            : {</a>
<a name="1760"><span class="lineNum">    1760 </span><span class="lineCov">       6692 :         unsigned long duration;</span></a>
<a name="1761"><span class="lineNum">    1761 </span>            : </a>
<a name="1762"><span class="lineNum">    1762 </span><span class="lineCov">       6692 :         if (!IS_ENABLED(CONFIG_RCU_TORTURE_TEST))</span></a>
<a name="1763"><span class="lineNum">    1763 </span><span class="lineCov">       6692 :                 return;</span></a>
<a name="1764"><span class="lineNum">    1764 </span>            :         duration = xchg(&amp;sleep_duration, 0UL);</a>
<a name="1765"><span class="lineNum">    1765 </span>            :         if (duration &gt; 0) {</a>
<a name="1766"><span class="lineNum">    1766 </span>            :                 pr_alert(&quot;%s: Waiting %lu jiffies\n&quot;, __func__, duration);</a>
<a name="1767"><span class="lineNum">    1767 </span>            :                 schedule_timeout_idle(duration);</a>
<a name="1768"><span class="lineNum">    1768 </span>            :                 pr_alert(&quot;%s: Wait complete\n&quot;, __func__);</a>
<a name="1769"><span class="lineNum">    1769 </span>            :         }</a>
<a name="1770"><span class="lineNum">    1770 </span>            : }</a>
<a name="1771"><span class="lineNum">    1771 </span>            : </a>
<a name="1772"><span class="lineNum">    1772 </span>            : /*</a>
<a name="1773"><span class="lineNum">    1773 </span>            :  * Handler for on_each_cpu() to invoke the target CPU's RCU core</a>
<a name="1774"><span class="lineNum">    1774 </span>            :  * processing.</a>
<a name="1775"><span class="lineNum">    1775 </span>            :  */</a>
<a name="1776"><span class="lineNum">    1776 </span>            : static void rcu_strict_gp_boundary(void *unused)</a>
<a name="1777"><span class="lineNum">    1777 </span>            : {</a>
<a name="1778"><span class="lineNum">    1778 </span>            :         invoke_rcu_core();</a>
<a name="1779"><span class="lineNum">    1779 </span>            : }</a>
<a name="1780"><span class="lineNum">    1780 </span>            : </a>
<a name="1781"><span class="lineNum">    1781 </span>            : /*</a>
<a name="1782"><span class="lineNum">    1782 </span>            :  * Initialize a new grace period.  Return false if no grace period required.</a>
<a name="1783"><span class="lineNum">    1783 </span>            :  */</a>
<a name="1784"><span class="lineNum">    1784 </span><span class="lineCov">       2119 : static bool rcu_gp_init(void)</span></a>
<a name="1785"><span class="lineNum">    1785 </span>            : {</a>
<a name="1786"><span class="lineNum">    1786 </span><span class="lineCov">       2119 :         unsigned long firstseq;</span></a>
<a name="1787"><span class="lineNum">    1787 </span><span class="lineCov">       2119 :         unsigned long flags;</span></a>
<a name="1788"><span class="lineNum">    1788 </span><span class="lineCov">       2119 :         unsigned long oldmask;</span></a>
<a name="1789"><span class="lineNum">    1789 </span><span class="lineCov">       2119 :         unsigned long mask;</span></a>
<a name="1790"><span class="lineNum">    1790 </span><span class="lineCov">       2119 :         struct rcu_data *rdp;</span></a>
<a name="1791"><span class="lineNum">    1791 </span><span class="lineCov">       2119 :         struct rcu_node *rnp = rcu_get_root();</span></a>
<a name="1792"><span class="lineNum">    1792 </span>            : </a>
<a name="1793"><span class="lineNum">    1793 </span><span class="lineCov">       2119 :         WRITE_ONCE(rcu_state.gp_activity, jiffies);</span></a>
<a name="1794"><span class="lineNum">    1794 </span><span class="lineCov">       2119 :         raw_spin_lock_irq_rcu_node(rnp);</span></a>
<a name="1795"><span class="lineNum">    1795 </span><span class="lineCov">       2119 :         if (!READ_ONCE(rcu_state.gp_flags)) {</span></a>
<a name="1796"><span class="lineNum">    1796 </span>            :                 /* Spurious wakeup, tell caller to go back to sleep.  */</a>
<a name="1797"><span class="lineNum">    1797 </span><span class="lineNoCov">          0 :                 raw_spin_unlock_irq_rcu_node(rnp);</span></a>
<a name="1798"><span class="lineNum">    1798 </span><span class="lineNoCov">          0 :                 return false;</span></a>
<a name="1799"><span class="lineNum">    1799 </span>            :         }</a>
<a name="1800"><span class="lineNum">    1800 </span><span class="lineCov">       2119 :         WRITE_ONCE(rcu_state.gp_flags, 0); /* Clear all flags: New GP. */</span></a>
<a name="1801"><span class="lineNum">    1801 </span>            : </a>
<a name="1802"><span class="lineNum">    1802 </span><span class="lineCov">       2119 :         if (WARN_ON_ONCE(rcu_gp_in_progress())) {</span></a>
<a name="1803"><span class="lineNum">    1803 </span>            :                 /*</a>
<a name="1804"><span class="lineNum">    1804 </span>            :                  * Grace period already in progress, don't start another.</a>
<a name="1805"><span class="lineNum">    1805 </span>            :                  * Not supposed to be able to happen.</a>
<a name="1806"><span class="lineNum">    1806 </span>            :                  */</a>
<a name="1807"><span class="lineNum">    1807 </span><span class="lineNoCov">          0 :                 raw_spin_unlock_irq_rcu_node(rnp);</span></a>
<a name="1808"><span class="lineNum">    1808 </span><span class="lineNoCov">          0 :                 return false;</span></a>
<a name="1809"><span class="lineNum">    1809 </span>            :         }</a>
<a name="1810"><span class="lineNum">    1810 </span>            : </a>
<a name="1811"><span class="lineNum">    1811 </span>            :         /* Advance to a new grace period and initialize state. */</a>
<a name="1812"><span class="lineNum">    1812 </span><span class="lineCov">       2119 :         record_gp_stall_check_time();</span></a>
<a name="1813"><span class="lineNum">    1813 </span>            :         /* Record GP times before starting GP, hence rcu_seq_start(). */</a>
<a name="1814"><span class="lineNum">    1814 </span><span class="lineCov">       2119 :         rcu_seq_start(&amp;rcu_state.gp_seq);</span></a>
<a name="1815"><span class="lineNum">    1815 </span><span class="lineCov">       2119 :         ASSERT_EXCLUSIVE_WRITER(rcu_state.gp_seq);</span></a>
<a name="1816"><span class="lineNum">    1816 </span><span class="lineCov">       2119 :         trace_rcu_grace_period(rcu_state.name, rcu_state.gp_seq, TPS(&quot;start&quot;));</span></a>
<a name="1817"><span class="lineNum">    1817 </span><span class="lineCov">       4238 :         raw_spin_unlock_irq_rcu_node(rnp);</span></a>
<a name="1818"><span class="lineNum">    1818 </span>            : </a>
<a name="1819"><span class="lineNum">    1819 </span>            :         /*</a>
<a name="1820"><span class="lineNum">    1820 </span>            :          * Apply per-leaf buffered online and offline operations to</a>
<a name="1821"><span class="lineNum">    1821 </span>            :          * the rcu_node tree. Note that this new grace period need not</a>
<a name="1822"><span class="lineNum">    1822 </span>            :          * wait for subsequent online CPUs, and that RCU hooks in the CPU</a>
<a name="1823"><span class="lineNum">    1823 </span>            :          * offlining path, when combined with checks in this function,</a>
<a name="1824"><span class="lineNum">    1824 </span>            :          * will handle CPUs that are currently going offline or that will</a>
<a name="1825"><span class="lineNum">    1825 </span>            :          * go offline later.  Please also refer to &quot;Hotplug CPU&quot; section</a>
<a name="1826"><span class="lineNum">    1826 </span>            :          * of RCU's Requirements documentation.</a>
<a name="1827"><span class="lineNum">    1827 </span>            :          */</a>
<a name="1828"><span class="lineNum">    1828 </span><span class="lineCov">       2119 :         WRITE_ONCE(rcu_state.gp_state, RCU_GP_ONOFF);</span></a>
<a name="1829"><span class="lineNum">    1829 </span><span class="lineCov">       4238 :         rcu_for_each_leaf_node(rnp) {</span></a>
<a name="1830"><span class="lineNum">    1830 </span><span class="lineCov">       2119 :                 smp_mb(); // Pair with barriers used when updating -&gt;ofl_seq to odd values.</span></a>
<a name="1831"><span class="lineNum">    1831 </span><span class="lineCov">       2119 :                 firstseq = READ_ONCE(rnp-&gt;ofl_seq);</span></a>
<a name="1832"><span class="lineNum">    1832 </span><span class="lineCov">       2119 :                 if (firstseq &amp; 0x1)</span></a>
<a name="1833"><span class="lineNum">    1833 </span><span class="lineNoCov">          0 :                         while (firstseq == READ_ONCE(rnp-&gt;ofl_seq))</span></a>
<a name="1834"><span class="lineNum">    1834 </span><span class="lineNoCov">          0 :                                 schedule_timeout_idle(1);  // Can't wake unless RCU is watching.</span></a>
<a name="1835"><span class="lineNum">    1835 </span><span class="lineCov">       2119 :                 smp_mb(); // Pair with barriers used when updating -&gt;ofl_seq to even values.</span></a>
<a name="1836"><span class="lineNum">    1836 </span><span class="lineCov">       2119 :                 raw_spin_lock(&amp;rcu_state.ofl_lock);</span></a>
<a name="1837"><span class="lineNum">    1837 </span><span class="lineCov">       2119 :                 raw_spin_lock_irq_rcu_node(rnp);</span></a>
<a name="1838"><span class="lineNum">    1838 </span><span class="lineCov">       2119 :                 if (rnp-&gt;qsmaskinit == rnp-&gt;qsmaskinitnext &amp;&amp;</span></a>
<a name="1839"><span class="lineNum">    1839 </span><span class="lineCov">       2115 :                     !rnp-&gt;wait_blkd_tasks) {</span></a>
<a name="1840"><span class="lineNum">    1840 </span>            :                         /* Nothing to do on this leaf rcu_node structure. */</a>
<a name="1841"><span class="lineNum">    1841 </span><span class="lineCov">       4230 :                         raw_spin_unlock_irq_rcu_node(rnp);</span></a>
<a name="1842"><span class="lineNum">    1842 </span><span class="lineCov">       2115 :                         raw_spin_unlock(&amp;rcu_state.ofl_lock);</span></a>
<a name="1843"><span class="lineNum">    1843 </span><span class="lineCov">       2115 :                         continue;</span></a>
<a name="1844"><span class="lineNum">    1844 </span>            :                 }</a>
<a name="1845"><span class="lineNum">    1845 </span>            : </a>
<a name="1846"><span class="lineNum">    1846 </span>            :                 /* Record old state, apply changes to -&gt;qsmaskinit field. */</a>
<a name="1847"><span class="lineNum">    1847 </span><span class="lineCov">          4 :                 oldmask = rnp-&gt;qsmaskinit;</span></a>
<a name="1848"><span class="lineNum">    1848 </span><span class="lineCov">          4 :                 rnp-&gt;qsmaskinit = rnp-&gt;qsmaskinitnext;</span></a>
<a name="1849"><span class="lineNum">    1849 </span>            : </a>
<a name="1850"><span class="lineNum">    1850 </span>            :                 /* If zero-ness of -&gt;qsmaskinit changed, propagate up tree. */</a>
<a name="1851"><span class="lineNum">    1851 </span><span class="lineCov">          4 :                 if (!oldmask != !rnp-&gt;qsmaskinit) {</span></a>
<a name="1852"><span class="lineNum">    1852 </span><span class="lineCov">          1 :                         if (!oldmask) { /* First online CPU for rcu_node. */</span></a>
<a name="1853"><span class="lineNum">    1853 </span><span class="lineCov">          1 :                                 if (!rnp-&gt;wait_blkd_tasks) /* Ever offline? */</span></a>
<a name="1854"><span class="lineNum">    1854 </span><span class="lineCov">          1 :                                         rcu_init_new_rnp(rnp);</span></a>
<a name="1855"><span class="lineNum">    1855 </span><span class="lineNoCov">          0 :                         } else if (rcu_preempt_has_tasks(rnp)) {</span></a>
<a name="1856"><span class="lineNum">    1856 </span>            :                                 rnp-&gt;wait_blkd_tasks = true; /* blocked tasks */</a>
<a name="1857"><span class="lineNum">    1857 </span>            :                         } else { /* Last offline CPU and can propagate. */</a>
<a name="1858"><span class="lineNum">    1858 </span><span class="lineNoCov">          0 :                                 rcu_cleanup_dead_rnp(rnp);</span></a>
<a name="1859"><span class="lineNum">    1859 </span>            :                         }</a>
<a name="1860"><span class="lineNum">    1860 </span>            :                 }</a>
<a name="1861"><span class="lineNum">    1861 </span>            : </a>
<a name="1862"><span class="lineNum">    1862 </span>            :                 /*</a>
<a name="1863"><span class="lineNum">    1863 </span>            :                  * If all waited-on tasks from prior grace period are</a>
<a name="1864"><span class="lineNum">    1864 </span>            :                  * done, and if all this rcu_node structure's CPUs are</a>
<a name="1865"><span class="lineNum">    1865 </span>            :                  * still offline, propagate up the rcu_node tree and</a>
<a name="1866"><span class="lineNum">    1866 </span>            :                  * clear -&gt;wait_blkd_tasks.  Otherwise, if one of this</a>
<a name="1867"><span class="lineNum">    1867 </span>            :                  * rcu_node structure's CPUs has since come back online,</a>
<a name="1868"><span class="lineNum">    1868 </span>            :                  * simply clear -&gt;wait_blkd_tasks.</a>
<a name="1869"><span class="lineNum">    1869 </span>            :                  */</a>
<a name="1870"><span class="lineNum">    1870 </span><span class="lineCov">          4 :                 if (rnp-&gt;wait_blkd_tasks &amp;&amp;</span></a>
<a name="1871"><span class="lineNum">    1871 </span><span class="lineNoCov">          0 :                     (!rcu_preempt_has_tasks(rnp) || rnp-&gt;qsmaskinit)) {</span></a>
<a name="1872"><span class="lineNum">    1872 </span><span class="lineNoCov">          0 :                         rnp-&gt;wait_blkd_tasks = false;</span></a>
<a name="1873"><span class="lineNum">    1873 </span><span class="lineNoCov">          0 :                         if (!rnp-&gt;qsmaskinit)</span></a>
<a name="1874"><span class="lineNum">    1874 </span><span class="lineNoCov">          0 :                                 rcu_cleanup_dead_rnp(rnp);</span></a>
<a name="1875"><span class="lineNum">    1875 </span>            :                 }</a>
<a name="1876"><span class="lineNum">    1876 </span>            : </a>
<a name="1877"><span class="lineNum">    1877 </span><span class="lineCov">          8 :                 raw_spin_unlock_irq_rcu_node(rnp);</span></a>
<a name="1878"><span class="lineNum">    1878 </span><span class="lineCov">          4 :                 raw_spin_unlock(&amp;rcu_state.ofl_lock);</span></a>
<a name="1879"><span class="lineNum">    1879 </span>            :         }</a>
<a name="1880"><span class="lineNum">    1880 </span><span class="lineCov">       2119 :         rcu_gp_slow(gp_preinit_delay); /* Races with CPU hotplug. */</span></a>
<a name="1881"><span class="lineNum">    1881 </span>            : </a>
<a name="1882"><span class="lineNum">    1882 </span>            :         /*</a>
<a name="1883"><span class="lineNum">    1883 </span>            :          * Set the quiescent-state-needed bits in all the rcu_node</a>
<a name="1884"><span class="lineNum">    1884 </span>            :          * structures for all currently online CPUs in breadth-first</a>
<a name="1885"><span class="lineNum">    1885 </span>            :          * order, starting from the root rcu_node structure, relying on the</a>
<a name="1886"><span class="lineNum">    1886 </span>            :          * layout of the tree within the rcu_state.node[] array.  Note that</a>
<a name="1887"><span class="lineNum">    1887 </span>            :          * other CPUs will access only the leaves of the hierarchy, thus</a>
<a name="1888"><span class="lineNum">    1888 </span>            :          * seeing that no grace period is in progress, at least until the</a>
<a name="1889"><span class="lineNum">    1889 </span>            :          * corresponding leaf node has been initialized.</a>
<a name="1890"><span class="lineNum">    1890 </span>            :          *</a>
<a name="1891"><span class="lineNum">    1891 </span>            :          * The grace period cannot complete until the initialization</a>
<a name="1892"><span class="lineNum">    1892 </span>            :          * process finishes, because this kthread handles both.</a>
<a name="1893"><span class="lineNum">    1893 </span>            :          */</a>
<a name="1894"><span class="lineNum">    1894 </span><span class="lineCov">       2119 :         WRITE_ONCE(rcu_state.gp_state, RCU_GP_INIT);</span></a>
<a name="1895"><span class="lineNum">    1895 </span><span class="lineCov">       4238 :         rcu_for_each_node_breadth_first(rnp) {</span></a>
<a name="1896"><span class="lineNum">    1896 </span><span class="lineCov">       2119 :                 rcu_gp_slow(gp_init_delay);</span></a>
<a name="1897"><span class="lineNum">    1897 </span><span class="lineCov">       2119 :                 raw_spin_lock_irqsave_rcu_node(rnp, flags);</span></a>
<a name="1898"><span class="lineNum">    1898 </span><span class="lineCov">       2119 :                 rdp = this_cpu_ptr(&amp;rcu_data);</span></a>
<a name="1899"><span class="lineNum">    1899 </span><span class="lineCov">       2119 :                 rcu_preempt_check_blocked_tasks(rnp);</span></a>
<a name="1900"><span class="lineNum">    1900 </span><span class="lineCov">       2119 :                 rnp-&gt;qsmask = rnp-&gt;qsmaskinit;</span></a>
<a name="1901"><span class="lineNum">    1901 </span><span class="lineCov">       2119 :                 WRITE_ONCE(rnp-&gt;gp_seq, rcu_state.gp_seq);</span></a>
<a name="1902"><span class="lineNum">    1902 </span><span class="lineCov">       2119 :                 if (rnp == rdp-&gt;mynode)</span></a>
<a name="1903"><span class="lineNum">    1903 </span><span class="lineCov">       2119 :                         (void)__note_gp_changes(rnp, rdp);</span></a>
<a name="1904"><span class="lineNum">    1904 </span><span class="lineCov">       2119 :                 rcu_preempt_boost_start_gp(rnp);</span></a>
<a name="1905"><span class="lineNum">    1905 </span><span class="lineCov">       2119 :                 trace_rcu_grace_period_init(rcu_state.name, rnp-&gt;gp_seq,</span></a>
<a name="1906"><span class="lineNum">    1906 </span><span class="lineCov">       2119 :                                             rnp-&gt;level, rnp-&gt;grplo,</span></a>
<a name="1907"><span class="lineNum">    1907 </span>            :                                             rnp-&gt;grphi, rnp-&gt;qsmask);</a>
<a name="1908"><span class="lineNum">    1908 </span>            :                 /* Quiescent states for tasks on any now-offline CPUs. */</a>
<a name="1909"><span class="lineNum">    1909 </span><span class="lineCov">       2119 :                 mask = rnp-&gt;qsmask &amp; ~rnp-&gt;qsmaskinitnext;</span></a>
<a name="1910"><span class="lineNum">    1910 </span><span class="lineCov">       2119 :                 rnp-&gt;rcu_gp_init_mask = mask;</span></a>
<a name="1911"><span class="lineNum">    1911 </span><span class="lineCov">       2119 :                 if ((mask || rnp-&gt;wait_blkd_tasks) &amp;&amp; rcu_is_leaf_node(rnp))</span></a>
<a name="1912"><span class="lineNum">    1912 </span><span class="lineNoCov">          0 :                         rcu_report_qs_rnp(mask, rnp, rnp-&gt;gp_seq, flags);</span></a>
<a name="1913"><span class="lineNum">    1913 </span>            :                 else</a>
<a name="1914"><span class="lineNum">    1914 </span><span class="lineCov">       4238 :                         raw_spin_unlock_irq_rcu_node(rnp);</span></a>
<a name="1915"><span class="lineNum">    1915 </span><span class="lineCov">       2119 :                 cond_resched_tasks_rcu_qs();</span></a>
<a name="1916"><span class="lineNum">    1916 </span><span class="lineCov">       2119 :                 WRITE_ONCE(rcu_state.gp_activity, jiffies);</span></a>
<a name="1917"><span class="lineNum">    1917 </span>            :         }</a>
<a name="1918"><span class="lineNum">    1918 </span>            : </a>
<a name="1919"><span class="lineNum">    1919 </span>            :         // If strict, make all CPUs aware of new grace period.</a>
<a name="1920"><span class="lineNum">    1920 </span>            :         if (IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD))</a>
<a name="1921"><span class="lineNum">    1921 </span>            :                 on_each_cpu(rcu_strict_gp_boundary, NULL, 0);</a>
<a name="1922"><span class="lineNum">    1922 </span>            : </a>
<a name="1923"><span class="lineNum">    1923 </span>            :         return true;</a>
<a name="1924"><span class="lineNum">    1924 </span>            : }</a>
<a name="1925"><span class="lineNum">    1925 </span>            : </a>
<a name="1926"><span class="lineNum">    1926 </span>            : /*</a>
<a name="1927"><span class="lineNum">    1927 </span>            :  * Helper function for swait_event_idle_exclusive() wakeup at force-quiescent-state</a>
<a name="1928"><span class="lineNum">    1928 </span>            :  * time.</a>
<a name="1929"><span class="lineNum">    1929 </span>            :  */</a>
<a name="1930"><span class="lineNum">    1930 </span><span class="lineCov">      12903 : static bool rcu_gp_fqs_check_wake(int *gfp)</span></a>
<a name="1931"><span class="lineNum">    1931 </span>            : {</a>
<a name="1932"><span class="lineNum">    1932 </span><span class="lineCov">      12903 :         struct rcu_node *rnp = rcu_get_root();</span></a>
<a name="1933"><span class="lineNum">    1933 </span>            : </a>
<a name="1934"><span class="lineNum">    1934 </span>            :         // If under overload conditions, force an immediate FQS scan.</a>
<a name="1935"><span class="lineNum">    1935 </span><span class="lineCov">      12903 :         if (*gfp &amp; RCU_GP_FLAG_OVLD)</span></a>
<a name="1936"><span class="lineNum">    1936 </span>            :                 return true;</a>
<a name="1937"><span class="lineNum">    1937 </span>            : </a>
<a name="1938"><span class="lineNum">    1938 </span>            :         // Someone like call_rcu() requested a force-quiescent-state scan.</a>
<a name="1939"><span class="lineNum">    1939 </span><span class="lineCov">      12903 :         *gfp = READ_ONCE(rcu_state.gp_flags);</span></a>
<a name="1940"><span class="lineNum">    1940 </span><span class="lineCov">      12903 :         if (*gfp &amp; RCU_GP_FLAG_FQS)</span></a>
<a name="1941"><span class="lineNum">    1941 </span>            :                 return true;</a>
<a name="1942"><span class="lineNum">    1942 </span>            : </a>
<a name="1943"><span class="lineNum">    1943 </span>            :         // The current grace period has completed.</a>
<a name="1944"><span class="lineNum">    1944 </span><span class="lineCov">      11196 :         if (!READ_ONCE(rnp-&gt;qsmask) &amp;&amp; !rcu_preempt_blocked_readers_cgp(rnp))</span></a>
<a name="1945"><span class="lineNum">    1945 </span><span class="lineCov">        408 :                 return true;</span></a>
<a name="1946"><span class="lineNum">    1946 </span>            : </a>
<a name="1947"><span class="lineNum">    1947 </span>            :         return false;</a>
<a name="1948"><span class="lineNum">    1948 </span>            : }</a>
<a name="1949"><span class="lineNum">    1949 </span>            : </a>
<a name="1950"><span class="lineNum">    1950 </span>            : /*</a>
<a name="1951"><span class="lineNum">    1951 </span>            :  * Do one round of quiescent-state forcing.</a>
<a name="1952"><span class="lineNum">    1952 </span>            :  */</a>
<a name="1953"><span class="lineNum">    1953 </span><span class="lineCov">       2455 : static void rcu_gp_fqs(bool first_time)</span></a>
<a name="1954"><span class="lineNum">    1954 </span>            : {</a>
<a name="1955"><span class="lineNum">    1955 </span><span class="lineCov">       2455 :         struct rcu_node *rnp = rcu_get_root();</span></a>
<a name="1956"><span class="lineNum">    1956 </span>            : </a>
<a name="1957"><span class="lineNum">    1957 </span><span class="lineCov">       2455 :         WRITE_ONCE(rcu_state.gp_activity, jiffies);</span></a>
<a name="1958"><span class="lineNum">    1958 </span><span class="lineCov">       2455 :         rcu_state.n_force_qs++;</span></a>
<a name="1959"><span class="lineNum">    1959 </span><span class="lineCov">       2455 :         if (first_time) {</span></a>
<a name="1960"><span class="lineNum">    1960 </span>            :                 /* Collect dyntick-idle snapshots. */</a>
<a name="1961"><span class="lineNum">    1961 </span><span class="lineCov">       1568 :                 force_qs_rnp(dyntick_save_progress_counter);</span></a>
<a name="1962"><span class="lineNum">    1962 </span>            :         } else {</a>
<a name="1963"><span class="lineNum">    1963 </span>            :                 /* Handle dyntick-idle and offline CPUs. */</a>
<a name="1964"><span class="lineNum">    1964 </span><span class="lineCov">        887 :                 force_qs_rnp(rcu_implicit_dynticks_qs);</span></a>
<a name="1965"><span class="lineNum">    1965 </span>            :         }</a>
<a name="1966"><span class="lineNum">    1966 </span>            :         /* Clear flag to prevent immediate re-entry. */</a>
<a name="1967"><span class="lineNum">    1967 </span><span class="lineCov">       2455 :         if (READ_ONCE(rcu_state.gp_flags) &amp; RCU_GP_FLAG_FQS) {</span></a>
<a name="1968"><span class="lineNum">    1968 </span><span class="lineCov">        407 :                 raw_spin_lock_irq_rcu_node(rnp);</span></a>
<a name="1969"><span class="lineNum">    1969 </span><span class="lineCov">        407 :                 WRITE_ONCE(rcu_state.gp_flags,</span></a>
<a name="1970"><span class="lineNum">    1970 </span>            :                            READ_ONCE(rcu_state.gp_flags) &amp; ~RCU_GP_FLAG_FQS);</a>
<a name="1971"><span class="lineNum">    1971 </span><span class="lineCov">        814 :                 raw_spin_unlock_irq_rcu_node(rnp);</span></a>
<a name="1972"><span class="lineNum">    1972 </span>            :         }</a>
<a name="1973"><span class="lineNum">    1973 </span><span class="lineCov">       2455 : }</span></a>
<a name="1974"><span class="lineNum">    1974 </span>            : </a>
<a name="1975"><span class="lineNum">    1975 </span>            : /*</a>
<a name="1976"><span class="lineNum">    1976 </span>            :  * Loop doing repeated quiescent-state forcing until the grace period ends.</a>
<a name="1977"><span class="lineNum">    1977 </span>            :  */</a>
<a name="1978"><span class="lineNum">    1978 </span><span class="lineCov">       2119 : static void rcu_gp_fqs_loop(void)</span></a>
<a name="1979"><span class="lineNum">    1979 </span>            : {</a>
<a name="1980"><span class="lineNum">    1980 </span><span class="lineCov">       2119 :         bool first_gp_fqs;</span></a>
<a name="1981"><span class="lineNum">    1981 </span><span class="lineCov">       2119 :         int gf = 0;</span></a>
<a name="1982"><span class="lineNum">    1982 </span><span class="lineCov">       2119 :         unsigned long j;</span></a>
<a name="1983"><span class="lineNum">    1983 </span><span class="lineCov">       2119 :         int ret;</span></a>
<a name="1984"><span class="lineNum">    1984 </span><span class="lineCov">       2119 :         struct rcu_node *rnp = rcu_get_root();</span></a>
<a name="1985"><span class="lineNum">    1985 </span>            : </a>
<a name="1986"><span class="lineNum">    1986 </span><span class="lineCov">       2119 :         first_gp_fqs = true;</span></a>
<a name="1987"><span class="lineNum">    1987 </span><span class="lineCov">       2119 :         j = READ_ONCE(jiffies_till_first_fqs);</span></a>
<a name="1988"><span class="lineNum">    1988 </span><span class="lineCov">       2119 :         if (rcu_state.cbovld)</span></a>
<a name="1989"><span class="lineNum">    1989 </span><span class="lineNoCov">          0 :                 gf = RCU_GP_FLAG_OVLD;</span></a>
<a name="1990"><span class="lineNum">    1990 </span>            :         ret = 0;</a>
<a name="1991"><span class="lineNum">    1991 </span><span class="lineCov">       4574 :         for (;;) {</span></a>
<a name="1992"><span class="lineNum">    1992 </span><span class="lineCov">       4574 :                 if (!ret) {</span></a>
<a name="1993"><span class="lineNum">    1993 </span><span class="lineCov">       4574 :                         WRITE_ONCE(rcu_state.jiffies_force_qs, jiffies + j);</span></a>
<a name="1994"><span class="lineNum">    1994 </span>            :                         /*</a>
<a name="1995"><span class="lineNum">    1995 </span>            :                          * jiffies_force_qs before RCU_GP_WAIT_FQS state</a>
<a name="1996"><span class="lineNum">    1996 </span>            :                          * update; required for stall checks.</a>
<a name="1997"><span class="lineNum">    1997 </span>            :                          */</a>
<a name="1998"><span class="lineNum">    1998 </span><span class="lineCov">       4574 :                         smp_wmb();</span></a>
<a name="1999"><span class="lineNum">    1999 </span><span class="lineCov">       4574 :                         WRITE_ONCE(rcu_state.jiffies_kick_kthreads,</span></a>
<a name="2000"><span class="lineNum">    2000 </span>            :                                    jiffies + (j ? 3 * j : 2));</a>
<a name="2001"><span class="lineNum">    2001 </span>            :                 }</a>
<a name="2002"><span class="lineNum">    2002 </span><span class="lineCov">       4574 :                 trace_rcu_grace_period(rcu_state.name, rcu_state.gp_seq,</span></a>
<a name="2003"><span class="lineNum">    2003 </span><span class="lineCov">       4574 :                                        TPS(&quot;fqswait&quot;));</span></a>
<a name="2004"><span class="lineNum">    2004 </span><span class="lineCov">       4574 :                 WRITE_ONCE(rcu_state.gp_state, RCU_GP_WAIT_FQS);</span></a>
<a name="2005"><span class="lineNum">    2005 </span><span class="lineCov">       8736 :                 ret = swait_event_idle_timeout_exclusive(</span></a>
<a name="2006"><span class="lineNum">    2006 </span>            :                                 rcu_state.gp_wq, rcu_gp_fqs_check_wake(&amp;gf), j);</a>
<a name="2007"><span class="lineNum">    2007 </span><span class="lineCov">       4573 :                 rcu_gp_torture_wait();</span></a>
<a name="2008"><span class="lineNum">    2008 </span><span class="lineCov">       4573 :                 WRITE_ONCE(rcu_state.gp_state, RCU_GP_DOING_FQS);</span></a>
<a name="2009"><span class="lineNum">    2009 </span>            :                 /* Locking provides needed memory barriers. */</a>
<a name="2010"><span class="lineNum">    2010 </span>            :                 /* If grace period done, leave loop. */</a>
<a name="2011"><span class="lineNum">    2011 </span><span class="lineCov">       4573 :                 if (!READ_ONCE(rnp-&gt;qsmask) &amp;&amp;</span></a>
<a name="2012"><span class="lineNum">    2012 </span><span class="lineCov">       2118 :                     !rcu_preempt_blocked_readers_cgp(rnp))</span></a>
<a name="2013"><span class="lineNum">    2013 </span>            :                         break;</a>
<a name="2014"><span class="lineNum">    2014 </span>            :                 /* If time for quiescent-state forcing, do it. */</a>
<a name="2015"><span class="lineNum">    2015 </span><span class="lineCov">       2455 :                 if (!time_after(rcu_state.jiffies_force_qs, jiffies) ||</span></a>
<a name="2016"><span class="lineNum">    2016 </span><span class="lineNoCov">          0 :                     (gf &amp; (RCU_GP_FLAG_FQS | RCU_GP_FLAG_OVLD))) {</span></a>
<a name="2017"><span class="lineNum">    2017 </span><span class="lineCov">       2455 :                         trace_rcu_grace_period(rcu_state.name, rcu_state.gp_seq,</span></a>
<a name="2018"><span class="lineNum">    2018 </span><span class="lineCov">       2455 :                                                TPS(&quot;fqsstart&quot;));</span></a>
<a name="2019"><span class="lineNum">    2019 </span><span class="lineCov">       2455 :                         rcu_gp_fqs(first_gp_fqs);</span></a>
<a name="2020"><span class="lineNum">    2020 </span><span class="lineCov">       2455 :                         gf = 0;</span></a>
<a name="2021"><span class="lineNum">    2021 </span><span class="lineCov">       2455 :                         if (first_gp_fqs) {</span></a>
<a name="2022"><span class="lineNum">    2022 </span><span class="lineCov">       1568 :                                 first_gp_fqs = false;</span></a>
<a name="2023"><span class="lineNum">    2023 </span><span class="lineCov">       3136 :                                 gf = rcu_state.cbovld ? RCU_GP_FLAG_OVLD : 0;</span></a>
<a name="2024"><span class="lineNum">    2024 </span>            :                         }</a>
<a name="2025"><span class="lineNum">    2025 </span><span class="lineCov">       2455 :                         trace_rcu_grace_period(rcu_state.name, rcu_state.gp_seq,</span></a>
<a name="2026"><span class="lineNum">    2026 </span><span class="lineCov">       2455 :                                                TPS(&quot;fqsend&quot;));</span></a>
<a name="2027"><span class="lineNum">    2027 </span><span class="lineCov">       2455 :                         cond_resched_tasks_rcu_qs();</span></a>
<a name="2028"><span class="lineNum">    2028 </span><span class="lineCov">       2455 :                         WRITE_ONCE(rcu_state.gp_activity, jiffies);</span></a>
<a name="2029"><span class="lineNum">    2029 </span><span class="lineCov">       2455 :                         ret = 0; /* Force full wait till next FQS. */</span></a>
<a name="2030"><span class="lineNum">    2030 </span><span class="lineCov">       2455 :                         j = READ_ONCE(jiffies_till_next_fqs);</span></a>
<a name="2031"><span class="lineNum">    2031 </span>            :                 } else {</a>
<a name="2032"><span class="lineNum">    2032 </span>            :                         /* Deal with stray signal. */</a>
<a name="2033"><span class="lineNum">    2033 </span><span class="lineNoCov">          0 :                         cond_resched_tasks_rcu_qs();</span></a>
<a name="2034"><span class="lineNum">    2034 </span><span class="lineNoCov">          0 :                         WRITE_ONCE(rcu_state.gp_activity, jiffies);</span></a>
<a name="2035"><span class="lineNum">    2035 </span><span class="lineNoCov">          0 :                         WARN_ON(signal_pending(current));</span></a>
<a name="2036"><span class="lineNum">    2036 </span><span class="lineNoCov">          0 :                         trace_rcu_grace_period(rcu_state.name, rcu_state.gp_seq,</span></a>
<a name="2037"><span class="lineNum">    2037 </span><span class="lineNoCov">          0 :                                                TPS(&quot;fqswaitsig&quot;));</span></a>
<a name="2038"><span class="lineNum">    2038 </span><span class="lineNoCov">          0 :                         ret = 1; /* Keep old FQS timing. */</span></a>
<a name="2039"><span class="lineNum">    2039 </span><span class="lineNoCov">          0 :                         j = jiffies;</span></a>
<a name="2040"><span class="lineNum">    2040 </span><span class="lineNoCov">          0 :                         if (time_after(jiffies, rcu_state.jiffies_force_qs))</span></a>
<a name="2041"><span class="lineNum">    2041 </span>            :                                 j = 1;</a>
<a name="2042"><span class="lineNum">    2042 </span>            :                         else</a>
<a name="2043"><span class="lineNum">    2043 </span><span class="lineNoCov">          0 :                                 j = rcu_state.jiffies_force_qs - j;</span></a>
<a name="2044"><span class="lineNum">    2044 </span><span class="lineNoCov">          0 :                         gf = 0;</span></a>
<a name="2045"><span class="lineNum">    2045 </span>            :                 }</a>
<a name="2046"><span class="lineNum">    2046 </span>            :         }</a>
<a name="2047"><span class="lineNum">    2047 </span><span class="lineCov">       2118 : }</span></a>
<a name="2048"><span class="lineNum">    2048 </span>            : </a>
<a name="2049"><span class="lineNum">    2049 </span>            : /*</a>
<a name="2050"><span class="lineNum">    2050 </span>            :  * Clean up after the old grace period.</a>
<a name="2051"><span class="lineNum">    2051 </span>            :  */</a>
<a name="2052"><span class="lineNum">    2052 </span><span class="lineCov">       2118 : static void rcu_gp_cleanup(void)</span></a>
<a name="2053"><span class="lineNum">    2053 </span>            : {</a>
<a name="2054"><span class="lineNum">    2054 </span><span class="lineCov">       2118 :         int cpu;</span></a>
<a name="2055"><span class="lineNum">    2055 </span><span class="lineCov">       2118 :         bool needgp = false;</span></a>
<a name="2056"><span class="lineNum">    2056 </span><span class="lineCov">       2118 :         unsigned long gp_duration;</span></a>
<a name="2057"><span class="lineNum">    2057 </span><span class="lineCov">       2118 :         unsigned long new_gp_seq;</span></a>
<a name="2058"><span class="lineNum">    2058 </span><span class="lineCov">       2118 :         bool offloaded;</span></a>
<a name="2059"><span class="lineNum">    2059 </span><span class="lineCov">       2118 :         struct rcu_data *rdp;</span></a>
<a name="2060"><span class="lineNum">    2060 </span><span class="lineCov">       2118 :         struct rcu_node *rnp = rcu_get_root();</span></a>
<a name="2061"><span class="lineNum">    2061 </span><span class="lineCov">       2118 :         struct swait_queue_head *sq;</span></a>
<a name="2062"><span class="lineNum">    2062 </span>            : </a>
<a name="2063"><span class="lineNum">    2063 </span><span class="lineCov">       2118 :         WRITE_ONCE(rcu_state.gp_activity, jiffies);</span></a>
<a name="2064"><span class="lineNum">    2064 </span><span class="lineCov">       2118 :         raw_spin_lock_irq_rcu_node(rnp);</span></a>
<a name="2065"><span class="lineNum">    2065 </span><span class="lineCov">       2118 :         rcu_state.gp_end = jiffies;</span></a>
<a name="2066"><span class="lineNum">    2066 </span><span class="lineCov">       2118 :         gp_duration = rcu_state.gp_end - rcu_state.gp_start;</span></a>
<a name="2067"><span class="lineNum">    2067 </span><span class="lineCov">       2118 :         if (gp_duration &gt; rcu_state.gp_max)</span></a>
<a name="2068"><span class="lineNum">    2068 </span><span class="lineCov">          5 :                 rcu_state.gp_max = gp_duration;</span></a>
<a name="2069"><span class="lineNum">    2069 </span>            : </a>
<a name="2070"><span class="lineNum">    2070 </span>            :         /*</a>
<a name="2071"><span class="lineNum">    2071 </span>            :          * We know the grace period is complete, but to everyone else</a>
<a name="2072"><span class="lineNum">    2072 </span>            :          * it appears to still be ongoing.  But it is also the case</a>
<a name="2073"><span class="lineNum">    2073 </span>            :          * that to everyone else it looks like there is nothing that</a>
<a name="2074"><span class="lineNum">    2074 </span>            :          * they can do to advance the grace period.  It is therefore</a>
<a name="2075"><span class="lineNum">    2075 </span>            :          * safe for us to drop the lock in order to mark the grace</a>
<a name="2076"><span class="lineNum">    2076 </span>            :          * period as completed in all of the rcu_node structures.</a>
<a name="2077"><span class="lineNum">    2077 </span>            :          */</a>
<a name="2078"><span class="lineNum">    2078 </span><span class="lineCov">       4236 :         raw_spin_unlock_irq_rcu_node(rnp);</span></a>
<a name="2079"><span class="lineNum">    2079 </span>            : </a>
<a name="2080"><span class="lineNum">    2080 </span>            :         /*</a>
<a name="2081"><span class="lineNum">    2081 </span>            :          * Propagate new -&gt;gp_seq value to rcu_node structures so that</a>
<a name="2082"><span class="lineNum">    2082 </span>            :          * other CPUs don't have to wait until the start of the next grace</a>
<a name="2083"><span class="lineNum">    2083 </span>            :          * period to process their callbacks.  This also avoids some nasty</a>
<a name="2084"><span class="lineNum">    2084 </span>            :          * RCU grace-period initialization races by forcing the end of</a>
<a name="2085"><span class="lineNum">    2085 </span>            :          * the current grace period to be completely recorded in all of</a>
<a name="2086"><span class="lineNum">    2086 </span>            :          * the rcu_node structures before the beginning of the next grace</a>
<a name="2087"><span class="lineNum">    2087 </span>            :          * period is recorded in any of the rcu_node structures.</a>
<a name="2088"><span class="lineNum">    2088 </span>            :          */</a>
<a name="2089"><span class="lineNum">    2089 </span><span class="lineCov">       2118 :         new_gp_seq = rcu_state.gp_seq;</span></a>
<a name="2090"><span class="lineNum">    2090 </span><span class="lineCov">       2118 :         rcu_seq_end(&amp;new_gp_seq);</span></a>
<a name="2091"><span class="lineNum">    2091 </span><span class="lineCov">       6354 :         rcu_for_each_node_breadth_first(rnp) {</span></a>
<a name="2092"><span class="lineNum">    2092 </span><span class="lineCov">       2118 :                 raw_spin_lock_irq_rcu_node(rnp);</span></a>
<a name="2093"><span class="lineNum">    2093 </span><span class="lineCov">       2118 :                 if (WARN_ON_ONCE(rcu_preempt_blocked_readers_cgp(rnp)))</span></a>
<a name="2094"><span class="lineNum">    2094 </span><span class="lineCov">       2118 :                         dump_blkd_tasks(rnp, 10);</span></a>
<a name="2095"><span class="lineNum">    2095 </span><span class="lineCov">       2118 :                 WARN_ON_ONCE(rnp-&gt;qsmask);</span></a>
<a name="2096"><span class="lineNum">    2096 </span><span class="lineCov">       2118 :                 WRITE_ONCE(rnp-&gt;gp_seq, new_gp_seq);</span></a>
<a name="2097"><span class="lineNum">    2097 </span><span class="lineCov">       2118 :                 rdp = this_cpu_ptr(&amp;rcu_data);</span></a>
<a name="2098"><span class="lineNum">    2098 </span><span class="lineCov">       2118 :                 if (rnp == rdp-&gt;mynode)</span></a>
<a name="2099"><span class="lineNum">    2099 </span><span class="lineCov">       4236 :                         needgp = __note_gp_changes(rnp, rdp) || needgp;</span></a>
<a name="2100"><span class="lineNum">    2100 </span>            :                 /* smp_mb() provided by prior unlock-lock pair. */</a>
<a name="2101"><span class="lineNum">    2101 </span><span class="lineCov">       4236 :                 needgp = rcu_future_gp_cleanup(rnp) || needgp;</span></a>
<a name="2102"><span class="lineNum">    2102 </span>            :                 // Reset overload indication for CPUs no longer overloaded</a>
<a name="2103"><span class="lineNum">    2103 </span><span class="lineCov">       2118 :                 if (rcu_is_leaf_node(rnp))</span></a>
<a name="2104"><span class="lineNum">    2104 </span><span class="lineCov">       2118 :                         for_each_leaf_node_cpu_mask(rnp, cpu, rnp-&gt;cbovldmask) {</span></a>
<a name="2105"><span class="lineNum">    2105 </span><span class="lineNoCov">          0 :                                 rdp = per_cpu_ptr(&amp;rcu_data, cpu);</span></a>
<a name="2106"><span class="lineNum">    2106 </span><span class="lineNoCov">          0 :                                 check_cb_ovld_locked(rdp, rnp);</span></a>
<a name="2107"><span class="lineNum">    2107 </span>            :                         }</a>
<a name="2108"><span class="lineNum">    2108 </span><span class="lineCov">       2118 :                 sq = rcu_nocb_gp_get(rnp);</span></a>
<a name="2109"><span class="lineNum">    2109 </span><span class="lineCov">       4236 :                 raw_spin_unlock_irq_rcu_node(rnp);</span></a>
<a name="2110"><span class="lineNum">    2110 </span><span class="lineCov">       2118 :                 rcu_nocb_gp_cleanup(sq);</span></a>
<a name="2111"><span class="lineNum">    2111 </span><span class="lineCov">       2118 :                 cond_resched_tasks_rcu_qs();</span></a>
<a name="2112"><span class="lineNum">    2112 </span><span class="lineCov">       2118 :                 WRITE_ONCE(rcu_state.gp_activity, jiffies);</span></a>
<a name="2113"><span class="lineNum">    2113 </span><span class="lineCov">       2118 :                 rcu_gp_slow(gp_cleanup_delay);</span></a>
<a name="2114"><span class="lineNum">    2114 </span>            :         }</a>
<a name="2115"><span class="lineNum">    2115 </span><span class="lineCov">       2118 :         rnp = rcu_get_root();</span></a>
<a name="2116"><span class="lineNum">    2116 </span><span class="lineCov">       2118 :         raw_spin_lock_irq_rcu_node(rnp); /* GP before -&gt;gp_seq update. */</span></a>
<a name="2117"><span class="lineNum">    2117 </span>            : </a>
<a name="2118"><span class="lineNum">    2118 </span>            :         /* Declare grace period done, trace first to use old GP number. */</a>
<a name="2119"><span class="lineNum">    2119 </span><span class="lineCov">       2118 :         trace_rcu_grace_period(rcu_state.name, rcu_state.gp_seq, TPS(&quot;end&quot;));</span></a>
<a name="2120"><span class="lineNum">    2120 </span><span class="lineCov">       2118 :         rcu_seq_end(&amp;rcu_state.gp_seq);</span></a>
<a name="2121"><span class="lineNum">    2121 </span><span class="lineCov">       2118 :         ASSERT_EXCLUSIVE_WRITER(rcu_state.gp_seq);</span></a>
<a name="2122"><span class="lineNum">    2122 </span><span class="lineCov">       2118 :         WRITE_ONCE(rcu_state.gp_state, RCU_GP_IDLE);</span></a>
<a name="2123"><span class="lineNum">    2123 </span>            :         /* Check for GP requests since above loop. */</a>
<a name="2124"><span class="lineNum">    2124 </span><span class="lineCov">       2118 :         rdp = this_cpu_ptr(&amp;rcu_data);</span></a>
<a name="2125"><span class="lineNum">    2125 </span><span class="lineCov">       2118 :         if (!needgp &amp;&amp; ULONG_CMP_LT(rnp-&gt;gp_seq, rnp-&gt;gp_seq_needed)) {</span></a>
<a name="2126"><span class="lineNum">    2126 </span><span class="lineNoCov">          0 :                 trace_rcu_this_gp(rnp, rdp, rnp-&gt;gp_seq_needed,</span></a>
<a name="2127"><span class="lineNum">    2127 </span><span class="lineNoCov">          0 :                                   TPS(&quot;CleanupMore&quot;));</span></a>
<a name="2128"><span class="lineNum">    2128 </span><span class="lineNoCov">          0 :                 needgp = true;</span></a>
<a name="2129"><span class="lineNum">    2129 </span>            :         }</a>
<a name="2130"><span class="lineNum">    2130 </span>            :         /* Advance CBs to reduce false positives below. */</a>
<a name="2131"><span class="lineNum">    2131 </span><span class="lineCov">       2118 :         offloaded = rcu_segcblist_is_offloaded(&amp;rdp-&gt;cblist);</span></a>
<a name="2132"><span class="lineNum">    2132 </span><span class="lineCov">       2118 :         if ((offloaded || !rcu_accelerate_cbs(rnp, rdp)) &amp;&amp; needgp) {</span></a>
<a name="2133"><span class="lineNum">    2133 </span><span class="lineCov">       2105 :                 WRITE_ONCE(rcu_state.gp_flags, RCU_GP_FLAG_INIT);</span></a>
<a name="2134"><span class="lineNum">    2134 </span><span class="lineCov">       2105 :                 WRITE_ONCE(rcu_state.gp_req_activity, jiffies);</span></a>
<a name="2135"><span class="lineNum">    2135 </span><span class="lineCov">       4223 :                 trace_rcu_grace_period(rcu_state.name,</span></a>
<a name="2136"><span class="lineNum">    2136 </span>            :                                        rcu_state.gp_seq,</a>
<a name="2137"><span class="lineNum">    2137 </span><span class="lineCov">       2105 :                                        TPS(&quot;newreq&quot;));</span></a>
<a name="2138"><span class="lineNum">    2138 </span>            :         } else {</a>
<a name="2139"><span class="lineNum">    2139 </span><span class="lineCov">         13 :                 WRITE_ONCE(rcu_state.gp_flags,</span></a>
<a name="2140"><span class="lineNum">    2140 </span>            :                            rcu_state.gp_flags &amp; RCU_GP_FLAG_INIT);</a>
<a name="2141"><span class="lineNum">    2141 </span>            :         }</a>
<a name="2142"><span class="lineNum">    2142 </span><span class="lineCov">       4236 :         raw_spin_unlock_irq_rcu_node(rnp);</span></a>
<a name="2143"><span class="lineNum">    2143 </span>            : </a>
<a name="2144"><span class="lineNum">    2144 </span>            :         // If strict, make all CPUs aware of the end of the old grace period.</a>
<a name="2145"><span class="lineNum">    2145 </span><span class="lineCov">       2118 :         if (IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD))</span></a>
<a name="2146"><span class="lineNum">    2146 </span>            :                 on_each_cpu(rcu_strict_gp_boundary, NULL, 0);</a>
<a name="2147"><span class="lineNum">    2147 </span><span class="lineCov">       2118 : }</span></a>
<a name="2148"><span class="lineNum">    2148 </span>            : </a>
<a name="2149"><span class="lineNum">    2149 </span>            : /*</a>
<a name="2150"><span class="lineNum">    2150 </span>            :  * Body of kthread that handles grace periods.</a>
<a name="2151"><span class="lineNum">    2151 </span>            :  */</a>
<a name="2152"><span class="lineNum">    2152 </span><span class="lineCov">          1 : static int __noreturn rcu_gp_kthread(void *unused)</span></a>
<a name="2153"><span class="lineNum">    2153 </span>            : {</a>
<a name="2154"><span class="lineNum">    2154 </span><span class="lineCov">          1 :         rcu_bind_gp_kthread();</span></a>
<a name="2155"><span class="lineNum">    2155 </span><span class="lineCov">       4237 :         for (;;) {</span></a>
<a name="2156"><span class="lineNum">    2156 </span>            : </a>
<a name="2157"><span class="lineNum">    2157 </span>            :                 /* Handle grace-period start. */</a>
<a name="2158"><span class="lineNum">    2158 </span><span class="lineCov">       2119 :                 for (;;) {</span></a>
<a name="2159"><span class="lineNum">    2159 </span><span class="lineCov">       2119 :                         trace_rcu_grace_period(rcu_state.name, rcu_state.gp_seq,</span></a>
<a name="2160"><span class="lineNum">    2160 </span><span class="lineCov">       2119 :                                                TPS(&quot;reqwait&quot;));</span></a>
<a name="2161"><span class="lineNum">    2161 </span><span class="lineCov">       2119 :                         WRITE_ONCE(rcu_state.gp_state, RCU_GP_WAIT_GPS);</span></a>
<a name="2162"><span class="lineNum">    2162 </span><span class="lineCov">       2132 :                         swait_event_idle_exclusive(rcu_state.gp_wq,</span></a>
<a name="2163"><span class="lineNum">    2163 </span>            :                                          READ_ONCE(rcu_state.gp_flags) &amp;</a>
<a name="2164"><span class="lineNum">    2164 </span>            :                                          RCU_GP_FLAG_INIT);</a>
<a name="2165"><span class="lineNum">    2165 </span><span class="lineCov">       2119 :                         rcu_gp_torture_wait();</span></a>
<a name="2166"><span class="lineNum">    2166 </span><span class="lineCov">       2119 :                         WRITE_ONCE(rcu_state.gp_state, RCU_GP_DONE_GPS);</span></a>
<a name="2167"><span class="lineNum">    2167 </span>            :                         /* Locking provides needed memory barrier. */</a>
<a name="2168"><span class="lineNum">    2168 </span><span class="lineCov">       2119 :                         if (rcu_gp_init())</span></a>
<a name="2169"><span class="lineNum">    2169 </span>            :                                 break;</a>
<a name="2170"><span class="lineNum">    2170 </span><span class="lineNoCov">          0 :                         cond_resched_tasks_rcu_qs();</span></a>
<a name="2171"><span class="lineNum">    2171 </span><span class="lineNoCov">          0 :                         WRITE_ONCE(rcu_state.gp_activity, jiffies);</span></a>
<a name="2172"><span class="lineNum">    2172 </span><span class="lineNoCov">          0 :                         WARN_ON(signal_pending(current));</span></a>
<a name="2173"><span class="lineNum">    2173 </span><span class="lineCov">       2119 :                         trace_rcu_grace_period(rcu_state.name, rcu_state.gp_seq,</span></a>
<a name="2174"><span class="lineNum">    2174 </span><span class="lineCov">       2118 :                                                TPS(&quot;reqwaitsig&quot;));</span></a>
<a name="2175"><span class="lineNum">    2175 </span>            :                 }</a>
<a name="2176"><span class="lineNum">    2176 </span>            : </a>
<a name="2177"><span class="lineNum">    2177 </span>            :                 /* Handle quiescent-state forcing. */</a>
<a name="2178"><span class="lineNum">    2178 </span><span class="lineCov">       2119 :                 rcu_gp_fqs_loop();</span></a>
<a name="2179"><span class="lineNum">    2179 </span>            : </a>
<a name="2180"><span class="lineNum">    2180 </span>            :                 /* Handle grace-period end. */</a>
<a name="2181"><span class="lineNum">    2181 </span><span class="lineCov">       2118 :                 WRITE_ONCE(rcu_state.gp_state, RCU_GP_CLEANUP);</span></a>
<a name="2182"><span class="lineNum">    2182 </span><span class="lineCov">       2118 :                 rcu_gp_cleanup();</span></a>
<a name="2183"><span class="lineNum">    2183 </span><span class="lineCov">       2118 :                 WRITE_ONCE(rcu_state.gp_state, RCU_GP_CLEANED);</span></a>
<a name="2184"><span class="lineNum">    2184 </span>            :         }</a>
<a name="2185"><span class="lineNum">    2185 </span>            : }</a>
<a name="2186"><span class="lineNum">    2186 </span>            : </a>
<a name="2187"><span class="lineNum">    2187 </span>            : /*</a>
<a name="2188"><span class="lineNum">    2188 </span>            :  * Report a full set of quiescent states to the rcu_state data structure.</a>
<a name="2189"><span class="lineNum">    2189 </span>            :  * Invoke rcu_gp_kthread_wake() to awaken the grace-period kthread if</a>
<a name="2190"><span class="lineNum">    2190 </span>            :  * another grace period is required.  Whether we wake the grace-period</a>
<a name="2191"><span class="lineNum">    2191 </span>            :  * kthread or it awakens itself for the next round of quiescent-state</a>
<a name="2192"><span class="lineNum">    2192 </span>            :  * forcing, that kthread will clean up after the just-completed grace</a>
<a name="2193"><span class="lineNum">    2193 </span>            :  * period.  Note that the caller must hold rnp-&gt;lock, which is released</a>
<a name="2194"><span class="lineNum">    2194 </span>            :  * before return.</a>
<a name="2195"><span class="lineNum">    2195 </span>            :  */</a>
<a name="2196"><span class="lineNum">    2196 </span><span class="lineCov">       2118 : static void rcu_report_qs_rsp(unsigned long flags)</span></a>
<a name="2197"><span class="lineNum">    2197 </span>            :         __releases(rcu_get_root()-&gt;lock)</a>
<a name="2198"><span class="lineNum">    2198 </span>            : {</a>
<a name="2199"><span class="lineNum">    2199 </span><span class="lineCov">       4236 :         raw_lockdep_assert_held_rcu_node(rcu_get_root());</span></a>
<a name="2200"><span class="lineNum">    2200 </span><span class="lineCov">       2118 :         WARN_ON_ONCE(!rcu_gp_in_progress());</span></a>
<a name="2201"><span class="lineNum">    2201 </span><span class="lineCov">       2118 :         WRITE_ONCE(rcu_state.gp_flags,</span></a>
<a name="2202"><span class="lineNum">    2202 </span>            :                    READ_ONCE(rcu_state.gp_flags) | RCU_GP_FLAG_FQS);</a>
<a name="2203"><span class="lineNum">    2203 </span><span class="lineCov">       4236 :         raw_spin_unlock_irqrestore_rcu_node(rcu_get_root(), flags);</span></a>
<a name="2204"><span class="lineNum">    2204 </span><span class="lineCov">       2118 :         rcu_gp_kthread_wake();</span></a>
<a name="2205"><span class="lineNum">    2205 </span><span class="lineCov">       2118 : }</span></a>
<a name="2206"><span class="lineNum">    2206 </span>            : </a>
<a name="2207"><span class="lineNum">    2207 </span>            : /*</a>
<a name="2208"><span class="lineNum">    2208 </span>            :  * Similar to rcu_report_qs_rdp(), for which it is a helper function.</a>
<a name="2209"><span class="lineNum">    2209 </span>            :  * Allows quiescent states for a group of CPUs to be reported at one go</a>
<a name="2210"><span class="lineNum">    2210 </span>            :  * to the specified rcu_node structure, though all the CPUs in the group</a>
<a name="2211"><span class="lineNum">    2211 </span>            :  * must be represented by the same rcu_node structure (which need not be a</a>
<a name="2212"><span class="lineNum">    2212 </span>            :  * leaf rcu_node structure, though it often will be).  The gps parameter</a>
<a name="2213"><span class="lineNum">    2213 </span>            :  * is the grace-period snapshot, which means that the quiescent states</a>
<a name="2214"><span class="lineNum">    2214 </span>            :  * are valid only if rnp-&gt;gp_seq is equal to gps.  That structure's lock</a>
<a name="2215"><span class="lineNum">    2215 </span>            :  * must be held upon entry, and it is released before return.</a>
<a name="2216"><span class="lineNum">    2216 </span>            :  *</a>
<a name="2217"><span class="lineNum">    2217 </span>            :  * As a special case, if mask is zero, the bit-already-cleared check is</a>
<a name="2218"><span class="lineNum">    2218 </span>            :  * disabled.  This allows propagating quiescent state due to resumed tasks</a>
<a name="2219"><span class="lineNum">    2219 </span>            :  * during grace-period initialization.</a>
<a name="2220"><span class="lineNum">    2220 </span>            :  */</a>
<a name="2221"><span class="lineNum">    2221 </span><span class="lineCov">       8251 : static void rcu_report_qs_rnp(unsigned long mask, struct rcu_node *rnp,</span></a>
<a name="2222"><span class="lineNum">    2222 </span>            :                               unsigned long gps, unsigned long flags)</a>
<a name="2223"><span class="lineNum">    2223 </span>            :         __releases(rnp-&gt;lock)</a>
<a name="2224"><span class="lineNum">    2224 </span>            : {</a>
<a name="2225"><span class="lineNum">    2225 </span><span class="lineCov">       8251 :         unsigned long oldmask = 0;</span></a>
<a name="2226"><span class="lineNum">    2226 </span><span class="lineCov">       8251 :         struct rcu_node *rnp_c;</span></a>
<a name="2227"><span class="lineNum">    2227 </span>            : </a>
<a name="2228"><span class="lineNum">    2228 </span><span class="lineCov">      16502 :         raw_lockdep_assert_held_rcu_node(rnp);</span></a>
<a name="2229"><span class="lineNum">    2229 </span>            : </a>
<a name="2230"><span class="lineNum">    2230 </span>            :         /* Walk up the rcu_node hierarchy. */</a>
<a name="2231"><span class="lineNum">    2231 </span><span class="lineCov">       8251 :         for (;;) {</span></a>
<a name="2232"><span class="lineNum">    2232 </span><span class="lineCov">       8251 :                 if ((!(rnp-&gt;qsmask &amp; mask) &amp;&amp; mask) || rnp-&gt;gp_seq != gps) {</span></a>
<a name="2233"><span class="lineNum">    2233 </span>            : </a>
<a name="2234"><span class="lineNum">    2234 </span>            :                         /*</a>
<a name="2235"><span class="lineNum">    2235 </span>            :                          * Our bit has already been cleared, or the</a>
<a name="2236"><span class="lineNum">    2236 </span>            :                          * relevant grace period is already over, so done.</a>
<a name="2237"><span class="lineNum">    2237 </span>            :                          */</a>
<a name="2238"><span class="lineNum">    2238 </span><span class="lineNoCov">          0 :                         raw_spin_unlock_irqrestore_rcu_node(rnp, flags);</span></a>
<a name="2239"><span class="lineNum">    2239 </span><span class="lineNoCov">          0 :                         return;</span></a>
<a name="2240"><span class="lineNum">    2240 </span>            :                 }</a>
<a name="2241"><span class="lineNum">    2241 </span><span class="lineCov">       8251 :                 WARN_ON_ONCE(oldmask); /* Any child must be all zeroed! */</span></a>
<a name="2242"><span class="lineNum">    2242 </span><span class="lineCov">       8251 :                 WARN_ON_ONCE(!rcu_is_leaf_node(rnp) &amp;&amp;</span></a>
<a name="2243"><span class="lineNum">    2243 </span>            :                              rcu_preempt_blocked_readers_cgp(rnp));</a>
<a name="2244"><span class="lineNum">    2244 </span><span class="lineCov">       8251 :                 WRITE_ONCE(rnp-&gt;qsmask, rnp-&gt;qsmask &amp; ~mask);</span></a>
<a name="2245"><span class="lineNum">    2245 </span><span class="lineCov">       8251 :                 trace_rcu_quiescent_state_report(rcu_state.name, rnp-&gt;gp_seq,</span></a>
<a name="2246"><span class="lineNum">    2246 </span>            :                                                  mask, rnp-&gt;qsmask, rnp-&gt;level,</a>
<a name="2247"><span class="lineNum">    2247 </span>            :                                                  rnp-&gt;grplo, rnp-&gt;grphi,</a>
<a name="2248"><span class="lineNum">    2248 </span><span class="lineCov">       8251 :                                                  !!rnp-&gt;gp_tasks);</span></a>
<a name="2249"><span class="lineNum">    2249 </span><span class="lineCov">       8251 :                 if (rnp-&gt;qsmask != 0 || rcu_preempt_blocked_readers_cgp(rnp)) {</span></a>
<a name="2250"><span class="lineNum">    2250 </span>            : </a>
<a name="2251"><span class="lineNum">    2251 </span>            :                         /* Other bits still set at this level, so done. */</a>
<a name="2252"><span class="lineNum">    2252 </span><span class="lineCov">      12266 :                         raw_spin_unlock_irqrestore_rcu_node(rnp, flags);</span></a>
<a name="2253"><span class="lineNum">    2253 </span><span class="lineCov">       6133 :                         return;</span></a>
<a name="2254"><span class="lineNum">    2254 </span>            :                 }</a>
<a name="2255"><span class="lineNum">    2255 </span><span class="lineCov">       2118 :                 rnp-&gt;completedqs = rnp-&gt;gp_seq;</span></a>
<a name="2256"><span class="lineNum">    2256 </span><span class="lineCov">       2118 :                 mask = rnp-&gt;grpmask;</span></a>
<a name="2257"><span class="lineNum">    2257 </span><span class="lineCov">       2118 :                 if (rnp-&gt;parent == NULL) {</span></a>
<a name="2258"><span class="lineNum">    2258 </span>            : </a>
<a name="2259"><span class="lineNum">    2259 </span>            :                         /* No more levels.  Exit loop holding root lock. */</a>
<a name="2260"><span class="lineNum">    2260 </span>            : </a>
<a name="2261"><span class="lineNum">    2261 </span>            :                         break;</a>
<a name="2262"><span class="lineNum">    2262 </span>            :                 }</a>
<a name="2263"><span class="lineNum">    2263 </span><span class="lineNoCov">          0 :                 raw_spin_unlock_irqrestore_rcu_node(rnp, flags);</span></a>
<a name="2264"><span class="lineNum">    2264 </span><span class="lineNoCov">          0 :                 rnp_c = rnp;</span></a>
<a name="2265"><span class="lineNum">    2265 </span><span class="lineNoCov">          0 :                 rnp = rnp-&gt;parent;</span></a>
<a name="2266"><span class="lineNum">    2266 </span><span class="lineNoCov">          0 :                 raw_spin_lock_irqsave_rcu_node(rnp, flags);</span></a>
<a name="2267"><span class="lineNum">    2267 </span><span class="lineNoCov">          0 :                 oldmask = READ_ONCE(rnp_c-&gt;qsmask);</span></a>
<a name="2268"><span class="lineNum">    2268 </span>            :         }</a>
<a name="2269"><span class="lineNum">    2269 </span>            : </a>
<a name="2270"><span class="lineNum">    2270 </span>            :         /*</a>
<a name="2271"><span class="lineNum">    2271 </span>            :          * Get here if we are the last CPU to pass through a quiescent</a>
<a name="2272"><span class="lineNum">    2272 </span>            :          * state for this grace period.  Invoke rcu_report_qs_rsp()</a>
<a name="2273"><span class="lineNum">    2273 </span>            :          * to clean up and start the next grace period if one is needed.</a>
<a name="2274"><span class="lineNum">    2274 </span>            :          */</a>
<a name="2275"><span class="lineNum">    2275 </span><span class="lineCov">       2118 :         rcu_report_qs_rsp(flags); /* releases rnp-&gt;lock. */</span></a>
<a name="2276"><span class="lineNum">    2276 </span>            : }</a>
<a name="2277"><span class="lineNum">    2277 </span>            : </a>
<a name="2278"><span class="lineNum">    2278 </span>            : /*</a>
<a name="2279"><span class="lineNum">    2279 </span>            :  * Record a quiescent state for all tasks that were previously queued</a>
<a name="2280"><span class="lineNum">    2280 </span>            :  * on the specified rcu_node structure and that were blocking the current</a>
<a name="2281"><span class="lineNum">    2281 </span>            :  * RCU grace period.  The caller must hold the corresponding rnp-&gt;lock with</a>
<a name="2282"><span class="lineNum">    2282 </span>            :  * irqs disabled, and this lock is released upon return, but irqs remain</a>
<a name="2283"><span class="lineNum">    2283 </span>            :  * disabled.</a>
<a name="2284"><span class="lineNum">    2284 </span>            :  */</a>
<a name="2285"><span class="lineNum">    2285 </span>            : static void __maybe_unused</a>
<a name="2286"><span class="lineNum">    2286 </span>            : rcu_report_unblock_qs_rnp(struct rcu_node *rnp, unsigned long flags)</a>
<a name="2287"><span class="lineNum">    2287 </span>            :         __releases(rnp-&gt;lock)</a>
<a name="2288"><span class="lineNum">    2288 </span>            : {</a>
<a name="2289"><span class="lineNum">    2289 </span>            :         unsigned long gps;</a>
<a name="2290"><span class="lineNum">    2290 </span>            :         unsigned long mask;</a>
<a name="2291"><span class="lineNum">    2291 </span>            :         struct rcu_node *rnp_p;</a>
<a name="2292"><span class="lineNum">    2292 </span>            : </a>
<a name="2293"><span class="lineNum">    2293 </span>            :         raw_lockdep_assert_held_rcu_node(rnp);</a>
<a name="2294"><span class="lineNum">    2294 </span>            :         if (WARN_ON_ONCE(!IS_ENABLED(CONFIG_PREEMPT_RCU)) ||</a>
<a name="2295"><span class="lineNum">    2295 </span>            :             WARN_ON_ONCE(rcu_preempt_blocked_readers_cgp(rnp)) ||</a>
<a name="2296"><span class="lineNum">    2296 </span>            :             rnp-&gt;qsmask != 0) {</a>
<a name="2297"><span class="lineNum">    2297 </span>            :                 raw_spin_unlock_irqrestore_rcu_node(rnp, flags);</a>
<a name="2298"><span class="lineNum">    2298 </span>            :                 return;  /* Still need more quiescent states! */</a>
<a name="2299"><span class="lineNum">    2299 </span>            :         }</a>
<a name="2300"><span class="lineNum">    2300 </span>            : </a>
<a name="2301"><span class="lineNum">    2301 </span>            :         rnp-&gt;completedqs = rnp-&gt;gp_seq;</a>
<a name="2302"><span class="lineNum">    2302 </span>            :         rnp_p = rnp-&gt;parent;</a>
<a name="2303"><span class="lineNum">    2303 </span>            :         if (rnp_p == NULL) {</a>
<a name="2304"><span class="lineNum">    2304 </span>            :                 /*</a>
<a name="2305"><span class="lineNum">    2305 </span>            :                  * Only one rcu_node structure in the tree, so don't</a>
<a name="2306"><span class="lineNum">    2306 </span>            :                  * try to report up to its nonexistent parent!</a>
<a name="2307"><span class="lineNum">    2307 </span>            :                  */</a>
<a name="2308"><span class="lineNum">    2308 </span>            :                 rcu_report_qs_rsp(flags);</a>
<a name="2309"><span class="lineNum">    2309 </span>            :                 return;</a>
<a name="2310"><span class="lineNum">    2310 </span>            :         }</a>
<a name="2311"><span class="lineNum">    2311 </span>            : </a>
<a name="2312"><span class="lineNum">    2312 </span>            :         /* Report up the rest of the hierarchy, tracking current -&gt;gp_seq. */</a>
<a name="2313"><span class="lineNum">    2313 </span>            :         gps = rnp-&gt;gp_seq;</a>
<a name="2314"><span class="lineNum">    2314 </span>            :         mask = rnp-&gt;grpmask;</a>
<a name="2315"><span class="lineNum">    2315 </span>            :         raw_spin_unlock_rcu_node(rnp);  /* irqs remain disabled. */</a>
<a name="2316"><span class="lineNum">    2316 </span>            :         raw_spin_lock_rcu_node(rnp_p);  /* irqs already disabled. */</a>
<a name="2317"><span class="lineNum">    2317 </span>            :         rcu_report_qs_rnp(mask, rnp_p, gps, flags);</a>
<a name="2318"><span class="lineNum">    2318 </span>            : }</a>
<a name="2319"><span class="lineNum">    2319 </span>            : </a>
<a name="2320"><span class="lineNum">    2320 </span>            : /*</a>
<a name="2321"><span class="lineNum">    2321 </span>            :  * Record a quiescent state for the specified CPU to that CPU's rcu_data</a>
<a name="2322"><span class="lineNum">    2322 </span>            :  * structure.  This must be called from the specified CPU.</a>
<a name="2323"><span class="lineNum">    2323 </span>            :  */</a>
<a name="2324"><span class="lineNum">    2324 </span>            : static void</a>
<a name="2325"><span class="lineNum">    2325 </span><span class="lineCov">       7619 : rcu_report_qs_rdp(struct rcu_data *rdp)</span></a>
<a name="2326"><span class="lineNum">    2326 </span>            : {</a>
<a name="2327"><span class="lineNum">    2327 </span><span class="lineCov">       7619 :         unsigned long flags;</span></a>
<a name="2328"><span class="lineNum">    2328 </span><span class="lineCov">       7619 :         unsigned long mask;</span></a>
<a name="2329"><span class="lineNum">    2329 </span><span class="lineCov">       7619 :         bool needwake = false;</span></a>
<a name="2330"><span class="lineNum">    2330 </span><span class="lineCov">       7619 :         const bool offloaded = rcu_segcblist_is_offloaded(&amp;rdp-&gt;cblist);</span></a>
<a name="2331"><span class="lineNum">    2331 </span><span class="lineCov">       7619 :         struct rcu_node *rnp;</span></a>
<a name="2332"><span class="lineNum">    2332 </span>            : </a>
<a name="2333"><span class="lineNum">    2333 </span><span class="lineCov">       7619 :         WARN_ON_ONCE(rdp-&gt;cpu != smp_processor_id());</span></a>
<a name="2334"><span class="lineNum">    2334 </span><span class="lineCov">       7619 :         rnp = rdp-&gt;mynode;</span></a>
<a name="2335"><span class="lineNum">    2335 </span><span class="lineCov">       7619 :         raw_spin_lock_irqsave_rcu_node(rnp, flags);</span></a>
<a name="2336"><span class="lineNum">    2336 </span><span class="lineCov">       7632 :         if (rdp-&gt;cpu_no_qs.b.norm || rdp-&gt;gp_seq != rnp-&gt;gp_seq ||</span></a>
<a name="2337"><span class="lineNum">    2337 </span><span class="lineCov">       7617 :             rdp-&gt;gpwrap) {</span></a>
<a name="2338"><span class="lineNum">    2338 </span>            : </a>
<a name="2339"><span class="lineNum">    2339 </span>            :                 /*</a>
<a name="2340"><span class="lineNum">    2340 </span>            :                  * The grace period in which this quiescent state was</a>
<a name="2341"><span class="lineNum">    2341 </span>            :                  * recorded has ended, so don't report it upwards.</a>
<a name="2342"><span class="lineNum">    2342 </span>            :                  * We will instead need a new quiescent state that lies</a>
<a name="2343"><span class="lineNum">    2343 </span>            :                  * within the current grace period.</a>
<a name="2344"><span class="lineNum">    2344 </span>            :                  */</a>
<a name="2345"><span class="lineNum">    2345 </span><span class="lineCov">         15 :                 rdp-&gt;cpu_no_qs.b.norm = true;        /* need qs for new gp. */</span></a>
<a name="2346"><span class="lineNum">    2346 </span><span class="lineCov">         30 :                 raw_spin_unlock_irqrestore_rcu_node(rnp, flags);</span></a>
<a name="2347"><span class="lineNum">    2347 </span><span class="lineCov">         15 :                 return;</span></a>
<a name="2348"><span class="lineNum">    2348 </span>            :         }</a>
<a name="2349"><span class="lineNum">    2349 </span><span class="lineCov">       7617 :         mask = rdp-&gt;grpmask;</span></a>
<a name="2350"><span class="lineNum">    2350 </span><span class="lineCov">       7617 :         rdp-&gt;core_needs_qs = false;</span></a>
<a name="2351"><span class="lineNum">    2351 </span><span class="lineCov">       7617 :         if ((rnp-&gt;qsmask &amp; mask) == 0) {</span></a>
<a name="2352"><span class="lineNum">    2352 </span><span class="lineCov">        170 :                 raw_spin_unlock_irqrestore_rcu_node(rnp, flags);</span></a>
<a name="2353"><span class="lineNum">    2353 </span>            :         } else {</a>
<a name="2354"><span class="lineNum">    2354 </span>            :                 /*</a>
<a name="2355"><span class="lineNum">    2355 </span>            :                  * This GP can't end until cpu checks in, so all of our</a>
<a name="2356"><span class="lineNum">    2356 </span>            :                  * callbacks can be processed during the next GP.</a>
<a name="2357"><span class="lineNum">    2357 </span>            :                  */</a>
<a name="2358"><span class="lineNum">    2358 </span><span class="lineCov">       7532 :                 if (!offloaded)</span></a>
<a name="2359"><span class="lineNum">    2359 </span><span class="lineCov">       7532 :                         needwake = rcu_accelerate_cbs(rnp, rdp);</span></a>
<a name="2360"><span class="lineNum">    2360 </span>            : </a>
<a name="2361"><span class="lineNum">    2361 </span><span class="lineCov">       7532 :                 rcu_disable_urgency_upon_qs(rdp);</span></a>
<a name="2362"><span class="lineNum">    2362 </span><span class="lineCov">       7532 :                 rcu_report_qs_rnp(mask, rnp, rnp-&gt;gp_seq, flags);</span></a>
<a name="2363"><span class="lineNum">    2363 </span>            :                 /* ^^^ Released rnp-&gt;lock */</a>
<a name="2364"><span class="lineNum">    2364 </span><span class="lineCov">       7532 :                 if (needwake)</span></a>
<a name="2365"><span class="lineNum">    2365 </span><span class="lineNoCov">          0 :                         rcu_gp_kthread_wake();</span></a>
<a name="2366"><span class="lineNum">    2366 </span>            :         }</a>
<a name="2367"><span class="lineNum">    2367 </span>            : }</a>
<a name="2368"><span class="lineNum">    2368 </span>            : </a>
<a name="2369"><span class="lineNum">    2369 </span>            : /*</a>
<a name="2370"><span class="lineNum">    2370 </span>            :  * Check to see if there is a new grace period of which this CPU</a>
<a name="2371"><span class="lineNum">    2371 </span>            :  * is not yet aware, and if so, set up local rcu_data state for it.</a>
<a name="2372"><span class="lineNum">    2372 </span>            :  * Otherwise, see if this CPU has just passed through its first</a>
<a name="2373"><span class="lineNum">    2373 </span>            :  * quiescent state for this grace period, and record that fact if so.</a>
<a name="2374"><span class="lineNum">    2374 </span>            :  */</a>
<a name="2375"><span class="lineNum">    2375 </span>            : static void</a>
<a name="2376"><span class="lineNum">    2376 </span><span class="lineCov">      54385 : rcu_check_quiescent_state(struct rcu_data *rdp)</span></a>
<a name="2377"><span class="lineNum">    2377 </span>            : {</a>
<a name="2378"><span class="lineNum">    2378 </span>            :         /* Check for grace-period ends and beginnings. */</a>
<a name="2379"><span class="lineNum">    2379 </span><span class="lineCov">      54385 :         note_gp_changes(rdp);</span></a>
<a name="2380"><span class="lineNum">    2380 </span>            : </a>
<a name="2381"><span class="lineNum">    2381 </span>            :         /*</a>
<a name="2382"><span class="lineNum">    2382 </span>            :          * Does this CPU still need to do its part for current grace period?</a>
<a name="2383"><span class="lineNum">    2383 </span>            :          * If no, return and let the other CPUs do their part as well.</a>
<a name="2384"><span class="lineNum">    2384 </span>            :          */</a>
<a name="2385"><span class="lineNum">    2385 </span><span class="lineCov">      54540 :         if (!rdp-&gt;core_needs_qs)</span></a>
<a name="2386"><span class="lineNum">    2386 </span>            :                 return;</a>
<a name="2387"><span class="lineNum">    2387 </span>            : </a>
<a name="2388"><span class="lineNum">    2388 </span>            :         /*</a>
<a name="2389"><span class="lineNum">    2389 </span>            :          * Was there a quiescent state since the beginning of the grace</a>
<a name="2390"><span class="lineNum">    2390 </span>            :          * period? If no, then exit and wait for the next call.</a>
<a name="2391"><span class="lineNum">    2391 </span>            :          */</a>
<a name="2392"><span class="lineNum">    2392 </span><span class="lineCov">      21930 :         if (rdp-&gt;cpu_no_qs.b.norm)</span></a>
<a name="2393"><span class="lineNum">    2393 </span>            :                 return;</a>
<a name="2394"><span class="lineNum">    2394 </span>            : </a>
<a name="2395"><span class="lineNum">    2395 </span>            :         /*</a>
<a name="2396"><span class="lineNum">    2396 </span>            :          * Tell RCU we are done (but rcu_report_qs_rdp() will be the</a>
<a name="2397"><span class="lineNum">    2397 </span>            :          * judge of that).</a>
<a name="2398"><span class="lineNum">    2398 </span>            :          */</a>
<a name="2399"><span class="lineNum">    2399 </span><span class="lineCov">       7624 :         rcu_report_qs_rdp(rdp);</span></a>
<a name="2400"><span class="lineNum">    2400 </span>            : }</a>
<a name="2401"><span class="lineNum">    2401 </span>            : </a>
<a name="2402"><span class="lineNum">    2402 </span>            : /*</a>
<a name="2403"><span class="lineNum">    2403 </span>            :  * Near the end of the offline process.  Trace the fact that this CPU</a>
<a name="2404"><span class="lineNum">    2404 </span>            :  * is going offline.</a>
<a name="2405"><span class="lineNum">    2405 </span>            :  */</a>
<a name="2406"><span class="lineNum">    2406 </span><span class="lineNoCov">          0 : int rcutree_dying_cpu(unsigned int cpu)</span></a>
<a name="2407"><span class="lineNum">    2407 </span>            : {</a>
<a name="2408"><span class="lineNum">    2408 </span><span class="lineNoCov">          0 :         bool blkd;</span></a>
<a name="2409"><span class="lineNum">    2409 </span><span class="lineNoCov">          0 :         struct rcu_data *rdp = this_cpu_ptr(&amp;rcu_data);</span></a>
<a name="2410"><span class="lineNum">    2410 </span><span class="lineNoCov">          0 :         struct rcu_node *rnp = rdp-&gt;mynode;</span></a>
<a name="2411"><span class="lineNum">    2411 </span>            : </a>
<a name="2412"><span class="lineNum">    2412 </span><span class="lineNoCov">          0 :         if (!IS_ENABLED(CONFIG_HOTPLUG_CPU))</span></a>
<a name="2413"><span class="lineNum">    2413 </span>            :                 return 0;</a>
<a name="2414"><span class="lineNum">    2414 </span>            : </a>
<a name="2415"><span class="lineNum">    2415 </span><span class="lineNoCov">          0 :         blkd = !!(rnp-&gt;qsmask &amp; rdp-&gt;grpmask);</span></a>
<a name="2416"><span class="lineNum">    2416 </span><span class="lineNoCov">          0 :         trace_rcu_grace_period(rcu_state.name, READ_ONCE(rnp-&gt;gp_seq),</span></a>
<a name="2417"><span class="lineNum">    2417 </span><span class="lineNoCov">          0 :                                blkd ? TPS(&quot;cpuofl&quot;) : TPS(&quot;cpuofl-bgp&quot;));</span></a>
<a name="2418"><span class="lineNum">    2418 </span><span class="lineNoCov">          0 :         return 0;</span></a>
<a name="2419"><span class="lineNum">    2419 </span>            : }</a>
<a name="2420"><span class="lineNum">    2420 </span>            : </a>
<a name="2421"><span class="lineNum">    2421 </span>            : /*</a>
<a name="2422"><span class="lineNum">    2422 </span>            :  * All CPUs for the specified rcu_node structure have gone offline,</a>
<a name="2423"><span class="lineNum">    2423 </span>            :  * and all tasks that were preempted within an RCU read-side critical</a>
<a name="2424"><span class="lineNum">    2424 </span>            :  * section while running on one of those CPUs have since exited their RCU</a>
<a name="2425"><span class="lineNum">    2425 </span>            :  * read-side critical section.  Some other CPU is reporting this fact with</a>
<a name="2426"><span class="lineNum">    2426 </span>            :  * the specified rcu_node structure's -&gt;lock held and interrupts disabled.</a>
<a name="2427"><span class="lineNum">    2427 </span>            :  * This function therefore goes up the tree of rcu_node structures,</a>
<a name="2428"><span class="lineNum">    2428 </span>            :  * clearing the corresponding bits in the -&gt;qsmaskinit fields.  Note that</a>
<a name="2429"><span class="lineNum">    2429 </span>            :  * the leaf rcu_node structure's -&gt;qsmaskinit field has already been</a>
<a name="2430"><span class="lineNum">    2430 </span>            :  * updated.</a>
<a name="2431"><span class="lineNum">    2431 </span>            :  *</a>
<a name="2432"><span class="lineNum">    2432 </span>            :  * This function does check that the specified rcu_node structure has</a>
<a name="2433"><span class="lineNum">    2433 </span>            :  * all CPUs offline and no blocked tasks, so it is OK to invoke it</a>
<a name="2434"><span class="lineNum">    2434 </span>            :  * prematurely.  That said, invoking it after the fact will cost you</a>
<a name="2435"><span class="lineNum">    2435 </span>            :  * a needless lock acquisition.  So once it has done its work, don't</a>
<a name="2436"><span class="lineNum">    2436 </span>            :  * invoke it again.</a>
<a name="2437"><span class="lineNum">    2437 </span>            :  */</a>
<a name="2438"><span class="lineNum">    2438 </span><span class="lineNoCov">          0 : static void rcu_cleanup_dead_rnp(struct rcu_node *rnp_leaf)</span></a>
<a name="2439"><span class="lineNum">    2439 </span>            : {</a>
<a name="2440"><span class="lineNum">    2440 </span><span class="lineNoCov">          0 :         long mask;</span></a>
<a name="2441"><span class="lineNum">    2441 </span><span class="lineNoCov">          0 :         struct rcu_node *rnp = rnp_leaf;</span></a>
<a name="2442"><span class="lineNum">    2442 </span>            : </a>
<a name="2443"><span class="lineNum">    2443 </span><span class="lineNoCov">          0 :         raw_lockdep_assert_held_rcu_node(rnp_leaf);</span></a>
<a name="2444"><span class="lineNum">    2444 </span><span class="lineNoCov">          0 :         if (!IS_ENABLED(CONFIG_HOTPLUG_CPU) ||</span></a>
<a name="2445"><span class="lineNum">    2445 </span><span class="lineNoCov">          0 :             WARN_ON_ONCE(rnp_leaf-&gt;qsmaskinit) ||</span></a>
<a name="2446"><span class="lineNum">    2446 </span><span class="lineNoCov">          0 :             WARN_ON_ONCE(rcu_preempt_has_tasks(rnp_leaf)))</span></a>
<a name="2447"><span class="lineNum">    2447 </span>            :                 return;</a>
<a name="2448"><span class="lineNum">    2448 </span><span class="lineNoCov">          0 :         for (;;) {</span></a>
<a name="2449"><span class="lineNum">    2449 </span><span class="lineNoCov">          0 :                 mask = rnp-&gt;grpmask;</span></a>
<a name="2450"><span class="lineNum">    2450 </span><span class="lineNoCov">          0 :                 rnp = rnp-&gt;parent;</span></a>
<a name="2451"><span class="lineNum">    2451 </span><span class="lineNoCov">          0 :                 if (!rnp)</span></a>
<a name="2452"><span class="lineNum">    2452 </span>            :                         break;</a>
<a name="2453"><span class="lineNum">    2453 </span><span class="lineNoCov">          0 :                 raw_spin_lock_rcu_node(rnp); /* irqs already disabled. */</span></a>
<a name="2454"><span class="lineNum">    2454 </span><span class="lineNoCov">          0 :                 rnp-&gt;qsmaskinit &amp;= ~mask;</span></a>
<a name="2455"><span class="lineNum">    2455 </span>            :                 /* Between grace periods, so better already be zero! */</a>
<a name="2456"><span class="lineNum">    2456 </span><span class="lineNoCov">          0 :                 WARN_ON_ONCE(rnp-&gt;qsmask);</span></a>
<a name="2457"><span class="lineNum">    2457 </span><span class="lineNoCov">          0 :                 if (rnp-&gt;qsmaskinit) {</span></a>
<a name="2458"><span class="lineNum">    2458 </span><span class="lineNoCov">          0 :                         raw_spin_unlock_rcu_node(rnp);</span></a>
<a name="2459"><span class="lineNum">    2459 </span>            :                         /* irqs remain disabled. */</a>
<a name="2460"><span class="lineNum">    2460 </span><span class="lineNoCov">          0 :                         return;</span></a>
<a name="2461"><span class="lineNum">    2461 </span>            :                 }</a>
<a name="2462"><span class="lineNum">    2462 </span><span class="lineNoCov">          0 :                 raw_spin_unlock_rcu_node(rnp); /* irqs remain disabled. */</span></a>
<a name="2463"><span class="lineNum">    2463 </span>            :         }</a>
<a name="2464"><span class="lineNum">    2464 </span>            : }</a>
<a name="2465"><span class="lineNum">    2465 </span>            : </a>
<a name="2466"><span class="lineNum">    2466 </span>            : /*</a>
<a name="2467"><span class="lineNum">    2467 </span>            :  * The CPU has been completely removed, and some other CPU is reporting</a>
<a name="2468"><span class="lineNum">    2468 </span>            :  * this fact from process context.  Do the remainder of the cleanup.</a>
<a name="2469"><span class="lineNum">    2469 </span>            :  * There can only be one CPU hotplug operation at a time, so no need for</a>
<a name="2470"><span class="lineNum">    2470 </span>            :  * explicit locking.</a>
<a name="2471"><span class="lineNum">    2471 </span>            :  */</a>
<a name="2472"><span class="lineNum">    2472 </span><span class="lineNoCov">          0 : int rcutree_dead_cpu(unsigned int cpu)</span></a>
<a name="2473"><span class="lineNum">    2473 </span>            : {</a>
<a name="2474"><span class="lineNum">    2474 </span><span class="lineNoCov">          0 :         struct rcu_data *rdp = per_cpu_ptr(&amp;rcu_data, cpu);</span></a>
<a name="2475"><span class="lineNum">    2475 </span><span class="lineNoCov">          0 :         struct rcu_node *rnp = rdp-&gt;mynode;  /* Outgoing CPU's rdp &amp; rnp. */</span></a>
<a name="2476"><span class="lineNum">    2476 </span>            : </a>
<a name="2477"><span class="lineNum">    2477 </span><span class="lineNoCov">          0 :         if (!IS_ENABLED(CONFIG_HOTPLUG_CPU))</span></a>
<a name="2478"><span class="lineNum">    2478 </span>            :                 return 0;</a>
<a name="2479"><span class="lineNum">    2479 </span>            : </a>
<a name="2480"><span class="lineNum">    2480 </span><span class="lineNoCov">          0 :         WRITE_ONCE(rcu_state.n_online_cpus, rcu_state.n_online_cpus - 1);</span></a>
<a name="2481"><span class="lineNum">    2481 </span>            :         /* Adjust any no-longer-needed kthreads. */</a>
<a name="2482"><span class="lineNum">    2482 </span><span class="lineNoCov">          0 :         rcu_boost_kthread_setaffinity(rnp, -1);</span></a>
<a name="2483"><span class="lineNum">    2483 </span>            :         /* Do any needed no-CB deferred wakeups from this CPU. */</a>
<a name="2484"><span class="lineNum">    2484 </span><span class="lineNoCov">          0 :         do_nocb_deferred_wakeup(per_cpu_ptr(&amp;rcu_data, cpu));</span></a>
<a name="2485"><span class="lineNum">    2485 </span>            : </a>
<a name="2486"><span class="lineNum">    2486 </span>            :         // Stop-machine done, so allow nohz_full to disable tick.</a>
<a name="2487"><span class="lineNum">    2487 </span><span class="lineNoCov">          0 :         tick_dep_clear(TICK_DEP_BIT_RCU);</span></a>
<a name="2488"><span class="lineNum">    2488 </span><span class="lineNoCov">          0 :         return 0;</span></a>
<a name="2489"><span class="lineNum">    2489 </span>            : }</a>
<a name="2490"><span class="lineNum">    2490 </span>            : </a>
<a name="2491"><span class="lineNum">    2491 </span>            : /*</a>
<a name="2492"><span class="lineNum">    2492 </span>            :  * Invoke any RCU callbacks that have made it to the end of their grace</a>
<a name="2493"><span class="lineNum">    2493 </span>            :  * period.  Thottle as specified by rdp-&gt;blimit.</a>
<a name="2494"><span class="lineNum">    2494 </span>            :  */</a>
<a name="2495"><span class="lineNum">    2495 </span><span class="lineCov">      49011 : static void rcu_do_batch(struct rcu_data *rdp)</span></a>
<a name="2496"><span class="lineNum">    2496 </span>            : {</a>
<a name="2497"><span class="lineNum">    2497 </span><span class="lineCov">      49011 :         int div;</span></a>
<a name="2498"><span class="lineNum">    2498 </span><span class="lineCov">      49011 :         bool __maybe_unused empty;</span></a>
<a name="2499"><span class="lineNum">    2499 </span><span class="lineCov">      49011 :         unsigned long flags;</span></a>
<a name="2500"><span class="lineNum">    2500 </span><span class="lineCov">      49011 :         const bool offloaded = rcu_segcblist_is_offloaded(&amp;rdp-&gt;cblist);</span></a>
<a name="2501"><span class="lineNum">    2501 </span><span class="lineCov">      49011 :         struct rcu_head *rhp;</span></a>
<a name="2502"><span class="lineNum">    2502 </span><span class="lineCov">      49011 :         struct rcu_cblist rcl = RCU_CBLIST_INITIALIZER(rcl);</span></a>
<a name="2503"><span class="lineNum">    2503 </span><span class="lineCov">      49011 :         long bl, count = 0;</span></a>
<a name="2504"><span class="lineNum">    2504 </span><span class="lineCov">      49011 :         long pending, tlimit = 0;</span></a>
<a name="2505"><span class="lineNum">    2505 </span>            : </a>
<a name="2506"><span class="lineNum">    2506 </span>            :         /* If no callbacks are ready, just return. */</a>
<a name="2507"><span class="lineNum">    2507 </span><span class="lineCov">      49011 :         if (!rcu_segcblist_ready_cbs(&amp;rdp-&gt;cblist)) {</span></a>
<a name="2508"><span class="lineNum">    2508 </span><span class="lineNoCov">          0 :                 trace_rcu_batch_start(rcu_state.name,</span></a>
<a name="2509"><span class="lineNum">    2509 </span>            :                                       rcu_segcblist_n_cbs(&amp;rdp-&gt;cblist), 0);</a>
<a name="2510"><span class="lineNum">    2510 </span><span class="lineNoCov">          0 :                 trace_rcu_batch_end(rcu_state.name, 0,</span></a>
<a name="2511"><span class="lineNum">    2511 </span><span class="lineNoCov">          0 :                                     !rcu_segcblist_empty(&amp;rdp-&gt;cblist),</span></a>
<a name="2512"><span class="lineNum">    2512 </span><span class="lineNoCov">          0 :                                     need_resched(), is_idle_task(current),</span></a>
<a name="2513"><span class="lineNum">    2513 </span>            :                                     rcu_is_callbacks_kthread());</a>
<a name="2514"><span class="lineNum">    2514 </span><span class="lineNoCov">          0 :                 return;</span></a>
<a name="2515"><span class="lineNum">    2515 </span>            :         }</a>
<a name="2516"><span class="lineNum">    2516 </span>            : </a>
<a name="2517"><span class="lineNum">    2517 </span>            :         /*</a>
<a name="2518"><span class="lineNum">    2518 </span>            :          * Extract the list of ready callbacks, disabling to prevent</a>
<a name="2519"><span class="lineNum">    2519 </span>            :          * races with call_rcu() from interrupt handlers.  Leave the</a>
<a name="2520"><span class="lineNum">    2520 </span>            :          * callback counts, as rcu_barrier() needs to be conservative.</a>
<a name="2521"><span class="lineNum">    2521 </span>            :          */</a>
<a name="2522"><span class="lineNum">    2522 </span><span class="lineCov">      98033 :         local_irq_save(flags);</span></a>
<a name="2523"><span class="lineNum">    2523 </span><span class="lineCov">      49012 :         rcu_nocb_lock(rdp);</span></a>
<a name="2524"><span class="lineNum">    2524 </span><span class="lineCov">      49012 :         WARN_ON_ONCE(cpu_is_offline(smp_processor_id()));</span></a>
<a name="2525"><span class="lineNum">    2525 </span><span class="lineCov">      49021 :         pending = rcu_segcblist_n_cbs(&amp;rdp-&gt;cblist);</span></a>
<a name="2526"><span class="lineNum">    2526 </span><span class="lineCov">      49021 :         div = READ_ONCE(rcu_divisor);</span></a>
<a name="2527"><span class="lineNum">    2527 </span><span class="lineCov">      49021 :         div = div &lt; 0 ? 7 : div &gt; sizeof(long) * 8 - 2 ? sizeof(long) * 8 - 2 : div;</span></a>
<a name="2528"><span class="lineNum">    2528 </span><span class="lineCov">      49021 :         bl = max(rdp-&gt;blimit, pending &gt;&gt; div);</span></a>
<a name="2529"><span class="lineNum">    2529 </span><span class="lineCov">      49021 :         if (unlikely(bl &gt; 100)) {</span></a>
<a name="2530"><span class="lineNum">    2530 </span><span class="lineNoCov">          0 :                 long rrn = READ_ONCE(rcu_resched_ns);</span></a>
<a name="2531"><span class="lineNum">    2531 </span>            : </a>
<a name="2532"><span class="lineNum">    2532 </span><span class="lineNoCov">          0 :                 rrn = rrn &lt; NSEC_PER_MSEC ? NSEC_PER_MSEC : rrn &gt; NSEC_PER_SEC ? NSEC_PER_SEC : rrn;</span></a>
<a name="2533"><span class="lineNum">    2533 </span><span class="lineNoCov">          0 :                 tlimit = local_clock() + rrn;</span></a>
<a name="2534"><span class="lineNum">    2534 </span>            :         }</a>
<a name="2535"><span class="lineNum">    2535 </span><span class="lineCov">      49021 :         trace_rcu_batch_start(rcu_state.name,</span></a>
<a name="2536"><span class="lineNum">    2536 </span>            :                               rcu_segcblist_n_cbs(&amp;rdp-&gt;cblist), bl);</a>
<a name="2537"><span class="lineNum">    2537 </span><span class="lineCov">      49021 :         rcu_segcblist_extract_done_cbs(&amp;rdp-&gt;cblist, &amp;rcl);</span></a>
<a name="2538"><span class="lineNum">    2538 </span><span class="lineCov">      49023 :         if (offloaded)</span></a>
<a name="2539"><span class="lineNum">    2539 </span>            :                 rdp-&gt;qlen_last_fqs_check = rcu_segcblist_n_cbs(&amp;rdp-&gt;cblist);</a>
<a name="2540"><span class="lineNum">    2540 </span>            : </a>
<a name="2541"><span class="lineNum">    2541 </span><span class="lineCov">      49023 :         trace_rcu_segcb_stats(&amp;rdp-&gt;cblist, TPS(&quot;SegCbDequeued&quot;));</span></a>
<a name="2542"><span class="lineNum">    2542 </span><span class="lineCov">      49023 :         rcu_nocb_unlock_irqrestore(rdp, flags);</span></a>
<a name="2543"><span class="lineNum">    2543 </span>            : </a>
<a name="2544"><span class="lineNum">    2544 </span>            :         /* Invoke callbacks. */</a>
<a name="2545"><span class="lineNum">    2545 </span><span class="lineCov">      49021 :         tick_dep_set_task(current, TICK_DEP_BIT_RCU);</span></a>
<a name="2546"><span class="lineNum">    2546 </span><span class="lineCov">      49021 :         rhp = rcu_cblist_dequeue(&amp;rcl);</span></a>
<a name="2547"><span class="lineNum">    2547 </span>            : </a>
<a name="2548"><span class="lineNum">    2548 </span><span class="lineCov">     678227 :         for (; rhp; rhp = rcu_cblist_dequeue(&amp;rcl)) {</span></a>
<a name="2549"><span class="lineNum">    2549 </span><span class="lineCov">     626082 :                 rcu_callback_t f;</span></a>
<a name="2550"><span class="lineNum">    2550 </span>            : </a>
<a name="2551"><span class="lineNum">    2551 </span><span class="lineCov">     626082 :                 count++;</span></a>
<a name="2552"><span class="lineNum">    2552 </span><span class="lineCov">     626082 :                 debug_rcu_head_unqueue(rhp);</span></a>
<a name="2553"><span class="lineNum">    2553 </span>            : </a>
<a name="2554"><span class="lineNum">    2554 </span><span class="lineCov">     624285 :                 rcu_lock_acquire(&amp;rcu_callback_map);</span></a>
<a name="2555"><span class="lineNum">    2555 </span><span class="lineCov">     624469 :                 trace_rcu_invoke_callback(rcu_state.name, rhp);</span></a>
<a name="2556"><span class="lineNum">    2556 </span>            : </a>
<a name="2557"><span class="lineNum">    2557 </span><span class="lineCov">     624469 :                 f = rhp-&gt;func;</span></a>
<a name="2558"><span class="lineNum">    2558 </span><span class="lineCov">     624469 :                 WRITE_ONCE(rhp-&gt;func, (rcu_callback_t)0L);</span></a>
<a name="2559"><span class="lineNum">    2559 </span><span class="lineCov">     624469 :                 f(rhp);</span></a>
<a name="2560"><span class="lineNum">    2560 </span>            : </a>
<a name="2561"><span class="lineNum">    2561 </span><span class="lineCov">     624469 :                 rcu_lock_release(&amp;rcu_callback_map);</span></a>
<a name="2562"><span class="lineNum">    2562 </span>            : </a>
<a name="2563"><span class="lineNum">    2563 </span>            :                 /*</a>
<a name="2564"><span class="lineNum">    2564 </span>            :                  * Stop only if limit reached and CPU has something to do.</a>
<a name="2565"><span class="lineNum">    2565 </span>            :                  */</a>
<a name="2566"><span class="lineNum">    2566 </span><span class="lineCov">     624007 :                 if (count &gt;= bl &amp;&amp; !offloaded &amp;&amp;</span></a>
<a name="2567"><span class="lineNum">    2567 </span><span class="lineCov">     196862 :                     (need_resched() ||</span></a>
<a name="2568"><span class="lineNum">    2568 </span><span class="lineCov">     195672 :                      (!is_idle_task(current) &amp;&amp; !rcu_is_callbacks_kthread())))</span></a>
<a name="2569"><span class="lineNum">    2569 </span>            :                         break;</a>
<a name="2570"><span class="lineNum">    2570 </span><span class="lineCov">     580180 :                 if (unlikely(tlimit)) {</span></a>
<a name="2571"><span class="lineNum">    2571 </span>            :                         /* only call local_clock() every 32 callbacks */</a>
<a name="2572"><span class="lineNum">    2572 </span><span class="lineNoCov">          0 :                         if (likely((count &amp; 31) || local_clock() &lt; tlimit))</span></a>
<a name="2573"><span class="lineNum">    2573 </span><span class="lineNoCov">          0 :                                 continue;</span></a>
<a name="2574"><span class="lineNum">    2574 </span>            :                         /* Exceeded the time limit, so leave. */</a>
<a name="2575"><span class="lineNum">    2575 </span>            :                         break;</a>
<a name="2576"><span class="lineNum">    2576 </span>            :                 }</a>
<a name="2577"><span class="lineNum">    2577 </span><span class="lineCov">     580180 :                 if (!in_serving_softirq()) {</span></a>
<a name="2578"><span class="lineNum">    2578 </span><span class="lineNoCov">          0 :                         local_bh_enable();</span></a>
<a name="2579"><span class="lineNum">    2579 </span><span class="lineNoCov">          0 :                         lockdep_assert_irqs_enabled();</span></a>
<a name="2580"><span class="lineNum">    2580 </span><span class="lineNoCov">          0 :                         cond_resched_tasks_rcu_qs();</span></a>
<a name="2581"><span class="lineNum">    2581 </span><span class="lineNoCov">          0 :                         lockdep_assert_irqs_enabled();</span></a>
<a name="2582"><span class="lineNum">    2582 </span><span class="lineNoCov">          0 :                         local_bh_disable();</span></a>
<a name="2583"><span class="lineNum">    2583 </span>            :                 }</a>
<a name="2584"><span class="lineNum">    2584 </span>            :         }</a>
<a name="2585"><span class="lineNum">    2585 </span>            : </a>
<a name="2586"><span class="lineNum">    2586 </span><span class="lineCov">      97981 :         local_irq_save(flags);</span></a>
<a name="2587"><span class="lineNum">    2587 </span><span class="lineCov">      48995 :         rcu_nocb_lock(rdp);</span></a>
<a name="2588"><span class="lineNum">    2588 </span><span class="lineCov">      48995 :         rdp-&gt;n_cbs_invoked += count;</span></a>
<a name="2589"><span class="lineNum">    2589 </span><span class="lineCov">      48995 :         trace_rcu_batch_end(rcu_state.name, count, !!rcl.head, need_resched(),</span></a>
<a name="2590"><span class="lineNum">    2590 </span><span class="lineCov">      48995 :                             is_idle_task(current), rcu_is_callbacks_kthread());</span></a>
<a name="2591"><span class="lineNum">    2591 </span>            : </a>
<a name="2592"><span class="lineNum">    2592 </span>            :         /* Update counts and requeue any remaining callbacks. */</a>
<a name="2593"><span class="lineNum">    2593 </span><span class="lineCov">      49006 :         rcu_segcblist_insert_done_cbs(&amp;rdp-&gt;cblist, &amp;rcl);</span></a>
<a name="2594"><span class="lineNum">    2594 </span><span class="lineCov">      49003 :         rcu_segcblist_add_len(&amp;rdp-&gt;cblist, -count);</span></a>
<a name="2595"><span class="lineNum">    2595 </span>            : </a>
<a name="2596"><span class="lineNum">    2596 </span>            :         /* Reinstate batch limit if we have worked down the excess. */</a>
<a name="2597"><span class="lineNum">    2597 </span><span class="lineCov">      49018 :         count = rcu_segcblist_n_cbs(&amp;rdp-&gt;cblist);</span></a>
<a name="2598"><span class="lineNum">    2598 </span><span class="lineCov">      49018 :         if (rdp-&gt;blimit &gt;= DEFAULT_MAX_RCU_BLIMIT &amp;&amp; count &lt;= qlowmark)</span></a>
<a name="2599"><span class="lineNum">    2599 </span><span class="lineNoCov">          0 :                 rdp-&gt;blimit = blimit;</span></a>
<a name="2600"><span class="lineNum">    2600 </span>            : </a>
<a name="2601"><span class="lineNum">    2601 </span>            :         /* Reset -&gt;qlen_last_fqs_check trigger if enough CBs have drained. */</a>
<a name="2602"><span class="lineNum">    2602 </span><span class="lineCov">      49018 :         if (count == 0 &amp;&amp; rdp-&gt;qlen_last_fqs_check != 0) {</span></a>
<a name="2603"><span class="lineNum">    2603 </span><span class="lineNoCov">          0 :                 rdp-&gt;qlen_last_fqs_check = 0;</span></a>
<a name="2604"><span class="lineNum">    2604 </span><span class="lineNoCov">          0 :                 rdp-&gt;n_force_qs_snap = rcu_state.n_force_qs;</span></a>
<a name="2605"><span class="lineNum">    2605 </span><span class="lineCov">      49018 :         } else if (count &lt; rdp-&gt;qlen_last_fqs_check - qhimark)</span></a>
<a name="2606"><span class="lineNum">    2606 </span><span class="lineNoCov">          0 :                 rdp-&gt;qlen_last_fqs_check = count;</span></a>
<a name="2607"><span class="lineNum">    2607 </span>            : </a>
<a name="2608"><span class="lineNum">    2608 </span>            :         /*</a>
<a name="2609"><span class="lineNum">    2609 </span>            :          * The following usually indicates a double call_rcu().  To track</a>
<a name="2610"><span class="lineNum">    2610 </span>            :          * this down, try building with CONFIG_DEBUG_OBJECTS_RCU_HEAD=y.</a>
<a name="2611"><span class="lineNum">    2611 </span>            :          */</a>
<a name="2612"><span class="lineNum">    2612 </span><span class="lineCov">      49018 :         empty = rcu_segcblist_empty(&amp;rdp-&gt;cblist);</span></a>
<a name="2613"><span class="lineNum">    2613 </span><span class="lineCov">      49018 :         WARN_ON_ONCE(count == 0 &amp;&amp; !empty);</span></a>
<a name="2614"><span class="lineNum">    2614 </span><span class="lineCov">      49018 :         WARN_ON_ONCE(!IS_ENABLED(CONFIG_RCU_NOCB_CPU) &amp;&amp;</span></a>
<a name="2615"><span class="lineNum">    2615 </span>            :                      count != 0 &amp;&amp; empty);</a>
<a name="2616"><span class="lineNum">    2616 </span><span class="lineCov">      49271 :         WARN_ON_ONCE(count == 0 &amp;&amp; rcu_segcblist_n_segment_cbs(&amp;rdp-&gt;cblist) != 0);</span></a>
<a name="2617"><span class="lineNum">    2617 </span><span class="lineCov">      97777 :         WARN_ON_ONCE(!empty &amp;&amp; rcu_segcblist_n_segment_cbs(&amp;rdp-&gt;cblist) == 0);</span></a>
<a name="2618"><span class="lineNum">    2618 </span>            : </a>
<a name="2619"><span class="lineNum">    2619 </span><span class="lineCov">      49024 :         rcu_nocb_unlock_irqrestore(rdp, flags);</span></a>
<a name="2620"><span class="lineNum">    2620 </span>            : </a>
<a name="2621"><span class="lineNum">    2621 </span>            :         /* Re-invoke RCU core processing if there are callbacks remaining. */</a>
<a name="2622"><span class="lineNum">    2622 </span><span class="lineCov">      49016 :         if (!offloaded &amp;&amp; rcu_segcblist_ready_cbs(&amp;rdp-&gt;cblist))</span></a>
<a name="2623"><span class="lineNum">    2623 </span><span class="lineCov">      43538 :                 invoke_rcu_core();</span></a>
<a name="2624"><span class="lineNum">    2624 </span><span class="lineCov">      49013 :         tick_dep_clear_task(current, TICK_DEP_BIT_RCU);</span></a>
<a name="2625"><span class="lineNum">    2625 </span>            : }</a>
<a name="2626"><span class="lineNum">    2626 </span>            : </a>
<a name="2627"><span class="lineNum">    2627 </span>            : /*</a>
<a name="2628"><span class="lineNum">    2628 </span>            :  * This function is invoked from each scheduling-clock interrupt,</a>
<a name="2629"><span class="lineNum">    2629 </span>            :  * and checks to see if this CPU is in a non-context-switch quiescent</a>
<a name="2630"><span class="lineNum">    2630 </span>            :  * state, for example, user mode or idle loop.  It also schedules RCU</a>
<a name="2631"><span class="lineNum">    2631 </span>            :  * core processing.  If the current grace period has gone on too long,</a>
<a name="2632"><span class="lineNum">    2632 </span>            :  * it will ask the scheduler to manufacture a context switch for the sole</a>
<a name="2633"><span class="lineNum">    2633 </span>            :  * purpose of providing a providing the needed quiescent state.</a>
<a name="2634"><span class="lineNum">    2634 </span>            :  */</a>
<a name="2635"><span class="lineNum">    2635 </span><span class="lineCov">      27553 : void rcu_sched_clock_irq(int user)</span></a>
<a name="2636"><span class="lineNum">    2636 </span>            : {</a>
<a name="2637"><span class="lineNum">    2637 </span><span class="lineCov">      27553 :         trace_rcu_utilization(TPS(&quot;Start scheduler-tick&quot;));</span></a>
<a name="2638"><span class="lineNum">    2638 </span><span class="lineCov">      54651 :         lockdep_assert_irqs_disabled();</span></a>
<a name="2639"><span class="lineNum">    2639 </span><span class="lineCov">      27328 :         raw_cpu_inc(rcu_data.ticks_this_gp);</span></a>
<a name="2640"><span class="lineNum">    2640 </span>            :         /* The load-acquire pairs with the store-release setting to true. */</a>
<a name="2641"><span class="lineNum">    2641 </span><span class="lineCov">      27328 :         if (smp_load_acquire(this_cpu_ptr(&amp;rcu_data.rcu_urgent_qs))) {</span></a>
<a name="2642"><span class="lineNum">    2642 </span>            :                 /* Idle and userspace execution already are quiescent states. */</a>
<a name="2643"><span class="lineNum">    2643 </span><span class="lineCov">         23 :                 if (!rcu_is_cpu_rrupt_from_idle() &amp;&amp; !user) {</span></a>
<a name="2644"><span class="lineNum">    2644 </span><span class="lineCov">         23 :                         set_tsk_need_resched(current);</span></a>
<a name="2645"><span class="lineNum">    2645 </span><span class="lineCov">         23 :                         set_preempt_need_resched();</span></a>
<a name="2646"><span class="lineNum">    2646 </span>            :                 }</a>
<a name="2647"><span class="lineNum">    2647 </span><span class="lineCov">      27388 :                 __this_cpu_write(rcu_data.rcu_urgent_qs, false);</span></a>
<a name="2648"><span class="lineNum">    2648 </span>            :         }</a>
<a name="2649"><span class="lineNum">    2649 </span><span class="lineCov">      27388 :         rcu_flavor_sched_clock_irq(user);</span></a>
<a name="2650"><span class="lineNum">    2650 </span><span class="lineCov">      27880 :         if (rcu_pending(user))</span></a>
<a name="2651"><span class="lineNum">    2651 </span><span class="lineCov">      11529 :                 invoke_rcu_core();</span></a>
<a name="2652"><span class="lineNum">    2652 </span><span class="lineCov">      55421 :         lockdep_assert_irqs_disabled();</span></a>
<a name="2653"><span class="lineNum">    2653 </span>            : </a>
<a name="2654"><span class="lineNum">    2654 </span><span class="lineCov">      27851 :         trace_rcu_utilization(TPS(&quot;End scheduler-tick&quot;));</span></a>
<a name="2655"><span class="lineNum">    2655 </span><span class="lineCov">      27778 : }</span></a>
<a name="2656"><span class="lineNum">    2656 </span>            : </a>
<a name="2657"><span class="lineNum">    2657 </span>            : /*</a>
<a name="2658"><span class="lineNum">    2658 </span>            :  * Scan the leaf rcu_node structures.  For each structure on which all</a>
<a name="2659"><span class="lineNum">    2659 </span>            :  * CPUs have reported a quiescent state and on which there are tasks</a>
<a name="2660"><span class="lineNum">    2660 </span>            :  * blocking the current grace period, initiate RCU priority boosting.</a>
<a name="2661"><span class="lineNum">    2661 </span>            :  * Otherwise, invoke the specified function to check dyntick state for</a>
<a name="2662"><span class="lineNum">    2662 </span>            :  * each CPU that has not yet reported a quiescent state.</a>
<a name="2663"><span class="lineNum">    2663 </span>            :  */</a>
<a name="2664"><span class="lineNum">    2664 </span><span class="lineCov">       2455 : static void force_qs_rnp(int (*f)(struct rcu_data *rdp))</span></a>
<a name="2665"><span class="lineNum">    2665 </span>            : {</a>
<a name="2666"><span class="lineNum">    2666 </span><span class="lineCov">       2455 :         int cpu;</span></a>
<a name="2667"><span class="lineNum">    2667 </span><span class="lineCov">       2455 :         unsigned long flags;</span></a>
<a name="2668"><span class="lineNum">    2668 </span><span class="lineCov">       2455 :         unsigned long mask;</span></a>
<a name="2669"><span class="lineNum">    2669 </span><span class="lineCov">       2455 :         struct rcu_data *rdp;</span></a>
<a name="2670"><span class="lineNum">    2670 </span><span class="lineCov">       2455 :         struct rcu_node *rnp;</span></a>
<a name="2671"><span class="lineNum">    2671 </span>            : </a>
<a name="2672"><span class="lineNum">    2672 </span><span class="lineCov">       2455 :         rcu_state.cbovld = rcu_state.cbovldnext;</span></a>
<a name="2673"><span class="lineNum">    2673 </span><span class="lineCov">       2455 :         rcu_state.cbovldnext = false;</span></a>
<a name="2674"><span class="lineNum">    2674 </span><span class="lineCov">       4910 :         rcu_for_each_leaf_node(rnp) {</span></a>
<a name="2675"><span class="lineNum">    2675 </span><span class="lineCov">       2455 :                 cond_resched_tasks_rcu_qs();</span></a>
<a name="2676"><span class="lineNum">    2676 </span><span class="lineCov">       2455 :                 mask = 0;</span></a>
<a name="2677"><span class="lineNum">    2677 </span><span class="lineCov">       2455 :                 raw_spin_lock_irqsave_rcu_node(rnp, flags);</span></a>
<a name="2678"><span class="lineNum">    2678 </span><span class="lineCov">       2455 :                 rcu_state.cbovldnext |= !!rnp-&gt;cbovldmask;</span></a>
<a name="2679"><span class="lineNum">    2679 </span><span class="lineCov">       2455 :                 if (rnp-&gt;qsmask == 0) {</span></a>
<a name="2680"><span class="lineNum">    2680 </span><span class="lineCov">          2 :                         if (rcu_preempt_blocked_readers_cgp(rnp)) {</span></a>
<a name="2681"><span class="lineNum">    2681 </span>            :                                 /*</a>
<a name="2682"><span class="lineNum">    2682 </span>            :                                  * No point in scanning bits because they</a>
<a name="2683"><span class="lineNum">    2683 </span>            :                                  * are all zero.  But we might need to</a>
<a name="2684"><span class="lineNum">    2684 </span>            :                                  * priority-boost blocked readers.</a>
<a name="2685"><span class="lineNum">    2685 </span>            :                                  */</a>
<a name="2686"><span class="lineNum">    2686 </span>            :                                 rcu_initiate_boost(rnp, flags);</a>
<a name="2687"><span class="lineNum">    2687 </span>            :                                 /* rcu_initiate_boost() releases rnp-&gt;lock */</a>
<a name="2688"><span class="lineNum">    2688 </span>            :                                 continue;</a>
<a name="2689"><span class="lineNum">    2689 </span>            :                         }</a>
<a name="2690"><span class="lineNum">    2690 </span><span class="lineCov">          4 :                         raw_spin_unlock_irqrestore_rcu_node(rnp, flags);</span></a>
<a name="2691"><span class="lineNum">    2691 </span><span class="lineCov">          2 :                         continue;</span></a>
<a name="2692"><span class="lineNum">    2692 </span>            :                 }</a>
<a name="2693"><span class="lineNum">    2693 </span><span class="lineCov">       6001 :                 for_each_leaf_node_cpu_mask(rnp, cpu, rnp-&gt;qsmask) {</span></a>
<a name="2694"><span class="lineNum">    2694 </span><span class="lineCov">       3548 :                         rdp = per_cpu_ptr(&amp;rcu_data, cpu);</span></a>
<a name="2695"><span class="lineNum">    2695 </span><span class="lineCov">       3548 :                         if (f(rdp)) {</span></a>
<a name="2696"><span class="lineNum">    2696 </span><span class="lineCov">        931 :                                 mask |= rdp-&gt;grpmask;</span></a>
<a name="2697"><span class="lineNum">    2697 </span><span class="lineCov">        931 :                                 rcu_disable_urgency_upon_qs(rdp);</span></a>
<a name="2698"><span class="lineNum">    2698 </span>            :                         }</a>
<a name="2699"><span class="lineNum">    2699 </span>            :                 }</a>
<a name="2700"><span class="lineNum">    2700 </span><span class="lineCov">       2453 :                 if (mask != 0) {</span></a>
<a name="2701"><span class="lineNum">    2701 </span>            :                         /* Idle/offline CPUs, report (releases rnp-&gt;lock). */</a>
<a name="2702"><span class="lineNum">    2702 </span><span class="lineCov">        719 :                         rcu_report_qs_rnp(mask, rnp, rnp-&gt;gp_seq, flags);</span></a>
<a name="2703"><span class="lineNum">    2703 </span>            :                 } else {</a>
<a name="2704"><span class="lineNum">    2704 </span>            :                         /* Nothing to do here, so just drop the lock. */</a>
<a name="2705"><span class="lineNum">    2705 </span><span class="lineCov">       4189 :                         raw_spin_unlock_irqrestore_rcu_node(rnp, flags);</span></a>
<a name="2706"><span class="lineNum">    2706 </span>            :                 }</a>
<a name="2707"><span class="lineNum">    2707 </span>            :         }</a>
<a name="2708"><span class="lineNum">    2708 </span><span class="lineCov">       2455 : }</span></a>
<a name="2709"><span class="lineNum">    2709 </span>            : </a>
<a name="2710"><span class="lineNum">    2710 </span>            : /*</a>
<a name="2711"><span class="lineNum">    2711 </span>            :  * Force quiescent states on reluctant CPUs, and also detect which</a>
<a name="2712"><span class="lineNum">    2712 </span>            :  * CPUs are in dyntick-idle mode.</a>
<a name="2713"><span class="lineNum">    2713 </span>            :  */</a>
<a name="2714"><span class="lineNum">    2714 </span><span class="lineNoCov">          0 : void rcu_force_quiescent_state(void)</span></a>
<a name="2715"><span class="lineNum">    2715 </span>            : {</a>
<a name="2716"><span class="lineNum">    2716 </span><span class="lineNoCov">          0 :         unsigned long flags;</span></a>
<a name="2717"><span class="lineNum">    2717 </span><span class="lineNoCov">          0 :         bool ret;</span></a>
<a name="2718"><span class="lineNum">    2718 </span><span class="lineNoCov">          0 :         struct rcu_node *rnp;</span></a>
<a name="2719"><span class="lineNum">    2719 </span><span class="lineNoCov">          0 :         struct rcu_node *rnp_old = NULL;</span></a>
<a name="2720"><span class="lineNum">    2720 </span>            : </a>
<a name="2721"><span class="lineNum">    2721 </span>            :         /* Funnel through hierarchy to reduce memory contention. */</a>
<a name="2722"><span class="lineNum">    2722 </span><span class="lineNoCov">          0 :         rnp = __this_cpu_read(rcu_data.mynode);</span></a>
<a name="2723"><span class="lineNum">    2723 </span><span class="lineNoCov">          0 :         for (; rnp != NULL; rnp = rnp-&gt;parent) {</span></a>
<a name="2724"><span class="lineNum">    2724 </span><span class="lineNoCov">          0 :                 ret = (READ_ONCE(rcu_state.gp_flags) &amp; RCU_GP_FLAG_FQS) ||</span></a>
<a name="2725"><span class="lineNum">    2725 </span><span class="lineNoCov">          0 :                        !raw_spin_trylock(&amp;rnp-&gt;fqslock);</span></a>
<a name="2726"><span class="lineNum">    2726 </span><span class="lineNoCov">          0 :                 if (rnp_old != NULL)</span></a>
<a name="2727"><span class="lineNum">    2727 </span><span class="lineNoCov">          0 :                         raw_spin_unlock(&amp;rnp_old-&gt;fqslock);</span></a>
<a name="2728"><span class="lineNum">    2728 </span><span class="lineNoCov">          0 :                 if (ret)</span></a>
<a name="2729"><span class="lineNum">    2729 </span>            :                         return;</a>
<a name="2730"><span class="lineNum">    2730 </span><span class="lineNoCov">          0 :                 rnp_old = rnp;</span></a>
<a name="2731"><span class="lineNum">    2731 </span>            :         }</a>
<a name="2732"><span class="lineNum">    2732 </span>            :         /* rnp_old == rcu_get_root(), rnp == NULL. */</a>
<a name="2733"><span class="lineNum">    2733 </span>            : </a>
<a name="2734"><span class="lineNum">    2734 </span>            :         /* Reached the root of the rcu_node tree, acquire lock. */</a>
<a name="2735"><span class="lineNum">    2735 </span><span class="lineNoCov">          0 :         raw_spin_lock_irqsave_rcu_node(rnp_old, flags);</span></a>
<a name="2736"><span class="lineNum">    2736 </span><span class="lineNoCov">          0 :         raw_spin_unlock(&amp;rnp_old-&gt;fqslock);</span></a>
<a name="2737"><span class="lineNum">    2737 </span><span class="lineNoCov">          0 :         if (READ_ONCE(rcu_state.gp_flags) &amp; RCU_GP_FLAG_FQS) {</span></a>
<a name="2738"><span class="lineNum">    2738 </span><span class="lineNoCov">          0 :                 raw_spin_unlock_irqrestore_rcu_node(rnp_old, flags);</span></a>
<a name="2739"><span class="lineNum">    2739 </span><span class="lineNoCov">          0 :                 return;  /* Someone beat us to it. */</span></a>
<a name="2740"><span class="lineNum">    2740 </span>            :         }</a>
<a name="2741"><span class="lineNum">    2741 </span><span class="lineNoCov">          0 :         WRITE_ONCE(rcu_state.gp_flags,</span></a>
<a name="2742"><span class="lineNum">    2742 </span>            :                    READ_ONCE(rcu_state.gp_flags) | RCU_GP_FLAG_FQS);</a>
<a name="2743"><span class="lineNum">    2743 </span><span class="lineNoCov">          0 :         raw_spin_unlock_irqrestore_rcu_node(rnp_old, flags);</span></a>
<a name="2744"><span class="lineNum">    2744 </span><span class="lineNoCov">          0 :         rcu_gp_kthread_wake();</span></a>
<a name="2745"><span class="lineNum">    2745 </span>            : }</a>
<a name="2746"><span class="lineNum">    2746 </span>            : EXPORT_SYMBOL_GPL(rcu_force_quiescent_state);</a>
<a name="2747"><span class="lineNum">    2747 </span>            : </a>
<a name="2748"><span class="lineNum">    2748 </span>            : // Workqueue handler for an RCU reader for kernels enforcing struct RCU</a>
<a name="2749"><span class="lineNum">    2749 </span>            : // grace periods.</a>
<a name="2750"><span class="lineNum">    2750 </span><span class="lineNoCov">          0 : static void strict_work_handler(struct work_struct *work)</span></a>
<a name="2751"><span class="lineNum">    2751 </span>            : {</a>
<a name="2752"><span class="lineNum">    2752 </span><span class="lineNoCov">          0 :         rcu_read_lock();</span></a>
<a name="2753"><span class="lineNum">    2753 </span><span class="lineNoCov">          0 :         rcu_read_unlock();</span></a>
<a name="2754"><span class="lineNum">    2754 </span><span class="lineNoCov">          0 : }</span></a>
<a name="2755"><span class="lineNum">    2755 </span>            : </a>
<a name="2756"><span class="lineNum">    2756 </span>            : /* Perform RCU core processing work for the current CPU.  */</a>
<a name="2757"><span class="lineNum">    2757 </span><span class="lineCov">      54297 : static __latent_entropy void rcu_core(void)</span></a>
<a name="2758"><span class="lineNum">    2758 </span>            : {</a>
<a name="2759"><span class="lineNum">    2759 </span><span class="lineCov">      54297 :         unsigned long flags;</span></a>
<a name="2760"><span class="lineNum">    2760 </span><span class="lineCov">      54297 :         struct rcu_data *rdp = raw_cpu_ptr(&amp;rcu_data);</span></a>
<a name="2761"><span class="lineNum">    2761 </span><span class="lineCov">      54354 :         struct rcu_node *rnp = rdp-&gt;mynode;</span></a>
<a name="2762"><span class="lineNum">    2762 </span><span class="lineCov">      54354 :         const bool do_batch = !rcu_segcblist_completely_offloaded(&amp;rdp-&gt;cblist);</span></a>
<a name="2763"><span class="lineNum">    2763 </span>            : </a>
<a name="2764"><span class="lineNum">    2764 </span><span class="lineCov">      54354 :         if (cpu_is_offline(smp_processor_id()))</span></a>
<a name="2765"><span class="lineNum">    2765 </span>            :                 return;</a>
<a name="2766"><span class="lineNum">    2766 </span><span class="lineCov">      54365 :         trace_rcu_utilization(TPS(&quot;Start RCU core&quot;));</span></a>
<a name="2767"><span class="lineNum">    2767 </span><span class="lineCov">      54468 :         WARN_ON_ONCE(!rdp-&gt;beenonline);</span></a>
<a name="2768"><span class="lineNum">    2768 </span>            : </a>
<a name="2769"><span class="lineNum">    2769 </span>            :         /* Report any deferred quiescent states if preemption enabled. */</a>
<a name="2770"><span class="lineNum">    2770 </span><span class="lineCov">      54468 :         if (!(preempt_count() &amp; PREEMPT_MASK)) {</span></a>
<a name="2771"><span class="lineNum">    2771 </span><span class="lineCov">      38495 :                 rcu_preempt_deferred_qs(current);</span></a>
<a name="2772"><span class="lineNum">    2772 </span><span class="lineCov">      15973 :         } else if (rcu_preempt_need_deferred_qs(current)) {</span></a>
<a name="2773"><span class="lineNum">    2773 </span>            :                 set_tsk_need_resched(current);</a>
<a name="2774"><span class="lineNum">    2774 </span>            :                 set_preempt_need_resched();</a>
<a name="2775"><span class="lineNum">    2775 </span>            :         }</a>
<a name="2776"><span class="lineNum">    2776 </span>            : </a>
<a name="2777"><span class="lineNum">    2777 </span>            :         /* Update RCU state based on any recent quiescent states. */</a>
<a name="2778"><span class="lineNum">    2778 </span><span class="lineCov">      54468 :         rcu_check_quiescent_state(rdp);</span></a>
<a name="2779"><span class="lineNum">    2779 </span>            : </a>
<a name="2780"><span class="lineNum">    2780 </span>            :         /* No grace period and unregistered callbacks? */</a>
<a name="2781"><span class="lineNum">    2781 </span><span class="lineCov">      54541 :         if (!rcu_gp_in_progress() &amp;&amp;</span></a>
<a name="2782"><span class="lineNum">    2782 </span><span class="lineCov">         73 :             rcu_segcblist_is_enabled(&amp;rdp-&gt;cblist) &amp;&amp; do_batch) {</span></a>
<a name="2783"><span class="lineNum">    2783 </span><span class="lineCov">        146 :                 rcu_nocb_lock_irqsave(rdp, flags);</span></a>
<a name="2784"><span class="lineNum">    2784 </span><span class="lineCov">         73 :                 if (!rcu_segcblist_restempty(&amp;rdp-&gt;cblist, RCU_NEXT_READY_TAIL))</span></a>
<a name="2785"><span class="lineNum">    2785 </span><span class="lineCov">         16 :                         rcu_accelerate_cbs_unlocked(rnp, rdp);</span></a>
<a name="2786"><span class="lineNum">    2786 </span><span class="lineCov">         73 :                 rcu_nocb_unlock_irqrestore(rdp, flags);</span></a>
<a name="2787"><span class="lineNum">    2787 </span>            :         }</a>
<a name="2788"><span class="lineNum">    2788 </span>            : </a>
<a name="2789"><span class="lineNum">    2789 </span><span class="lineCov">      54541 :         rcu_check_gp_start_stall(rnp, rdp, rcu_jiffies_till_stall_check());</span></a>
<a name="2790"><span class="lineNum">    2790 </span>            : </a>
<a name="2791"><span class="lineNum">    2791 </span>            :         /* If there are callbacks ready, invoke them. */</a>
<a name="2792"><span class="lineNum">    2792 </span><span class="lineCov">      54504 :         if (do_batch &amp;&amp; rcu_segcblist_ready_cbs(&amp;rdp-&gt;cblist) &amp;&amp;</span></a>
<a name="2793"><span class="lineNum">    2793 </span><span class="lineCov">      49011 :             likely(READ_ONCE(rcu_scheduler_fully_active)))</span></a>
<a name="2794"><span class="lineNum">    2794 </span><span class="lineCov">      49011 :                 rcu_do_batch(rdp);</span></a>
<a name="2795"><span class="lineNum">    2795 </span>            : </a>
<a name="2796"><span class="lineNum">    2796 </span>            :         /* Do any needed deferred wakeups of rcuo kthreads. */</a>
<a name="2797"><span class="lineNum">    2797 </span><span class="lineCov">      54511 :         do_nocb_deferred_wakeup(rdp);</span></a>
<a name="2798"><span class="lineNum">    2798 </span><span class="lineCov">      54511 :         trace_rcu_utilization(TPS(&quot;End RCU core&quot;));</span></a>
<a name="2799"><span class="lineNum">    2799 </span>            : </a>
<a name="2800"><span class="lineNum">    2800 </span>            :         // If strict GPs, schedule an RCU reader in a clean environment.</a>
<a name="2801"><span class="lineNum">    2801 </span><span class="lineCov">      54511 :         if (IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD))</span></a>
<a name="2802"><span class="lineNum">    2802 </span>            :                 queue_work_on(rdp-&gt;cpu, rcu_gp_wq, &amp;rdp-&gt;strict_work);</a>
<a name="2803"><span class="lineNum">    2803 </span>            : }</a>
<a name="2804"><span class="lineNum">    2804 </span>            : </a>
<a name="2805"><span class="lineNum">    2805 </span><span class="lineCov">      54354 : static void rcu_core_si(struct softirq_action *h)</span></a>
<a name="2806"><span class="lineNum">    2806 </span>            : {</a>
<a name="2807"><span class="lineNum">    2807 </span><span class="lineCov">      54354 :         rcu_core();</span></a>
<a name="2808"><span class="lineNum">    2808 </span><span class="lineCov">      54528 : }</span></a>
<a name="2809"><span class="lineNum">    2809 </span>            : </a>
<a name="2810"><span class="lineNum">    2810 </span><span class="lineNoCov">          0 : static void rcu_wake_cond(struct task_struct *t, int status)</span></a>
<a name="2811"><span class="lineNum">    2811 </span>            : {</a>
<a name="2812"><span class="lineNum">    2812 </span>            :         /*</a>
<a name="2813"><span class="lineNum">    2813 </span>            :          * If the thread is yielding, only wake it when this</a>
<a name="2814"><span class="lineNum">    2814 </span>            :          * is invoked from idle</a>
<a name="2815"><span class="lineNum">    2815 </span>            :          */</a>
<a name="2816"><span class="lineNum">    2816 </span><span class="lineNoCov">          0 :         if (t &amp;&amp; (status != RCU_KTHREAD_YIELDING || is_idle_task(current)))</span></a>
<a name="2817"><span class="lineNum">    2817 </span><span class="lineNoCov">          0 :                 wake_up_process(t);</span></a>
<a name="2818"><span class="lineNum">    2818 </span><span class="lineNoCov">          0 : }</span></a>
<a name="2819"><span class="lineNum">    2819 </span>            : </a>
<a name="2820"><span class="lineNum">    2820 </span><span class="lineNoCov">          0 : static void invoke_rcu_core_kthread(void)</span></a>
<a name="2821"><span class="lineNum">    2821 </span>            : {</a>
<a name="2822"><span class="lineNum">    2822 </span><span class="lineNoCov">          0 :         struct task_struct *t;</span></a>
<a name="2823"><span class="lineNum">    2823 </span><span class="lineNoCov">          0 :         unsigned long flags;</span></a>
<a name="2824"><span class="lineNum">    2824 </span>            : </a>
<a name="2825"><span class="lineNum">    2825 </span><span class="lineNoCov">          0 :         local_irq_save(flags);</span></a>
<a name="2826"><span class="lineNum">    2826 </span><span class="lineNoCov">          0 :         __this_cpu_write(rcu_data.rcu_cpu_has_work, 1);</span></a>
<a name="2827"><span class="lineNum">    2827 </span><span class="lineNoCov">          0 :         t = __this_cpu_read(rcu_data.rcu_cpu_kthread_task);</span></a>
<a name="2828"><span class="lineNum">    2828 </span><span class="lineNoCov">          0 :         if (t != NULL &amp;&amp; t != current)</span></a>
<a name="2829"><span class="lineNum">    2829 </span><span class="lineNoCov">          0 :                 rcu_wake_cond(t, __this_cpu_read(rcu_data.rcu_cpu_kthread_status));</span></a>
<a name="2830"><span class="lineNum">    2830 </span><span class="lineNoCov">          0 :         local_irq_restore(flags);</span></a>
<a name="2831"><span class="lineNum">    2831 </span><span class="lineNoCov">          0 : }</span></a>
<a name="2832"><span class="lineNum">    2832 </span>            : </a>
<a name="2833"><span class="lineNum">    2833 </span>            : /*</a>
<a name="2834"><span class="lineNum">    2834 </span>            :  * Wake up this CPU's rcuc kthread to do RCU core processing.</a>
<a name="2835"><span class="lineNum">    2835 </span>            :  */</a>
<a name="2836"><span class="lineNum">    2836 </span><span class="lineCov">      54974 : static void invoke_rcu_core(void)</span></a>
<a name="2837"><span class="lineNum">    2837 </span>            : {</a>
<a name="2838"><span class="lineNum">    2838 </span><span class="lineCov">      54974 :         if (!cpu_online(smp_processor_id()))</span></a>
<a name="2839"><span class="lineNum">    2839 </span>            :                 return;</a>
<a name="2840"><span class="lineNum">    2840 </span><span class="lineCov">      55017 :         if (use_softirq)</span></a>
<a name="2841"><span class="lineNum">    2841 </span><span class="lineCov">      55017 :                 raise_softirq(RCU_SOFTIRQ);</span></a>
<a name="2842"><span class="lineNum">    2842 </span>            :         else</a>
<a name="2843"><span class="lineNum">    2843 </span><span class="lineNoCov">          0 :                 invoke_rcu_core_kthread();</span></a>
<a name="2844"><span class="lineNum">    2844 </span>            : }</a>
<a name="2845"><span class="lineNum">    2845 </span>            : </a>
<a name="2846"><span class="lineNum">    2846 </span><span class="lineNoCov">          0 : static void rcu_cpu_kthread_park(unsigned int cpu)</span></a>
<a name="2847"><span class="lineNum">    2847 </span>            : {</a>
<a name="2848"><span class="lineNum">    2848 </span><span class="lineNoCov">          0 :         per_cpu(rcu_data.rcu_cpu_kthread_status, cpu) = RCU_KTHREAD_OFFCPU;</span></a>
<a name="2849"><span class="lineNum">    2849 </span><span class="lineNoCov">          0 : }</span></a>
<a name="2850"><span class="lineNum">    2850 </span>            : </a>
<a name="2851"><span class="lineNum">    2851 </span><span class="lineNoCov">          0 : static int rcu_cpu_kthread_should_run(unsigned int cpu)</span></a>
<a name="2852"><span class="lineNum">    2852 </span>            : {</a>
<a name="2853"><span class="lineNum">    2853 </span><span class="lineNoCov">          0 :         return __this_cpu_read(rcu_data.rcu_cpu_has_work);</span></a>
<a name="2854"><span class="lineNum">    2854 </span>            : }</a>
<a name="2855"><span class="lineNum">    2855 </span>            : </a>
<a name="2856"><span class="lineNum">    2856 </span>            : /*</a>
<a name="2857"><span class="lineNum">    2857 </span>            :  * Per-CPU kernel thread that invokes RCU callbacks.  This replaces</a>
<a name="2858"><span class="lineNum">    2858 </span>            :  * the RCU softirq used in configurations of RCU that do not support RCU</a>
<a name="2859"><span class="lineNum">    2859 </span>            :  * priority boosting.</a>
<a name="2860"><span class="lineNum">    2860 </span>            :  */</a>
<a name="2861"><span class="lineNum">    2861 </span><span class="lineNoCov">          0 : static void rcu_cpu_kthread(unsigned int cpu)</span></a>
<a name="2862"><span class="lineNum">    2862 </span>            : {</a>
<a name="2863"><span class="lineNum">    2863 </span><span class="lineNoCov">          0 :         unsigned int *statusp = this_cpu_ptr(&amp;rcu_data.rcu_cpu_kthread_status);</span></a>
<a name="2864"><span class="lineNum">    2864 </span><span class="lineNoCov">          0 :         char work, *workp = this_cpu_ptr(&amp;rcu_data.rcu_cpu_has_work);</span></a>
<a name="2865"><span class="lineNum">    2865 </span><span class="lineNoCov">          0 :         int spincnt;</span></a>
<a name="2866"><span class="lineNum">    2866 </span>            : </a>
<a name="2867"><span class="lineNum">    2867 </span><span class="lineNoCov">          0 :         trace_rcu_utilization(TPS(&quot;Start CPU kthread@rcu_run&quot;));</span></a>
<a name="2868"><span class="lineNum">    2868 </span><span class="lineNoCov">          0 :         for (spincnt = 0; spincnt &lt; 10; spincnt++) {</span></a>
<a name="2869"><span class="lineNum">    2869 </span><span class="lineNoCov">          0 :                 local_bh_disable();</span></a>
<a name="2870"><span class="lineNum">    2870 </span><span class="lineNoCov">          0 :                 *statusp = RCU_KTHREAD_RUNNING;</span></a>
<a name="2871"><span class="lineNum">    2871 </span><span class="lineNoCov">          0 :                 local_irq_disable();</span></a>
<a name="2872"><span class="lineNum">    2872 </span><span class="lineNoCov">          0 :                 work = *workp;</span></a>
<a name="2873"><span class="lineNum">    2873 </span><span class="lineNoCov">          0 :                 *workp = 0;</span></a>
<a name="2874"><span class="lineNum">    2874 </span><span class="lineNoCov">          0 :                 local_irq_enable();</span></a>
<a name="2875"><span class="lineNum">    2875 </span><span class="lineNoCov">          0 :                 if (work)</span></a>
<a name="2876"><span class="lineNum">    2876 </span><span class="lineNoCov">          0 :                         rcu_core();</span></a>
<a name="2877"><span class="lineNum">    2877 </span><span class="lineNoCov">          0 :                 local_bh_enable();</span></a>
<a name="2878"><span class="lineNum">    2878 </span><span class="lineNoCov">          0 :                 if (*workp == 0) {</span></a>
<a name="2879"><span class="lineNum">    2879 </span><span class="lineNoCov">          0 :                         trace_rcu_utilization(TPS(&quot;End CPU kthread@rcu_wait&quot;));</span></a>
<a name="2880"><span class="lineNum">    2880 </span><span class="lineNoCov">          0 :                         *statusp = RCU_KTHREAD_WAITING;</span></a>
<a name="2881"><span class="lineNum">    2881 </span><span class="lineNoCov">          0 :                         return;</span></a>
<a name="2882"><span class="lineNum">    2882 </span>            :                 }</a>
<a name="2883"><span class="lineNum">    2883 </span>            :         }</a>
<a name="2884"><span class="lineNum">    2884 </span><span class="lineNoCov">          0 :         *statusp = RCU_KTHREAD_YIELDING;</span></a>
<a name="2885"><span class="lineNum">    2885 </span><span class="lineNoCov">          0 :         trace_rcu_utilization(TPS(&quot;Start CPU kthread@rcu_yield&quot;));</span></a>
<a name="2886"><span class="lineNum">    2886 </span><span class="lineNoCov">          0 :         schedule_timeout_idle(2);</span></a>
<a name="2887"><span class="lineNum">    2887 </span><span class="lineNoCov">          0 :         trace_rcu_utilization(TPS(&quot;End CPU kthread@rcu_yield&quot;));</span></a>
<a name="2888"><span class="lineNum">    2888 </span><span class="lineNoCov">          0 :         *statusp = RCU_KTHREAD_WAITING;</span></a>
<a name="2889"><span class="lineNum">    2889 </span>            : }</a>
<a name="2890"><span class="lineNum">    2890 </span>            : </a>
<a name="2891"><span class="lineNum">    2891 </span>            : static struct smp_hotplug_thread rcu_cpu_thread_spec = {</a>
<a name="2892"><span class="lineNum">    2892 </span>            :         .store                  = &amp;rcu_data.rcu_cpu_kthread_task,</a>
<a name="2893"><span class="lineNum">    2893 </span>            :         .thread_should_run      = rcu_cpu_kthread_should_run,</a>
<a name="2894"><span class="lineNum">    2894 </span>            :         .thread_fn              = rcu_cpu_kthread,</a>
<a name="2895"><span class="lineNum">    2895 </span>            :         .thread_comm            = &quot;rcuc/%u&quot;,</a>
<a name="2896"><span class="lineNum">    2896 </span>            :         .setup                  = rcu_cpu_kthread_setup,</a>
<a name="2897"><span class="lineNum">    2897 </span>            :         .park                   = rcu_cpu_kthread_park,</a>
<a name="2898"><span class="lineNum">    2898 </span>            : };</a>
<a name="2899"><span class="lineNum">    2899 </span>            : </a>
<a name="2900"><span class="lineNum">    2900 </span>            : /*</a>
<a name="2901"><span class="lineNum">    2901 </span>            :  * Spawn per-CPU RCU core processing kthreads.</a>
<a name="2902"><span class="lineNum">    2902 </span>            :  */</a>
<a name="2903"><span class="lineNum">    2903 </span><span class="lineCov">          1 : static int __init rcu_spawn_core_kthreads(void)</span></a>
<a name="2904"><span class="lineNum">    2904 </span>            : {</a>
<a name="2905"><span class="lineNum">    2905 </span><span class="lineCov">          1 :         int cpu;</span></a>
<a name="2906"><span class="lineNum">    2906 </span>            : </a>
<a name="2907"><span class="lineNum">    2907 </span><span class="lineCov">          5 :         for_each_possible_cpu(cpu)</span></a>
<a name="2908"><span class="lineNum">    2908 </span><span class="lineCov">          4 :                 per_cpu(rcu_data.rcu_cpu_has_work, cpu) = 0;</span></a>
<a name="2909"><span class="lineNum">    2909 </span><span class="lineCov">          1 :         if (!IS_ENABLED(CONFIG_RCU_BOOST) &amp;&amp; use_softirq)</span></a>
<a name="2910"><span class="lineNum">    2910 </span>            :                 return 0;</a>
<a name="2911"><span class="lineNum">    2911 </span><span class="lineNoCov">          0 :         WARN_ONCE(smpboot_register_percpu_thread(&amp;rcu_cpu_thread_spec),</span></a>
<a name="2912"><span class="lineNum">    2912 </span>            :                   &quot;%s: Could not start rcuc kthread, OOM is now expected behavior\n&quot;, __func__);</a>
<a name="2913"><span class="lineNum">    2913 </span>            :         return 0;</a>
<a name="2914"><span class="lineNum">    2914 </span>            : }</a>
<a name="2915"><span class="lineNum">    2915 </span>            : early_initcall(rcu_spawn_core_kthreads);</a>
<a name="2916"><span class="lineNum">    2916 </span>            : </a>
<a name="2917"><span class="lineNum">    2917 </span>            : /*</a>
<a name="2918"><span class="lineNum">    2918 </span>            :  * Handle any core-RCU processing required by a call_rcu() invocation.</a>
<a name="2919"><span class="lineNum">    2919 </span>            :  */</a>
<a name="2920"><span class="lineNum">    2920 </span><span class="lineCov">     626982 : static void __call_rcu_core(struct rcu_data *rdp, struct rcu_head *head,</span></a>
<a name="2921"><span class="lineNum">    2921 </span>            :                             unsigned long flags)</a>
<a name="2922"><span class="lineNum">    2922 </span>            : {</a>
<a name="2923"><span class="lineNum">    2923 </span>            :         /*</a>
<a name="2924"><span class="lineNum">    2924 </span>            :          * If called from an extended quiescent state, invoke the RCU</a>
<a name="2925"><span class="lineNum">    2925 </span>            :          * core in order to force a re-evaluation of RCU's idleness.</a>
<a name="2926"><span class="lineNum">    2926 </span>            :          */</a>
<a name="2927"><span class="lineNum">    2927 </span><span class="lineCov">    1254021 :         if (!rcu_is_watching())</span></a>
<a name="2928"><span class="lineNum">    2928 </span><span class="lineNoCov">          0 :                 invoke_rcu_core();</span></a>
<a name="2929"><span class="lineNum">    2929 </span>            : </a>
<a name="2930"><span class="lineNum">    2930 </span>            :         /* If interrupts were disabled or CPU offline, don't invoke RCU core. */</a>
<a name="2931"><span class="lineNum">    2931 </span><span class="lineCov">     627039 :         if (irqs_disabled_flags(flags) || cpu_is_offline(smp_processor_id()))</span></a>
<a name="2932"><span class="lineNum">    2932 </span><span class="lineCov">      20195 :                 return;</span></a>
<a name="2933"><span class="lineNum">    2933 </span>            : </a>
<a name="2934"><span class="lineNum">    2934 </span>            :         /*</a>
<a name="2935"><span class="lineNum">    2935 </span>            :          * Force the grace period if too many callbacks or too long waiting.</a>
<a name="2936"><span class="lineNum">    2936 </span>            :          * Enforce hysteresis, and don't invoke rcu_force_quiescent_state()</a>
<a name="2937"><span class="lineNum">    2937 </span>            :          * if some other CPU has recently done so.  Also, don't bother</a>
<a name="2938"><span class="lineNum">    2938 </span>            :          * invoking rcu_force_quiescent_state() if the newly enqueued callback</a>
<a name="2939"><span class="lineNum">    2939 </span>            :          * is the only one waiting for a grace period to complete.</a>
<a name="2940"><span class="lineNum">    2940 </span>            :          */</a>
<a name="2941"><span class="lineNum">    2941 </span><span class="lineCov">     606743 :         if (unlikely(rcu_segcblist_n_cbs(&amp;rdp-&gt;cblist) &gt;</span></a>
<a name="2942"><span class="lineNum">    2942 </span>            :                      rdp-&gt;qlen_last_fqs_check + qhimark)) {</a>
<a name="2943"><span class="lineNum">    2943 </span>            : </a>
<a name="2944"><span class="lineNum">    2944 </span>            :                 /* Are we ignoring a completed grace period? */</a>
<a name="2945"><span class="lineNum">    2945 </span><span class="lineNoCov">          0 :                 note_gp_changes(rdp);</span></a>
<a name="2946"><span class="lineNum">    2946 </span>            : </a>
<a name="2947"><span class="lineNum">    2947 </span>            :                 /* Start a new grace period if one not already started. */</a>
<a name="2948"><span class="lineNum">    2948 </span><span class="lineNoCov">          0 :                 if (!rcu_gp_in_progress()) {</span></a>
<a name="2949"><span class="lineNum">    2949 </span><span class="lineNoCov">          0 :                         rcu_accelerate_cbs_unlocked(rdp-&gt;mynode, rdp);</span></a>
<a name="2950"><span class="lineNum">    2950 </span>            :                 } else {</a>
<a name="2951"><span class="lineNum">    2951 </span>            :                         /* Give the grace period a kick. */</a>
<a name="2952"><span class="lineNum">    2952 </span><span class="lineNoCov">          0 :                         rdp-&gt;blimit = DEFAULT_MAX_RCU_BLIMIT;</span></a>
<a name="2953"><span class="lineNum">    2953 </span><span class="lineNoCov">          0 :                         if (rcu_state.n_force_qs == rdp-&gt;n_force_qs_snap &amp;&amp;</span></a>
<a name="2954"><span class="lineNum">    2954 </span><span class="lineNoCov">          0 :                             rcu_segcblist_first_pend_cb(&amp;rdp-&gt;cblist) != head)</span></a>
<a name="2955"><span class="lineNum">    2955 </span><span class="lineNoCov">          0 :                                 rcu_force_quiescent_state();</span></a>
<a name="2956"><span class="lineNum">    2956 </span><span class="lineNoCov">          0 :                         rdp-&gt;n_force_qs_snap = rcu_state.n_force_qs;</span></a>
<a name="2957"><span class="lineNum">    2957 </span><span class="lineNoCov">          0 :                         rdp-&gt;qlen_last_fqs_check = rcu_segcblist_n_cbs(&amp;rdp-&gt;cblist);</span></a>
<a name="2958"><span class="lineNum">    2958 </span>            :                 }</a>
<a name="2959"><span class="lineNum">    2959 </span>            :         }</a>
<a name="2960"><span class="lineNum">    2960 </span>            : }</a>
<a name="2961"><span class="lineNum">    2961 </span>            : </a>
<a name="2962"><span class="lineNum">    2962 </span>            : /*</a>
<a name="2963"><span class="lineNum">    2963 </span>            :  * RCU callback function to leak a callback.</a>
<a name="2964"><span class="lineNum">    2964 </span>            :  */</a>
<a name="2965"><span class="lineNum">    2965 </span><span class="lineNoCov">          0 : static void rcu_leak_callback(struct rcu_head *rhp)</span></a>
<a name="2966"><span class="lineNum">    2966 </span>            : {</a>
<a name="2967"><span class="lineNum">    2967 </span><span class="lineNoCov">          0 : }</span></a>
<a name="2968"><span class="lineNum">    2968 </span>            : </a>
<a name="2969"><span class="lineNum">    2969 </span>            : /*</a>
<a name="2970"><span class="lineNum">    2970 </span>            :  * Check and if necessary update the leaf rcu_node structure's</a>
<a name="2971"><span class="lineNum">    2971 </span>            :  * -&gt;cbovldmask bit corresponding to the current CPU based on that CPU's</a>
<a name="2972"><span class="lineNum">    2972 </span>            :  * number of queued RCU callbacks.  The caller must hold the leaf rcu_node</a>
<a name="2973"><span class="lineNum">    2973 </span>            :  * structure's -&gt;lock.</a>
<a name="2974"><span class="lineNum">    2974 </span>            :  */</a>
<a name="2975"><span class="lineNum">    2975 </span><span class="lineNoCov">          0 : static void check_cb_ovld_locked(struct rcu_data *rdp, struct rcu_node *rnp)</span></a>
<a name="2976"><span class="lineNum">    2976 </span>            : {</a>
<a name="2977"><span class="lineNum">    2977 </span><span class="lineNoCov">          0 :         raw_lockdep_assert_held_rcu_node(rnp);</span></a>
<a name="2978"><span class="lineNum">    2978 </span><span class="lineNoCov">          0 :         if (qovld_calc &lt;= 0)</span></a>
<a name="2979"><span class="lineNum">    2979 </span>            :                 return; // Early boot and wildcard value set.</a>
<a name="2980"><span class="lineNum">    2980 </span><span class="lineNoCov">          0 :         if (rcu_segcblist_n_cbs(&amp;rdp-&gt;cblist) &gt;= qovld_calc)</span></a>
<a name="2981"><span class="lineNum">    2981 </span><span class="lineNoCov">          0 :                 WRITE_ONCE(rnp-&gt;cbovldmask, rnp-&gt;cbovldmask | rdp-&gt;grpmask);</span></a>
<a name="2982"><span class="lineNum">    2982 </span>            :         else</a>
<a name="2983"><span class="lineNum">    2983 </span><span class="lineNoCov">          0 :                 WRITE_ONCE(rnp-&gt;cbovldmask, rnp-&gt;cbovldmask &amp; ~rdp-&gt;grpmask);</span></a>
<a name="2984"><span class="lineNum">    2984 </span>            : }</a>
<a name="2985"><span class="lineNum">    2985 </span>            : </a>
<a name="2986"><span class="lineNum">    2986 </span>            : /*</a>
<a name="2987"><span class="lineNum">    2987 </span>            :  * Check and if necessary update the leaf rcu_node structure's</a>
<a name="2988"><span class="lineNum">    2988 </span>            :  * -&gt;cbovldmask bit corresponding to the current CPU based on that CPU's</a>
<a name="2989"><span class="lineNum">    2989 </span>            :  * number of queued RCU callbacks.  No locks need be held, but the</a>
<a name="2990"><span class="lineNum">    2990 </span>            :  * caller must have disabled interrupts.</a>
<a name="2991"><span class="lineNum">    2991 </span>            :  *</a>
<a name="2992"><span class="lineNum">    2992 </span>            :  * Note that this function ignores the possibility that there are a lot</a>
<a name="2993"><span class="lineNum">    2993 </span>            :  * of callbacks all of which have already seen the end of their respective</a>
<a name="2994"><span class="lineNum">    2994 </span>            :  * grace periods.  This omission is due to the need for no-CBs CPUs to</a>
<a name="2995"><span class="lineNum">    2995 </span>            :  * be holding -&gt;nocb_lock to do this check, which is too heavy for a</a>
<a name="2996"><span class="lineNum">    2996 </span>            :  * common-case operation.</a>
<a name="2997"><span class="lineNum">    2997 </span>            :  */</a>
<a name="2998"><span class="lineNum">    2998 </span><span class="lineCov">     627040 : static void check_cb_ovld(struct rcu_data *rdp)</span></a>
<a name="2999"><span class="lineNum">    2999 </span>            : {</a>
<a name="3000"><span class="lineNum">    3000 </span><span class="lineCov">     627040 :         struct rcu_node *const rnp = rdp-&gt;mynode;</span></a>
<a name="3001"><span class="lineNum">    3001 </span>            : </a>
<a name="3002"><span class="lineNum">    3002 </span><span class="lineCov">     627040 :         if (qovld_calc &lt;= 0 ||</span></a>
<a name="3003"><span class="lineNum">    3003 </span><span class="lineCov">     627037 :             ((rcu_segcblist_n_cbs(&amp;rdp-&gt;cblist) &gt;= qovld_calc) ==</span></a>
<a name="3004"><span class="lineNum">    3004 </span><span class="lineCov">     627037 :              !!(READ_ONCE(rnp-&gt;cbovldmask) &amp; rdp-&gt;grpmask)))</span></a>
<a name="3005"><span class="lineNum">    3005 </span>            :                 return; // Early boot wildcard value or already set correctly.</a>
<a name="3006"><span class="lineNum">    3006 </span><span class="lineNoCov">          0 :         raw_spin_lock_rcu_node(rnp);</span></a>
<a name="3007"><span class="lineNum">    3007 </span><span class="lineNoCov">          0 :         check_cb_ovld_locked(rdp, rnp);</span></a>
<a name="3008"><span class="lineNum">    3008 </span><span class="lineNoCov">          0 :         raw_spin_unlock_rcu_node(rnp);</span></a>
<a name="3009"><span class="lineNum">    3009 </span>            : }</a>
<a name="3010"><span class="lineNum">    3010 </span>            : </a>
<a name="3011"><span class="lineNum">    3011 </span>            : /* Helper function for call_rcu() and friends.  */</a>
<a name="3012"><span class="lineNum">    3012 </span>            : static void</a>
<a name="3013"><span class="lineNum">    3013 </span><span class="lineCov">     626984 : __call_rcu(struct rcu_head *head, rcu_callback_t func)</span></a>
<a name="3014"><span class="lineNum">    3014 </span>            : {</a>
<a name="3015"><span class="lineNum">    3015 </span><span class="lineCov">     626984 :         static atomic_t doublefrees;</span></a>
<a name="3016"><span class="lineNum">    3016 </span><span class="lineCov">     626984 :         unsigned long flags;</span></a>
<a name="3017"><span class="lineNum">    3017 </span><span class="lineCov">     626984 :         struct rcu_data *rdp;</span></a>
<a name="3018"><span class="lineNum">    3018 </span><span class="lineCov">     626984 :         bool was_alldone;</span></a>
<a name="3019"><span class="lineNum">    3019 </span>            : </a>
<a name="3020"><span class="lineNum">    3020 </span>            :         /* Misaligned rcu_head! */</a>
<a name="3021"><span class="lineNum">    3021 </span><span class="lineCov">     626984 :         WARN_ON_ONCE((unsigned long)head &amp; (sizeof(void *) - 1));</span></a>
<a name="3022"><span class="lineNum">    3022 </span>            : </a>
<a name="3023"><span class="lineNum">    3023 </span><span class="lineCov">     626984 :         if (debug_rcu_head_queue(head)) {</span></a>
<a name="3024"><span class="lineNum">    3024 </span>            :                 /*</a>
<a name="3025"><span class="lineNum">    3025 </span>            :                  * Probable double call_rcu(), so leak the callback.</a>
<a name="3026"><span class="lineNum">    3026 </span>            :                  * Use rcu:rcu_callback trace event to find the previous</a>
<a name="3027"><span class="lineNum">    3027 </span>            :                  * time callback was passed to __call_rcu().</a>
<a name="3028"><span class="lineNum">    3028 </span>            :                  */</a>
<a name="3029"><span class="lineNum">    3029 </span><span class="lineNoCov">          0 :                 if (atomic_inc_return(&amp;doublefrees) &lt; 4) {</span></a>
<a name="3030"><span class="lineNum">    3030 </span><span class="lineNoCov">          0 :                         pr_err(&quot;%s(): Double-freed CB %p-&gt;%pS()!!!  &quot;, __func__, head, head-&gt;func);</span></a>
<a name="3031"><span class="lineNum">    3031 </span><span class="lineNoCov">          0 :                         mem_dump_obj(head);</span></a>
<a name="3032"><span class="lineNum">    3032 </span>            :                 }</a>
<a name="3033"><span class="lineNum">    3033 </span><span class="lineNoCov">          0 :                 WRITE_ONCE(head-&gt;func, rcu_leak_callback);</span></a>
<a name="3034"><span class="lineNum">    3034 </span><span class="lineNoCov">          0 :                 return;</span></a>
<a name="3035"><span class="lineNum">    3035 </span>            :         }</a>
<a name="3036"><span class="lineNum">    3036 </span><span class="lineCov">     626762 :         head-&gt;func = func;</span></a>
<a name="3037"><span class="lineNum">    3037 </span><span class="lineCov">     626762 :         head-&gt;next = NULL;</span></a>
<a name="3038"><span class="lineNum">    3038 </span><span class="lineCov">    1253561 :         local_irq_save(flags);</span></a>
<a name="3039"><span class="lineNum">    3039 </span><span class="lineCov">     626733 :         kasan_record_aux_stack(head);</span></a>
<a name="3040"><span class="lineNum">    3040 </span><span class="lineCov">     627049 :         rdp = this_cpu_ptr(&amp;rcu_data);</span></a>
<a name="3041"><span class="lineNum">    3041 </span>            : </a>
<a name="3042"><span class="lineNum">    3042 </span>            :         /* Add the callback to our list. */</a>
<a name="3043"><span class="lineNum">    3043 </span><span class="lineCov">     627054 :         if (unlikely(!rcu_segcblist_is_enabled(&amp;rdp-&gt;cblist))) {</span></a>
<a name="3044"><span class="lineNum">    3044 </span>            :                 // This can trigger due to call_rcu() from offline CPU:</a>
<a name="3045"><span class="lineNum">    3045 </span><span class="lineCov">          1 :                 WARN_ON_ONCE(rcu_scheduler_active != RCU_SCHEDULER_INACTIVE);</span></a>
<a name="3046"><span class="lineNum">    3046 </span><span class="lineCov">          2 :                 WARN_ON_ONCE(!rcu_is_watching());</span></a>
<a name="3047"><span class="lineNum">    3047 </span>            :                 // Very early boot, before rcu_init().  Initialize if needed</a>
<a name="3048"><span class="lineNum">    3048 </span>            :                 // and then drop through to queue the callback.</a>
<a name="3049"><span class="lineNum">    3049 </span><span class="lineCov">          1 :                 if (rcu_segcblist_empty(&amp;rdp-&gt;cblist))</span></a>
<a name="3050"><span class="lineNum">    3050 </span><span class="lineCov">          1 :                         rcu_segcblist_init(&amp;rdp-&gt;cblist);</span></a>
<a name="3051"><span class="lineNum">    3051 </span>            :         }</a>
<a name="3052"><span class="lineNum">    3052 </span>            : </a>
<a name="3053"><span class="lineNum">    3053 </span><span class="lineCov">     627054 :         check_cb_ovld(rdp);</span></a>
<a name="3054"><span class="lineNum">    3054 </span><span class="lineCov">     627037 :         if (rcu_nocb_try_bypass(rdp, head, &amp;was_alldone, flags))</span></a>
<a name="3055"><span class="lineNum">    3055 </span>            :                 return; // Enqueued onto -&gt;nocb_bypass, so just leave.</a>
<a name="3056"><span class="lineNum">    3056 </span>            :         // If no-CBs CPU gets here, rcu_nocb_try_bypass() acquired -&gt;nocb_lock.</a>
<a name="3057"><span class="lineNum">    3057 </span><span class="lineCov">     627037 :         rcu_segcblist_enqueue(&amp;rdp-&gt;cblist, head);</span></a>
<a name="3058"><span class="lineNum">    3058 </span><span class="lineCov">     626980 :         if (__is_kvfree_rcu_offset((unsigned long)func))</span></a>
<a name="3059"><span class="lineNum">    3059 </span><span class="lineNoCov">          0 :                 trace_rcu_kvfree_callback(rcu_state.name, head,</span></a>
<a name="3060"><span class="lineNum">    3060 </span>            :                                          (unsigned long)func,</a>
<a name="3061"><span class="lineNum">    3061 </span>            :                                          rcu_segcblist_n_cbs(&amp;rdp-&gt;cblist));</a>
<a name="3062"><span class="lineNum">    3062 </span>            :         else</a>
<a name="3063"><span class="lineNum">    3063 </span><span class="lineCov">     626980 :                 trace_rcu_callback(rcu_state.name, head,</span></a>
<a name="3064"><span class="lineNum">    3064 </span>            :                                    rcu_segcblist_n_cbs(&amp;rdp-&gt;cblist));</a>
<a name="3065"><span class="lineNum">    3065 </span>            : </a>
<a name="3066"><span class="lineNum">    3066 </span><span class="lineCov">     626980 :         trace_rcu_segcb_stats(&amp;rdp-&gt;cblist, TPS(&quot;SegCBQueued&quot;));</span></a>
<a name="3067"><span class="lineNum">    3067 </span>            : </a>
<a name="3068"><span class="lineNum">    3068 </span>            :         /* Go handle any RCU core processing required. */</a>
<a name="3069"><span class="lineNum">    3069 </span><span class="lineCov">     626980 :         if (unlikely(rcu_segcblist_is_offloaded(&amp;rdp-&gt;cblist))) {</span></a>
<a name="3070"><span class="lineNum">    3070 </span><span class="lineCov">     626764 :                 __call_rcu_nocb_wake(rdp, was_alldone, flags); /* unlocks */</span></a>
<a name="3071"><span class="lineNum">    3071 </span>            :         } else {</a>
<a name="3072"><span class="lineNum">    3072 </span><span class="lineCov">     626980 :                 __call_rcu_core(rdp, head, flags);</span></a>
<a name="3073"><span class="lineNum">    3073 </span><span class="lineCov">     626928 :                 local_irq_restore(flags);</span></a>
<a name="3074"><span class="lineNum">    3074 </span>            :         }</a>
<a name="3075"><span class="lineNum">    3075 </span>            : }</a>
<a name="3076"><span class="lineNum">    3076 </span>            : </a>
<a name="3077"><span class="lineNum">    3077 </span>            : /**</a>
<a name="3078"><span class="lineNum">    3078 </span>            :  * call_rcu() - Queue an RCU callback for invocation after a grace period.</a>
<a name="3079"><span class="lineNum">    3079 </span>            :  * @head: structure to be used for queueing the RCU updates.</a>
<a name="3080"><span class="lineNum">    3080 </span>            :  * @func: actual callback function to be invoked after the grace period</a>
<a name="3081"><span class="lineNum">    3081 </span>            :  *</a>
<a name="3082"><span class="lineNum">    3082 </span>            :  * The callback function will be invoked some time after a full grace</a>
<a name="3083"><span class="lineNum">    3083 </span>            :  * period elapses, in other words after all pre-existing RCU read-side</a>
<a name="3084"><span class="lineNum">    3084 </span>            :  * critical sections have completed.  However, the callback function</a>
<a name="3085"><span class="lineNum">    3085 </span>            :  * might well execute concurrently with RCU read-side critical sections</a>
<a name="3086"><span class="lineNum">    3086 </span>            :  * that started after call_rcu() was invoked.  RCU read-side critical</a>
<a name="3087"><span class="lineNum">    3087 </span>            :  * sections are delimited by rcu_read_lock() and rcu_read_unlock(), and</a>
<a name="3088"><span class="lineNum">    3088 </span>            :  * may be nested.  In addition, regions of code across which interrupts,</a>
<a name="3089"><span class="lineNum">    3089 </span>            :  * preemption, or softirqs have been disabled also serve as RCU read-side</a>
<a name="3090"><span class="lineNum">    3090 </span>            :  * critical sections.  This includes hardware interrupt handlers, softirq</a>
<a name="3091"><span class="lineNum">    3091 </span>            :  * handlers, and NMI handlers.</a>
<a name="3092"><span class="lineNum">    3092 </span>            :  *</a>
<a name="3093"><span class="lineNum">    3093 </span>            :  * Note that all CPUs must agree that the grace period extended beyond</a>
<a name="3094"><span class="lineNum">    3094 </span>            :  * all pre-existing RCU read-side critical section.  On systems with more</a>
<a name="3095"><span class="lineNum">    3095 </span>            :  * than one CPU, this means that when &quot;func()&quot; is invoked, each CPU is</a>
<a name="3096"><span class="lineNum">    3096 </span>            :  * guaranteed to have executed a full memory barrier since the end of its</a>
<a name="3097"><span class="lineNum">    3097 </span>            :  * last RCU read-side critical section whose beginning preceded the call</a>
<a name="3098"><span class="lineNum">    3098 </span>            :  * to call_rcu().  It also means that each CPU executing an RCU read-side</a>
<a name="3099"><span class="lineNum">    3099 </span>            :  * critical section that continues beyond the start of &quot;func()&quot; must have</a>
<a name="3100"><span class="lineNum">    3100 </span>            :  * executed a memory barrier after the call_rcu() but before the beginning</a>
<a name="3101"><span class="lineNum">    3101 </span>            :  * of that RCU read-side critical section.  Note that these guarantees</a>
<a name="3102"><span class="lineNum">    3102 </span>            :  * include CPUs that are offline, idle, or executing in user mode, as</a>
<a name="3103"><span class="lineNum">    3103 </span>            :  * well as CPUs that are executing in the kernel.</a>
<a name="3104"><span class="lineNum">    3104 </span>            :  *</a>
<a name="3105"><span class="lineNum">    3105 </span>            :  * Furthermore, if CPU A invoked call_rcu() and CPU B invoked the</a>
<a name="3106"><span class="lineNum">    3106 </span>            :  * resulting RCU callback function &quot;func()&quot;, then both CPU A and CPU B are</a>
<a name="3107"><span class="lineNum">    3107 </span>            :  * guaranteed to execute a full memory barrier during the time interval</a>
<a name="3108"><span class="lineNum">    3108 </span>            :  * between the call to call_rcu() and the invocation of &quot;func()&quot; -- even</a>
<a name="3109"><span class="lineNum">    3109 </span>            :  * if CPU A and CPU B are the same CPU (but again only if the system has</a>
<a name="3110"><span class="lineNum">    3110 </span>            :  * more than one CPU).</a>
<a name="3111"><span class="lineNum">    3111 </span>            :  */</a>
<a name="3112"><span class="lineNum">    3112 </span><span class="lineCov">     626984 : void call_rcu(struct rcu_head *head, rcu_callback_t func)</span></a>
<a name="3113"><span class="lineNum">    3113 </span>            : {</a>
<a name="3114"><span class="lineNum">    3114 </span><span class="lineCov">     626984 :         __call_rcu(head, func);</span></a>
<a name="3115"><span class="lineNum">    3115 </span><span class="lineCov">     626752 : }</span></a>
<a name="3116"><span class="lineNum">    3116 </span>            : EXPORT_SYMBOL_GPL(call_rcu);</a>
<a name="3117"><span class="lineNum">    3117 </span>            : </a>
<a name="3118"><span class="lineNum">    3118 </span>            : </a>
<a name="3119"><span class="lineNum">    3119 </span>            : /* Maximum number of jiffies to wait before draining a batch. */</a>
<a name="3120"><span class="lineNum">    3120 </span>            : #define KFREE_DRAIN_JIFFIES (HZ / 50)</a>
<a name="3121"><span class="lineNum">    3121 </span>            : #define KFREE_N_BATCHES 2</a>
<a name="3122"><span class="lineNum">    3122 </span>            : #define FREE_N_CHANNELS 2</a>
<a name="3123"><span class="lineNum">    3123 </span>            : </a>
<a name="3124"><span class="lineNum">    3124 </span>            : /**</a>
<a name="3125"><span class="lineNum">    3125 </span>            :  * struct kvfree_rcu_bulk_data - single block to store kvfree_rcu() pointers</a>
<a name="3126"><span class="lineNum">    3126 </span>            :  * @nr_records: Number of active pointers in the array</a>
<a name="3127"><span class="lineNum">    3127 </span>            :  * @next: Next bulk object in the block chain</a>
<a name="3128"><span class="lineNum">    3128 </span>            :  * @records: Array of the kvfree_rcu() pointers</a>
<a name="3129"><span class="lineNum">    3129 </span>            :  */</a>
<a name="3130"><span class="lineNum">    3130 </span>            : struct kvfree_rcu_bulk_data {</a>
<a name="3131"><span class="lineNum">    3131 </span>            :         unsigned long nr_records;</a>
<a name="3132"><span class="lineNum">    3132 </span>            :         struct kvfree_rcu_bulk_data *next;</a>
<a name="3133"><span class="lineNum">    3133 </span>            :         void *records[];</a>
<a name="3134"><span class="lineNum">    3134 </span>            : };</a>
<a name="3135"><span class="lineNum">    3135 </span>            : </a>
<a name="3136"><span class="lineNum">    3136 </span>            : /*</a>
<a name="3137"><span class="lineNum">    3137 </span>            :  * This macro defines how many entries the &quot;records&quot; array</a>
<a name="3138"><span class="lineNum">    3138 </span>            :  * will contain. It is based on the fact that the size of</a>
<a name="3139"><span class="lineNum">    3139 </span>            :  * kvfree_rcu_bulk_data structure becomes exactly one page.</a>
<a name="3140"><span class="lineNum">    3140 </span>            :  */</a>
<a name="3141"><span class="lineNum">    3141 </span>            : #define KVFREE_BULK_MAX_ENTR \</a>
<a name="3142"><span class="lineNum">    3142 </span>            :         ((PAGE_SIZE - sizeof(struct kvfree_rcu_bulk_data)) / sizeof(void *))</a>
<a name="3143"><span class="lineNum">    3143 </span>            : </a>
<a name="3144"><span class="lineNum">    3144 </span>            : /**</a>
<a name="3145"><span class="lineNum">    3145 </span>            :  * struct kfree_rcu_cpu_work - single batch of kfree_rcu() requests</a>
<a name="3146"><span class="lineNum">    3146 </span>            :  * @rcu_work: Let queue_rcu_work() invoke workqueue handler after grace period</a>
<a name="3147"><span class="lineNum">    3147 </span>            :  * @head_free: List of kfree_rcu() objects waiting for a grace period</a>
<a name="3148"><span class="lineNum">    3148 </span>            :  * @bkvhead_free: Bulk-List of kvfree_rcu() objects waiting for a grace period</a>
<a name="3149"><span class="lineNum">    3149 </span>            :  * @krcp: Pointer to @kfree_rcu_cpu structure</a>
<a name="3150"><span class="lineNum">    3150 </span>            :  */</a>
<a name="3151"><span class="lineNum">    3151 </span>            : </a>
<a name="3152"><span class="lineNum">    3152 </span>            : struct kfree_rcu_cpu_work {</a>
<a name="3153"><span class="lineNum">    3153 </span>            :         struct rcu_work rcu_work;</a>
<a name="3154"><span class="lineNum">    3154 </span>            :         struct rcu_head *head_free;</a>
<a name="3155"><span class="lineNum">    3155 </span>            :         struct kvfree_rcu_bulk_data *bkvhead_free[FREE_N_CHANNELS];</a>
<a name="3156"><span class="lineNum">    3156 </span>            :         struct kfree_rcu_cpu *krcp;</a>
<a name="3157"><span class="lineNum">    3157 </span>            : };</a>
<a name="3158"><span class="lineNum">    3158 </span>            : </a>
<a name="3159"><span class="lineNum">    3159 </span>            : /**</a>
<a name="3160"><span class="lineNum">    3160 </span>            :  * struct kfree_rcu_cpu - batch up kfree_rcu() requests for RCU grace period</a>
<a name="3161"><span class="lineNum">    3161 </span>            :  * @head: List of kfree_rcu() objects not yet waiting for a grace period</a>
<a name="3162"><span class="lineNum">    3162 </span>            :  * @bkvhead: Bulk-List of kvfree_rcu() objects not yet waiting for a grace period</a>
<a name="3163"><span class="lineNum">    3163 </span>            :  * @krw_arr: Array of batches of kfree_rcu() objects waiting for a grace period</a>
<a name="3164"><span class="lineNum">    3164 </span>            :  * @lock: Synchronize access to this structure</a>
<a name="3165"><span class="lineNum">    3165 </span>            :  * @monitor_work: Promote @head to @head_free after KFREE_DRAIN_JIFFIES</a>
<a name="3166"><span class="lineNum">    3166 </span>            :  * @monitor_todo: Tracks whether a @monitor_work delayed work is pending</a>
<a name="3167"><span class="lineNum">    3167 </span>            :  * @initialized: The @rcu_work fields have been initialized</a>
<a name="3168"><span class="lineNum">    3168 </span>            :  * @count: Number of objects for which GP not started</a>
<a name="3169"><span class="lineNum">    3169 </span>            :  * @bkvcache:</a>
<a name="3170"><span class="lineNum">    3170 </span>            :  *      A simple cache list that contains objects for reuse purpose.</a>
<a name="3171"><span class="lineNum">    3171 </span>            :  *      In order to save some per-cpu space the list is singular.</a>
<a name="3172"><span class="lineNum">    3172 </span>            :  *      Even though it is lockless an access has to be protected by the</a>
<a name="3173"><span class="lineNum">    3173 </span>            :  *      per-cpu lock.</a>
<a name="3174"><span class="lineNum">    3174 </span>            :  * @page_cache_work: A work to refill the cache when it is empty</a>
<a name="3175"><span class="lineNum">    3175 </span>            :  * @work_in_progress: Indicates that page_cache_work is running</a>
<a name="3176"><span class="lineNum">    3176 </span>            :  * @hrtimer: A hrtimer for scheduling a page_cache_work</a>
<a name="3177"><span class="lineNum">    3177 </span>            :  * @nr_bkv_objs: number of allocated objects at @bkvcache.</a>
<a name="3178"><span class="lineNum">    3178 </span>            :  *</a>
<a name="3179"><span class="lineNum">    3179 </span>            :  * This is a per-CPU structure.  The reason that it is not included in</a>
<a name="3180"><span class="lineNum">    3180 </span>            :  * the rcu_data structure is to permit this code to be extracted from</a>
<a name="3181"><span class="lineNum">    3181 </span>            :  * the RCU files.  Such extraction could allow further optimization of</a>
<a name="3182"><span class="lineNum">    3182 </span>            :  * the interactions with the slab allocators.</a>
<a name="3183"><span class="lineNum">    3183 </span>            :  */</a>
<a name="3184"><span class="lineNum">    3184 </span>            : struct kfree_rcu_cpu {</a>
<a name="3185"><span class="lineNum">    3185 </span>            :         struct rcu_head *head;</a>
<a name="3186"><span class="lineNum">    3186 </span>            :         struct kvfree_rcu_bulk_data *bkvhead[FREE_N_CHANNELS];</a>
<a name="3187"><span class="lineNum">    3187 </span>            :         struct kfree_rcu_cpu_work krw_arr[KFREE_N_BATCHES];</a>
<a name="3188"><span class="lineNum">    3188 </span>            :         raw_spinlock_t lock;</a>
<a name="3189"><span class="lineNum">    3189 </span>            :         struct delayed_work monitor_work;</a>
<a name="3190"><span class="lineNum">    3190 </span>            :         bool monitor_todo;</a>
<a name="3191"><span class="lineNum">    3191 </span>            :         bool initialized;</a>
<a name="3192"><span class="lineNum">    3192 </span>            :         int count;</a>
<a name="3193"><span class="lineNum">    3193 </span>            : </a>
<a name="3194"><span class="lineNum">    3194 </span>            :         struct work_struct page_cache_work;</a>
<a name="3195"><span class="lineNum">    3195 </span>            :         atomic_t work_in_progress;</a>
<a name="3196"><span class="lineNum">    3196 </span>            :         struct hrtimer hrtimer;</a>
<a name="3197"><span class="lineNum">    3197 </span>            : </a>
<a name="3198"><span class="lineNum">    3198 </span>            :         struct llist_head bkvcache;</a>
<a name="3199"><span class="lineNum">    3199 </span>            :         int nr_bkv_objs;</a>
<a name="3200"><span class="lineNum">    3200 </span>            : };</a>
<a name="3201"><span class="lineNum">    3201 </span>            : </a>
<a name="3202"><span class="lineNum">    3202 </span>            : static DEFINE_PER_CPU(struct kfree_rcu_cpu, krc) = {</a>
<a name="3203"><span class="lineNum">    3203 </span>            :         .lock = __RAW_SPIN_LOCK_UNLOCKED(krc.lock),</a>
<a name="3204"><span class="lineNum">    3204 </span>            : };</a>
<a name="3205"><span class="lineNum">    3205 </span>            : </a>
<a name="3206"><span class="lineNum">    3206 </span>            : static __always_inline void</a>
<a name="3207"><span class="lineNum">    3207 </span><span class="lineCov">        141 : debug_rcu_bhead_unqueue(struct kvfree_rcu_bulk_data *bhead)</span></a>
<a name="3208"><span class="lineNum">    3208 </span>            : {</a>
<a name="3209"><span class="lineNum">    3209 </span>            : #ifdef CONFIG_DEBUG_OBJECTS_RCU_HEAD</a>
<a name="3210"><span class="lineNum">    3210 </span><span class="lineCov">        141 :         int i;</span></a>
<a name="3211"><span class="lineNum">    3211 </span>            : </a>
<a name="3212"><span class="lineNum">    3212 </span><span class="lineCov">        394 :         for (i = 0; i &lt; bhead-&gt;nr_records; i++)</span></a>
<a name="3213"><span class="lineNum">    3213 </span><span class="lineCov">        253 :                 debug_rcu_head_unqueue((struct rcu_head *)(bhead-&gt;records[i]));</span></a>
<a name="3214"><span class="lineNum">    3214 </span>            : #endif</a>
<a name="3215"><span class="lineNum">    3215 </span>            : }</a>
<a name="3216"><span class="lineNum">    3216 </span>            : </a>
<a name="3217"><span class="lineNum">    3217 </span>            : static inline struct kfree_rcu_cpu *</a>
<a name="3218"><span class="lineNum">    3218 </span><span class="lineCov">        257 : krc_this_cpu_lock(unsigned long *flags)</span></a>
<a name="3219"><span class="lineNum">    3219 </span>            : {</a>
<a name="3220"><span class="lineNum">    3220 </span><span class="lineCov">        257 :         struct kfree_rcu_cpu *krcp;</span></a>
<a name="3221"><span class="lineNum">    3221 </span>            : </a>
<a name="3222"><span class="lineNum">    3222 </span><span class="lineCov">        514 :         local_irq_save(*flags); // For safely calling this_cpu_ptr().</span></a>
<a name="3223"><span class="lineNum">    3223 </span><span class="lineCov">        257 :         krcp = this_cpu_ptr(&amp;krc);</span></a>
<a name="3224"><span class="lineNum">    3224 </span><span class="lineCov">        257 :         raw_spin_lock(&amp;krcp-&gt;lock);</span></a>
<a name="3225"><span class="lineNum">    3225 </span>            : </a>
<a name="3226"><span class="lineNum">    3226 </span><span class="lineCov">        257 :         return krcp;</span></a>
<a name="3227"><span class="lineNum">    3227 </span>            : }</a>
<a name="3228"><span class="lineNum">    3228 </span>            : </a>
<a name="3229"><span class="lineNum">    3229 </span>            : static inline void</a>
<a name="3230"><span class="lineNum">    3230 </span><span class="lineCov">        257 : krc_this_cpu_unlock(struct kfree_rcu_cpu *krcp, unsigned long flags)</span></a>
<a name="3231"><span class="lineNum">    3231 </span>            : {</a>
<a name="3232"><span class="lineNum">    3232 </span><span class="lineCov">        257 :         raw_spin_unlock(&amp;krcp-&gt;lock);</span></a>
<a name="3233"><span class="lineNum">    3233 </span><span class="lineCov">        257 :         local_irq_restore(flags);</span></a>
<a name="3234"><span class="lineNum">    3234 </span><span class="lineCov">        257 : }</span></a>
<a name="3235"><span class="lineNum">    3235 </span>            : </a>
<a name="3236"><span class="lineNum">    3236 </span>            : static inline struct kvfree_rcu_bulk_data *</a>
<a name="3237"><span class="lineNum">    3237 </span><span class="lineCov">        145 : get_cached_bnode(struct kfree_rcu_cpu *krcp)</span></a>
<a name="3238"><span class="lineNum">    3238 </span>            : {</a>
<a name="3239"><span class="lineNum">    3239 </span><span class="lineCov">        145 :         if (!krcp-&gt;nr_bkv_objs)</span></a>
<a name="3240"><span class="lineNum">    3240 </span>            :                 return NULL;</a>
<a name="3241"><span class="lineNum">    3241 </span>            : </a>
<a name="3242"><span class="lineNum">    3242 </span><span class="lineCov">        141 :         krcp-&gt;nr_bkv_objs--;</span></a>
<a name="3243"><span class="lineNum">    3243 </span><span class="lineCov">        141 :         return (struct kvfree_rcu_bulk_data *)</span></a>
<a name="3244"><span class="lineNum">    3244 </span><span class="lineCov">        141 :                 llist_del_first(&amp;krcp-&gt;bkvcache);</span></a>
<a name="3245"><span class="lineNum">    3245 </span>            : }</a>
<a name="3246"><span class="lineNum">    3246 </span>            : </a>
<a name="3247"><span class="lineNum">    3247 </span>            : static inline bool</a>
<a name="3248"><span class="lineNum">    3248 </span><span class="lineCov">        161 : put_cached_bnode(struct kfree_rcu_cpu *krcp,</span></a>
<a name="3249"><span class="lineNum">    3249 </span>            :         struct kvfree_rcu_bulk_data *bnode)</a>
<a name="3250"><span class="lineNum">    3250 </span>            : {</a>
<a name="3251"><span class="lineNum">    3251 </span>            :         // Check the limit.</a>
<a name="3252"><span class="lineNum">    3252 </span><span class="lineCov">        161 :         if (krcp-&gt;nr_bkv_objs &gt;= rcu_min_cached_objs)</span></a>
<a name="3253"><span class="lineNum">    3253 </span>            :                 return false;</a>
<a name="3254"><span class="lineNum">    3254 </span>            : </a>
<a name="3255"><span class="lineNum">    3255 </span><span class="lineCov">        161 :         llist_add((struct llist_node *) bnode, &amp;krcp-&gt;bkvcache);</span></a>
<a name="3256"><span class="lineNum">    3256 </span><span class="lineCov">        161 :         krcp-&gt;nr_bkv_objs++;</span></a>
<a name="3257"><span class="lineNum">    3257 </span><span class="lineCov">        161 :         return true;</span></a>
<a name="3258"><span class="lineNum">    3258 </span>            : </a>
<a name="3259"><span class="lineNum">    3259 </span>            : }</a>
<a name="3260"><span class="lineNum">    3260 </span>            : </a>
<a name="3261"><span class="lineNum">    3261 </span>            : /*</a>
<a name="3262"><span class="lineNum">    3262 </span>            :  * This function is invoked in workqueue context after a grace period.</a>
<a name="3263"><span class="lineNum">    3263 </span>            :  * It frees all the objects queued on -&gt;bhead_free or -&gt;head_free.</a>
<a name="3264"><span class="lineNum">    3264 </span>            :  */</a>
<a name="3265"><span class="lineNum">    3265 </span><span class="lineCov">        145 : static void kfree_rcu_work(struct work_struct *work)</span></a>
<a name="3266"><span class="lineNum">    3266 </span>            : {</a>
<a name="3267"><span class="lineNum">    3267 </span><span class="lineCov">        145 :         unsigned long flags;</span></a>
<a name="3268"><span class="lineNum">    3268 </span><span class="lineCov">        145 :         struct kvfree_rcu_bulk_data *bkvhead[FREE_N_CHANNELS], *bnext;</span></a>
<a name="3269"><span class="lineNum">    3269 </span><span class="lineCov">        145 :         struct rcu_head *head, *next;</span></a>
<a name="3270"><span class="lineNum">    3270 </span><span class="lineCov">        145 :         struct kfree_rcu_cpu *krcp;</span></a>
<a name="3271"><span class="lineNum">    3271 </span><span class="lineCov">        145 :         struct kfree_rcu_cpu_work *krwp;</span></a>
<a name="3272"><span class="lineNum">    3272 </span><span class="lineCov">        145 :         int i, j;</span></a>
<a name="3273"><span class="lineNum">    3273 </span>            : </a>
<a name="3274"><span class="lineNum">    3274 </span><span class="lineCov">        145 :         krwp = container_of(to_rcu_work(work),</span></a>
<a name="3275"><span class="lineNum">    3275 </span>            :                             struct kfree_rcu_cpu_work, rcu_work);</a>
<a name="3276"><span class="lineNum">    3276 </span><span class="lineCov">        145 :         krcp = krwp-&gt;krcp;</span></a>
<a name="3277"><span class="lineNum">    3277 </span>            : </a>
<a name="3278"><span class="lineNum">    3278 </span><span class="lineCov">        145 :         raw_spin_lock_irqsave(&amp;krcp-&gt;lock, flags);</span></a>
<a name="3279"><span class="lineNum">    3279 </span>            :         // Channels 1 and 2.</a>
<a name="3280"><span class="lineNum">    3280 </span><span class="lineCov">        580 :         for (i = 0; i &lt; FREE_N_CHANNELS; i++) {</span></a>
<a name="3281"><span class="lineNum">    3281 </span><span class="lineCov">        290 :                 bkvhead[i] = krwp-&gt;bkvhead_free[i];</span></a>
<a name="3282"><span class="lineNum">    3282 </span><span class="lineCov">        290 :                 krwp-&gt;bkvhead_free[i] = NULL;</span></a>
<a name="3283"><span class="lineNum">    3283 </span>            :         }</a>
<a name="3284"><span class="lineNum">    3284 </span>            : </a>
<a name="3285"><span class="lineNum">    3285 </span>            :         // Channel 3.</a>
<a name="3286"><span class="lineNum">    3286 </span><span class="lineCov">        145 :         head = krwp-&gt;head_free;</span></a>
<a name="3287"><span class="lineNum">    3287 </span><span class="lineCov">        145 :         krwp-&gt;head_free = NULL;</span></a>
<a name="3288"><span class="lineNum">    3288 </span><span class="lineCov">        145 :         raw_spin_unlock_irqrestore(&amp;krcp-&gt;lock, flags);</span></a>
<a name="3289"><span class="lineNum">    3289 </span>            : </a>
<a name="3290"><span class="lineNum">    3290 </span>            :         // Handle two first channels.</a>
<a name="3291"><span class="lineNum">    3291 </span><span class="lineCov">        580 :         for (i = 0; i &lt; FREE_N_CHANNELS; i++) {</span></a>
<a name="3292"><span class="lineNum">    3292 </span><span class="lineCov">        431 :                 for (; bkvhead[i]; bkvhead[i] = bnext) {</span></a>
<a name="3293"><span class="lineNum">    3293 </span><span class="lineCov">        141 :                         bnext = bkvhead[i]-&gt;next;</span></a>
<a name="3294"><span class="lineNum">    3294 </span><span class="lineCov">        141 :                         debug_rcu_bhead_unqueue(bkvhead[i]);</span></a>
<a name="3295"><span class="lineNum">    3295 </span>            : </a>
<a name="3296"><span class="lineNum">    3296 </span><span class="lineCov">        141 :                         rcu_lock_acquire(&amp;rcu_callback_map);</span></a>
<a name="3297"><span class="lineNum">    3297 </span><span class="lineCov">        141 :                         if (i == 0) { // kmalloc() / kfree().</span></a>
<a name="3298"><span class="lineNum">    3298 </span><span class="lineCov">        141 :                                 trace_rcu_invoke_kfree_bulk_callback(</span></a>
<a name="3299"><span class="lineNum">    3299 </span>            :                                         rcu_state.name, bkvhead[i]-&gt;nr_records,</a>
<a name="3300"><span class="lineNum">    3300 </span><span class="lineCov">        141 :                                         bkvhead[i]-&gt;records);</span></a>
<a name="3301"><span class="lineNum">    3301 </span>            : </a>
<a name="3302"><span class="lineNum">    3302 </span><span class="lineCov">        141 :                                 kfree_bulk(bkvhead[i]-&gt;nr_records,</span></a>
<a name="3303"><span class="lineNum">    3303 </span>            :                                         bkvhead[i]-&gt;records);</a>
<a name="3304"><span class="lineNum">    3304 </span>            :                         } else { // vmalloc() / vfree().</a>
<a name="3305"><span class="lineNum">    3305 </span><span class="lineNoCov">          0 :                                 for (j = 0; j &lt; bkvhead[i]-&gt;nr_records; j++) {</span></a>
<a name="3306"><span class="lineNum">    3306 </span><span class="lineNoCov">          0 :                                         trace_rcu_invoke_kvfree_callback(</span></a>
<a name="3307"><span class="lineNum">    3307 </span>            :                                                 rcu_state.name,</a>
<a name="3308"><span class="lineNum">    3308 </span><span class="lineNoCov">          0 :                                                 bkvhead[i]-&gt;records[j], 0);</span></a>
<a name="3309"><span class="lineNum">    3309 </span>            : </a>
<a name="3310"><span class="lineNum">    3310 </span><span class="lineNoCov">          0 :                                         vfree(bkvhead[i]-&gt;records[j]);</span></a>
<a name="3311"><span class="lineNum">    3311 </span>            :                                 }</a>
<a name="3312"><span class="lineNum">    3312 </span>            :                         }</a>
<a name="3313"><span class="lineNum">    3313 </span><span class="lineCov">        141 :                         rcu_lock_release(&amp;rcu_callback_map);</span></a>
<a name="3314"><span class="lineNum">    3314 </span>            : </a>
<a name="3315"><span class="lineNum">    3315 </span><span class="lineCov">        141 :                         raw_spin_lock_irqsave(&amp;krcp-&gt;lock, flags);</span></a>
<a name="3316"><span class="lineNum">    3316 </span><span class="lineCov">        141 :                         if (put_cached_bnode(krcp, bkvhead[i]))</span></a>
<a name="3317"><span class="lineNum">    3317 </span><span class="lineCov">        141 :                                 bkvhead[i] = NULL;</span></a>
<a name="3318"><span class="lineNum">    3318 </span><span class="lineCov">        141 :                         raw_spin_unlock_irqrestore(&amp;krcp-&gt;lock, flags);</span></a>
<a name="3319"><span class="lineNum">    3319 </span>            : </a>
<a name="3320"><span class="lineNum">    3320 </span><span class="lineCov">        141 :                         if (bkvhead[i])</span></a>
<a name="3321"><span class="lineNum">    3321 </span><span class="lineNoCov">          0 :                                 free_page((unsigned long) bkvhead[i]);</span></a>
<a name="3322"><span class="lineNum">    3322 </span>            : </a>
<a name="3323"><span class="lineNum">    3323 </span><span class="lineCov">        141 :                         cond_resched_tasks_rcu_qs();</span></a>
<a name="3324"><span class="lineNum">    3324 </span>            :                 }</a>
<a name="3325"><span class="lineNum">    3325 </span>            :         }</a>
<a name="3326"><span class="lineNum">    3326 </span>            : </a>
<a name="3327"><span class="lineNum">    3327 </span>            :         /*</a>
<a name="3328"><span class="lineNum">    3328 </span>            :          * Emergency case only. It can happen under low memory</a>
<a name="3329"><span class="lineNum">    3329 </span>            :          * condition when an allocation gets failed, so the &quot;bulk&quot;</a>
<a name="3330"><span class="lineNum">    3330 </span>            :          * path can not be temporary maintained.</a>
<a name="3331"><span class="lineNum">    3331 </span>            :          */</a>
<a name="3332"><span class="lineNum">    3332 </span><span class="lineCov">        149 :         for (; head; head = next) {</span></a>
<a name="3333"><span class="lineNum">    3333 </span><span class="lineCov">          4 :                 unsigned long offset = (unsigned long)head-&gt;func;</span></a>
<a name="3334"><span class="lineNum">    3334 </span><span class="lineCov">          4 :                 void *ptr = (void *)head - offset;</span></a>
<a name="3335"><span class="lineNum">    3335 </span>            : </a>
<a name="3336"><span class="lineNum">    3336 </span><span class="lineCov">          4 :                 next = head-&gt;next;</span></a>
<a name="3337"><span class="lineNum">    3337 </span><span class="lineCov">          4 :                 debug_rcu_head_unqueue((struct rcu_head *)ptr);</span></a>
<a name="3338"><span class="lineNum">    3338 </span><span class="lineCov">          4 :                 rcu_lock_acquire(&amp;rcu_callback_map);</span></a>
<a name="3339"><span class="lineNum">    3339 </span><span class="lineCov">          4 :                 trace_rcu_invoke_kvfree_callback(rcu_state.name, head, offset);</span></a>
<a name="3340"><span class="lineNum">    3340 </span>            : </a>
<a name="3341"><span class="lineNum">    3341 </span><span class="lineCov">          4 :                 if (!WARN_ON_ONCE(!__is_kvfree_rcu_offset(offset)))</span></a>
<a name="3342"><span class="lineNum">    3342 </span><span class="lineCov">          4 :                         kvfree(ptr);</span></a>
<a name="3343"><span class="lineNum">    3343 </span>            : </a>
<a name="3344"><span class="lineNum">    3344 </span><span class="lineCov">          4 :                 rcu_lock_release(&amp;rcu_callback_map);</span></a>
<a name="3345"><span class="lineNum">    3345 </span><span class="lineCov">          4 :                 cond_resched_tasks_rcu_qs();</span></a>
<a name="3346"><span class="lineNum">    3346 </span>            :         }</a>
<a name="3347"><span class="lineNum">    3347 </span><span class="lineCov">        145 : }</span></a>
<a name="3348"><span class="lineNum">    3348 </span>            : </a>
<a name="3349"><span class="lineNum">    3349 </span>            : /*</a>
<a name="3350"><span class="lineNum">    3350 </span>            :  * Schedule the kfree batch RCU work to run in workqueue context after a GP.</a>
<a name="3351"><span class="lineNum">    3351 </span>            :  *</a>
<a name="3352"><span class="lineNum">    3352 </span>            :  * This function is invoked by kfree_rcu_monitor() when the KFREE_DRAIN_JIFFIES</a>
<a name="3353"><span class="lineNum">    3353 </span>            :  * timeout has been reached.</a>
<a name="3354"><span class="lineNum">    3354 </span>            :  */</a>
<a name="3355"><span class="lineNum">    3355 </span><span class="lineCov">        172 : static inline bool queue_kfree_rcu_work(struct kfree_rcu_cpu *krcp)</span></a>
<a name="3356"><span class="lineNum">    3356 </span>            : {</a>
<a name="3357"><span class="lineNum">    3357 </span><span class="lineCov">        172 :         struct kfree_rcu_cpu_work *krwp;</span></a>
<a name="3358"><span class="lineNum">    3358 </span><span class="lineCov">        172 :         bool repeat = false;</span></a>
<a name="3359"><span class="lineNum">    3359 </span><span class="lineCov">        172 :         int i, j;</span></a>
<a name="3360"><span class="lineNum">    3360 </span>            : </a>
<a name="3361"><span class="lineNum">    3361 </span><span class="lineCov">        344 :         lockdep_assert_held(&amp;krcp-&gt;lock);</span></a>
<a name="3362"><span class="lineNum">    3362 </span>            : </a>
<a name="3363"><span class="lineNum">    3363 </span><span class="lineCov">        516 :         for (i = 0; i &lt; KFREE_N_BATCHES; i++) {</span></a>
<a name="3364"><span class="lineNum">    3364 </span><span class="lineCov">        344 :                 krwp = &amp;(krcp-&gt;krw_arr[i]);</span></a>
<a name="3365"><span class="lineNum">    3365 </span>            : </a>
<a name="3366"><span class="lineNum">    3366 </span>            :                 /*</a>
<a name="3367"><span class="lineNum">    3367 </span>            :                  * Try to detach bkvhead or head and attach it over any</a>
<a name="3368"><span class="lineNum">    3368 </span>            :                  * available corresponding free channel. It can be that</a>
<a name="3369"><span class="lineNum">    3369 </span>            :                  * a previous RCU batch is in progress, it means that</a>
<a name="3370"><span class="lineNum">    3370 </span>            :                  * immediately to queue another one is not possible so</a>
<a name="3371"><span class="lineNum">    3371 </span>            :                  * return false to tell caller to retry.</a>
<a name="3372"><span class="lineNum">    3372 </span>            :                  */</a>
<a name="3373"><span class="lineNum">    3373 </span><span class="lineCov">        344 :                 if ((krcp-&gt;bkvhead[0] &amp;&amp; !krwp-&gt;bkvhead_free[0]) ||</span></a>
<a name="3374"><span class="lineNum">    3374 </span><span class="lineCov">        203 :                         (krcp-&gt;bkvhead[1] &amp;&amp; !krwp-&gt;bkvhead_free[1]) ||</span></a>
<a name="3375"><span class="lineNum">    3375 </span><span class="lineCov">        203 :                                 (krcp-&gt;head &amp;&amp; !krwp-&gt;head_free)) {</span></a>
<a name="3376"><span class="lineNum">    3376 </span>            :                         // Channel 1 corresponds to SLAB ptrs.</a>
<a name="3377"><span class="lineNum">    3377 </span>            :                         // Channel 2 corresponds to vmalloc ptrs.</a>
<a name="3378"><span class="lineNum">    3378 </span><span class="lineCov">        435 :                         for (j = 0; j &lt; FREE_N_CHANNELS; j++) {</span></a>
<a name="3379"><span class="lineNum">    3379 </span><span class="lineCov">        290 :                                 if (!krwp-&gt;bkvhead_free[j]) {</span></a>
<a name="3380"><span class="lineNum">    3380 </span><span class="lineCov">        290 :                                         krwp-&gt;bkvhead_free[j] = krcp-&gt;bkvhead[j];</span></a>
<a name="3381"><span class="lineNum">    3381 </span><span class="lineCov">        290 :                                         krcp-&gt;bkvhead[j] = NULL;</span></a>
<a name="3382"><span class="lineNum">    3382 </span>            :                                 }</a>
<a name="3383"><span class="lineNum">    3383 </span>            :                         }</a>
<a name="3384"><span class="lineNum">    3384 </span>            : </a>
<a name="3385"><span class="lineNum">    3385 </span>            :                         // Channel 3 corresponds to emergency path.</a>
<a name="3386"><span class="lineNum">    3386 </span><span class="lineCov">        145 :                         if (!krwp-&gt;head_free) {</span></a>
<a name="3387"><span class="lineNum">    3387 </span><span class="lineCov">        145 :                                 krwp-&gt;head_free = krcp-&gt;head;</span></a>
<a name="3388"><span class="lineNum">    3388 </span><span class="lineCov">        145 :                                 krcp-&gt;head = NULL;</span></a>
<a name="3389"><span class="lineNum">    3389 </span>            :                         }</a>
<a name="3390"><span class="lineNum">    3390 </span>            : </a>
<a name="3391"><span class="lineNum">    3391 </span><span class="lineCov">        145 :                         WRITE_ONCE(krcp-&gt;count, 0);</span></a>
<a name="3392"><span class="lineNum">    3392 </span>            : </a>
<a name="3393"><span class="lineNum">    3393 </span>            :                         /*</a>
<a name="3394"><span class="lineNum">    3394 </span>            :                          * One work is per one batch, so there are three</a>
<a name="3395"><span class="lineNum">    3395 </span>            :                          * &quot;free channels&quot;, the batch can handle. It can</a>
<a name="3396"><span class="lineNum">    3396 </span>            :                          * be that the work is in the pending state when</a>
<a name="3397"><span class="lineNum">    3397 </span>            :                          * channels have been detached following by each</a>
<a name="3398"><span class="lineNum">    3398 </span>            :                          * other.</a>
<a name="3399"><span class="lineNum">    3399 </span>            :                          */</a>
<a name="3400"><span class="lineNum">    3400 </span><span class="lineCov">        145 :                         queue_rcu_work(system_wq, &amp;krwp-&gt;rcu_work);</span></a>
<a name="3401"><span class="lineNum">    3401 </span>            :                 }</a>
<a name="3402"><span class="lineNum">    3402 </span>            : </a>
<a name="3403"><span class="lineNum">    3403 </span>            :                 // Repeat if any &quot;free&quot; corresponding channel is still busy.</a>
<a name="3404"><span class="lineNum">    3404 </span><span class="lineCov">        344 :                 if (krcp-&gt;bkvhead[0] || krcp-&gt;bkvhead[1] || krcp-&gt;head)</span></a>
<a name="3405"><span class="lineNum">    3405 </span><span class="lineCov">         58 :                         repeat = true;</span></a>
<a name="3406"><span class="lineNum">    3406 </span>            :         }</a>
<a name="3407"><span class="lineNum">    3407 </span>            : </a>
<a name="3408"><span class="lineNum">    3408 </span><span class="lineCov">        172 :         return !repeat;</span></a>
<a name="3409"><span class="lineNum">    3409 </span>            : }</a>
<a name="3410"><span class="lineNum">    3410 </span>            : </a>
<a name="3411"><span class="lineNum">    3411 </span><span class="lineCov">        172 : static inline void kfree_rcu_drain_unlock(struct kfree_rcu_cpu *krcp,</span></a>
<a name="3412"><span class="lineNum">    3412 </span>            :                                           unsigned long flags)</a>
<a name="3413"><span class="lineNum">    3413 </span>            : {</a>
<a name="3414"><span class="lineNum">    3414 </span>            :         // Attempt to start a new batch.</a>
<a name="3415"><span class="lineNum">    3415 </span><span class="lineCov">        172 :         krcp-&gt;monitor_todo = false;</span></a>
<a name="3416"><span class="lineNum">    3416 </span><span class="lineCov">        172 :         if (queue_kfree_rcu_work(krcp)) {</span></a>
<a name="3417"><span class="lineNum">    3417 </span>            :                 // Success! Our job is done here.</a>
<a name="3418"><span class="lineNum">    3418 </span><span class="lineCov">        134 :                 raw_spin_unlock_irqrestore(&amp;krcp-&gt;lock, flags);</span></a>
<a name="3419"><span class="lineNum">    3419 </span><span class="lineCov">        134 :                 return;</span></a>
<a name="3420"><span class="lineNum">    3420 </span>            :         }</a>
<a name="3421"><span class="lineNum">    3421 </span>            : </a>
<a name="3422"><span class="lineNum">    3422 </span>            :         // Previous RCU batch still in progress, try again later.</a>
<a name="3423"><span class="lineNum">    3423 </span><span class="lineCov">         38 :         krcp-&gt;monitor_todo = true;</span></a>
<a name="3424"><span class="lineNum">    3424 </span><span class="lineCov">         38 :         schedule_delayed_work(&amp;krcp-&gt;monitor_work, KFREE_DRAIN_JIFFIES);</span></a>
<a name="3425"><span class="lineNum">    3425 </span><span class="lineCov">         38 :         raw_spin_unlock_irqrestore(&amp;krcp-&gt;lock, flags);</span></a>
<a name="3426"><span class="lineNum">    3426 </span>            : }</a>
<a name="3427"><span class="lineNum">    3427 </span>            : </a>
<a name="3428"><span class="lineNum">    3428 </span>            : /*</a>
<a name="3429"><span class="lineNum">    3429 </span>            :  * This function is invoked after the KFREE_DRAIN_JIFFIES timeout.</a>
<a name="3430"><span class="lineNum">    3430 </span>            :  * It invokes kfree_rcu_drain_unlock() to attempt to start another batch.</a>
<a name="3431"><span class="lineNum">    3431 </span>            :  */</a>
<a name="3432"><span class="lineNum">    3432 </span><span class="lineCov">        172 : static void kfree_rcu_monitor(struct work_struct *work)</span></a>
<a name="3433"><span class="lineNum">    3433 </span>            : {</a>
<a name="3434"><span class="lineNum">    3434 </span><span class="lineCov">        172 :         unsigned long flags;</span></a>
<a name="3435"><span class="lineNum">    3435 </span><span class="lineCov">        172 :         struct kfree_rcu_cpu *krcp = container_of(work, struct kfree_rcu_cpu,</span></a>
<a name="3436"><span class="lineNum">    3436 </span>            :                                                  monitor_work.work);</a>
<a name="3437"><span class="lineNum">    3437 </span>            : </a>
<a name="3438"><span class="lineNum">    3438 </span><span class="lineCov">        172 :         raw_spin_lock_irqsave(&amp;krcp-&gt;lock, flags);</span></a>
<a name="3439"><span class="lineNum">    3439 </span><span class="lineCov">        172 :         if (krcp-&gt;monitor_todo)</span></a>
<a name="3440"><span class="lineNum">    3440 </span><span class="lineCov">        172 :                 kfree_rcu_drain_unlock(krcp, flags);</span></a>
<a name="3441"><span class="lineNum">    3441 </span>            :         else</a>
<a name="3442"><span class="lineNum">    3442 </span><span class="lineNoCov">          0 :                 raw_spin_unlock_irqrestore(&amp;krcp-&gt;lock, flags);</span></a>
<a name="3443"><span class="lineNum">    3443 </span><span class="lineCov">        172 : }</span></a>
<a name="3444"><span class="lineNum">    3444 </span>            : </a>
<a name="3445"><span class="lineNum">    3445 </span>            : static enum hrtimer_restart</a>
<a name="3446"><span class="lineNum">    3446 </span><span class="lineCov">          4 : schedule_page_work_fn(struct hrtimer *t)</span></a>
<a name="3447"><span class="lineNum">    3447 </span>            : {</a>
<a name="3448"><span class="lineNum">    3448 </span><span class="lineCov">          4 :         struct kfree_rcu_cpu *krcp =</span></a>
<a name="3449"><span class="lineNum">    3449 </span><span class="lineCov">          4 :                 container_of(t, struct kfree_rcu_cpu, hrtimer);</span></a>
<a name="3450"><span class="lineNum">    3450 </span>            : </a>
<a name="3451"><span class="lineNum">    3451 </span><span class="lineCov">          4 :         queue_work(system_highpri_wq, &amp;krcp-&gt;page_cache_work);</span></a>
<a name="3452"><span class="lineNum">    3452 </span><span class="lineCov">          4 :         return HRTIMER_NORESTART;</span></a>
<a name="3453"><span class="lineNum">    3453 </span>            : }</a>
<a name="3454"><span class="lineNum">    3454 </span>            : </a>
<a name="3455"><span class="lineNum">    3455 </span><span class="lineCov">          4 : static void fill_page_cache_func(struct work_struct *work)</span></a>
<a name="3456"><span class="lineNum">    3456 </span>            : {</a>
<a name="3457"><span class="lineNum">    3457 </span><span class="lineCov">          4 :         struct kvfree_rcu_bulk_data *bnode;</span></a>
<a name="3458"><span class="lineNum">    3458 </span><span class="lineCov">          4 :         struct kfree_rcu_cpu *krcp =</span></a>
<a name="3459"><span class="lineNum">    3459 </span><span class="lineCov">          4 :                 container_of(work, struct kfree_rcu_cpu,</span></a>
<a name="3460"><span class="lineNum">    3460 </span>            :                         page_cache_work);</a>
<a name="3461"><span class="lineNum">    3461 </span><span class="lineCov">          4 :         unsigned long flags;</span></a>
<a name="3462"><span class="lineNum">    3462 </span><span class="lineCov">          4 :         bool pushed;</span></a>
<a name="3463"><span class="lineNum">    3463 </span><span class="lineCov">          4 :         int i;</span></a>
<a name="3464"><span class="lineNum">    3464 </span>            : </a>
<a name="3465"><span class="lineNum">    3465 </span><span class="lineCov">         24 :         for (i = 0; i &lt; rcu_min_cached_objs; i++) {</span></a>
<a name="3466"><span class="lineNum">    3466 </span><span class="lineCov">         40 :                 bnode = (struct kvfree_rcu_bulk_data *)</span></a>
<a name="3467"><span class="lineNum">    3467 </span><span class="lineCov">         20 :                         __get_free_page(GFP_KERNEL | __GFP_NOWARN);</span></a>
<a name="3468"><span class="lineNum">    3468 </span>            : </a>
<a name="3469"><span class="lineNum">    3469 </span><span class="lineCov">         20 :                 if (bnode) {</span></a>
<a name="3470"><span class="lineNum">    3470 </span><span class="lineCov">         20 :                         raw_spin_lock_irqsave(&amp;krcp-&gt;lock, flags);</span></a>
<a name="3471"><span class="lineNum">    3471 </span><span class="lineCov">         20 :                         pushed = put_cached_bnode(krcp, bnode);</span></a>
<a name="3472"><span class="lineNum">    3472 </span><span class="lineCov">         20 :                         raw_spin_unlock_irqrestore(&amp;krcp-&gt;lock, flags);</span></a>
<a name="3473"><span class="lineNum">    3473 </span>            : </a>
<a name="3474"><span class="lineNum">    3474 </span><span class="lineCov">         20 :                         if (!pushed) {</span></a>
<a name="3475"><span class="lineNum">    3475 </span><span class="lineNoCov">          0 :                                 free_page((unsigned long) bnode);</span></a>
<a name="3476"><span class="lineNum">    3476 </span><span class="lineNoCov">          0 :                                 break;</span></a>
<a name="3477"><span class="lineNum">    3477 </span>            :                         }</a>
<a name="3478"><span class="lineNum">    3478 </span>            :                 }</a>
<a name="3479"><span class="lineNum">    3479 </span>            :         }</a>
<a name="3480"><span class="lineNum">    3480 </span>            : </a>
<a name="3481"><span class="lineNum">    3481 </span><span class="lineCov">          4 :         atomic_set(&amp;krcp-&gt;work_in_progress, 0);</span></a>
<a name="3482"><span class="lineNum">    3482 </span><span class="lineCov">          4 : }</span></a>
<a name="3483"><span class="lineNum">    3483 </span>            : </a>
<a name="3484"><span class="lineNum">    3484 </span>            : static void</a>
<a name="3485"><span class="lineNum">    3485 </span><span class="lineCov">          4 : run_page_cache_worker(struct kfree_rcu_cpu *krcp)</span></a>
<a name="3486"><span class="lineNum">    3486 </span>            : {</a>
<a name="3487"><span class="lineNum">    3487 </span><span class="lineCov">          4 :         if (rcu_scheduler_active == RCU_SCHEDULER_RUNNING &amp;&amp;</span></a>
<a name="3488"><span class="lineNum">    3488 </span><span class="lineCov">          8 :                         !atomic_xchg(&amp;krcp-&gt;work_in_progress, 1)) {</span></a>
<a name="3489"><span class="lineNum">    3489 </span><span class="lineCov">          4 :                 hrtimer_init(&amp;krcp-&gt;hrtimer, CLOCK_MONOTONIC,</span></a>
<a name="3490"><span class="lineNum">    3490 </span>            :                         HRTIMER_MODE_REL);</a>
<a name="3491"><span class="lineNum">    3491 </span><span class="lineCov">          4 :                 krcp-&gt;hrtimer.function = schedule_page_work_fn;</span></a>
<a name="3492"><span class="lineNum">    3492 </span><span class="lineCov">          4 :                 hrtimer_start(&amp;krcp-&gt;hrtimer, 0, HRTIMER_MODE_REL);</span></a>
<a name="3493"><span class="lineNum">    3493 </span>            :         }</a>
<a name="3494"><span class="lineNum">    3494 </span><span class="lineCov">          4 : }</span></a>
<a name="3495"><span class="lineNum">    3495 </span>            : </a>
<a name="3496"><span class="lineNum">    3496 </span>            : static inline bool</a>
<a name="3497"><span class="lineNum">    3497 </span><span class="lineCov">        257 : kvfree_call_rcu_add_ptr_to_bulk(struct kfree_rcu_cpu *krcp, void *ptr)</span></a>
<a name="3498"><span class="lineNum">    3498 </span>            : {</a>
<a name="3499"><span class="lineNum">    3499 </span><span class="lineCov">        257 :         struct kvfree_rcu_bulk_data *bnode;</span></a>
<a name="3500"><span class="lineNum">    3500 </span><span class="lineCov">        257 :         int idx;</span></a>
<a name="3501"><span class="lineNum">    3501 </span>            : </a>
<a name="3502"><span class="lineNum">    3502 </span><span class="lineCov">        257 :         if (unlikely(!krcp-&gt;initialized))</span></a>
<a name="3503"><span class="lineNum">    3503 </span>            :                 return false;</a>
<a name="3504"><span class="lineNum">    3504 </span>            : </a>
<a name="3505"><span class="lineNum">    3505 </span><span class="lineCov">        514 :         lockdep_assert_held(&amp;krcp-&gt;lock);</span></a>
<a name="3506"><span class="lineNum">    3506 </span><span class="lineCov">        257 :         idx = !!is_vmalloc_addr(ptr);</span></a>
<a name="3507"><span class="lineNum">    3507 </span>            : </a>
<a name="3508"><span class="lineNum">    3508 </span>            :         /* Check if a new block is required. */</a>
<a name="3509"><span class="lineNum">    3509 </span><span class="lineCov">        257 :         if (!krcp-&gt;bkvhead[idx] ||</span></a>
<a name="3510"><span class="lineNum">    3510 </span><span class="lineCov">        112 :                         krcp-&gt;bkvhead[idx]-&gt;nr_records == KVFREE_BULK_MAX_ENTR) {</span></a>
<a name="3511"><span class="lineNum">    3511 </span><span class="lineCov">        145 :                 bnode = get_cached_bnode(krcp);</span></a>
<a name="3512"><span class="lineNum">    3512 </span>            :                 /* Switch to emergency path. */</a>
<a name="3513"><span class="lineNum">    3513 </span><span class="lineCov">        145 :                 if (!bnode)</span></a>
<a name="3514"><span class="lineNum">    3514 </span>            :                         return false;</a>
<a name="3515"><span class="lineNum">    3515 </span>            : </a>
<a name="3516"><span class="lineNum">    3516 </span>            :                 /* Initialize the new block. */</a>
<a name="3517"><span class="lineNum">    3517 </span><span class="lineCov">        141 :                 bnode-&gt;nr_records = 0;</span></a>
<a name="3518"><span class="lineNum">    3518 </span><span class="lineCov">        141 :                 bnode-&gt;next = krcp-&gt;bkvhead[idx];</span></a>
<a name="3519"><span class="lineNum">    3519 </span>            : </a>
<a name="3520"><span class="lineNum">    3520 </span>            :                 /* Attach it to the head. */</a>
<a name="3521"><span class="lineNum">    3521 </span><span class="lineCov">        141 :                 krcp-&gt;bkvhead[idx] = bnode;</span></a>
<a name="3522"><span class="lineNum">    3522 </span>            :         }</a>
<a name="3523"><span class="lineNum">    3523 </span>            : </a>
<a name="3524"><span class="lineNum">    3524 </span>            :         /* Finally insert. */</a>
<a name="3525"><span class="lineNum">    3525 </span><span class="lineCov">        253 :         krcp-&gt;bkvhead[idx]-&gt;records</span></a>
<a name="3526"><span class="lineNum">    3526 </span><span class="lineCov">        253 :                 [krcp-&gt;bkvhead[idx]-&gt;nr_records++] = ptr;</span></a>
<a name="3527"><span class="lineNum">    3527 </span>            : </a>
<a name="3528"><span class="lineNum">    3528 </span><span class="lineCov">        253 :         return true;</span></a>
<a name="3529"><span class="lineNum">    3529 </span>            : }</a>
<a name="3530"><span class="lineNum">    3530 </span>            : </a>
<a name="3531"><span class="lineNum">    3531 </span>            : /*</a>
<a name="3532"><span class="lineNum">    3532 </span>            :  * Queue a request for lazy invocation of appropriate free routine after a</a>
<a name="3533"><span class="lineNum">    3533 </span>            :  * grace period. Please note there are three paths are maintained, two are the</a>
<a name="3534"><span class="lineNum">    3534 </span>            :  * main ones that use array of pointers interface and third one is emergency</a>
<a name="3535"><span class="lineNum">    3535 </span>            :  * one, that is used only when the main path can not be maintained temporary,</a>
<a name="3536"><span class="lineNum">    3536 </span>            :  * due to memory pressure.</a>
<a name="3537"><span class="lineNum">    3537 </span>            :  *</a>
<a name="3538"><span class="lineNum">    3538 </span>            :  * Each kvfree_call_rcu() request is added to a batch. The batch will be drained</a>
<a name="3539"><span class="lineNum">    3539 </span>            :  * every KFREE_DRAIN_JIFFIES number of jiffies. All the objects in the batch will</a>
<a name="3540"><span class="lineNum">    3540 </span>            :  * be free'd in workqueue context. This allows us to: batch requests together to</a>
<a name="3541"><span class="lineNum">    3541 </span>            :  * reduce the number of grace periods during heavy kfree_rcu()/kvfree_rcu() load.</a>
<a name="3542"><span class="lineNum">    3542 </span>            :  */</a>
<a name="3543"><span class="lineNum">    3543 </span><span class="lineCov">        257 : void kvfree_call_rcu(struct rcu_head *head, rcu_callback_t func)</span></a>
<a name="3544"><span class="lineNum">    3544 </span>            : {</a>
<a name="3545"><span class="lineNum">    3545 </span><span class="lineCov">        257 :         unsigned long flags;</span></a>
<a name="3546"><span class="lineNum">    3546 </span><span class="lineCov">        257 :         struct kfree_rcu_cpu *krcp;</span></a>
<a name="3547"><span class="lineNum">    3547 </span><span class="lineCov">        257 :         bool success;</span></a>
<a name="3548"><span class="lineNum">    3548 </span><span class="lineCov">        257 :         void *ptr;</span></a>
<a name="3549"><span class="lineNum">    3549 </span>            : </a>
<a name="3550"><span class="lineNum">    3550 </span><span class="lineCov">        257 :         if (head) {</span></a>
<a name="3551"><span class="lineNum">    3551 </span><span class="lineCov">        257 :                 ptr = (void *) head - (unsigned long) func;</span></a>
<a name="3552"><span class="lineNum">    3552 </span>            :         } else {</a>
<a name="3553"><span class="lineNum">    3553 </span>            :                 /*</a>
<a name="3554"><span class="lineNum">    3554 </span>            :                  * Please note there is a limitation for the head-less</a>
<a name="3555"><span class="lineNum">    3555 </span>            :                  * variant, that is why there is a clear rule for such</a>
<a name="3556"><span class="lineNum">    3556 </span>            :                  * objects: it can be used from might_sleep() context</a>
<a name="3557"><span class="lineNum">    3557 </span>            :                  * only. For other places please embed an rcu_head to</a>
<a name="3558"><span class="lineNum">    3558 </span>            :                  * your data.</a>
<a name="3559"><span class="lineNum">    3559 </span>            :                  */</a>
<a name="3560"><span class="lineNum">    3560 </span><span class="lineNoCov">          0 :                 might_sleep();</span></a>
<a name="3561"><span class="lineNum">    3561 </span><span class="lineNoCov">          0 :                 ptr = (unsigned long *) func;</span></a>
<a name="3562"><span class="lineNum">    3562 </span>            :         }</a>
<a name="3563"><span class="lineNum">    3563 </span>            : </a>
<a name="3564"><span class="lineNum">    3564 </span><span class="lineCov">        257 :         krcp = krc_this_cpu_lock(&amp;flags);</span></a>
<a name="3565"><span class="lineNum">    3565 </span>            : </a>
<a name="3566"><span class="lineNum">    3566 </span>            :         // Queue the object but don't yet schedule the batch.</a>
<a name="3567"><span class="lineNum">    3567 </span><span class="lineCov">        257 :         if (debug_rcu_head_queue(ptr)) {</span></a>
<a name="3568"><span class="lineNum">    3568 </span>            :                 // Probable double kfree_rcu(), just leak.</a>
<a name="3569"><span class="lineNum">    3569 </span><span class="lineNoCov">          0 :                 WARN_ONCE(1, &quot;%s(): Double-freed call. rcu_head %p\n&quot;,</span></a>
<a name="3570"><span class="lineNum">    3570 </span>            :                           __func__, head);</a>
<a name="3571"><span class="lineNum">    3571 </span>            : </a>
<a name="3572"><span class="lineNum">    3572 </span>            :                 // Mark as success and leave.</a>
<a name="3573"><span class="lineNum">    3573 </span><span class="lineNoCov">          0 :                 success = true;</span></a>
<a name="3574"><span class="lineNum">    3574 </span><span class="lineNoCov">          0 :                 goto unlock_return;</span></a>
<a name="3575"><span class="lineNum">    3575 </span>            :         }</a>
<a name="3576"><span class="lineNum">    3576 </span>            : </a>
<a name="3577"><span class="lineNum">    3577 </span><span class="lineCov">        257 :         kasan_record_aux_stack(ptr);</span></a>
<a name="3578"><span class="lineNum">    3578 </span><span class="lineCov">        257 :         success = kvfree_call_rcu_add_ptr_to_bulk(krcp, ptr);</span></a>
<a name="3579"><span class="lineNum">    3579 </span><span class="lineCov">        257 :         if (!success) {</span></a>
<a name="3580"><span class="lineNum">    3580 </span><span class="lineCov">          4 :                 run_page_cache_worker(krcp);</span></a>
<a name="3581"><span class="lineNum">    3581 </span>            : </a>
<a name="3582"><span class="lineNum">    3582 </span><span class="lineCov">          4 :                 if (head == NULL)</span></a>
<a name="3583"><span class="lineNum">    3583 </span>            :                         // Inline if kvfree_rcu(one_arg) call.</a>
<a name="3584"><span class="lineNum">    3584 </span><span class="lineNoCov">          0 :                         goto unlock_return;</span></a>
<a name="3585"><span class="lineNum">    3585 </span>            : </a>
<a name="3586"><span class="lineNum">    3586 </span><span class="lineCov">          4 :                 head-&gt;func = func;</span></a>
<a name="3587"><span class="lineNum">    3587 </span><span class="lineCov">          4 :                 head-&gt;next = krcp-&gt;head;</span></a>
<a name="3588"><span class="lineNum">    3588 </span><span class="lineCov">          4 :                 krcp-&gt;head = head;</span></a>
<a name="3589"><span class="lineNum">    3589 </span><span class="lineCov">          4 :                 success = true;</span></a>
<a name="3590"><span class="lineNum">    3590 </span>            :         }</a>
<a name="3591"><span class="lineNum">    3591 </span>            : </a>
<a name="3592"><span class="lineNum">    3592 </span><span class="lineCov">        257 :         WRITE_ONCE(krcp-&gt;count, krcp-&gt;count + 1);</span></a>
<a name="3593"><span class="lineNum">    3593 </span>            : </a>
<a name="3594"><span class="lineNum">    3594 </span>            :         // Set timer to drain after KFREE_DRAIN_JIFFIES.</a>
<a name="3595"><span class="lineNum">    3595 </span><span class="lineCov">        257 :         if (rcu_scheduler_active == RCU_SCHEDULER_RUNNING &amp;&amp;</span></a>
<a name="3596"><span class="lineNum">    3596 </span><span class="lineCov">        257 :             !krcp-&gt;monitor_todo) {</span></a>
<a name="3597"><span class="lineNum">    3597 </span><span class="lineCov">        134 :                 krcp-&gt;monitor_todo = true;</span></a>
<a name="3598"><span class="lineNum">    3598 </span><span class="lineCov">        134 :                 schedule_delayed_work(&amp;krcp-&gt;monitor_work, KFREE_DRAIN_JIFFIES);</span></a>
<a name="3599"><span class="lineNum">    3599 </span>            :         }</a>
<a name="3600"><span class="lineNum">    3600 </span>            : </a>
<a name="3601"><span class="lineNum">    3601 </span><span class="lineCov">        123 : unlock_return:</span></a>
<a name="3602"><span class="lineNum">    3602 </span><span class="lineCov">        257 :         krc_this_cpu_unlock(krcp, flags);</span></a>
<a name="3603"><span class="lineNum">    3603 </span>            : </a>
<a name="3604"><span class="lineNum">    3604 </span>            :         /*</a>
<a name="3605"><span class="lineNum">    3605 </span>            :          * Inline kvfree() after synchronize_rcu(). We can do</a>
<a name="3606"><span class="lineNum">    3606 </span>            :          * it from might_sleep() context only, so the current</a>
<a name="3607"><span class="lineNum">    3607 </span>            :          * CPU can pass the QS state.</a>
<a name="3608"><span class="lineNum">    3608 </span>            :          */</a>
<a name="3609"><span class="lineNum">    3609 </span><span class="lineCov">        257 :         if (!success) {</span></a>
<a name="3610"><span class="lineNum">    3610 </span><span class="lineNoCov">          0 :                 debug_rcu_head_unqueue((struct rcu_head *) ptr);</span></a>
<a name="3611"><span class="lineNum">    3611 </span><span class="lineNoCov">          0 :                 synchronize_rcu();</span></a>
<a name="3612"><span class="lineNum">    3612 </span><span class="lineNoCov">          0 :                 kvfree(ptr);</span></a>
<a name="3613"><span class="lineNum">    3613 </span>            :         }</a>
<a name="3614"><span class="lineNum">    3614 </span><span class="lineCov">        257 : }</span></a>
<a name="3615"><span class="lineNum">    3615 </span>            : EXPORT_SYMBOL_GPL(kvfree_call_rcu);</a>
<a name="3616"><span class="lineNum">    3616 </span>            : </a>
<a name="3617"><span class="lineNum">    3617 </span>            : static unsigned long</a>
<a name="3618"><span class="lineNum">    3618 </span><span class="lineNoCov">          0 : kfree_rcu_shrink_count(struct shrinker *shrink, struct shrink_control *sc)</span></a>
<a name="3619"><span class="lineNum">    3619 </span>            : {</a>
<a name="3620"><span class="lineNum">    3620 </span><span class="lineNoCov">          0 :         int cpu;</span></a>
<a name="3621"><span class="lineNum">    3621 </span><span class="lineNoCov">          0 :         unsigned long count = 0;</span></a>
<a name="3622"><span class="lineNum">    3622 </span>            : </a>
<a name="3623"><span class="lineNum">    3623 </span>            :         /* Snapshot count of all CPUs */</a>
<a name="3624"><span class="lineNum">    3624 </span><span class="lineNoCov">          0 :         for_each_possible_cpu(cpu) {</span></a>
<a name="3625"><span class="lineNum">    3625 </span><span class="lineNoCov">          0 :                 struct kfree_rcu_cpu *krcp = per_cpu_ptr(&amp;krc, cpu);</span></a>
<a name="3626"><span class="lineNum">    3626 </span>            : </a>
<a name="3627"><span class="lineNum">    3627 </span><span class="lineNoCov">          0 :                 count += READ_ONCE(krcp-&gt;count);</span></a>
<a name="3628"><span class="lineNum">    3628 </span>            :         }</a>
<a name="3629"><span class="lineNum">    3629 </span>            : </a>
<a name="3630"><span class="lineNum">    3630 </span><span class="lineNoCov">          0 :         return count;</span></a>
<a name="3631"><span class="lineNum">    3631 </span>            : }</a>
<a name="3632"><span class="lineNum">    3632 </span>            : </a>
<a name="3633"><span class="lineNum">    3633 </span>            : static unsigned long</a>
<a name="3634"><span class="lineNum">    3634 </span><span class="lineNoCov">          0 : kfree_rcu_shrink_scan(struct shrinker *shrink, struct shrink_control *sc)</span></a>
<a name="3635"><span class="lineNum">    3635 </span>            : {</a>
<a name="3636"><span class="lineNum">    3636 </span><span class="lineNoCov">          0 :         int cpu, freed = 0;</span></a>
<a name="3637"><span class="lineNum">    3637 </span><span class="lineNoCov">          0 :         unsigned long flags;</span></a>
<a name="3638"><span class="lineNum">    3638 </span>            : </a>
<a name="3639"><span class="lineNum">    3639 </span><span class="lineNoCov">          0 :         for_each_possible_cpu(cpu) {</span></a>
<a name="3640"><span class="lineNum">    3640 </span><span class="lineNoCov">          0 :                 int count;</span></a>
<a name="3641"><span class="lineNum">    3641 </span><span class="lineNoCov">          0 :                 struct kfree_rcu_cpu *krcp = per_cpu_ptr(&amp;krc, cpu);</span></a>
<a name="3642"><span class="lineNum">    3642 </span>            : </a>
<a name="3643"><span class="lineNum">    3643 </span><span class="lineNoCov">          0 :                 count = krcp-&gt;count;</span></a>
<a name="3644"><span class="lineNum">    3644 </span><span class="lineNoCov">          0 :                 raw_spin_lock_irqsave(&amp;krcp-&gt;lock, flags);</span></a>
<a name="3645"><span class="lineNum">    3645 </span><span class="lineNoCov">          0 :                 if (krcp-&gt;monitor_todo)</span></a>
<a name="3646"><span class="lineNum">    3646 </span><span class="lineNoCov">          0 :                         kfree_rcu_drain_unlock(krcp, flags);</span></a>
<a name="3647"><span class="lineNum">    3647 </span>            :                 else</a>
<a name="3648"><span class="lineNum">    3648 </span><span class="lineNoCov">          0 :                         raw_spin_unlock_irqrestore(&amp;krcp-&gt;lock, flags);</span></a>
<a name="3649"><span class="lineNum">    3649 </span>            : </a>
<a name="3650"><span class="lineNum">    3650 </span><span class="lineNoCov">          0 :                 sc-&gt;nr_to_scan -= count;</span></a>
<a name="3651"><span class="lineNum">    3651 </span><span class="lineNoCov">          0 :                 freed += count;</span></a>
<a name="3652"><span class="lineNum">    3652 </span>            : </a>
<a name="3653"><span class="lineNum">    3653 </span><span class="lineNoCov">          0 :                 if (sc-&gt;nr_to_scan &lt;= 0)</span></a>
<a name="3654"><span class="lineNum">    3654 </span>            :                         break;</a>
<a name="3655"><span class="lineNum">    3655 </span>            :         }</a>
<a name="3656"><span class="lineNum">    3656 </span>            : </a>
<a name="3657"><span class="lineNum">    3657 </span><span class="lineNoCov">          0 :         return freed == 0 ? SHRINK_STOP : freed;</span></a>
<a name="3658"><span class="lineNum">    3658 </span>            : }</a>
<a name="3659"><span class="lineNum">    3659 </span>            : </a>
<a name="3660"><span class="lineNum">    3660 </span>            : static struct shrinker kfree_rcu_shrinker = {</a>
<a name="3661"><span class="lineNum">    3661 </span>            :         .count_objects = kfree_rcu_shrink_count,</a>
<a name="3662"><span class="lineNum">    3662 </span>            :         .scan_objects = kfree_rcu_shrink_scan,</a>
<a name="3663"><span class="lineNum">    3663 </span>            :         .batch = 0,</a>
<a name="3664"><span class="lineNum">    3664 </span>            :         .seeks = DEFAULT_SEEKS,</a>
<a name="3665"><span class="lineNum">    3665 </span>            : };</a>
<a name="3666"><span class="lineNum">    3666 </span>            : </a>
<a name="3667"><span class="lineNum">    3667 </span><span class="lineCov">          1 : void __init kfree_rcu_scheduler_running(void)</span></a>
<a name="3668"><span class="lineNum">    3668 </span>            : {</a>
<a name="3669"><span class="lineNum">    3669 </span><span class="lineCov">          1 :         int cpu;</span></a>
<a name="3670"><span class="lineNum">    3670 </span><span class="lineCov">          1 :         unsigned long flags;</span></a>
<a name="3671"><span class="lineNum">    3671 </span>            : </a>
<a name="3672"><span class="lineNum">    3672 </span><span class="lineCov">          6 :         for_each_possible_cpu(cpu) {</span></a>
<a name="3673"><span class="lineNum">    3673 </span><span class="lineCov">          4 :                 struct kfree_rcu_cpu *krcp = per_cpu_ptr(&amp;krc, cpu);</span></a>
<a name="3674"><span class="lineNum">    3674 </span>            : </a>
<a name="3675"><span class="lineNum">    3675 </span><span class="lineCov">          4 :                 raw_spin_lock_irqsave(&amp;krcp-&gt;lock, flags);</span></a>
<a name="3676"><span class="lineNum">    3676 </span><span class="lineCov">          4 :                 if (!krcp-&gt;head || krcp-&gt;monitor_todo) {</span></a>
<a name="3677"><span class="lineNum">    3677 </span><span class="lineCov">          4 :                         raw_spin_unlock_irqrestore(&amp;krcp-&gt;lock, flags);</span></a>
<a name="3678"><span class="lineNum">    3678 </span><span class="lineCov">          4 :                         continue;</span></a>
<a name="3679"><span class="lineNum">    3679 </span>            :                 }</a>
<a name="3680"><span class="lineNum">    3680 </span><span class="lineNoCov">          0 :                 krcp-&gt;monitor_todo = true;</span></a>
<a name="3681"><span class="lineNum">    3681 </span><span class="lineNoCov">          0 :                 schedule_delayed_work_on(cpu, &amp;krcp-&gt;monitor_work,</span></a>
<a name="3682"><span class="lineNum">    3682 </span>            :                                          KFREE_DRAIN_JIFFIES);</a>
<a name="3683"><span class="lineNum">    3683 </span><span class="lineCov">          5 :                 raw_spin_unlock_irqrestore(&amp;krcp-&gt;lock, flags);</span></a>
<a name="3684"><span class="lineNum">    3684 </span>            :         }</a>
<a name="3685"><span class="lineNum">    3685 </span><span class="lineCov">          1 : }</span></a>
<a name="3686"><span class="lineNum">    3686 </span>            : </a>
<a name="3687"><span class="lineNum">    3687 </span>            : /*</a>
<a name="3688"><span class="lineNum">    3688 </span>            :  * During early boot, any blocking grace-period wait automatically</a>
<a name="3689"><span class="lineNum">    3689 </span>            :  * implies a grace period.  Later on, this is never the case for PREEMPTION.</a>
<a name="3690"><span class="lineNum">    3690 </span>            :  *</a>
<a name="3691"><span class="lineNum">    3691 </span>            :  * However, because a context switch is a grace period for !PREEMPTION, any</a>
<a name="3692"><span class="lineNum">    3692 </span>            :  * blocking grace-period wait automatically implies a grace period if</a>
<a name="3693"><span class="lineNum">    3693 </span>            :  * there is only one CPU online at any point time during execution of</a>
<a name="3694"><span class="lineNum">    3694 </span>            :  * either synchronize_rcu() or synchronize_rcu_expedited().  It is OK to</a>
<a name="3695"><span class="lineNum">    3695 </span>            :  * occasionally incorrectly indicate that there are multiple CPUs online</a>
<a name="3696"><span class="lineNum">    3696 </span>            :  * when there was in fact only one the whole time, as this just adds some</a>
<a name="3697"><span class="lineNum">    3697 </span>            :  * overhead: RCU still operates correctly.</a>
<a name="3698"><span class="lineNum">    3698 </span>            :  */</a>
<a name="3699"><span class="lineNum">    3699 </span><span class="lineCov">        174 : static int rcu_blocking_is_gp(void)</span></a>
<a name="3700"><span class="lineNum">    3700 </span>            : {</a>
<a name="3701"><span class="lineNum">    3701 </span><span class="lineCov">        174 :         int ret;</span></a>
<a name="3702"><span class="lineNum">    3702 </span>            : </a>
<a name="3703"><span class="lineNum">    3703 </span><span class="lineCov">        174 :         if (IS_ENABLED(CONFIG_PREEMPTION))</span></a>
<a name="3704"><span class="lineNum">    3704 </span>            :                 return rcu_scheduler_active == RCU_SCHEDULER_INACTIVE;</a>
<a name="3705"><span class="lineNum">    3705 </span><span class="lineCov">        174 :         might_sleep();  /* Check for RCU read-side critical section. */</span></a>
<a name="3706"><span class="lineNum">    3706 </span><span class="lineCov">        174 :         preempt_disable();</span></a>
<a name="3707"><span class="lineNum">    3707 </span>            :         /*</a>
<a name="3708"><span class="lineNum">    3708 </span>            :          * If the rcu_state.n_online_cpus counter is equal to one,</a>
<a name="3709"><span class="lineNum">    3709 </span>            :          * there is only one CPU, and that CPU sees all prior accesses</a>
<a name="3710"><span class="lineNum">    3710 </span>            :          * made by any CPU that was online at the time of its access.</a>
<a name="3711"><span class="lineNum">    3711 </span>            :          * Furthermore, if this counter is equal to one, its value cannot</a>
<a name="3712"><span class="lineNum">    3712 </span>            :          * change until after the preempt_enable() below.</a>
<a name="3713"><span class="lineNum">    3713 </span>            :          *</a>
<a name="3714"><span class="lineNum">    3714 </span>            :          * Furthermore, if rcu_state.n_online_cpus is equal to one here,</a>
<a name="3715"><span class="lineNum">    3715 </span>            :          * all later CPUs (both this one and any that come online later</a>
<a name="3716"><span class="lineNum">    3716 </span>            :          * on) are guaranteed to see all accesses prior to this point</a>
<a name="3717"><span class="lineNum">    3717 </span>            :          * in the code, without the need for additional memory barriers.</a>
<a name="3718"><span class="lineNum">    3718 </span>            :          * Those memory barriers are provided by CPU-hotplug code.</a>
<a name="3719"><span class="lineNum">    3719 </span>            :          */</a>
<a name="3720"><span class="lineNum">    3720 </span><span class="lineCov">        174 :         ret = READ_ONCE(rcu_state.n_online_cpus) &lt;= 1;</span></a>
<a name="3721"><span class="lineNum">    3721 </span><span class="lineCov">        174 :         preempt_enable();</span></a>
<a name="3722"><span class="lineNum">    3722 </span><span class="lineCov">        174 :         return ret;</span></a>
<a name="3723"><span class="lineNum">    3723 </span>            : }</a>
<a name="3724"><span class="lineNum">    3724 </span>            : </a>
<a name="3725"><span class="lineNum">    3725 </span>            : /**</a>
<a name="3726"><span class="lineNum">    3726 </span>            :  * synchronize_rcu - wait until a grace period has elapsed.</a>
<a name="3727"><span class="lineNum">    3727 </span>            :  *</a>
<a name="3728"><span class="lineNum">    3728 </span>            :  * Control will return to the caller some time after a full grace</a>
<a name="3729"><span class="lineNum">    3729 </span>            :  * period has elapsed, in other words after all currently executing RCU</a>
<a name="3730"><span class="lineNum">    3730 </span>            :  * read-side critical sections have completed.  Note, however, that</a>
<a name="3731"><span class="lineNum">    3731 </span>            :  * upon return from synchronize_rcu(), the caller might well be executing</a>
<a name="3732"><span class="lineNum">    3732 </span>            :  * concurrently with new RCU read-side critical sections that began while</a>
<a name="3733"><span class="lineNum">    3733 </span>            :  * synchronize_rcu() was waiting.  RCU read-side critical sections are</a>
<a name="3734"><span class="lineNum">    3734 </span>            :  * delimited by rcu_read_lock() and rcu_read_unlock(), and may be nested.</a>
<a name="3735"><span class="lineNum">    3735 </span>            :  * In addition, regions of code across which interrupts, preemption, or</a>
<a name="3736"><span class="lineNum">    3736 </span>            :  * softirqs have been disabled also serve as RCU read-side critical</a>
<a name="3737"><span class="lineNum">    3737 </span>            :  * sections.  This includes hardware interrupt handlers, softirq handlers,</a>
<a name="3738"><span class="lineNum">    3738 </span>            :  * and NMI handlers.</a>
<a name="3739"><span class="lineNum">    3739 </span>            :  *</a>
<a name="3740"><span class="lineNum">    3740 </span>            :  * Note that this guarantee implies further memory-ordering guarantees.</a>
<a name="3741"><span class="lineNum">    3741 </span>            :  * On systems with more than one CPU, when synchronize_rcu() returns,</a>
<a name="3742"><span class="lineNum">    3742 </span>            :  * each CPU is guaranteed to have executed a full memory barrier since</a>
<a name="3743"><span class="lineNum">    3743 </span>            :  * the end of its last RCU read-side critical section whose beginning</a>
<a name="3744"><span class="lineNum">    3744 </span>            :  * preceded the call to synchronize_rcu().  In addition, each CPU having</a>
<a name="3745"><span class="lineNum">    3745 </span>            :  * an RCU read-side critical section that extends beyond the return from</a>
<a name="3746"><span class="lineNum">    3746 </span>            :  * synchronize_rcu() is guaranteed to have executed a full memory barrier</a>
<a name="3747"><span class="lineNum">    3747 </span>            :  * after the beginning of synchronize_rcu() and before the beginning of</a>
<a name="3748"><span class="lineNum">    3748 </span>            :  * that RCU read-side critical section.  Note that these guarantees include</a>
<a name="3749"><span class="lineNum">    3749 </span>            :  * CPUs that are offline, idle, or executing in user mode, as well as CPUs</a>
<a name="3750"><span class="lineNum">    3750 </span>            :  * that are executing in the kernel.</a>
<a name="3751"><span class="lineNum">    3751 </span>            :  *</a>
<a name="3752"><span class="lineNum">    3752 </span>            :  * Furthermore, if CPU A invoked synchronize_rcu(), which returned</a>
<a name="3753"><span class="lineNum">    3753 </span>            :  * to its caller on CPU B, then both CPU A and CPU B are guaranteed</a>
<a name="3754"><span class="lineNum">    3754 </span>            :  * to have executed a full memory barrier during the execution of</a>
<a name="3755"><span class="lineNum">    3755 </span>            :  * synchronize_rcu() -- even if CPU A and CPU B are the same CPU (but</a>
<a name="3756"><span class="lineNum">    3756 </span>            :  * again only if the system has more than one CPU).</a>
<a name="3757"><span class="lineNum">    3757 </span>            :  */</a>
<a name="3758"><span class="lineNum">    3758 </span><span class="lineCov">         10 : void synchronize_rcu(void)</span></a>
<a name="3759"><span class="lineNum">    3759 </span>            : {</a>
<a name="3760"><span class="lineNum">    3760 </span><span class="lineCov">         31 :         RCU_LOCKDEP_WARN(lock_is_held(&amp;rcu_bh_lock_map) ||</span></a>
<a name="3761"><span class="lineNum">    3761 </span>            :                          lock_is_held(&amp;rcu_lock_map) ||</a>
<a name="3762"><span class="lineNum">    3762 </span>            :                          lock_is_held(&amp;rcu_sched_lock_map),</a>
<a name="3763"><span class="lineNum">    3763 </span>            :                          &quot;Illegal synchronize_rcu() in RCU read-side critical section&quot;);</a>
<a name="3764"><span class="lineNum">    3764 </span><span class="lineCov">         10 :         if (rcu_blocking_is_gp())</span></a>
<a name="3765"><span class="lineNum">    3765 </span>            :                 return;  // Context allows vacuous grace periods.</a>
<a name="3766"><span class="lineNum">    3766 </span><span class="lineCov">          5 :         if (rcu_gp_is_expedited())</span></a>
<a name="3767"><span class="lineNum">    3767 </span><span class="lineCov">          4 :                 synchronize_rcu_expedited();</span></a>
<a name="3768"><span class="lineNum">    3768 </span>            :         else</a>
<a name="3769"><span class="lineNum">    3769 </span><span class="lineCov">          1 :                 wait_rcu_gp(call_rcu);</span></a>
<a name="3770"><span class="lineNum">    3770 </span>            : }</a>
<a name="3771"><span class="lineNum">    3771 </span>            : EXPORT_SYMBOL_GPL(synchronize_rcu);</a>
<a name="3772"><span class="lineNum">    3772 </span>            : </a>
<a name="3773"><span class="lineNum">    3773 </span>            : /**</a>
<a name="3774"><span class="lineNum">    3774 </span>            :  * get_state_synchronize_rcu - Snapshot current RCU state</a>
<a name="3775"><span class="lineNum">    3775 </span>            :  *</a>
<a name="3776"><span class="lineNum">    3776 </span>            :  * Returns a cookie that is used by a later call to cond_synchronize_rcu()</a>
<a name="3777"><span class="lineNum">    3777 </span>            :  * to determine whether or not a full grace period has elapsed in the</a>
<a name="3778"><span class="lineNum">    3778 </span>            :  * meantime.</a>
<a name="3779"><span class="lineNum">    3779 </span>            :  */</a>
<a name="3780"><span class="lineNum">    3780 </span><span class="lineNoCov">          0 : unsigned long get_state_synchronize_rcu(void)</span></a>
<a name="3781"><span class="lineNum">    3781 </span>            : {</a>
<a name="3782"><span class="lineNum">    3782 </span>            :         /*</a>
<a name="3783"><span class="lineNum">    3783 </span>            :          * Any prior manipulation of RCU-protected data must happen</a>
<a name="3784"><span class="lineNum">    3784 </span>            :          * before the load from -&gt;gp_seq.</a>
<a name="3785"><span class="lineNum">    3785 </span>            :          */</a>
<a name="3786"><span class="lineNum">    3786 </span><span class="lineNoCov">          0 :         smp_mb();  /* ^^^ */</span></a>
<a name="3787"><span class="lineNum">    3787 </span><span class="lineNoCov">          0 :         return rcu_seq_snap(&amp;rcu_state.gp_seq);</span></a>
<a name="3788"><span class="lineNum">    3788 </span>            : }</a>
<a name="3789"><span class="lineNum">    3789 </span>            : EXPORT_SYMBOL_GPL(get_state_synchronize_rcu);</a>
<a name="3790"><span class="lineNum">    3790 </span>            : </a>
<a name="3791"><span class="lineNum">    3791 </span>            : /**</a>
<a name="3792"><span class="lineNum">    3792 </span>            :  * cond_synchronize_rcu - Conditionally wait for an RCU grace period</a>
<a name="3793"><span class="lineNum">    3793 </span>            :  *</a>
<a name="3794"><span class="lineNum">    3794 </span>            :  * @oldstate: return value from earlier call to get_state_synchronize_rcu()</a>
<a name="3795"><span class="lineNum">    3795 </span>            :  *</a>
<a name="3796"><span class="lineNum">    3796 </span>            :  * If a full RCU grace period has elapsed since the earlier call to</a>
<a name="3797"><span class="lineNum">    3797 </span>            :  * get_state_synchronize_rcu(), just return.  Otherwise, invoke</a>
<a name="3798"><span class="lineNum">    3798 </span>            :  * synchronize_rcu() to wait for a full grace period.</a>
<a name="3799"><span class="lineNum">    3799 </span>            :  *</a>
<a name="3800"><span class="lineNum">    3800 </span>            :  * Yes, this function does not take counter wrap into account.  But</a>
<a name="3801"><span class="lineNum">    3801 </span>            :  * counter wrap is harmless.  If the counter wraps, we have waited for</a>
<a name="3802"><span class="lineNum">    3802 </span>            :  * more than 2 billion grace periods (and way more on a 64-bit system!),</a>
<a name="3803"><span class="lineNum">    3803 </span>            :  * so waiting for one additional grace period should be just fine.</a>
<a name="3804"><span class="lineNum">    3804 </span>            :  */</a>
<a name="3805"><span class="lineNum">    3805 </span><span class="lineNoCov">          0 : void cond_synchronize_rcu(unsigned long oldstate)</span></a>
<a name="3806"><span class="lineNum">    3806 </span>            : {</a>
<a name="3807"><span class="lineNum">    3807 </span><span class="lineNoCov">          0 :         if (!rcu_seq_done(&amp;rcu_state.gp_seq, oldstate))</span></a>
<a name="3808"><span class="lineNum">    3808 </span><span class="lineNoCov">          0 :                 synchronize_rcu();</span></a>
<a name="3809"><span class="lineNum">    3809 </span>            :         else</a>
<a name="3810"><span class="lineNum">    3810 </span><span class="lineNoCov">          0 :                 smp_mb(); /* Ensure GP ends before subsequent accesses. */</span></a>
<a name="3811"><span class="lineNum">    3811 </span><span class="lineNoCov">          0 : }</span></a>
<a name="3812"><span class="lineNum">    3812 </span>            : EXPORT_SYMBOL_GPL(cond_synchronize_rcu);</a>
<a name="3813"><span class="lineNum">    3813 </span>            : </a>
<a name="3814"><span class="lineNum">    3814 </span>            : /*</a>
<a name="3815"><span class="lineNum">    3815 </span>            :  * Check to see if there is any immediate RCU-related work to be done by</a>
<a name="3816"><span class="lineNum">    3816 </span>            :  * the current CPU, returning 1 if so and zero otherwise.  The checks are</a>
<a name="3817"><span class="lineNum">    3817 </span>            :  * in order of increasing expense: checks that can be carried out against</a>
<a name="3818"><span class="lineNum">    3818 </span>            :  * CPU-local state are performed first.  However, we must check for CPU</a>
<a name="3819"><span class="lineNum">    3819 </span>            :  * stalls first, else we might not get a chance.</a>
<a name="3820"><span class="lineNum">    3820 </span>            :  */</a>
<a name="3821"><span class="lineNum">    3821 </span><span class="lineCov">      27322 : static int rcu_pending(int user)</span></a>
<a name="3822"><span class="lineNum">    3822 </span>            : {</a>
<a name="3823"><span class="lineNum">    3823 </span><span class="lineCov">      27322 :         bool gp_in_progress;</span></a>
<a name="3824"><span class="lineNum">    3824 </span><span class="lineCov">      27322 :         struct rcu_data *rdp = this_cpu_ptr(&amp;rcu_data);</span></a>
<a name="3825"><span class="lineNum">    3825 </span><span class="lineCov">      27911 :         struct rcu_node *rnp = rdp-&gt;mynode;</span></a>
<a name="3826"><span class="lineNum">    3826 </span>            : </a>
<a name="3827"><span class="lineNum">    3827 </span><span class="lineCov">      55864 :         lockdep_assert_irqs_disabled();</span></a>
<a name="3828"><span class="lineNum">    3828 </span>            : </a>
<a name="3829"><span class="lineNum">    3829 </span>            :         /* Check for CPU stalls, if enabled. */</a>
<a name="3830"><span class="lineNum">    3830 </span><span class="lineCov">      27897 :         check_cpu_stall(rdp);</span></a>
<a name="3831"><span class="lineNum">    3831 </span>            : </a>
<a name="3832"><span class="lineNum">    3832 </span>            :         /* Does this CPU need a deferred NOCB wakeup? */</a>
<a name="3833"><span class="lineNum">    3833 </span><span class="lineCov">      27560 :         if (rcu_nocb_need_deferred_wakeup(rdp))</span></a>
<a name="3834"><span class="lineNum">    3834 </span>            :                 return 1;</a>
<a name="3835"><span class="lineNum">    3835 </span>            : </a>
<a name="3836"><span class="lineNum">    3836 </span>            :         /* Is this a nohz_full CPU in userspace or idle?  (Ignore RCU if so.) */</a>
<a name="3837"><span class="lineNum">    3837 </span><span class="lineCov">      27560 :         if ((user || rcu_is_cpu_rrupt_from_idle()) &amp;&amp; rcu_nohz_full_cpu())</span></a>
<a name="3838"><span class="lineNum">    3838 </span>            :                 return 0;</a>
<a name="3839"><span class="lineNum">    3839 </span>            : </a>
<a name="3840"><span class="lineNum">    3840 </span>            :         /* Is the RCU core waiting for a quiescent state from this CPU? */</a>
<a name="3841"><span class="lineNum">    3841 </span><span class="lineCov">      28053 :         gp_in_progress = rcu_gp_in_progress();</span></a>
<a name="3842"><span class="lineNum">    3842 </span><span class="lineCov">      28053 :         if (rdp-&gt;core_needs_qs &amp;&amp; !rdp-&gt;cpu_no_qs.b.norm &amp;&amp; gp_in_progress)</span></a>
<a name="3843"><span class="lineNum">    3843 </span>            :                 return 1;</a>
<a name="3844"><span class="lineNum">    3844 </span>            : </a>
<a name="3845"><span class="lineNum">    3845 </span>            :         /* Does this CPU have callbacks ready to invoke? */</a>
<a name="3846"><span class="lineNum">    3846 </span><span class="lineCov">      22432 :         if (!rcu_segcblist_is_offloaded(&amp;rdp-&gt;cblist) &amp;&amp;</span></a>
<a name="3847"><span class="lineNum">    3847 </span><span class="lineCov">      22432 :             rcu_segcblist_ready_cbs(&amp;rdp-&gt;cblist))</span></a>
<a name="3848"><span class="lineNum">    3848 </span>            :                 return 1;</a>
<a name="3849"><span class="lineNum">    3849 </span>            : </a>
<a name="3850"><span class="lineNum">    3850 </span>            :         /* Has RCU gone idle with this CPU needing another grace period? */</a>
<a name="3851"><span class="lineNum">    3851 </span><span class="lineCov">      21121 :         if (!gp_in_progress &amp;&amp; rcu_segcblist_is_enabled(&amp;rdp-&gt;cblist) &amp;&amp;</span></a>
<a name="3852"><span class="lineNum">    3852 </span><span class="lineCov">        129 :             !rcu_segcblist_is_offloaded(&amp;rdp-&gt;cblist) &amp;&amp;</span></a>
<a name="3853"><span class="lineNum">    3853 </span><span class="lineCov">        129 :             !rcu_segcblist_restempty(&amp;rdp-&gt;cblist, RCU_NEXT_READY_TAIL))</span></a>
<a name="3854"><span class="lineNum">    3854 </span>            :                 return 1;</a>
<a name="3855"><span class="lineNum">    3855 </span>            : </a>
<a name="3856"><span class="lineNum">    3856 </span>            :         /* Have RCU grace period completed or started?  */</a>
<a name="3857"><span class="lineNum">    3857 </span><span class="lineCov">      21103 :         if (rcu_seq_current(&amp;rnp-&gt;gp_seq) != rdp-&gt;gp_seq ||</span></a>
<a name="3858"><span class="lineNum">    3858 </span><span class="lineCov">      15822 :             unlikely(READ_ONCE(rdp-&gt;gpwrap))) /* outside lock */</span></a>
<a name="3859"><span class="lineNum">    3859 </span><span class="lineCov">       5281 :                 return 1;</span></a>
<a name="3860"><span class="lineNum">    3860 </span>            : </a>
<a name="3861"><span class="lineNum">    3861 </span>            :         /* nothing to do */</a>
<a name="3862"><span class="lineNum">    3862 </span>            :         return 0;</a>
<a name="3863"><span class="lineNum">    3863 </span>            : }</a>
<a name="3864"><span class="lineNum">    3864 </span>            : </a>
<a name="3865"><span class="lineNum">    3865 </span>            : /*</a>
<a name="3866"><span class="lineNum">    3866 </span>            :  * Helper function for rcu_barrier() tracing.  If tracing is disabled,</a>
<a name="3867"><span class="lineNum">    3867 </span>            :  * the compiler is expected to optimize this away.</a>
<a name="3868"><span class="lineNum">    3868 </span>            :  */</a>
<a name="3869"><span class="lineNum">    3869 </span><span class="lineCov">         13 : static void rcu_barrier_trace(const char *s, int cpu, unsigned long done)</span></a>
<a name="3870"><span class="lineNum">    3870 </span>            : {</a>
<a name="3871"><span class="lineNum">    3871 </span><span class="lineCov">         13 :         trace_rcu_barrier(rcu_state.name, s, cpu,</span></a>
<a name="3872"><span class="lineNum">    3872 </span>            :                           atomic_read(&amp;rcu_state.barrier_cpu_count), done);</a>
<a name="3873"><span class="lineNum">    3873 </span><span class="lineCov">          3 : }</span></a>
<a name="3874"><span class="lineNum">    3874 </span>            : </a>
<a name="3875"><span class="lineNum">    3875 </span>            : /*</a>
<a name="3876"><span class="lineNum">    3876 </span>            :  * RCU callback function for rcu_barrier().  If we are last, wake</a>
<a name="3877"><span class="lineNum">    3877 </span>            :  * up the task executing rcu_barrier().</a>
<a name="3878"><span class="lineNum">    3878 </span>            :  *</a>
<a name="3879"><span class="lineNum">    3879 </span>            :  * Note that the value of rcu_state.barrier_sequence must be captured</a>
<a name="3880"><span class="lineNum">    3880 </span>            :  * before the atomic_dec_and_test().  Otherwise, if this CPU is not last,</a>
<a name="3881"><span class="lineNum">    3881 </span>            :  * other CPUs might count the value down to zero before this CPU gets</a>
<a name="3882"><span class="lineNum">    3882 </span>            :  * around to invoking rcu_barrier_trace(), which might result in bogus</a>
<a name="3883"><span class="lineNum">    3883 </span>            :  * data from the next instance of rcu_barrier().</a>
<a name="3884"><span class="lineNum">    3884 </span>            :  */</a>
<a name="3885"><span class="lineNum">    3885 </span><span class="lineCov">          3 : static void rcu_barrier_callback(struct rcu_head *rhp)</span></a>
<a name="3886"><span class="lineNum">    3886 </span>            : {</a>
<a name="3887"><span class="lineNum">    3887 </span><span class="lineCov">          3 :         unsigned long __maybe_unused s = rcu_state.barrier_sequence;</span></a>
<a name="3888"><span class="lineNum">    3888 </span>            : </a>
<a name="3889"><span class="lineNum">    3889 </span><span class="lineCov">          6 :         if (atomic_dec_and_test(&amp;rcu_state.barrier_cpu_count)) {</span></a>
<a name="3890"><span class="lineNum">    3890 </span><span class="lineCov">          1 :                 rcu_barrier_trace(TPS(&quot;LastCB&quot;), -1, s);</span></a>
<a name="3891"><span class="lineNum">    3891 </span><span class="lineCov">          1 :                 complete(&amp;rcu_state.barrier_completion);</span></a>
<a name="3892"><span class="lineNum">    3892 </span>            :         } else {</a>
<a name="3893"><span class="lineNum">    3893 </span><span class="lineCov">          2 :                 rcu_barrier_trace(TPS(&quot;CB&quot;), -1, s);</span></a>
<a name="3894"><span class="lineNum">    3894 </span>            :         }</a>
<a name="3895"><span class="lineNum">    3895 </span><span class="lineCov">          3 : }</span></a>
<a name="3896"><span class="lineNum">    3896 </span>            : </a>
<a name="3897"><span class="lineNum">    3897 </span>            : /*</a>
<a name="3898"><span class="lineNum">    3898 </span>            :  * Called with preemption disabled, and from cross-cpu IRQ context.</a>
<a name="3899"><span class="lineNum">    3899 </span>            :  */</a>
<a name="3900"><span class="lineNum">    3900 </span><span class="lineCov">          3 : static void rcu_barrier_func(void *cpu_in)</span></a>
<a name="3901"><span class="lineNum">    3901 </span>            : {</a>
<a name="3902"><span class="lineNum">    3902 </span><span class="lineCov">          3 :         uintptr_t cpu = (uintptr_t)cpu_in;</span></a>
<a name="3903"><span class="lineNum">    3903 </span><span class="lineCov">          3 :         struct rcu_data *rdp = per_cpu_ptr(&amp;rcu_data, cpu);</span></a>
<a name="3904"><span class="lineNum">    3904 </span>            : </a>
<a name="3905"><span class="lineNum">    3905 </span><span class="lineCov">          3 :         rcu_barrier_trace(TPS(&quot;IRQ&quot;), -1, rcu_state.barrier_sequence);</span></a>
<a name="3906"><span class="lineNum">    3906 </span><span class="lineCov">          3 :         rdp-&gt;barrier_head.func = rcu_barrier_callback;</span></a>
<a name="3907"><span class="lineNum">    3907 </span><span class="lineCov">          3 :         debug_rcu_head_queue(&amp;rdp-&gt;barrier_head);</span></a>
<a name="3908"><span class="lineNum">    3908 </span><span class="lineCov">          3 :         rcu_nocb_lock(rdp);</span></a>
<a name="3909"><span class="lineNum">    3909 </span><span class="lineCov">          3 :         WARN_ON_ONCE(!rcu_nocb_flush_bypass(rdp, NULL, jiffies));</span></a>
<a name="3910"><span class="lineNum">    3910 </span><span class="lineCov">          3 :         if (rcu_segcblist_entrain(&amp;rdp-&gt;cblist, &amp;rdp-&gt;barrier_head)) {</span></a>
<a name="3911"><span class="lineNum">    3911 </span><span class="lineCov">          3 :                 atomic_inc(&amp;rcu_state.barrier_cpu_count);</span></a>
<a name="3912"><span class="lineNum">    3912 </span>            :         } else {</a>
<a name="3913"><span class="lineNum">    3913 </span><span class="lineNoCov">          0 :                 debug_rcu_head_unqueue(&amp;rdp-&gt;barrier_head);</span></a>
<a name="3914"><span class="lineNum">    3914 </span><span class="lineNoCov">          0 :                 rcu_barrier_trace(TPS(&quot;IRQNQ&quot;), -1,</span></a>
<a name="3915"><span class="lineNum">    3915 </span>            :                                   rcu_state.barrier_sequence);</a>
<a name="3916"><span class="lineNum">    3916 </span>            :         }</a>
<a name="3917"><span class="lineNum">    3917 </span><span class="lineCov">          3 :         rcu_nocb_unlock(rdp);</span></a>
<a name="3918"><span class="lineNum">    3918 </span><span class="lineCov">          3 : }</span></a>
<a name="3919"><span class="lineNum">    3919 </span>            : </a>
<a name="3920"><span class="lineNum">    3920 </span>            : /**</a>
<a name="3921"><span class="lineNum">    3921 </span>            :  * rcu_barrier - Wait until all in-flight call_rcu() callbacks complete.</a>
<a name="3922"><span class="lineNum">    3922 </span>            :  *</a>
<a name="3923"><span class="lineNum">    3923 </span>            :  * Note that this primitive does not necessarily wait for an RCU grace period</a>
<a name="3924"><span class="lineNum">    3924 </span>            :  * to complete.  For example, if there are no RCU callbacks queued anywhere</a>
<a name="3925"><span class="lineNum">    3925 </span>            :  * in the system, then rcu_barrier() is within its rights to return</a>
<a name="3926"><span class="lineNum">    3926 </span>            :  * immediately, without waiting for anything, much less an RCU grace period.</a>
<a name="3927"><span class="lineNum">    3927 </span>            :  */</a>
<a name="3928"><span class="lineNum">    3928 </span><span class="lineCov">          1 : void rcu_barrier(void)</span></a>
<a name="3929"><span class="lineNum">    3929 </span>            : {</a>
<a name="3930"><span class="lineNum">    3930 </span><span class="lineCov">          1 :         uintptr_t cpu;</span></a>
<a name="3931"><span class="lineNum">    3931 </span><span class="lineCov">          1 :         struct rcu_data *rdp;</span></a>
<a name="3932"><span class="lineNum">    3932 </span><span class="lineCov">          1 :         unsigned long s = rcu_seq_snap(&amp;rcu_state.barrier_sequence);</span></a>
<a name="3933"><span class="lineNum">    3933 </span>            : </a>
<a name="3934"><span class="lineNum">    3934 </span><span class="lineCov">          1 :         rcu_barrier_trace(TPS(&quot;Begin&quot;), -1, s);</span></a>
<a name="3935"><span class="lineNum">    3935 </span>            : </a>
<a name="3936"><span class="lineNum">    3936 </span>            :         /* Take mutex to serialize concurrent rcu_barrier() requests. */</a>
<a name="3937"><span class="lineNum">    3937 </span><span class="lineCov">          1 :         mutex_lock(&amp;rcu_state.barrier_mutex);</span></a>
<a name="3938"><span class="lineNum">    3938 </span>            : </a>
<a name="3939"><span class="lineNum">    3939 </span>            :         /* Did someone else do our work for us? */</a>
<a name="3940"><span class="lineNum">    3940 </span><span class="lineCov">          1 :         if (rcu_seq_done(&amp;rcu_state.barrier_sequence, s)) {</span></a>
<a name="3941"><span class="lineNum">    3941 </span><span class="lineNoCov">          0 :                 rcu_barrier_trace(TPS(&quot;EarlyExit&quot;), -1,</span></a>
<a name="3942"><span class="lineNum">    3942 </span>            :                                   rcu_state.barrier_sequence);</a>
<a name="3943"><span class="lineNum">    3943 </span><span class="lineNoCov">          0 :                 smp_mb(); /* caller's subsequent code after above check. */</span></a>
<a name="3944"><span class="lineNum">    3944 </span><span class="lineNoCov">          0 :                 mutex_unlock(&amp;rcu_state.barrier_mutex);</span></a>
<a name="3945"><span class="lineNum">    3945 </span><span class="lineNoCov">          0 :                 return;</span></a>
<a name="3946"><span class="lineNum">    3946 </span>            :         }</a>
<a name="3947"><span class="lineNum">    3947 </span>            : </a>
<a name="3948"><span class="lineNum">    3948 </span>            :         /* Mark the start of the barrier operation. */</a>
<a name="3949"><span class="lineNum">    3949 </span><span class="lineCov">          1 :         rcu_seq_start(&amp;rcu_state.barrier_sequence);</span></a>
<a name="3950"><span class="lineNum">    3950 </span><span class="lineCov">          1 :         rcu_barrier_trace(TPS(&quot;Inc1&quot;), -1, rcu_state.barrier_sequence);</span></a>
<a name="3951"><span class="lineNum">    3951 </span>            : </a>
<a name="3952"><span class="lineNum">    3952 </span>            :         /*</a>
<a name="3953"><span class="lineNum">    3953 </span>            :          * Initialize the count to two rather than to zero in order</a>
<a name="3954"><span class="lineNum">    3954 </span>            :          * to avoid a too-soon return to zero in case of an immediate</a>
<a name="3955"><span class="lineNum">    3955 </span>            :          * invocation of the just-enqueued callback (or preemption of</a>
<a name="3956"><span class="lineNum">    3956 </span>            :          * this task).  Exclude CPU-hotplug operations to ensure that no</a>
<a name="3957"><span class="lineNum">    3957 </span>            :          * offline non-offloaded CPU has callbacks queued.</a>
<a name="3958"><span class="lineNum">    3958 </span>            :          */</a>
<a name="3959"><span class="lineNum">    3959 </span><span class="lineCov">          1 :         init_completion(&amp;rcu_state.barrier_completion);</span></a>
<a name="3960"><span class="lineNum">    3960 </span><span class="lineCov">          1 :         atomic_set(&amp;rcu_state.barrier_cpu_count, 2);</span></a>
<a name="3961"><span class="lineNum">    3961 </span><span class="lineCov">          1 :         get_online_cpus();</span></a>
<a name="3962"><span class="lineNum">    3962 </span>            : </a>
<a name="3963"><span class="lineNum">    3963 </span>            :         /*</a>
<a name="3964"><span class="lineNum">    3964 </span>            :          * Force each CPU with callbacks to register a new callback.</a>
<a name="3965"><span class="lineNum">    3965 </span>            :          * When that callback is invoked, we will know that all of the</a>
<a name="3966"><span class="lineNum">    3966 </span>            :          * corresponding CPU's preceding callbacks have been invoked.</a>
<a name="3967"><span class="lineNum">    3967 </span>            :          */</a>
<a name="3968"><span class="lineNum">    3968 </span><span class="lineCov">          6 :         for_each_possible_cpu(cpu) {</span></a>
<a name="3969"><span class="lineNum">    3969 </span><span class="lineCov">          4 :                 rdp = per_cpu_ptr(&amp;rcu_data, cpu);</span></a>
<a name="3970"><span class="lineNum">    3970 </span><span class="lineCov">          4 :                 if (cpu_is_offline(cpu) &amp;&amp;</span></a>
<a name="3971"><span class="lineNum">    3971 </span><span class="lineNoCov">          0 :                     !rcu_segcblist_is_offloaded(&amp;rdp-&gt;cblist))</span></a>
<a name="3972"><span class="lineNum">    3972 </span><span class="lineNoCov">          0 :                         continue;</span></a>
<a name="3973"><span class="lineNum">    3973 </span><span class="lineCov">          4 :                 if (rcu_segcblist_n_cbs(&amp;rdp-&gt;cblist) &amp;&amp; cpu_online(cpu)) {</span></a>
<a name="3974"><span class="lineNum">    3974 </span><span class="lineCov">          3 :                         rcu_barrier_trace(TPS(&quot;OnlineQ&quot;), cpu,</span></a>
<a name="3975"><span class="lineNum">    3975 </span>            :                                           rcu_state.barrier_sequence);</a>
<a name="3976"><span class="lineNum">    3976 </span><span class="lineCov">          3 :                         smp_call_function_single(cpu, rcu_barrier_func, (void *)cpu, 1);</span></a>
<a name="3977"><span class="lineNum">    3977 </span><span class="lineCov">          1 :                 } else if (rcu_segcblist_n_cbs(&amp;rdp-&gt;cblist) &amp;&amp;</span></a>
<a name="3978"><span class="lineNum">    3978 </span><span class="lineNoCov">          0 :                            cpu_is_offline(cpu)) {</span></a>
<a name="3979"><span class="lineNum">    3979 </span><span class="lineNoCov">          0 :                         rcu_barrier_trace(TPS(&quot;OfflineNoCBQ&quot;), cpu,</span></a>
<a name="3980"><span class="lineNum">    3980 </span>            :                                           rcu_state.barrier_sequence);</a>
<a name="3981"><span class="lineNum">    3981 </span><span class="lineNoCov">          0 :                         local_irq_disable();</span></a>
<a name="3982"><span class="lineNum">    3982 </span><span class="lineNoCov">          0 :                         rcu_barrier_func((void *)cpu);</span></a>
<a name="3983"><span class="lineNum">    3983 </span><span class="lineNoCov">          0 :                         local_irq_enable();</span></a>
<a name="3984"><span class="lineNum">    3984 </span><span class="lineCov">          1 :                 } else if (cpu_is_offline(cpu)) {</span></a>
<a name="3985"><span class="lineNum">    3985 </span><span class="lineNoCov">          0 :                         rcu_barrier_trace(TPS(&quot;OfflineNoCBNoQ&quot;), cpu,</span></a>
<a name="3986"><span class="lineNum">    3986 </span>            :                                           rcu_state.barrier_sequence);</a>
<a name="3987"><span class="lineNum">    3987 </span>            :                 } else {</a>
<a name="3988"><span class="lineNum">    3988 </span><span class="lineCov">          6 :                         rcu_barrier_trace(TPS(&quot;OnlineNQ&quot;), cpu,</span></a>
<a name="3989"><span class="lineNum">    3989 </span>            :                                           rcu_state.barrier_sequence);</a>
<a name="3990"><span class="lineNum">    3990 </span>            :                 }</a>
<a name="3991"><span class="lineNum">    3991 </span>            :         }</a>
<a name="3992"><span class="lineNum">    3992 </span><span class="lineCov">          1 :         put_online_cpus();</span></a>
<a name="3993"><span class="lineNum">    3993 </span>            : </a>
<a name="3994"><span class="lineNum">    3994 </span>            :         /*</a>
<a name="3995"><span class="lineNum">    3995 </span>            :          * Now that we have an rcu_barrier_callback() callback on each</a>
<a name="3996"><span class="lineNum">    3996 </span>            :          * CPU, and thus each counted, remove the initial count.</a>
<a name="3997"><span class="lineNum">    3997 </span>            :          */</a>
<a name="3998"><span class="lineNum">    3998 </span><span class="lineCov">          2 :         if (atomic_sub_and_test(2, &amp;rcu_state.barrier_cpu_count))</span></a>
<a name="3999"><span class="lineNum">    3999 </span><span class="lineNoCov">          0 :                 complete(&amp;rcu_state.barrier_completion);</span></a>
<a name="4000"><span class="lineNum">    4000 </span>            : </a>
<a name="4001"><span class="lineNum">    4001 </span>            :         /* Wait for all rcu_barrier_callback() callbacks to be invoked. */</a>
<a name="4002"><span class="lineNum">    4002 </span><span class="lineCov">          1 :         wait_for_completion(&amp;rcu_state.barrier_completion);</span></a>
<a name="4003"><span class="lineNum">    4003 </span>            : </a>
<a name="4004"><span class="lineNum">    4004 </span>            :         /* Mark the end of the barrier operation. */</a>
<a name="4005"><span class="lineNum">    4005 </span><span class="lineCov">          1 :         rcu_barrier_trace(TPS(&quot;Inc2&quot;), -1, rcu_state.barrier_sequence);</span></a>
<a name="4006"><span class="lineNum">    4006 </span><span class="lineCov">          1 :         rcu_seq_end(&amp;rcu_state.barrier_sequence);</span></a>
<a name="4007"><span class="lineNum">    4007 </span>            : </a>
<a name="4008"><span class="lineNum">    4008 </span>            :         /* Other rcu_barrier() invocations can now safely proceed. */</a>
<a name="4009"><span class="lineNum">    4009 </span><span class="lineCov">          1 :         mutex_unlock(&amp;rcu_state.barrier_mutex);</span></a>
<a name="4010"><span class="lineNum">    4010 </span>            : }</a>
<a name="4011"><span class="lineNum">    4011 </span>            : EXPORT_SYMBOL_GPL(rcu_barrier);</a>
<a name="4012"><span class="lineNum">    4012 </span>            : </a>
<a name="4013"><span class="lineNum">    4013 </span>            : /*</a>
<a name="4014"><span class="lineNum">    4014 </span>            :  * Propagate -&gt;qsinitmask bits up the rcu_node tree to account for the</a>
<a name="4015"><span class="lineNum">    4015 </span>            :  * first CPU in a given leaf rcu_node structure coming online.  The caller</a>
<a name="4016"><span class="lineNum">    4016 </span>            :  * must hold the corresponding leaf rcu_node -&gt;lock with interrrupts</a>
<a name="4017"><span class="lineNum">    4017 </span>            :  * disabled.</a>
<a name="4018"><span class="lineNum">    4018 </span>            :  */</a>
<a name="4019"><span class="lineNum">    4019 </span><span class="lineCov">          1 : static void rcu_init_new_rnp(struct rcu_node *rnp_leaf)</span></a>
<a name="4020"><span class="lineNum">    4020 </span>            : {</a>
<a name="4021"><span class="lineNum">    4021 </span><span class="lineCov">          1 :         long mask;</span></a>
<a name="4022"><span class="lineNum">    4022 </span><span class="lineCov">          1 :         long oldmask;</span></a>
<a name="4023"><span class="lineNum">    4023 </span><span class="lineCov">          1 :         struct rcu_node *rnp = rnp_leaf;</span></a>
<a name="4024"><span class="lineNum">    4024 </span>            : </a>
<a name="4025"><span class="lineNum">    4025 </span><span class="lineCov">          2 :         raw_lockdep_assert_held_rcu_node(rnp_leaf);</span></a>
<a name="4026"><span class="lineNum">    4026 </span><span class="lineCov">          1 :         WARN_ON_ONCE(rnp-&gt;wait_blkd_tasks);</span></a>
<a name="4027"><span class="lineNum">    4027 </span><span class="lineCov">          1 :         for (;;) {</span></a>
<a name="4028"><span class="lineNum">    4028 </span><span class="lineCov">          1 :                 mask = rnp-&gt;grpmask;</span></a>
<a name="4029"><span class="lineNum">    4029 </span><span class="lineCov">          1 :                 rnp = rnp-&gt;parent;</span></a>
<a name="4030"><span class="lineNum">    4030 </span><span class="lineCov">          1 :                 if (rnp == NULL)</span></a>
<a name="4031"><span class="lineNum">    4031 </span>            :                         return;</a>
<a name="4032"><span class="lineNum">    4032 </span><span class="lineNoCov">          0 :                 raw_spin_lock_rcu_node(rnp); /* Interrupts already disabled. */</span></a>
<a name="4033"><span class="lineNum">    4033 </span><span class="lineNoCov">          0 :                 oldmask = rnp-&gt;qsmaskinit;</span></a>
<a name="4034"><span class="lineNum">    4034 </span><span class="lineNoCov">          0 :                 rnp-&gt;qsmaskinit |= mask;</span></a>
<a name="4035"><span class="lineNum">    4035 </span><span class="lineNoCov">          0 :                 raw_spin_unlock_rcu_node(rnp); /* Interrupts remain disabled. */</span></a>
<a name="4036"><span class="lineNum">    4036 </span><span class="lineNoCov">          0 :                 if (oldmask)</span></a>
<a name="4037"><span class="lineNum">    4037 </span>            :                         return;</a>
<a name="4038"><span class="lineNum">    4038 </span>            :         }</a>
<a name="4039"><span class="lineNum">    4039 </span>            : }</a>
<a name="4040"><span class="lineNum">    4040 </span>            : </a>
<a name="4041"><span class="lineNum">    4041 </span>            : /*</a>
<a name="4042"><span class="lineNum">    4042 </span>            :  * Do boot-time initialization of a CPU's per-CPU RCU data.</a>
<a name="4043"><span class="lineNum">    4043 </span>            :  */</a>
<a name="4044"><span class="lineNum">    4044 </span>            : static void __init</a>
<a name="4045"><span class="lineNum">    4045 </span><span class="lineCov">          4 : rcu_boot_init_percpu_data(int cpu)</span></a>
<a name="4046"><span class="lineNum">    4046 </span>            : {</a>
<a name="4047"><span class="lineNum">    4047 </span><span class="lineCov">          4 :         struct rcu_data *rdp = per_cpu_ptr(&amp;rcu_data, cpu);</span></a>
<a name="4048"><span class="lineNum">    4048 </span>            : </a>
<a name="4049"><span class="lineNum">    4049 </span>            :         /* Set up local state, ensuring consistent view of global state. */</a>
<a name="4050"><span class="lineNum">    4050 </span><span class="lineCov">          4 :         rdp-&gt;grpmask = leaf_node_cpu_bit(rdp-&gt;mynode, cpu);</span></a>
<a name="4051"><span class="lineNum">    4051 </span><span class="lineCov">          4 :         INIT_WORK(&amp;rdp-&gt;strict_work, strict_work_handler);</span></a>
<a name="4052"><span class="lineNum">    4052 </span><span class="lineCov">          4 :         WARN_ON_ONCE(rdp-&gt;dynticks_nesting != 1);</span></a>
<a name="4053"><span class="lineNum">    4053 </span><span class="lineCov">          4 :         WARN_ON_ONCE(rcu_dynticks_in_eqs(rcu_dynticks_snap(rdp)));</span></a>
<a name="4054"><span class="lineNum">    4054 </span><span class="lineCov">          4 :         rdp-&gt;rcu_ofl_gp_seq = rcu_state.gp_seq;</span></a>
<a name="4055"><span class="lineNum">    4055 </span><span class="lineCov">          4 :         rdp-&gt;rcu_ofl_gp_flags = RCU_GP_CLEANED;</span></a>
<a name="4056"><span class="lineNum">    4056 </span><span class="lineCov">          4 :         rdp-&gt;rcu_onl_gp_seq = rcu_state.gp_seq;</span></a>
<a name="4057"><span class="lineNum">    4057 </span><span class="lineCov">          4 :         rdp-&gt;rcu_onl_gp_flags = RCU_GP_CLEANED;</span></a>
<a name="4058"><span class="lineNum">    4058 </span><span class="lineCov">          4 :         rdp-&gt;cpu = cpu;</span></a>
<a name="4059"><span class="lineNum">    4059 </span><span class="lineCov">          4 :         rcu_boot_init_nocb_percpu_data(rdp);</span></a>
<a name="4060"><span class="lineNum">    4060 </span><span class="lineCov">          4 : }</span></a>
<a name="4061"><span class="lineNum">    4061 </span>            : </a>
<a name="4062"><span class="lineNum">    4062 </span>            : /*</a>
<a name="4063"><span class="lineNum">    4063 </span>            :  * Invoked early in the CPU-online process, when pretty much all services</a>
<a name="4064"><span class="lineNum">    4064 </span>            :  * are available.  The incoming CPU is not present.</a>
<a name="4065"><span class="lineNum">    4065 </span>            :  *</a>
<a name="4066"><span class="lineNum">    4066 </span>            :  * Initializes a CPU's per-CPU RCU data.  Note that only one online or</a>
<a name="4067"><span class="lineNum">    4067 </span>            :  * offline event can be happening at a given time.  Note also that we can</a>
<a name="4068"><span class="lineNum">    4068 </span>            :  * accept some slop in the rsp-&gt;gp_seq access due to the fact that this</a>
<a name="4069"><span class="lineNum">    4069 </span>            :  * CPU cannot possibly have any non-offloaded RCU callbacks in flight yet.</a>
<a name="4070"><span class="lineNum">    4070 </span>            :  * And any offloaded callbacks are being numbered elsewhere.</a>
<a name="4071"><span class="lineNum">    4071 </span>            :  */</a>
<a name="4072"><span class="lineNum">    4072 </span><span class="lineCov">          4 : int rcutree_prepare_cpu(unsigned int cpu)</span></a>
<a name="4073"><span class="lineNum">    4073 </span>            : {</a>
<a name="4074"><span class="lineNum">    4074 </span><span class="lineCov">          4 :         unsigned long flags;</span></a>
<a name="4075"><span class="lineNum">    4075 </span><span class="lineCov">          4 :         struct rcu_data *rdp = per_cpu_ptr(&amp;rcu_data, cpu);</span></a>
<a name="4076"><span class="lineNum">    4076 </span><span class="lineCov">          4 :         struct rcu_node *rnp = rcu_get_root();</span></a>
<a name="4077"><span class="lineNum">    4077 </span>            : </a>
<a name="4078"><span class="lineNum">    4078 </span>            :         /* Set up local state, ensuring consistent view of global state. */</a>
<a name="4079"><span class="lineNum">    4079 </span><span class="lineCov">          4 :         raw_spin_lock_irqsave_rcu_node(rnp, flags);</span></a>
<a name="4080"><span class="lineNum">    4080 </span><span class="lineCov">          4 :         rdp-&gt;qlen_last_fqs_check = 0;</span></a>
<a name="4081"><span class="lineNum">    4081 </span><span class="lineCov">          4 :         rdp-&gt;n_force_qs_snap = rcu_state.n_force_qs;</span></a>
<a name="4082"><span class="lineNum">    4082 </span><span class="lineCov">          4 :         rdp-&gt;blimit = blimit;</span></a>
<a name="4083"><span class="lineNum">    4083 </span><span class="lineCov">          4 :         rdp-&gt;dynticks_nesting = 1;   /* CPU not up, no tearing. */</span></a>
<a name="4084"><span class="lineNum">    4084 </span><span class="lineCov">          4 :         rcu_dynticks_eqs_online();</span></a>
<a name="4085"><span class="lineNum">    4085 </span><span class="lineCov">          8 :         raw_spin_unlock_rcu_node(rnp);          /* irqs remain disabled. */</span></a>
<a name="4086"><span class="lineNum">    4086 </span>            :         /*</a>
<a name="4087"><span class="lineNum">    4087 </span>            :          * Lock in case the CB/GP kthreads are still around handling</a>
<a name="4088"><span class="lineNum">    4088 </span>            :          * old callbacks (longer term we should flush all callbacks</a>
<a name="4089"><span class="lineNum">    4089 </span>            :          * before completing CPU offline)</a>
<a name="4090"><span class="lineNum">    4090 </span>            :          */</a>
<a name="4091"><span class="lineNum">    4091 </span><span class="lineCov">          4 :         rcu_nocb_lock(rdp);</span></a>
<a name="4092"><span class="lineNum">    4092 </span><span class="lineCov">          4 :         if (rcu_segcblist_empty(&amp;rdp-&gt;cblist)) /* No early-boot CBs? */</span></a>
<a name="4093"><span class="lineNum">    4093 </span><span class="lineCov">          3 :                 rcu_segcblist_init(&amp;rdp-&gt;cblist);  /* Re-enable callbacks. */</span></a>
<a name="4094"><span class="lineNum">    4094 </span><span class="lineCov">          4 :         rcu_nocb_unlock(rdp);</span></a>
<a name="4095"><span class="lineNum">    4095 </span>            : </a>
<a name="4096"><span class="lineNum">    4096 </span>            :         /*</a>
<a name="4097"><span class="lineNum">    4097 </span>            :          * Add CPU to leaf rcu_node pending-online bitmask.  Any needed</a>
<a name="4098"><span class="lineNum">    4098 </span>            :          * propagation up the rcu_node tree will happen at the beginning</a>
<a name="4099"><span class="lineNum">    4099 </span>            :          * of the next grace period.</a>
<a name="4100"><span class="lineNum">    4100 </span>            :          */</a>
<a name="4101"><span class="lineNum">    4101 </span><span class="lineCov">          4 :         rnp = rdp-&gt;mynode;</span></a>
<a name="4102"><span class="lineNum">    4102 </span><span class="lineCov">          4 :         raw_spin_lock_rcu_node(rnp);            /* irqs already disabled. */</span></a>
<a name="4103"><span class="lineNum">    4103 </span><span class="lineCov">          4 :         rdp-&gt;beenonline = true;       /* We have now been online. */</span></a>
<a name="4104"><span class="lineNum">    4104 </span><span class="lineCov">          4 :         rdp-&gt;gp_seq = READ_ONCE(rnp-&gt;gp_seq);</span></a>
<a name="4105"><span class="lineNum">    4105 </span><span class="lineCov">          4 :         rdp-&gt;gp_seq_needed = rdp-&gt;gp_seq;</span></a>
<a name="4106"><span class="lineNum">    4106 </span><span class="lineCov">          4 :         rdp-&gt;cpu_no_qs.b.norm = true;</span></a>
<a name="4107"><span class="lineNum">    4107 </span><span class="lineCov">          4 :         rdp-&gt;core_needs_qs = false;</span></a>
<a name="4108"><span class="lineNum">    4108 </span><span class="lineCov">          4 :         rdp-&gt;rcu_iw_pending = false;</span></a>
<a name="4109"><span class="lineNum">    4109 </span><span class="lineCov">          4 :         rdp-&gt;rcu_iw = IRQ_WORK_INIT_HARD(rcu_iw_handler);</span></a>
<a name="4110"><span class="lineNum">    4110 </span><span class="lineCov">          4 :         rdp-&gt;rcu_iw_gp_seq = rdp-&gt;gp_seq - 1;</span></a>
<a name="4111"><span class="lineNum">    4111 </span><span class="lineCov">          4 :         trace_rcu_grace_period(rcu_state.name, rdp-&gt;gp_seq, TPS(&quot;cpuonl&quot;));</span></a>
<a name="4112"><span class="lineNum">    4112 </span><span class="lineCov">          8 :         raw_spin_unlock_irqrestore_rcu_node(rnp, flags);</span></a>
<a name="4113"><span class="lineNum">    4113 </span><span class="lineCov">          4 :         rcu_prepare_kthreads(cpu);</span></a>
<a name="4114"><span class="lineNum">    4114 </span><span class="lineCov">          4 :         rcu_spawn_cpu_nocb_kthread(cpu);</span></a>
<a name="4115"><span class="lineNum">    4115 </span><span class="lineCov">          4 :         WRITE_ONCE(rcu_state.n_online_cpus, rcu_state.n_online_cpus + 1);</span></a>
<a name="4116"><span class="lineNum">    4116 </span>            : </a>
<a name="4117"><span class="lineNum">    4117 </span><span class="lineCov">          4 :         return 0;</span></a>
<a name="4118"><span class="lineNum">    4118 </span>            : }</a>
<a name="4119"><span class="lineNum">    4119 </span>            : </a>
<a name="4120"><span class="lineNum">    4120 </span>            : /*</a>
<a name="4121"><span class="lineNum">    4121 </span>            :  * Update RCU priority boot kthread affinity for CPU-hotplug changes.</a>
<a name="4122"><span class="lineNum">    4122 </span>            :  */</a>
<a name="4123"><span class="lineNum">    4123 </span><span class="lineCov">          3 : static void rcutree_affinity_setting(unsigned int cpu, int outgoing)</span></a>
<a name="4124"><span class="lineNum">    4124 </span>            : {</a>
<a name="4125"><span class="lineNum">    4125 </span><span class="lineCov">          3 :         struct rcu_data *rdp = per_cpu_ptr(&amp;rcu_data, cpu);</span></a>
<a name="4126"><span class="lineNum">    4126 </span>            : </a>
<a name="4127"><span class="lineNum">    4127 </span><span class="lineCov">          3 :         rcu_boost_kthread_setaffinity(rdp-&gt;mynode, outgoing);</span></a>
<a name="4128"><span class="lineNum">    4128 </span>            : }</a>
<a name="4129"><span class="lineNum">    4129 </span>            : </a>
<a name="4130"><span class="lineNum">    4130 </span>            : /*</a>
<a name="4131"><span class="lineNum">    4131 </span>            :  * Near the end of the CPU-online process.  Pretty much all services</a>
<a name="4132"><span class="lineNum">    4132 </span>            :  * enabled, and the CPU is now very much alive.</a>
<a name="4133"><span class="lineNum">    4133 </span>            :  */</a>
<a name="4134"><span class="lineNum">    4134 </span><span class="lineCov">          4 : int rcutree_online_cpu(unsigned int cpu)</span></a>
<a name="4135"><span class="lineNum">    4135 </span>            : {</a>
<a name="4136"><span class="lineNum">    4136 </span><span class="lineCov">          4 :         unsigned long flags;</span></a>
<a name="4137"><span class="lineNum">    4137 </span><span class="lineCov">          4 :         struct rcu_data *rdp;</span></a>
<a name="4138"><span class="lineNum">    4138 </span><span class="lineCov">          4 :         struct rcu_node *rnp;</span></a>
<a name="4139"><span class="lineNum">    4139 </span>            : </a>
<a name="4140"><span class="lineNum">    4140 </span><span class="lineCov">          4 :         rdp = per_cpu_ptr(&amp;rcu_data, cpu);</span></a>
<a name="4141"><span class="lineNum">    4141 </span><span class="lineCov">          4 :         rnp = rdp-&gt;mynode;</span></a>
<a name="4142"><span class="lineNum">    4142 </span><span class="lineCov">          4 :         raw_spin_lock_irqsave_rcu_node(rnp, flags);</span></a>
<a name="4143"><span class="lineNum">    4143 </span><span class="lineCov">          4 :         rnp-&gt;ffmask |= rdp-&gt;grpmask;</span></a>
<a name="4144"><span class="lineNum">    4144 </span><span class="lineCov">          8 :         raw_spin_unlock_irqrestore_rcu_node(rnp, flags);</span></a>
<a name="4145"><span class="lineNum">    4145 </span><span class="lineCov">          4 :         if (rcu_scheduler_active == RCU_SCHEDULER_INACTIVE)</span></a>
<a name="4146"><span class="lineNum">    4146 </span>            :                 return 0; /* Too early in boot for scheduler work. */</a>
<a name="4147"><span class="lineNum">    4147 </span><span class="lineCov">          3 :         sync_sched_exp_online_cleanup(cpu);</span></a>
<a name="4148"><span class="lineNum">    4148 </span><span class="lineCov">          3 :         rcutree_affinity_setting(cpu, -1);</span></a>
<a name="4149"><span class="lineNum">    4149 </span>            : </a>
<a name="4150"><span class="lineNum">    4150 </span>            :         // Stop-machine done, so allow nohz_full to disable tick.</a>
<a name="4151"><span class="lineNum">    4151 </span><span class="lineCov">          3 :         tick_dep_clear(TICK_DEP_BIT_RCU);</span></a>
<a name="4152"><span class="lineNum">    4152 </span><span class="lineCov">          3 :         return 0;</span></a>
<a name="4153"><span class="lineNum">    4153 </span>            : }</a>
<a name="4154"><span class="lineNum">    4154 </span>            : </a>
<a name="4155"><span class="lineNum">    4155 </span>            : /*</a>
<a name="4156"><span class="lineNum">    4156 </span>            :  * Near the beginning of the process.  The CPU is still very much alive</a>
<a name="4157"><span class="lineNum">    4157 </span>            :  * with pretty much all services enabled.</a>
<a name="4158"><span class="lineNum">    4158 </span>            :  */</a>
<a name="4159"><span class="lineNum">    4159 </span><span class="lineNoCov">          0 : int rcutree_offline_cpu(unsigned int cpu)</span></a>
<a name="4160"><span class="lineNum">    4160 </span>            : {</a>
<a name="4161"><span class="lineNum">    4161 </span><span class="lineNoCov">          0 :         unsigned long flags;</span></a>
<a name="4162"><span class="lineNum">    4162 </span><span class="lineNoCov">          0 :         struct rcu_data *rdp;</span></a>
<a name="4163"><span class="lineNum">    4163 </span><span class="lineNoCov">          0 :         struct rcu_node *rnp;</span></a>
<a name="4164"><span class="lineNum">    4164 </span>            : </a>
<a name="4165"><span class="lineNum">    4165 </span><span class="lineNoCov">          0 :         rdp = per_cpu_ptr(&amp;rcu_data, cpu);</span></a>
<a name="4166"><span class="lineNum">    4166 </span><span class="lineNoCov">          0 :         rnp = rdp-&gt;mynode;</span></a>
<a name="4167"><span class="lineNum">    4167 </span><span class="lineNoCov">          0 :         raw_spin_lock_irqsave_rcu_node(rnp, flags);</span></a>
<a name="4168"><span class="lineNum">    4168 </span><span class="lineNoCov">          0 :         rnp-&gt;ffmask &amp;= ~rdp-&gt;grpmask;</span></a>
<a name="4169"><span class="lineNum">    4169 </span><span class="lineNoCov">          0 :         raw_spin_unlock_irqrestore_rcu_node(rnp, flags);</span></a>
<a name="4170"><span class="lineNum">    4170 </span>            : </a>
<a name="4171"><span class="lineNum">    4171 </span><span class="lineNoCov">          0 :         rcutree_affinity_setting(cpu, cpu);</span></a>
<a name="4172"><span class="lineNum">    4172 </span>            : </a>
<a name="4173"><span class="lineNum">    4173 </span>            :         // nohz_full CPUs need the tick for stop-machine to work quickly</a>
<a name="4174"><span class="lineNum">    4174 </span><span class="lineNoCov">          0 :         tick_dep_set(TICK_DEP_BIT_RCU);</span></a>
<a name="4175"><span class="lineNum">    4175 </span><span class="lineNoCov">          0 :         return 0;</span></a>
<a name="4176"><span class="lineNum">    4176 </span>            : }</a>
<a name="4177"><span class="lineNum">    4177 </span>            : </a>
<a name="4178"><span class="lineNum">    4178 </span>            : /*</a>
<a name="4179"><span class="lineNum">    4179 </span>            :  * Mark the specified CPU as being online so that subsequent grace periods</a>
<a name="4180"><span class="lineNum">    4180 </span>            :  * (both expedited and normal) will wait on it.  Note that this means that</a>
<a name="4181"><span class="lineNum">    4181 </span>            :  * incoming CPUs are not allowed to use RCU read-side critical sections</a>
<a name="4182"><span class="lineNum">    4182 </span>            :  * until this function is called.  Failing to observe this restriction</a>
<a name="4183"><span class="lineNum">    4183 </span>            :  * will result in lockdep splats.</a>
<a name="4184"><span class="lineNum">    4184 </span>            :  *</a>
<a name="4185"><span class="lineNum">    4185 </span>            :  * Note that this function is special in that it is invoked directly</a>
<a name="4186"><span class="lineNum">    4186 </span>            :  * from the incoming CPU rather than from the cpuhp_step mechanism.</a>
<a name="4187"><span class="lineNum">    4187 </span>            :  * This is because this function must be invoked at a precise location.</a>
<a name="4188"><span class="lineNum">    4188 </span>            :  */</a>
<a name="4189"><span class="lineNum">    4189 </span><span class="lineCov">          7 : void rcu_cpu_starting(unsigned int cpu)</span></a>
<a name="4190"><span class="lineNum">    4190 </span>            : {</a>
<a name="4191"><span class="lineNum">    4191 </span><span class="lineCov">          7 :         unsigned long flags;</span></a>
<a name="4192"><span class="lineNum">    4192 </span><span class="lineCov">          7 :         unsigned long mask;</span></a>
<a name="4193"><span class="lineNum">    4193 </span><span class="lineCov">          7 :         struct rcu_data *rdp;</span></a>
<a name="4194"><span class="lineNum">    4194 </span><span class="lineCov">          7 :         struct rcu_node *rnp;</span></a>
<a name="4195"><span class="lineNum">    4195 </span><span class="lineCov">          7 :         bool newcpu;</span></a>
<a name="4196"><span class="lineNum">    4196 </span>            : </a>
<a name="4197"><span class="lineNum">    4197 </span><span class="lineCov">          7 :         rdp = per_cpu_ptr(&amp;rcu_data, cpu);</span></a>
<a name="4198"><span class="lineNum">    4198 </span><span class="lineCov">          7 :         if (rdp-&gt;cpu_started)</span></a>
<a name="4199"><span class="lineNum">    4199 </span>            :                 return;</a>
<a name="4200"><span class="lineNum">    4200 </span><span class="lineCov">          4 :         rdp-&gt;cpu_started = true;</span></a>
<a name="4201"><span class="lineNum">    4201 </span>            : </a>
<a name="4202"><span class="lineNum">    4202 </span><span class="lineCov">          4 :         rnp = rdp-&gt;mynode;</span></a>
<a name="4203"><span class="lineNum">    4203 </span><span class="lineCov">          4 :         mask = rdp-&gt;grpmask;</span></a>
<a name="4204"><span class="lineNum">    4204 </span><span class="lineCov">          4 :         WRITE_ONCE(rnp-&gt;ofl_seq, rnp-&gt;ofl_seq + 1);</span></a>
<a name="4205"><span class="lineNum">    4205 </span><span class="lineCov">          4 :         WARN_ON_ONCE(!(rnp-&gt;ofl_seq &amp; 0x1));</span></a>
<a name="4206"><span class="lineNum">    4206 </span><span class="lineCov">          4 :         smp_mb(); // Pair with rcu_gp_cleanup()'s -&gt;ofl_seq barrier().</span></a>
<a name="4207"><span class="lineNum">    4207 </span><span class="lineCov">          4 :         raw_spin_lock_irqsave_rcu_node(rnp, flags);</span></a>
<a name="4208"><span class="lineNum">    4208 </span><span class="lineCov">          4 :         WRITE_ONCE(rnp-&gt;qsmaskinitnext, rnp-&gt;qsmaskinitnext | mask);</span></a>
<a name="4209"><span class="lineNum">    4209 </span><span class="lineCov">          4 :         newcpu = !(rnp-&gt;expmaskinitnext &amp; mask);</span></a>
<a name="4210"><span class="lineNum">    4210 </span><span class="lineCov">          4 :         rnp-&gt;expmaskinitnext |= mask;</span></a>
<a name="4211"><span class="lineNum">    4211 </span>            :         /* Allow lockless access for expedited grace periods. */</a>
<a name="4212"><span class="lineNum">    4212 </span><span class="lineCov">          4 :         smp_store_release(&amp;rcu_state.ncpus, rcu_state.ncpus + newcpu); /* ^^^ */</span></a>
<a name="4213"><span class="lineNum">    4213 </span><span class="lineCov">          4 :         ASSERT_EXCLUSIVE_WRITER(rcu_state.ncpus);</span></a>
<a name="4214"><span class="lineNum">    4214 </span><span class="lineCov">          4 :         rcu_gpnum_ovf(rnp, rdp); /* Offline-induced counter wrap? */</span></a>
<a name="4215"><span class="lineNum">    4215 </span><span class="lineCov">          4 :         rdp-&gt;rcu_onl_gp_seq = READ_ONCE(rcu_state.gp_seq);</span></a>
<a name="4216"><span class="lineNum">    4216 </span><span class="lineCov">          4 :         rdp-&gt;rcu_onl_gp_flags = READ_ONCE(rcu_state.gp_flags);</span></a>
<a name="4217"><span class="lineNum">    4217 </span>            : </a>
<a name="4218"><span class="lineNum">    4218 </span>            :         /* An incoming CPU should never be blocking a grace period. */</a>
<a name="4219"><span class="lineNum">    4219 </span><span class="lineCov">          4 :         if (WARN_ON_ONCE(rnp-&gt;qsmask &amp; mask)) { /* RCU waiting on incoming CPU? */</span></a>
<a name="4220"><span class="lineNum">    4220 </span><span class="lineNoCov">          0 :                 rcu_disable_urgency_upon_qs(rdp);</span></a>
<a name="4221"><span class="lineNum">    4221 </span>            :                 /* Report QS -after- changing -&gt;qsmaskinitnext! */</a>
<a name="4222"><span class="lineNum">    4222 </span><span class="lineNoCov">          0 :                 rcu_report_qs_rnp(mask, rnp, rnp-&gt;gp_seq, flags);</span></a>
<a name="4223"><span class="lineNum">    4223 </span>            :         } else {</a>
<a name="4224"><span class="lineNum">    4224 </span><span class="lineCov">          8 :                 raw_spin_unlock_irqrestore_rcu_node(rnp, flags);</span></a>
<a name="4225"><span class="lineNum">    4225 </span>            :         }</a>
<a name="4226"><span class="lineNum">    4226 </span><span class="lineCov">          4 :         smp_mb(); // Pair with rcu_gp_cleanup()'s -&gt;ofl_seq barrier().</span></a>
<a name="4227"><span class="lineNum">    4227 </span><span class="lineCov">          4 :         WRITE_ONCE(rnp-&gt;ofl_seq, rnp-&gt;ofl_seq + 1);</span></a>
<a name="4228"><span class="lineNum">    4228 </span><span class="lineCov">          4 :         WARN_ON_ONCE(rnp-&gt;ofl_seq &amp; 0x1);</span></a>
<a name="4229"><span class="lineNum">    4229 </span><span class="lineCov">          4 :         smp_mb(); /* Ensure RCU read-side usage follows above initialization. */</span></a>
<a name="4230"><span class="lineNum">    4230 </span>            : }</a>
<a name="4231"><span class="lineNum">    4231 </span>            : </a>
<a name="4232"><span class="lineNum">    4232 </span>            : /*</a>
<a name="4233"><span class="lineNum">    4233 </span>            :  * The outgoing function has no further need of RCU, so remove it from</a>
<a name="4234"><span class="lineNum">    4234 </span>            :  * the rcu_node tree's -&gt;qsmaskinitnext bit masks.</a>
<a name="4235"><span class="lineNum">    4235 </span>            :  *</a>
<a name="4236"><span class="lineNum">    4236 </span>            :  * Note that this function is special in that it is invoked directly</a>
<a name="4237"><span class="lineNum">    4237 </span>            :  * from the outgoing CPU rather than from the cpuhp_step mechanism.</a>
<a name="4238"><span class="lineNum">    4238 </span>            :  * This is because this function must be invoked at a precise location.</a>
<a name="4239"><span class="lineNum">    4239 </span>            :  */</a>
<a name="4240"><span class="lineNum">    4240 </span><span class="lineNoCov">          0 : void rcu_report_dead(unsigned int cpu)</span></a>
<a name="4241"><span class="lineNum">    4241 </span>            : {</a>
<a name="4242"><span class="lineNum">    4242 </span><span class="lineNoCov">          0 :         unsigned long flags;</span></a>
<a name="4243"><span class="lineNum">    4243 </span><span class="lineNoCov">          0 :         unsigned long mask;</span></a>
<a name="4244"><span class="lineNum">    4244 </span><span class="lineNoCov">          0 :         struct rcu_data *rdp = per_cpu_ptr(&amp;rcu_data, cpu);</span></a>
<a name="4245"><span class="lineNum">    4245 </span><span class="lineNoCov">          0 :         struct rcu_node *rnp = rdp-&gt;mynode;  /* Outgoing CPU's rdp &amp; rnp. */</span></a>
<a name="4246"><span class="lineNum">    4246 </span>            : </a>
<a name="4247"><span class="lineNum">    4247 </span>            :         // Do any dangling deferred wakeups.</a>
<a name="4248"><span class="lineNum">    4248 </span><span class="lineNoCov">          0 :         do_nocb_deferred_wakeup(rdp);</span></a>
<a name="4249"><span class="lineNum">    4249 </span>            : </a>
<a name="4250"><span class="lineNum">    4250 </span>            :         /* QS for any half-done expedited grace period. */</a>
<a name="4251"><span class="lineNum">    4251 </span><span class="lineNoCov">          0 :         preempt_disable();</span></a>
<a name="4252"><span class="lineNum">    4252 </span><span class="lineNoCov">          0 :         rcu_report_exp_rdp(this_cpu_ptr(&amp;rcu_data));</span></a>
<a name="4253"><span class="lineNum">    4253 </span><span class="lineNoCov">          0 :         preempt_enable();</span></a>
<a name="4254"><span class="lineNum">    4254 </span><span class="lineNoCov">          0 :         rcu_preempt_deferred_qs(current);</span></a>
<a name="4255"><span class="lineNum">    4255 </span>            : </a>
<a name="4256"><span class="lineNum">    4256 </span>            :         /* Remove outgoing CPU from mask in the leaf rcu_node structure. */</a>
<a name="4257"><span class="lineNum">    4257 </span><span class="lineNoCov">          0 :         mask = rdp-&gt;grpmask;</span></a>
<a name="4258"><span class="lineNum">    4258 </span><span class="lineNoCov">          0 :         WRITE_ONCE(rnp-&gt;ofl_seq, rnp-&gt;ofl_seq + 1);</span></a>
<a name="4259"><span class="lineNum">    4259 </span><span class="lineNoCov">          0 :         WARN_ON_ONCE(!(rnp-&gt;ofl_seq &amp; 0x1));</span></a>
<a name="4260"><span class="lineNum">    4260 </span><span class="lineNoCov">          0 :         smp_mb(); // Pair with rcu_gp_cleanup()'s -&gt;ofl_seq barrier().</span></a>
<a name="4261"><span class="lineNum">    4261 </span><span class="lineNoCov">          0 :         raw_spin_lock(&amp;rcu_state.ofl_lock);</span></a>
<a name="4262"><span class="lineNum">    4262 </span><span class="lineNoCov">          0 :         raw_spin_lock_irqsave_rcu_node(rnp, flags); /* Enforce GP memory-order guarantee. */</span></a>
<a name="4263"><span class="lineNum">    4263 </span><span class="lineNoCov">          0 :         rdp-&gt;rcu_ofl_gp_seq = READ_ONCE(rcu_state.gp_seq);</span></a>
<a name="4264"><span class="lineNum">    4264 </span><span class="lineNoCov">          0 :         rdp-&gt;rcu_ofl_gp_flags = READ_ONCE(rcu_state.gp_flags);</span></a>
<a name="4265"><span class="lineNum">    4265 </span><span class="lineNoCov">          0 :         if (rnp-&gt;qsmask &amp; mask) { /* RCU waiting on outgoing CPU? */</span></a>
<a name="4266"><span class="lineNum">    4266 </span>            :                 /* Report quiescent state -before- changing -&gt;qsmaskinitnext! */</a>
<a name="4267"><span class="lineNum">    4267 </span><span class="lineNoCov">          0 :                 rcu_report_qs_rnp(mask, rnp, rnp-&gt;gp_seq, flags);</span></a>
<a name="4268"><span class="lineNum">    4268 </span><span class="lineNoCov">          0 :                 raw_spin_lock_irqsave_rcu_node(rnp, flags);</span></a>
<a name="4269"><span class="lineNum">    4269 </span>            :         }</a>
<a name="4270"><span class="lineNum">    4270 </span><span class="lineNoCov">          0 :         WRITE_ONCE(rnp-&gt;qsmaskinitnext, rnp-&gt;qsmaskinitnext &amp; ~mask);</span></a>
<a name="4271"><span class="lineNum">    4271 </span><span class="lineNoCov">          0 :         raw_spin_unlock_irqrestore_rcu_node(rnp, flags);</span></a>
<a name="4272"><span class="lineNum">    4272 </span><span class="lineNoCov">          0 :         raw_spin_unlock(&amp;rcu_state.ofl_lock);</span></a>
<a name="4273"><span class="lineNum">    4273 </span><span class="lineNoCov">          0 :         smp_mb(); // Pair with rcu_gp_cleanup()'s -&gt;ofl_seq barrier().</span></a>
<a name="4274"><span class="lineNum">    4274 </span><span class="lineNoCov">          0 :         WRITE_ONCE(rnp-&gt;ofl_seq, rnp-&gt;ofl_seq + 1);</span></a>
<a name="4275"><span class="lineNum">    4275 </span><span class="lineNoCov">          0 :         WARN_ON_ONCE(rnp-&gt;ofl_seq &amp; 0x1);</span></a>
<a name="4276"><span class="lineNum">    4276 </span>            : </a>
<a name="4277"><span class="lineNum">    4277 </span><span class="lineNoCov">          0 :         rdp-&gt;cpu_started = false;</span></a>
<a name="4278"><span class="lineNum">    4278 </span><span class="lineNoCov">          0 : }</span></a>
<a name="4279"><span class="lineNum">    4279 </span>            : </a>
<a name="4280"><span class="lineNum">    4280 </span>            : #ifdef CONFIG_HOTPLUG_CPU</a>
<a name="4281"><span class="lineNum">    4281 </span>            : /*</a>
<a name="4282"><span class="lineNum">    4282 </span>            :  * The outgoing CPU has just passed through the dying-idle state, and we</a>
<a name="4283"><span class="lineNum">    4283 </span>            :  * are being invoked from the CPU that was IPIed to continue the offline</a>
<a name="4284"><span class="lineNum">    4284 </span>            :  * operation.  Migrate the outgoing CPU's callbacks to the current CPU.</a>
<a name="4285"><span class="lineNum">    4285 </span>            :  */</a>
<a name="4286"><span class="lineNum">    4286 </span><span class="lineNoCov">          0 : void rcutree_migrate_callbacks(int cpu)</span></a>
<a name="4287"><span class="lineNum">    4287 </span>            : {</a>
<a name="4288"><span class="lineNum">    4288 </span><span class="lineNoCov">          0 :         unsigned long flags;</span></a>
<a name="4289"><span class="lineNum">    4289 </span><span class="lineNoCov">          0 :         struct rcu_data *my_rdp;</span></a>
<a name="4290"><span class="lineNum">    4290 </span><span class="lineNoCov">          0 :         struct rcu_node *my_rnp;</span></a>
<a name="4291"><span class="lineNum">    4291 </span><span class="lineNoCov">          0 :         struct rcu_data *rdp = per_cpu_ptr(&amp;rcu_data, cpu);</span></a>
<a name="4292"><span class="lineNum">    4292 </span><span class="lineNoCov">          0 :         bool needwake;</span></a>
<a name="4293"><span class="lineNum">    4293 </span>            : </a>
<a name="4294"><span class="lineNum">    4294 </span><span class="lineNoCov">          0 :         if (rcu_segcblist_is_offloaded(&amp;rdp-&gt;cblist) ||</span></a>
<a name="4295"><span class="lineNum">    4295 </span><span class="lineNoCov">          0 :             rcu_segcblist_empty(&amp;rdp-&gt;cblist))</span></a>
<a name="4296"><span class="lineNum">    4296 </span>            :                 return;  /* No callbacks to migrate. */</a>
<a name="4297"><span class="lineNum">    4297 </span>            : </a>
<a name="4298"><span class="lineNum">    4298 </span><span class="lineNoCov">          0 :         local_irq_save(flags);</span></a>
<a name="4299"><span class="lineNum">    4299 </span><span class="lineNoCov">          0 :         my_rdp = this_cpu_ptr(&amp;rcu_data);</span></a>
<a name="4300"><span class="lineNum">    4300 </span><span class="lineNoCov">          0 :         my_rnp = my_rdp-&gt;mynode;</span></a>
<a name="4301"><span class="lineNum">    4301 </span><span class="lineNoCov">          0 :         rcu_nocb_lock(my_rdp); /* irqs already disabled. */</span></a>
<a name="4302"><span class="lineNum">    4302 </span><span class="lineNoCov">          0 :         WARN_ON_ONCE(!rcu_nocb_flush_bypass(my_rdp, NULL, jiffies));</span></a>
<a name="4303"><span class="lineNum">    4303 </span><span class="lineNoCov">          0 :         raw_spin_lock_rcu_node(my_rnp); /* irqs already disabled. */</span></a>
<a name="4304"><span class="lineNum">    4304 </span>            :         /* Leverage recent GPs and set GP for new callbacks. */</a>
<a name="4305"><span class="lineNum">    4305 </span><span class="lineNoCov">          0 :         needwake = rcu_advance_cbs(my_rnp, rdp) ||</span></a>
<a name="4306"><span class="lineNum">    4306 </span><span class="lineNoCov">          0 :                    rcu_advance_cbs(my_rnp, my_rdp);</span></a>
<a name="4307"><span class="lineNum">    4307 </span><span class="lineNoCov">          0 :         rcu_segcblist_merge(&amp;my_rdp-&gt;cblist, &amp;rdp-&gt;cblist);</span></a>
<a name="4308"><span class="lineNum">    4308 </span><span class="lineNoCov">          0 :         needwake = needwake || rcu_advance_cbs(my_rnp, my_rdp);</span></a>
<a name="4309"><span class="lineNum">    4309 </span><span class="lineNoCov">          0 :         rcu_segcblist_disable(&amp;rdp-&gt;cblist);</span></a>
<a name="4310"><span class="lineNum">    4310 </span><span class="lineNoCov">          0 :         WARN_ON_ONCE(rcu_segcblist_empty(&amp;my_rdp-&gt;cblist) !=</span></a>
<a name="4311"><span class="lineNum">    4311 </span>            :                      !rcu_segcblist_n_cbs(&amp;my_rdp-&gt;cblist));</a>
<a name="4312"><span class="lineNum">    4312 </span><span class="lineNoCov">          0 :         if (rcu_segcblist_is_offloaded(&amp;my_rdp-&gt;cblist)) {</span></a>
<a name="4313"><span class="lineNum">    4313 </span>            :                 raw_spin_unlock_rcu_node(my_rnp); /* irqs remain disabled. */</a>
<a name="4314"><span class="lineNum">    4314 </span><span class="lineNoCov">          0 :                 __call_rcu_nocb_wake(my_rdp, true, flags);</span></a>
<a name="4315"><span class="lineNum">    4315 </span>            :         } else {</a>
<a name="4316"><span class="lineNum">    4316 </span><span class="lineNoCov">          0 :                 rcu_nocb_unlock(my_rdp); /* irqs remain disabled. */</span></a>
<a name="4317"><span class="lineNum">    4317 </span><span class="lineNoCov">          0 :                 raw_spin_unlock_irqrestore_rcu_node(my_rnp, flags);</span></a>
<a name="4318"><span class="lineNum">    4318 </span>            :         }</a>
<a name="4319"><span class="lineNum">    4319 </span><span class="lineNoCov">          0 :         if (needwake)</span></a>
<a name="4320"><span class="lineNum">    4320 </span><span class="lineNoCov">          0 :                 rcu_gp_kthread_wake();</span></a>
<a name="4321"><span class="lineNum">    4321 </span><span class="lineNoCov">          0 :         lockdep_assert_irqs_enabled();</span></a>
<a name="4322"><span class="lineNum">    4322 </span><span class="lineNoCov">          0 :         WARN_ONCE(rcu_segcblist_n_cbs(&amp;rdp-&gt;cblist) != 0 ||</span></a>
<a name="4323"><span class="lineNum">    4323 </span>            :                   !rcu_segcblist_empty(&amp;rdp-&gt;cblist),</a>
<a name="4324"><span class="lineNum">    4324 </span>            :                   &quot;rcu_cleanup_dead_cpu: Callbacks on offline CPU %d: qlen=%lu, 1stCB=%p\n&quot;,</a>
<a name="4325"><span class="lineNum">    4325 </span>            :                   cpu, rcu_segcblist_n_cbs(&amp;rdp-&gt;cblist),</a>
<a name="4326"><span class="lineNum">    4326 </span>            :                   rcu_segcblist_first_cb(&amp;rdp-&gt;cblist));</a>
<a name="4327"><span class="lineNum">    4327 </span>            : }</a>
<a name="4328"><span class="lineNum">    4328 </span>            : #endif</a>
<a name="4329"><span class="lineNum">    4329 </span>            : </a>
<a name="4330"><span class="lineNum">    4330 </span>            : /*</a>
<a name="4331"><span class="lineNum">    4331 </span>            :  * On non-huge systems, use expedited RCU grace periods to make suspend</a>
<a name="4332"><span class="lineNum">    4332 </span>            :  * and hibernation run faster.</a>
<a name="4333"><span class="lineNum">    4333 </span>            :  */</a>
<a name="4334"><span class="lineNum">    4334 </span>            : static int rcu_pm_notify(struct notifier_block *self,</a>
<a name="4335"><span class="lineNum">    4335 </span>            :                          unsigned long action, void *hcpu)</a>
<a name="4336"><span class="lineNum">    4336 </span>            : {</a>
<a name="4337"><span class="lineNum">    4337 </span>            :         switch (action) {</a>
<a name="4338"><span class="lineNum">    4338 </span>            :         case PM_HIBERNATION_PREPARE:</a>
<a name="4339"><span class="lineNum">    4339 </span>            :         case PM_SUSPEND_PREPARE:</a>
<a name="4340"><span class="lineNum">    4340 </span>            :                 rcu_expedite_gp();</a>
<a name="4341"><span class="lineNum">    4341 </span>            :                 break;</a>
<a name="4342"><span class="lineNum">    4342 </span>            :         case PM_POST_HIBERNATION:</a>
<a name="4343"><span class="lineNum">    4343 </span>            :         case PM_POST_SUSPEND:</a>
<a name="4344"><span class="lineNum">    4344 </span>            :                 rcu_unexpedite_gp();</a>
<a name="4345"><span class="lineNum">    4345 </span>            :                 break;</a>
<a name="4346"><span class="lineNum">    4346 </span>            :         default:</a>
<a name="4347"><span class="lineNum">    4347 </span>            :                 break;</a>
<a name="4348"><span class="lineNum">    4348 </span>            :         }</a>
<a name="4349"><span class="lineNum">    4349 </span>            :         return NOTIFY_OK;</a>
<a name="4350"><span class="lineNum">    4350 </span>            : }</a>
<a name="4351"><span class="lineNum">    4351 </span>            : </a>
<a name="4352"><span class="lineNum">    4352 </span>            : /*</a>
<a name="4353"><span class="lineNum">    4353 </span>            :  * Spawn the kthreads that handle RCU's grace periods.</a>
<a name="4354"><span class="lineNum">    4354 </span>            :  */</a>
<a name="4355"><span class="lineNum">    4355 </span><span class="lineCov">          1 : static int __init rcu_spawn_gp_kthread(void)</span></a>
<a name="4356"><span class="lineNum">    4356 </span>            : {</a>
<a name="4357"><span class="lineNum">    4357 </span><span class="lineCov">          1 :         unsigned long flags;</span></a>
<a name="4358"><span class="lineNum">    4358 </span><span class="lineCov">          1 :         int kthread_prio_in = kthread_prio;</span></a>
<a name="4359"><span class="lineNum">    4359 </span><span class="lineCov">          1 :         struct rcu_node *rnp;</span></a>
<a name="4360"><span class="lineNum">    4360 </span><span class="lineCov">          1 :         struct sched_param sp;</span></a>
<a name="4361"><span class="lineNum">    4361 </span><span class="lineCov">          1 :         struct task_struct *t;</span></a>
<a name="4362"><span class="lineNum">    4362 </span>            : </a>
<a name="4363"><span class="lineNum">    4363 </span>            :         /* Force priority into range. */</a>
<a name="4364"><span class="lineNum">    4364 </span><span class="lineCov">          1 :         if (IS_ENABLED(CONFIG_RCU_BOOST) &amp;&amp; kthread_prio &lt; 2</span></a>
<a name="4365"><span class="lineNum">    4365 </span>            :             &amp;&amp; IS_BUILTIN(CONFIG_RCU_TORTURE_TEST))</a>
<a name="4366"><span class="lineNum">    4366 </span>            :                 kthread_prio = 2;</a>
<a name="4367"><span class="lineNum">    4367 </span><span class="lineCov">          1 :         else if (IS_ENABLED(CONFIG_RCU_BOOST) &amp;&amp; kthread_prio &lt; 1)</span></a>
<a name="4368"><span class="lineNum">    4368 </span>            :                 kthread_prio = 1;</a>
<a name="4369"><span class="lineNum">    4369 </span><span class="lineCov">          1 :         else if (kthread_prio &lt; 0)</span></a>
<a name="4370"><span class="lineNum">    4370 </span><span class="lineNoCov">          0 :                 kthread_prio = 0;</span></a>
<a name="4371"><span class="lineNum">    4371 </span><span class="lineCov">          1 :         else if (kthread_prio &gt; 99)</span></a>
<a name="4372"><span class="lineNum">    4372 </span><span class="lineNoCov">          0 :                 kthread_prio = 99;</span></a>
<a name="4373"><span class="lineNum">    4373 </span>            : </a>
<a name="4374"><span class="lineNum">    4374 </span><span class="lineCov">          1 :         if (kthread_prio != kthread_prio_in)</span></a>
<a name="4375"><span class="lineNum">    4375 </span><span class="lineNoCov">          0 :                 pr_alert(&quot;rcu_spawn_gp_kthread(): Limited prio to %d from %d\n&quot;,</span></a>
<a name="4376"><span class="lineNum">    4376 </span>            :                          kthread_prio, kthread_prio_in);</a>
<a name="4377"><span class="lineNum">    4377 </span>            : </a>
<a name="4378"><span class="lineNum">    4378 </span><span class="lineCov">          1 :         rcu_scheduler_fully_active = 1;</span></a>
<a name="4379"><span class="lineNum">    4379 </span><span class="lineCov">          1 :         t = kthread_create(rcu_gp_kthread, NULL, &quot;%s&quot;, rcu_state.name);</span></a>
<a name="4380"><span class="lineNum">    4380 </span><span class="lineCov">          1 :         if (WARN_ONCE(IS_ERR(t), &quot;%s: Could not start grace-period kthread, OOM is now expected behavior\n&quot;, __func__))</span></a>
<a name="4381"><span class="lineNum">    4381 </span>            :                 return 0;</a>
<a name="4382"><span class="lineNum">    4382 </span><span class="lineCov">          1 :         if (kthread_prio) {</span></a>
<a name="4383"><span class="lineNum">    4383 </span><span class="lineNoCov">          0 :                 sp.sched_priority = kthread_prio;</span></a>
<a name="4384"><span class="lineNum">    4384 </span><span class="lineNoCov">          0 :                 sched_setscheduler_nocheck(t, SCHED_FIFO, &amp;sp);</span></a>
<a name="4385"><span class="lineNum">    4385 </span>            :         }</a>
<a name="4386"><span class="lineNum">    4386 </span><span class="lineCov">          1 :         rnp = rcu_get_root();</span></a>
<a name="4387"><span class="lineNum">    4387 </span><span class="lineCov">          1 :         raw_spin_lock_irqsave_rcu_node(rnp, flags);</span></a>
<a name="4388"><span class="lineNum">    4388 </span><span class="lineCov">          1 :         WRITE_ONCE(rcu_state.gp_activity, jiffies);</span></a>
<a name="4389"><span class="lineNum">    4389 </span><span class="lineCov">          1 :         WRITE_ONCE(rcu_state.gp_req_activity, jiffies);</span></a>
<a name="4390"><span class="lineNum">    4390 </span>            :         // Reset .gp_activity and .gp_req_activity before setting .gp_kthread.</a>
<a name="4391"><span class="lineNum">    4391 </span><span class="lineCov">          1 :         smp_store_release(&amp;rcu_state.gp_kthread, t);  /* ^^^ */</span></a>
<a name="4392"><span class="lineNum">    4392 </span><span class="lineCov">          2 :         raw_spin_unlock_irqrestore_rcu_node(rnp, flags);</span></a>
<a name="4393"><span class="lineNum">    4393 </span><span class="lineCov">          1 :         wake_up_process(t);</span></a>
<a name="4394"><span class="lineNum">    4394 </span><span class="lineCov">          1 :         rcu_spawn_nocb_kthreads();</span></a>
<a name="4395"><span class="lineNum">    4395 </span><span class="lineCov">          1 :         rcu_spawn_boost_kthreads();</span></a>
<a name="4396"><span class="lineNum">    4396 </span><span class="lineCov">          1 :         return 0;</span></a>
<a name="4397"><span class="lineNum">    4397 </span>            : }</a>
<a name="4398"><span class="lineNum">    4398 </span>            : early_initcall(rcu_spawn_gp_kthread);</a>
<a name="4399"><span class="lineNum">    4399 </span>            : </a>
<a name="4400"><span class="lineNum">    4400 </span>            : /*</a>
<a name="4401"><span class="lineNum">    4401 </span>            :  * This function is invoked towards the end of the scheduler's</a>
<a name="4402"><span class="lineNum">    4402 </span>            :  * initialization process.  Before this is called, the idle task might</a>
<a name="4403"><span class="lineNum">    4403 </span>            :  * contain synchronous grace-period primitives (during which time, this idle</a>
<a name="4404"><span class="lineNum">    4404 </span>            :  * task is booting the system, and such primitives are no-ops).  After this</a>
<a name="4405"><span class="lineNum">    4405 </span>            :  * function is called, any synchronous grace-period primitives are run as</a>
<a name="4406"><span class="lineNum">    4406 </span>            :  * expedited, with the requesting task driving the grace period forward.</a>
<a name="4407"><span class="lineNum">    4407 </span>            :  * A later core_initcall() rcu_set_runtime_mode() will switch to full</a>
<a name="4408"><span class="lineNum">    4408 </span>            :  * runtime RCU functionality.</a>
<a name="4409"><span class="lineNum">    4409 </span>            :  */</a>
<a name="4410"><span class="lineNum">    4410 </span><span class="lineCov">          1 : void rcu_scheduler_starting(void)</span></a>
<a name="4411"><span class="lineNum">    4411 </span>            : {</a>
<a name="4412"><span class="lineNum">    4412 </span><span class="lineCov">          1 :         WARN_ON(num_online_cpus() != 1);</span></a>
<a name="4413"><span class="lineNum">    4413 </span><span class="lineCov">          1 :         WARN_ON(nr_context_switches() &gt; 0);</span></a>
<a name="4414"><span class="lineNum">    4414 </span><span class="lineCov">          1 :         rcu_test_sync_prims();</span></a>
<a name="4415"><span class="lineNum">    4415 </span><span class="lineCov">          1 :         rcu_scheduler_active = RCU_SCHEDULER_INIT;</span></a>
<a name="4416"><span class="lineNum">    4416 </span><span class="lineCov">          1 :         rcu_test_sync_prims();</span></a>
<a name="4417"><span class="lineNum">    4417 </span><span class="lineCov">          1 : }</span></a>
<a name="4418"><span class="lineNum">    4418 </span>            : </a>
<a name="4419"><span class="lineNum">    4419 </span>            : /*</a>
<a name="4420"><span class="lineNum">    4420 </span>            :  * Helper function for rcu_init() that initializes the rcu_state structure.</a>
<a name="4421"><span class="lineNum">    4421 </span>            :  */</a>
<a name="4422"><span class="lineNum">    4422 </span><span class="lineCov">          1 : static void __init rcu_init_one(void)</span></a>
<a name="4423"><span class="lineNum">    4423 </span>            : {</a>
<a name="4424"><span class="lineNum">    4424 </span><span class="lineCov">          1 :         static const char * const buf[] = RCU_NODE_NAME_INIT;</span></a>
<a name="4425"><span class="lineNum">    4425 </span><span class="lineCov">          1 :         static const char * const fqs[] = RCU_FQS_NAME_INIT;</span></a>
<a name="4426"><span class="lineNum">    4426 </span><span class="lineCov">          1 :         static struct lock_class_key rcu_node_class[RCU_NUM_LVLS];</span></a>
<a name="4427"><span class="lineNum">    4427 </span><span class="lineCov">          1 :         static struct lock_class_key rcu_fqs_class[RCU_NUM_LVLS];</span></a>
<a name="4428"><span class="lineNum">    4428 </span>            : </a>
<a name="4429"><span class="lineNum">    4429 </span><span class="lineCov">          1 :         int levelspread[RCU_NUM_LVLS];          /* kids/node in each level. */</span></a>
<a name="4430"><span class="lineNum">    4430 </span><span class="lineCov">          1 :         int cpustride = 1;</span></a>
<a name="4431"><span class="lineNum">    4431 </span><span class="lineCov">          1 :         int i;</span></a>
<a name="4432"><span class="lineNum">    4432 </span><span class="lineCov">          1 :         int j;</span></a>
<a name="4433"><span class="lineNum">    4433 </span><span class="lineCov">          1 :         struct rcu_node *rnp;</span></a>
<a name="4434"><span class="lineNum">    4434 </span>            : </a>
<a name="4435"><span class="lineNum">    4435 </span><span class="lineCov">          1 :         BUILD_BUG_ON(RCU_NUM_LVLS &gt; ARRAY_SIZE(buf));  /* Fix buf[] init! */</span></a>
<a name="4436"><span class="lineNum">    4436 </span>            : </a>
<a name="4437"><span class="lineNum">    4437 </span>            :         /* Silence gcc 4.8 false positive about array index out of range. */</a>
<a name="4438"><span class="lineNum">    4438 </span><span class="lineCov">          1 :         if (rcu_num_lvls &lt;= 0 || rcu_num_lvls &gt; RCU_NUM_LVLS)</span></a>
<a name="4439"><span class="lineNum">    4439 </span><span class="lineNoCov">          0 :                 panic(&quot;rcu_init_one: rcu_num_lvls out of range&quot;);</span></a>
<a name="4440"><span class="lineNum">    4440 </span>            : </a>
<a name="4441"><span class="lineNum">    4441 </span>            :         /* Initialize the level-tracking arrays. */</a>
<a name="4442"><span class="lineNum">    4442 </span>            : </a>
<a name="4443"><span class="lineNum">    4443 </span><span class="lineCov">          1 :         for (i = 1; i &lt; rcu_num_lvls; i++)</span></a>
<a name="4444"><span class="lineNum">    4444 </span>            :                 rcu_state.level[i] =</a>
<a name="4445"><span class="lineNum">    4445 </span>            :                         rcu_state.level[i - 1] + num_rcu_lvl[i - 1];</a>
<a name="4446"><span class="lineNum">    4446 </span><span class="lineCov">          1 :         rcu_init_levelspread(levelspread, num_rcu_lvl);</span></a>
<a name="4447"><span class="lineNum">    4447 </span>            : </a>
<a name="4448"><span class="lineNum">    4448 </span>            :         /* Initialize the elements themselves, starting from the leaves. */</a>
<a name="4449"><span class="lineNum">    4449 </span>            : </a>
<a name="4450"><span class="lineNum">    4450 </span><span class="lineCov">          2 :         for (i = rcu_num_lvls - 1; i &gt;= 0; i--) {</span></a>
<a name="4451"><span class="lineNum">    4451 </span><span class="lineCov">          1 :                 cpustride *= levelspread[i];</span></a>
<a name="4452"><span class="lineNum">    4452 </span><span class="lineCov">          1 :                 rnp = rcu_state.level[i];</span></a>
<a name="4453"><span class="lineNum">    4453 </span><span class="lineCov">          2 :                 for (j = 0; j &lt; num_rcu_lvl[i]; j++, rnp++) {</span></a>
<a name="4454"><span class="lineNum">    4454 </span><span class="lineCov">          1 :                         raw_spin_lock_init(&amp;ACCESS_PRIVATE(rnp, lock));</span></a>
<a name="4455"><span class="lineNum">    4455 </span><span class="lineCov">          1 :                         lockdep_set_class_and_name(&amp;ACCESS_PRIVATE(rnp, lock),</span></a>
<a name="4456"><span class="lineNum">    4456 </span>            :                                                    &amp;rcu_node_class[i], buf[i]);</a>
<a name="4457"><span class="lineNum">    4457 </span><span class="lineCov">          1 :                         raw_spin_lock_init(&amp;rnp-&gt;fqslock);</span></a>
<a name="4458"><span class="lineNum">    4458 </span><span class="lineCov">          1 :                         lockdep_set_class_and_name(&amp;rnp-&gt;fqslock,</span></a>
<a name="4459"><span class="lineNum">    4459 </span>            :                                                    &amp;rcu_fqs_class[i], fqs[i]);</a>
<a name="4460"><span class="lineNum">    4460 </span><span class="lineCov">          1 :                         rnp-&gt;gp_seq = rcu_state.gp_seq;</span></a>
<a name="4461"><span class="lineNum">    4461 </span><span class="lineCov">          1 :                         rnp-&gt;gp_seq_needed = rcu_state.gp_seq;</span></a>
<a name="4462"><span class="lineNum">    4462 </span><span class="lineCov">          1 :                         rnp-&gt;completedqs = rcu_state.gp_seq;</span></a>
<a name="4463"><span class="lineNum">    4463 </span><span class="lineCov">          1 :                         rnp-&gt;qsmask = 0;</span></a>
<a name="4464"><span class="lineNum">    4464 </span><span class="lineCov">          1 :                         rnp-&gt;qsmaskinit = 0;</span></a>
<a name="4465"><span class="lineNum">    4465 </span><span class="lineCov">          1 :                         rnp-&gt;grplo = j * cpustride;</span></a>
<a name="4466"><span class="lineNum">    4466 </span><span class="lineCov">          1 :                         rnp-&gt;grphi = (j + 1) * cpustride - 1;</span></a>
<a name="4467"><span class="lineNum">    4467 </span><span class="lineCov">          1 :                         if (rnp-&gt;grphi &gt;= nr_cpu_ids)</span></a>
<a name="4468"><span class="lineNum">    4468 </span><span class="lineNoCov">          0 :                                 rnp-&gt;grphi = nr_cpu_ids - 1;</span></a>
<a name="4469"><span class="lineNum">    4469 </span><span class="lineCov">          1 :                         if (i == 0) {</span></a>
<a name="4470"><span class="lineNum">    4470 </span><span class="lineCov">          1 :                                 rnp-&gt;grpnum = 0;</span></a>
<a name="4471"><span class="lineNum">    4471 </span><span class="lineCov">          1 :                                 rnp-&gt;grpmask = 0;</span></a>
<a name="4472"><span class="lineNum">    4472 </span><span class="lineCov">          1 :                                 rnp-&gt;parent = NULL;</span></a>
<a name="4473"><span class="lineNum">    4473 </span>            :                         } else {</a>
<a name="4474"><span class="lineNum">    4474 </span><span class="lineNoCov">          0 :                                 rnp-&gt;grpnum = j % levelspread[i - 1];</span></a>
<a name="4475"><span class="lineNum">    4475 </span><span class="lineNoCov">          0 :                                 rnp-&gt;grpmask = BIT(rnp-&gt;grpnum);</span></a>
<a name="4476"><span class="lineNum">    4476 </span><span class="lineNoCov">          0 :                                 rnp-&gt;parent = rcu_state.level[i - 1] +</span></a>
<a name="4477"><span class="lineNum">    4477 </span><span class="lineNoCov">          0 :                                               j / levelspread[i - 1];</span></a>
<a name="4478"><span class="lineNum">    4478 </span>            :                         }</a>
<a name="4479"><span class="lineNum">    4479 </span><span class="lineCov">          1 :                         rnp-&gt;level = i;</span></a>
<a name="4480"><span class="lineNum">    4480 </span><span class="lineCov">          1 :                         INIT_LIST_HEAD(&amp;rnp-&gt;blkd_tasks);</span></a>
<a name="4481"><span class="lineNum">    4481 </span><span class="lineCov">          1 :                         rcu_init_one_nocb(rnp);</span></a>
<a name="4482"><span class="lineNum">    4482 </span><span class="lineCov">          1 :                         init_waitqueue_head(&amp;rnp-&gt;exp_wq[0]);</span></a>
<a name="4483"><span class="lineNum">    4483 </span><span class="lineCov">          1 :                         init_waitqueue_head(&amp;rnp-&gt;exp_wq[1]);</span></a>
<a name="4484"><span class="lineNum">    4484 </span><span class="lineCov">          1 :                         init_waitqueue_head(&amp;rnp-&gt;exp_wq[2]);</span></a>
<a name="4485"><span class="lineNum">    4485 </span><span class="lineCov">          1 :                         init_waitqueue_head(&amp;rnp-&gt;exp_wq[3]);</span></a>
<a name="4486"><span class="lineNum">    4486 </span><span class="lineCov">          1 :                         spin_lock_init(&amp;rnp-&gt;exp_lock);</span></a>
<a name="4487"><span class="lineNum">    4487 </span>            :                 }</a>
<a name="4488"><span class="lineNum">    4488 </span>            :         }</a>
<a name="4489"><span class="lineNum">    4489 </span>            : </a>
<a name="4490"><span class="lineNum">    4490 </span><span class="lineCov">          1 :         init_swait_queue_head(&amp;rcu_state.gp_wq);</span></a>
<a name="4491"><span class="lineNum">    4491 </span><span class="lineCov">          1 :         init_swait_queue_head(&amp;rcu_state.expedited_wq);</span></a>
<a name="4492"><span class="lineNum">    4492 </span><span class="lineCov">          1 :         rnp = rcu_first_leaf_node();</span></a>
<a name="4493"><span class="lineNum">    4493 </span><span class="lineCov">          5 :         for_each_possible_cpu(i) {</span></a>
<a name="4494"><span class="lineNum">    4494 </span><span class="lineCov">          4 :                 while (i &gt; rnp-&gt;grphi)</span></a>
<a name="4495"><span class="lineNum">    4495 </span><span class="lineNoCov">          0 :                         rnp++;</span></a>
<a name="4496"><span class="lineNum">    4496 </span><span class="lineCov">          4 :                 per_cpu_ptr(&amp;rcu_data, i)-&gt;mynode = rnp;</span></a>
<a name="4497"><span class="lineNum">    4497 </span><span class="lineCov">          4 :                 rcu_boot_init_percpu_data(i);</span></a>
<a name="4498"><span class="lineNum">    4498 </span>            :         }</a>
<a name="4499"><span class="lineNum">    4499 </span><span class="lineCov">          1 : }</span></a>
<a name="4500"><span class="lineNum">    4500 </span>            : </a>
<a name="4501"><span class="lineNum">    4501 </span>            : /*</a>
<a name="4502"><span class="lineNum">    4502 </span>            :  * Compute the rcu_node tree geometry from kernel parameters.  This cannot</a>
<a name="4503"><span class="lineNum">    4503 </span>            :  * replace the definitions in tree.h because those are needed to size</a>
<a name="4504"><span class="lineNum">    4504 </span>            :  * the -&gt;node array in the rcu_state structure.</a>
<a name="4505"><span class="lineNum">    4505 </span>            :  */</a>
<a name="4506"><span class="lineNum">    4506 </span><span class="lineCov">          1 : static void __init rcu_init_geometry(void)</span></a>
<a name="4507"><span class="lineNum">    4507 </span>            : {</a>
<a name="4508"><span class="lineNum">    4508 </span><span class="lineCov">          1 :         ulong d;</span></a>
<a name="4509"><span class="lineNum">    4509 </span><span class="lineCov">          1 :         int i;</span></a>
<a name="4510"><span class="lineNum">    4510 </span><span class="lineCov">          1 :         int rcu_capacity[RCU_NUM_LVLS];</span></a>
<a name="4511"><span class="lineNum">    4511 </span>            : </a>
<a name="4512"><span class="lineNum">    4512 </span>            :         /*</a>
<a name="4513"><span class="lineNum">    4513 </span>            :          * Initialize any unspecified boot parameters.</a>
<a name="4514"><span class="lineNum">    4514 </span>            :          * The default values of jiffies_till_first_fqs and</a>
<a name="4515"><span class="lineNum">    4515 </span>            :          * jiffies_till_next_fqs are set to the RCU_JIFFIES_TILL_FORCE_QS</a>
<a name="4516"><span class="lineNum">    4516 </span>            :          * value, which is a function of HZ, then adding one for each</a>
<a name="4517"><span class="lineNum">    4517 </span>            :          * RCU_JIFFIES_FQS_DIV CPUs that might be on the system.</a>
<a name="4518"><span class="lineNum">    4518 </span>            :          */</a>
<a name="4519"><span class="lineNum">    4519 </span><span class="lineCov">          1 :         d = RCU_JIFFIES_TILL_FORCE_QS + nr_cpu_ids / RCU_JIFFIES_FQS_DIV;</span></a>
<a name="4520"><span class="lineNum">    4520 </span><span class="lineCov">          1 :         if (jiffies_till_first_fqs == ULONG_MAX)</span></a>
<a name="4521"><span class="lineNum">    4521 </span><span class="lineCov">          1 :                 jiffies_till_first_fqs = d;</span></a>
<a name="4522"><span class="lineNum">    4522 </span><span class="lineCov">          1 :         if (jiffies_till_next_fqs == ULONG_MAX)</span></a>
<a name="4523"><span class="lineNum">    4523 </span><span class="lineCov">          1 :                 jiffies_till_next_fqs = d;</span></a>
<a name="4524"><span class="lineNum">    4524 </span><span class="lineCov">          1 :         adjust_jiffies_till_sched_qs();</span></a>
<a name="4525"><span class="lineNum">    4525 </span>            : </a>
<a name="4526"><span class="lineNum">    4526 </span>            :         /* If the compile-time values are accurate, just leave. */</a>
<a name="4527"><span class="lineNum">    4527 </span><span class="lineCov">          1 :         if (rcu_fanout_leaf == RCU_FANOUT_LEAF &amp;&amp;</span></a>
<a name="4528"><span class="lineNum">    4528 </span><span class="lineCov">          1 :             nr_cpu_ids == NR_CPUS)</span></a>
<a name="4529"><span class="lineNum">    4529 </span>            :                 return;</a>
<a name="4530"><span class="lineNum">    4530 </span><span class="lineCov">          1 :         pr_info(&quot;Adjusting geometry for rcu_fanout_leaf=%d, nr_cpu_ids=%u\n&quot;,</span></a>
<a name="4531"><span class="lineNum">    4531 </span>            :                 rcu_fanout_leaf, nr_cpu_ids);</a>
<a name="4532"><span class="lineNum">    4532 </span>            : </a>
<a name="4533"><span class="lineNum">    4533 </span>            :         /*</a>
<a name="4534"><span class="lineNum">    4534 </span>            :          * The boot-time rcu_fanout_leaf parameter must be at least two</a>
<a name="4535"><span class="lineNum">    4535 </span>            :          * and cannot exceed the number of bits in the rcu_node masks.</a>
<a name="4536"><span class="lineNum">    4536 </span>            :          * Complain and fall back to the compile-time values if this</a>
<a name="4537"><span class="lineNum">    4537 </span>            :          * limit is exceeded.</a>
<a name="4538"><span class="lineNum">    4538 </span>            :          */</a>
<a name="4539"><span class="lineNum">    4539 </span><span class="lineCov">          1 :         if (rcu_fanout_leaf &lt; 2 ||</span></a>
<a name="4540"><span class="lineNum">    4540 </span>            :             rcu_fanout_leaf &gt; sizeof(unsigned long) * 8) {</a>
<a name="4541"><span class="lineNum">    4541 </span><span class="lineNoCov">          0 :                 rcu_fanout_leaf = RCU_FANOUT_LEAF;</span></a>
<a name="4542"><span class="lineNum">    4542 </span><span class="lineNoCov">          0 :                 WARN_ON(1);</span></a>
<a name="4543"><span class="lineNum">    4543 </span><span class="lineNoCov">          0 :                 return;</span></a>
<a name="4544"><span class="lineNum">    4544 </span>            :         }</a>
<a name="4545"><span class="lineNum">    4545 </span>            : </a>
<a name="4546"><span class="lineNum">    4546 </span>            :         /*</a>
<a name="4547"><span class="lineNum">    4547 </span>            :          * Compute number of nodes that can be handled an rcu_node tree</a>
<a name="4548"><span class="lineNum">    4548 </span>            :          * with the given number of levels.</a>
<a name="4549"><span class="lineNum">    4549 </span>            :          */</a>
<a name="4550"><span class="lineNum">    4550 </span><span class="lineCov">          1 :         rcu_capacity[0] = rcu_fanout_leaf;</span></a>
<a name="4551"><span class="lineNum">    4551 </span><span class="lineCov">          1 :         for (i = 1; i &lt; RCU_NUM_LVLS; i++)</span></a>
<a name="4552"><span class="lineNum">    4552 </span>            :                 rcu_capacity[i] = rcu_capacity[i - 1] * RCU_FANOUT;</a>
<a name="4553"><span class="lineNum">    4553 </span>            : </a>
<a name="4554"><span class="lineNum">    4554 </span>            :         /*</a>
<a name="4555"><span class="lineNum">    4555 </span>            :          * The tree must be able to accommodate the configured number of CPUs.</a>
<a name="4556"><span class="lineNum">    4556 </span>            :          * If this limit is exceeded, fall back to the compile-time values.</a>
<a name="4557"><span class="lineNum">    4557 </span>            :          */</a>
<a name="4558"><span class="lineNum">    4558 </span><span class="lineCov">          1 :         if (nr_cpu_ids &gt; rcu_capacity[RCU_NUM_LVLS - 1]) {</span></a>
<a name="4559"><span class="lineNum">    4559 </span><span class="lineNoCov">          0 :                 rcu_fanout_leaf = RCU_FANOUT_LEAF;</span></a>
<a name="4560"><span class="lineNum">    4560 </span><span class="lineNoCov">          0 :                 WARN_ON(1);</span></a>
<a name="4561"><span class="lineNum">    4561 </span><span class="lineNoCov">          0 :                 return;</span></a>
<a name="4562"><span class="lineNum">    4562 </span>            :         }</a>
<a name="4563"><span class="lineNum">    4563 </span>            : </a>
<a name="4564"><span class="lineNum">    4564 </span>            :         /* Calculate the number of levels in the tree. */</a>
<a name="4565"><span class="lineNum">    4565 </span><span class="lineCov">          1 :         for (i = 0; nr_cpu_ids &gt; rcu_capacity[i]; i++) {</span></a>
<a name="4566"><span class="lineNum">    4566 </span>            :         }</a>
<a name="4567"><span class="lineNum">    4567 </span><span class="lineCov">          1 :         rcu_num_lvls = i + 1;</span></a>
<a name="4568"><span class="lineNum">    4568 </span>            : </a>
<a name="4569"><span class="lineNum">    4569 </span>            :         /* Calculate the number of rcu_nodes at each level of the tree. */</a>
<a name="4570"><span class="lineNum">    4570 </span><span class="lineCov">          2 :         for (i = 0; i &lt; rcu_num_lvls; i++) {</span></a>
<a name="4571"><span class="lineNum">    4571 </span><span class="lineCov">          1 :                 int cap = rcu_capacity[(rcu_num_lvls - 1) - i];</span></a>
<a name="4572"><span class="lineNum">    4572 </span><span class="lineCov">          1 :                 num_rcu_lvl[i] = DIV_ROUND_UP(nr_cpu_ids, cap);</span></a>
<a name="4573"><span class="lineNum">    4573 </span>            :         }</a>
<a name="4574"><span class="lineNum">    4574 </span>            : </a>
<a name="4575"><span class="lineNum">    4575 </span>            :         /* Calculate the total number of rcu_node structures. */</a>
<a name="4576"><span class="lineNum">    4576 </span><span class="lineCov">          1 :         rcu_num_nodes = 0;</span></a>
<a name="4577"><span class="lineNum">    4577 </span><span class="lineCov">          2 :         for (i = 0; i &lt; rcu_num_lvls; i++)</span></a>
<a name="4578"><span class="lineNum">    4578 </span><span class="lineCov">          1 :                 rcu_num_nodes += num_rcu_lvl[i];</span></a>
<a name="4579"><span class="lineNum">    4579 </span>            : }</a>
<a name="4580"><span class="lineNum">    4580 </span>            : </a>
<a name="4581"><span class="lineNum">    4581 </span>            : /*</a>
<a name="4582"><span class="lineNum">    4582 </span>            :  * Dump out the structure of the rcu_node combining tree associated</a>
<a name="4583"><span class="lineNum">    4583 </span>            :  * with the rcu_state structure.</a>
<a name="4584"><span class="lineNum">    4584 </span>            :  */</a>
<a name="4585"><span class="lineNum">    4585 </span><span class="lineNoCov">          0 : static void __init rcu_dump_rcu_node_tree(void)</span></a>
<a name="4586"><span class="lineNum">    4586 </span>            : {</a>
<a name="4587"><span class="lineNum">    4587 </span><span class="lineNoCov">          0 :         int level = 0;</span></a>
<a name="4588"><span class="lineNum">    4588 </span><span class="lineNoCov">          0 :         struct rcu_node *rnp;</span></a>
<a name="4589"><span class="lineNum">    4589 </span>            : </a>
<a name="4590"><span class="lineNum">    4590 </span><span class="lineNoCov">          0 :         pr_info(&quot;rcu_node tree layout dump\n&quot;);</span></a>
<a name="4591"><span class="lineNum">    4591 </span><span class="lineNoCov">          0 :         pr_info(&quot; &quot;);</span></a>
<a name="4592"><span class="lineNum">    4592 </span><span class="lineNoCov">          0 :         rcu_for_each_node_breadth_first(rnp) {</span></a>
<a name="4593"><span class="lineNum">    4593 </span><span class="lineNoCov">          0 :                 if (rnp-&gt;level != level) {</span></a>
<a name="4594"><span class="lineNum">    4594 </span><span class="lineNoCov">          0 :                         pr_cont(&quot;\n&quot;);</span></a>
<a name="4595"><span class="lineNum">    4595 </span><span class="lineNoCov">          0 :                         pr_info(&quot; &quot;);</span></a>
<a name="4596"><span class="lineNum">    4596 </span><span class="lineNoCov">          0 :                         level = rnp-&gt;level;</span></a>
<a name="4597"><span class="lineNum">    4597 </span>            :                 }</a>
<a name="4598"><span class="lineNum">    4598 </span><span class="lineNoCov">          0 :                 pr_cont(&quot;%d:%d ^%d  &quot;, rnp-&gt;grplo, rnp-&gt;grphi, rnp-&gt;grpnum);</span></a>
<a name="4599"><span class="lineNum">    4599 </span>            :         }</a>
<a name="4600"><span class="lineNum">    4600 </span><span class="lineNoCov">          0 :         pr_cont(&quot;\n&quot;);</span></a>
<a name="4601"><span class="lineNum">    4601 </span><span class="lineNoCov">          0 : }</span></a>
<a name="4602"><span class="lineNum">    4602 </span>            : </a>
<a name="4603"><span class="lineNum">    4603 </span>            : struct workqueue_struct *rcu_gp_wq;</a>
<a name="4604"><span class="lineNum">    4604 </span>            : struct workqueue_struct *rcu_par_gp_wq;</a>
<a name="4605"><span class="lineNum">    4605 </span>            : </a>
<a name="4606"><span class="lineNum">    4606 </span><span class="lineCov">          1 : static void __init kfree_rcu_batch_init(void)</span></a>
<a name="4607"><span class="lineNum">    4607 </span>            : {</a>
<a name="4608"><span class="lineNum">    4608 </span><span class="lineCov">          1 :         int cpu;</span></a>
<a name="4609"><span class="lineNum">    4609 </span><span class="lineCov">          1 :         int i;</span></a>
<a name="4610"><span class="lineNum">    4610 </span>            : </a>
<a name="4611"><span class="lineNum">    4611 </span><span class="lineCov">          5 :         for_each_possible_cpu(cpu) {</span></a>
<a name="4612"><span class="lineNum">    4612 </span><span class="lineCov">          4 :                 struct kfree_rcu_cpu *krcp = per_cpu_ptr(&amp;krc, cpu);</span></a>
<a name="4613"><span class="lineNum">    4613 </span>            : </a>
<a name="4614"><span class="lineNum">    4614 </span><span class="lineCov">         12 :                 for (i = 0; i &lt; KFREE_N_BATCHES; i++) {</span></a>
<a name="4615"><span class="lineNum">    4615 </span><span class="lineCov">          8 :                         INIT_RCU_WORK(&amp;krcp-&gt;krw_arr[i].rcu_work, kfree_rcu_work);</span></a>
<a name="4616"><span class="lineNum">    4616 </span><span class="lineCov">          8 :                         krcp-&gt;krw_arr[i].krcp = krcp;</span></a>
<a name="4617"><span class="lineNum">    4617 </span>            :                 }</a>
<a name="4618"><span class="lineNum">    4618 </span>            : </a>
<a name="4619"><span class="lineNum">    4619 </span><span class="lineCov">          4 :                 INIT_DELAYED_WORK(&amp;krcp-&gt;monitor_work, kfree_rcu_monitor);</span></a>
<a name="4620"><span class="lineNum">    4620 </span><span class="lineCov">          4 :                 INIT_WORK(&amp;krcp-&gt;page_cache_work, fill_page_cache_func);</span></a>
<a name="4621"><span class="lineNum">    4621 </span><span class="lineCov">          4 :                 krcp-&gt;initialized = true;</span></a>
<a name="4622"><span class="lineNum">    4622 </span>            :         }</a>
<a name="4623"><span class="lineNum">    4623 </span><span class="lineCov">          1 :         if (register_shrinker(&amp;kfree_rcu_shrinker))</span></a>
<a name="4624"><span class="lineNum">    4624 </span><span class="lineNoCov">          0 :                 pr_err(&quot;Failed to register kfree_rcu() shrinker!\n&quot;);</span></a>
<a name="4625"><span class="lineNum">    4625 </span><span class="lineCov">          1 : }</span></a>
<a name="4626"><span class="lineNum">    4626 </span>            : </a>
<a name="4627"><span class="lineNum">    4627 </span><span class="lineCov">          1 : void __init rcu_init(void)</span></a>
<a name="4628"><span class="lineNum">    4628 </span>            : {</a>
<a name="4629"><span class="lineNum">    4629 </span><span class="lineCov">          1 :         int cpu;</span></a>
<a name="4630"><span class="lineNum">    4630 </span>            : </a>
<a name="4631"><span class="lineNum">    4631 </span><span class="lineCov">          1 :         rcu_early_boot_tests();</span></a>
<a name="4632"><span class="lineNum">    4632 </span>            : </a>
<a name="4633"><span class="lineNum">    4633 </span><span class="lineCov">          1 :         kfree_rcu_batch_init();</span></a>
<a name="4634"><span class="lineNum">    4634 </span><span class="lineCov">          1 :         rcu_bootup_announce();</span></a>
<a name="4635"><span class="lineNum">    4635 </span><span class="lineCov">          1 :         rcu_init_geometry();</span></a>
<a name="4636"><span class="lineNum">    4636 </span><span class="lineCov">          1 :         rcu_init_one();</span></a>
<a name="4637"><span class="lineNum">    4637 </span><span class="lineCov">          1 :         if (dump_tree)</span></a>
<a name="4638"><span class="lineNum">    4638 </span><span class="lineNoCov">          0 :                 rcu_dump_rcu_node_tree();</span></a>
<a name="4639"><span class="lineNum">    4639 </span><span class="lineCov">          1 :         if (use_softirq)</span></a>
<a name="4640"><span class="lineNum">    4640 </span><span class="lineCov">          1 :                 open_softirq(RCU_SOFTIRQ, rcu_core_si);</span></a>
<a name="4641"><span class="lineNum">    4641 </span>            : </a>
<a name="4642"><span class="lineNum">    4642 </span>            :         /*</a>
<a name="4643"><span class="lineNum">    4643 </span>            :          * We don't need protection against CPU-hotplug here because</a>
<a name="4644"><span class="lineNum">    4644 </span>            :          * this is called early in boot, before either interrupts</a>
<a name="4645"><span class="lineNum">    4645 </span>            :          * or the scheduler are operational.</a>
<a name="4646"><span class="lineNum">    4646 </span>            :          */</a>
<a name="4647"><span class="lineNum">    4647 </span>            :         pm_notifier(rcu_pm_notify, 0);</a>
<a name="4648"><span class="lineNum">    4648 </span><span class="lineCov">          2 :         for_each_online_cpu(cpu) {</span></a>
<a name="4649"><span class="lineNum">    4649 </span><span class="lineCov">          1 :                 rcutree_prepare_cpu(cpu);</span></a>
<a name="4650"><span class="lineNum">    4650 </span><span class="lineCov">          1 :                 rcu_cpu_starting(cpu);</span></a>
<a name="4651"><span class="lineNum">    4651 </span><span class="lineCov">          1 :                 rcutree_online_cpu(cpu);</span></a>
<a name="4652"><span class="lineNum">    4652 </span>            :         }</a>
<a name="4653"><span class="lineNum">    4653 </span>            : </a>
<a name="4654"><span class="lineNum">    4654 </span>            :         /* Create workqueue for expedited GPs and for Tree SRCU. */</a>
<a name="4655"><span class="lineNum">    4655 </span><span class="lineCov">          1 :         rcu_gp_wq = alloc_workqueue(&quot;rcu_gp&quot;, WQ_MEM_RECLAIM, 0);</span></a>
<a name="4656"><span class="lineNum">    4656 </span><span class="lineCov">          1 :         WARN_ON(!rcu_gp_wq);</span></a>
<a name="4657"><span class="lineNum">    4657 </span><span class="lineCov">          1 :         rcu_par_gp_wq = alloc_workqueue(&quot;rcu_par_gp&quot;, WQ_MEM_RECLAIM, 0);</span></a>
<a name="4658"><span class="lineNum">    4658 </span><span class="lineCov">          1 :         WARN_ON(!rcu_par_gp_wq);</span></a>
<a name="4659"><span class="lineNum">    4659 </span><span class="lineCov">          1 :         srcu_init();</span></a>
<a name="4660"><span class="lineNum">    4660 </span>            : </a>
<a name="4661"><span class="lineNum">    4661 </span>            :         /* Fill in default value for rcutree.qovld boot parameter. */</a>
<a name="4662"><span class="lineNum">    4662 </span>            :         /* -After- the rcu_node -&gt;lock fields are initialized! */</a>
<a name="4663"><span class="lineNum">    4663 </span><span class="lineCov">          1 :         if (qovld &lt; 0)</span></a>
<a name="4664"><span class="lineNum">    4664 </span><span class="lineNoCov">          0 :                 qovld_calc = DEFAULT_RCU_QOVLD_MULT * qhimark;</span></a>
<a name="4665"><span class="lineNum">    4665 </span>            :         else</a>
<a name="4666"><span class="lineNum">    4666 </span><span class="lineCov">          1 :                 qovld_calc = qovld;</span></a>
<a name="4667"><span class="lineNum">    4667 </span><span class="lineCov">          1 : }</span></a>
<a name="4668"><span class="lineNum">    4668 </span>            : </a>
<a name="4669"><span class="lineNum">    4669 </span>            : #include &quot;tree_stall.h&quot;</a>
<a name="4670"><span class="lineNum">    4670 </span>            : #include &quot;tree_exp.h&quot;</a>
<a name="4671"><span class="lineNum">    4671 </span>            : #include &quot;tree_plugin.h&quot;</a>
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="http://ltp.sourceforge.net/coverage/lcov.php" target="_parent">LCOV version 1.14</a></td></tr>
  </table>
  <br>

</body>
</html>
