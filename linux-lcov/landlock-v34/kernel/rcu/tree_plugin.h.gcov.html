<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - landlock.info - kernel/rcu/tree_plugin.h</title>
  <link rel="stylesheet" type="text/css" href="../../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../../index.html">top level</a> - <a href="index.html">kernel/rcu</a> - tree_plugin.h<span style="font-size: 80%;"> (source / <a href="tree_plugin.h.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">landlock.info</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">130</td>
            <td class="headerCovTableEntry">156</td>
            <td class="headerCovTableEntryMed">83.3 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2021-04-22 12:43:58</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">12</td>
            <td class="headerCovTableEntry">14</td>
            <td class="headerCovTableEntryMed">85.7 %</td>
          </tr>
          <tr><td><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : /* SPDX-License-Identifier: GPL-2.0+ */</a>
<a name="2"><span class="lineNum">       2 </span>            : /*</a>
<a name="3"><span class="lineNum">       3 </span>            :  * Read-Copy Update mechanism for mutual exclusion (tree-based version)</a>
<a name="4"><span class="lineNum">       4 </span>            :  * Internal non-public definitions that provide either classic</a>
<a name="5"><span class="lineNum">       5 </span>            :  * or preemptible semantics.</a>
<a name="6"><span class="lineNum">       6 </span>            :  *</a>
<a name="7"><span class="lineNum">       7 </span>            :  * Copyright Red Hat, 2009</a>
<a name="8"><span class="lineNum">       8 </span>            :  * Copyright IBM Corporation, 2009</a>
<a name="9"><span class="lineNum">       9 </span>            :  *</a>
<a name="10"><span class="lineNum">      10 </span>            :  * Author: Ingo Molnar &lt;mingo@elte.hu&gt;</a>
<a name="11"><span class="lineNum">      11 </span>            :  *         Paul E. McKenney &lt;paulmck@linux.ibm.com&gt;</a>
<a name="12"><span class="lineNum">      12 </span>            :  */</a>
<a name="13"><span class="lineNum">      13 </span>            : </a>
<a name="14"><span class="lineNum">      14 </span>            : #include &quot;../locking/rtmutex_common.h&quot;</a>
<a name="15"><span class="lineNum">      15 </span>            : </a>
<a name="16"><span class="lineNum">      16 </span>            : #ifdef CONFIG_RCU_NOCB_CPU</a>
<a name="17"><span class="lineNum">      17 </span>            : static cpumask_var_t rcu_nocb_mask; /* CPUs to have callbacks offloaded. */</a>
<a name="18"><span class="lineNum">      18 </span>            : static bool __read_mostly rcu_nocb_poll;    /* Offload kthread are to poll. */</a>
<a name="19"><span class="lineNum">      19 </span>            : #endif /* #ifdef CONFIG_RCU_NOCB_CPU */</a>
<a name="20"><span class="lineNum">      20 </span>            : </a>
<a name="21"><span class="lineNum">      21 </span>            : /*</a>
<a name="22"><span class="lineNum">      22 </span>            :  * Check the RCU kernel configuration parameters and print informative</a>
<a name="23"><span class="lineNum">      23 </span>            :  * messages about anything out of the ordinary.</a>
<a name="24"><span class="lineNum">      24 </span>            :  */</a>
<a name="25"><span class="lineNum">      25 </span><span class="lineCov">          1 : static void __init rcu_bootup_announce_oddness(void)</span></a>
<a name="26"><span class="lineNum">      26 </span>            : {</a>
<a name="27"><span class="lineNum">      27 </span><span class="lineCov">          1 :         if (IS_ENABLED(CONFIG_RCU_TRACE))</span></a>
<a name="28"><span class="lineNum">      28 </span>            :                 pr_info(&quot;\tRCU event tracing is enabled.\n&quot;);</a>
<a name="29"><span class="lineNum">      29 </span><span class="lineCov">          1 :         if ((IS_ENABLED(CONFIG_64BIT) &amp;&amp; RCU_FANOUT != 64) ||</span></a>
<a name="30"><span class="lineNum">      30 </span>            :             (!IS_ENABLED(CONFIG_64BIT) &amp;&amp; RCU_FANOUT != 32))</a>
<a name="31"><span class="lineNum">      31 </span>            :                 pr_info(&quot;\tCONFIG_RCU_FANOUT set to non-default value of %d.\n&quot;,</a>
<a name="32"><span class="lineNum">      32 </span>            :                         RCU_FANOUT);</a>
<a name="33"><span class="lineNum">      33 </span><span class="lineCov">          1 :         if (rcu_fanout_exact)</span></a>
<a name="34"><span class="lineNum">      34 </span><span class="lineNoCov">          0 :                 pr_info(&quot;\tHierarchical RCU autobalancing is disabled.\n&quot;);</span></a>
<a name="35"><span class="lineNum">      35 </span><span class="lineCov">          1 :         if (IS_ENABLED(CONFIG_RCU_FAST_NO_HZ))</span></a>
<a name="36"><span class="lineNum">      36 </span>            :                 pr_info(&quot;\tRCU dyntick-idle grace-period acceleration is enabled.\n&quot;);</a>
<a name="37"><span class="lineNum">      37 </span><span class="lineCov">          1 :         if (IS_ENABLED(CONFIG_PROVE_RCU))</span></a>
<a name="38"><span class="lineNum">      38 </span><span class="lineCov">          1 :                 pr_info(&quot;\tRCU lockdep checking is enabled.\n&quot;);</span></a>
<a name="39"><span class="lineNum">      39 </span><span class="lineCov">          1 :         if (IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD))</span></a>
<a name="40"><span class="lineNum">      40 </span>            :                 pr_info(&quot;\tRCU strict (and thus non-scalable) grace periods enabled.\n&quot;);</a>
<a name="41"><span class="lineNum">      41 </span><span class="lineCov">          1 :         if (RCU_NUM_LVLS &gt;= 4)</span></a>
<a name="42"><span class="lineNum">      42 </span>            :                 pr_info(&quot;\tFour(or more)-level hierarchy is enabled.\n&quot;);</a>
<a name="43"><span class="lineNum">      43 </span><span class="lineCov">          1 :         if (RCU_FANOUT_LEAF != 16)</span></a>
<a name="44"><span class="lineNum">      44 </span>            :                 pr_info(&quot;\tBuild-time adjustment of leaf fanout to %d.\n&quot;,</a>
<a name="45"><span class="lineNum">      45 </span>            :                         RCU_FANOUT_LEAF);</a>
<a name="46"><span class="lineNum">      46 </span><span class="lineCov">          1 :         if (rcu_fanout_leaf != RCU_FANOUT_LEAF)</span></a>
<a name="47"><span class="lineNum">      47 </span><span class="lineNoCov">          0 :                 pr_info(&quot;\tBoot-time adjustment of leaf fanout to %d.\n&quot;,</span></a>
<a name="48"><span class="lineNum">      48 </span>            :                         rcu_fanout_leaf);</a>
<a name="49"><span class="lineNum">      49 </span><span class="lineCov">          1 :         if (nr_cpu_ids != NR_CPUS)</span></a>
<a name="50"><span class="lineNum">      50 </span><span class="lineCov">          1 :                 pr_info(&quot;\tRCU restricting CPUs from NR_CPUS=%d to nr_cpu_ids=%u.\n&quot;, NR_CPUS, nr_cpu_ids);</span></a>
<a name="51"><span class="lineNum">      51 </span>            : #ifdef CONFIG_RCU_BOOST</a>
<a name="52"><span class="lineNum">      52 </span>            :         pr_info(&quot;\tRCU priority boosting: priority %d delay %d ms.\n&quot;,</a>
<a name="53"><span class="lineNum">      53 </span>            :                 kthread_prio, CONFIG_RCU_BOOST_DELAY);</a>
<a name="54"><span class="lineNum">      54 </span>            : #endif</a>
<a name="55"><span class="lineNum">      55 </span><span class="lineCov">          1 :         if (blimit != DEFAULT_RCU_BLIMIT)</span></a>
<a name="56"><span class="lineNum">      56 </span><span class="lineNoCov">          0 :                 pr_info(&quot;\tBoot-time adjustment of callback invocation limit to %ld.\n&quot;, blimit);</span></a>
<a name="57"><span class="lineNum">      57 </span><span class="lineCov">          1 :         if (qhimark != DEFAULT_RCU_QHIMARK)</span></a>
<a name="58"><span class="lineNum">      58 </span><span class="lineNoCov">          0 :                 pr_info(&quot;\tBoot-time adjustment of callback high-water mark to %ld.\n&quot;, qhimark);</span></a>
<a name="59"><span class="lineNum">      59 </span><span class="lineCov">          1 :         if (qlowmark != DEFAULT_RCU_QLOMARK)</span></a>
<a name="60"><span class="lineNum">      60 </span><span class="lineNoCov">          0 :                 pr_info(&quot;\tBoot-time adjustment of callback low-water mark to %ld.\n&quot;, qlowmark);</span></a>
<a name="61"><span class="lineNum">      61 </span><span class="lineCov">          1 :         if (qovld != DEFAULT_RCU_QOVLD)</span></a>
<a name="62"><span class="lineNum">      62 </span><span class="lineNoCov">          0 :                 pr_info(&quot;\tBoot-time adjustment of callback overload level to %ld.\n&quot;, qovld);</span></a>
<a name="63"><span class="lineNum">      63 </span><span class="lineCov">          1 :         if (jiffies_till_first_fqs != ULONG_MAX)</span></a>
<a name="64"><span class="lineNum">      64 </span><span class="lineNoCov">          0 :                 pr_info(&quot;\tBoot-time adjustment of first FQS scan delay to %ld jiffies.\n&quot;, jiffies_till_first_fqs);</span></a>
<a name="65"><span class="lineNum">      65 </span><span class="lineCov">          1 :         if (jiffies_till_next_fqs != ULONG_MAX)</span></a>
<a name="66"><span class="lineNum">      66 </span><span class="lineNoCov">          0 :                 pr_info(&quot;\tBoot-time adjustment of subsequent FQS scan delay to %ld jiffies.\n&quot;, jiffies_till_next_fqs);</span></a>
<a name="67"><span class="lineNum">      67 </span><span class="lineCov">          1 :         if (jiffies_till_sched_qs != ULONG_MAX)</span></a>
<a name="68"><span class="lineNum">      68 </span><span class="lineNoCov">          0 :                 pr_info(&quot;\tBoot-time adjustment of scheduler-enlistment delay to %ld jiffies.\n&quot;, jiffies_till_sched_qs);</span></a>
<a name="69"><span class="lineNum">      69 </span><span class="lineCov">          1 :         if (rcu_kick_kthreads)</span></a>
<a name="70"><span class="lineNum">      70 </span><span class="lineNoCov">          0 :                 pr_info(&quot;\tKick kthreads if too-long grace period.\n&quot;);</span></a>
<a name="71"><span class="lineNum">      71 </span><span class="lineCov">          1 :         if (IS_ENABLED(CONFIG_DEBUG_OBJECTS_RCU_HEAD))</span></a>
<a name="72"><span class="lineNum">      72 </span><span class="lineCov">          1 :                 pr_info(&quot;\tRCU callback double-/use-after-free debug enabled.\n&quot;);</span></a>
<a name="73"><span class="lineNum">      73 </span><span class="lineCov">          1 :         if (gp_preinit_delay)</span></a>
<a name="74"><span class="lineNum">      74 </span><span class="lineNoCov">          0 :                 pr_info(&quot;\tRCU debug GP pre-init slowdown %d jiffies.\n&quot;, gp_preinit_delay);</span></a>
<a name="75"><span class="lineNum">      75 </span><span class="lineCov">          1 :         if (gp_init_delay)</span></a>
<a name="76"><span class="lineNum">      76 </span><span class="lineNoCov">          0 :                 pr_info(&quot;\tRCU debug GP init slowdown %d jiffies.\n&quot;, gp_init_delay);</span></a>
<a name="77"><span class="lineNum">      77 </span><span class="lineCov">          1 :         if (gp_cleanup_delay)</span></a>
<a name="78"><span class="lineNum">      78 </span><span class="lineNoCov">          0 :                 pr_info(&quot;\tRCU debug GP init slowdown %d jiffies.\n&quot;, gp_cleanup_delay);</span></a>
<a name="79"><span class="lineNum">      79 </span><span class="lineCov">          1 :         if (!use_softirq)</span></a>
<a name="80"><span class="lineNum">      80 </span><span class="lineNoCov">          0 :                 pr_info(&quot;\tRCU_SOFTIRQ processing moved to rcuc kthreads.\n&quot;);</span></a>
<a name="81"><span class="lineNum">      81 </span><span class="lineCov">          1 :         if (IS_ENABLED(CONFIG_RCU_EQS_DEBUG))</span></a>
<a name="82"><span class="lineNum">      82 </span>            :                 pr_info(&quot;\tRCU debug extended QS entry/exit.\n&quot;);</a>
<a name="83"><span class="lineNum">      83 </span><span class="lineCov">          1 :         rcupdate_announce_bootup_oddness();</span></a>
<a name="84"><span class="lineNum">      84 </span><span class="lineCov">          1 : }</span></a>
<a name="85"><span class="lineNum">      85 </span>            : </a>
<a name="86"><span class="lineNum">      86 </span>            : #ifdef CONFIG_PREEMPT_RCU</a>
<a name="87"><span class="lineNum">      87 </span>            : </a>
<a name="88"><span class="lineNum">      88 </span>            : static void rcu_report_exp_rnp(struct rcu_node *rnp, bool wake);</a>
<a name="89"><span class="lineNum">      89 </span>            : static void rcu_read_unlock_special(struct task_struct *t);</a>
<a name="90"><span class="lineNum">      90 </span>            : </a>
<a name="91"><span class="lineNum">      91 </span>            : /*</a>
<a name="92"><span class="lineNum">      92 </span>            :  * Tell them what RCU they are running.</a>
<a name="93"><span class="lineNum">      93 </span>            :  */</a>
<a name="94"><span class="lineNum">      94 </span>            : static void __init rcu_bootup_announce(void)</a>
<a name="95"><span class="lineNum">      95 </span>            : {</a>
<a name="96"><span class="lineNum">      96 </span>            :         pr_info(&quot;Preemptible hierarchical RCU implementation.\n&quot;);</a>
<a name="97"><span class="lineNum">      97 </span>            :         rcu_bootup_announce_oddness();</a>
<a name="98"><span class="lineNum">      98 </span>            : }</a>
<a name="99"><span class="lineNum">      99 </span>            : </a>
<a name="100"><span class="lineNum">     100 </span>            : /* Flags for rcu_preempt_ctxt_queue() decision table. */</a>
<a name="101"><span class="lineNum">     101 </span>            : #define RCU_GP_TASKS    0x8</a>
<a name="102"><span class="lineNum">     102 </span>            : #define RCU_EXP_TASKS   0x4</a>
<a name="103"><span class="lineNum">     103 </span>            : #define RCU_GP_BLKD     0x2</a>
<a name="104"><span class="lineNum">     104 </span>            : #define RCU_EXP_BLKD    0x1</a>
<a name="105"><span class="lineNum">     105 </span>            : </a>
<a name="106"><span class="lineNum">     106 </span>            : /*</a>
<a name="107"><span class="lineNum">     107 </span>            :  * Queues a task preempted within an RCU-preempt read-side critical</a>
<a name="108"><span class="lineNum">     108 </span>            :  * section into the appropriate location within the -&gt;blkd_tasks list,</a>
<a name="109"><span class="lineNum">     109 </span>            :  * depending on the states of any ongoing normal and expedited grace</a>
<a name="110"><span class="lineNum">     110 </span>            :  * periods.  The -&gt;gp_tasks pointer indicates which element the normal</a>
<a name="111"><span class="lineNum">     111 </span>            :  * grace period is waiting on (NULL if none), and the -&gt;exp_tasks pointer</a>
<a name="112"><span class="lineNum">     112 </span>            :  * indicates which element the expedited grace period is waiting on (again,</a>
<a name="113"><span class="lineNum">     113 </span>            :  * NULL if none).  If a grace period is waiting on a given element in the</a>
<a name="114"><span class="lineNum">     114 </span>            :  * -&gt;blkd_tasks list, it also waits on all subsequent elements.  Thus,</a>
<a name="115"><span class="lineNum">     115 </span>            :  * adding a task to the tail of the list blocks any grace period that is</a>
<a name="116"><span class="lineNum">     116 </span>            :  * already waiting on one of the elements.  In contrast, adding a task</a>
<a name="117"><span class="lineNum">     117 </span>            :  * to the head of the list won't block any grace period that is already</a>
<a name="118"><span class="lineNum">     118 </span>            :  * waiting on one of the elements.</a>
<a name="119"><span class="lineNum">     119 </span>            :  *</a>
<a name="120"><span class="lineNum">     120 </span>            :  * This queuing is imprecise, and can sometimes make an ongoing grace</a>
<a name="121"><span class="lineNum">     121 </span>            :  * period wait for a task that is not strictly speaking blocking it.</a>
<a name="122"><span class="lineNum">     122 </span>            :  * Given the choice, we needlessly block a normal grace period rather than</a>
<a name="123"><span class="lineNum">     123 </span>            :  * blocking an expedited grace period.</a>
<a name="124"><span class="lineNum">     124 </span>            :  *</a>
<a name="125"><span class="lineNum">     125 </span>            :  * Note that an endless sequence of expedited grace periods still cannot</a>
<a name="126"><span class="lineNum">     126 </span>            :  * indefinitely postpone a normal grace period.  Eventually, all of the</a>
<a name="127"><span class="lineNum">     127 </span>            :  * fixed number of preempted tasks blocking the normal grace period that are</a>
<a name="128"><span class="lineNum">     128 </span>            :  * not also blocking the expedited grace period will resume and complete</a>
<a name="129"><span class="lineNum">     129 </span>            :  * their RCU read-side critical sections.  At that point, the -&gt;gp_tasks</a>
<a name="130"><span class="lineNum">     130 </span>            :  * pointer will equal the -&gt;exp_tasks pointer, at which point the end of</a>
<a name="131"><span class="lineNum">     131 </span>            :  * the corresponding expedited grace period will also be the end of the</a>
<a name="132"><span class="lineNum">     132 </span>            :  * normal grace period.</a>
<a name="133"><span class="lineNum">     133 </span>            :  */</a>
<a name="134"><span class="lineNum">     134 </span>            : static void rcu_preempt_ctxt_queue(struct rcu_node *rnp, struct rcu_data *rdp)</a>
<a name="135"><span class="lineNum">     135 </span>            :         __releases(rnp-&gt;lock) /* But leaves rrupts disabled. */</a>
<a name="136"><span class="lineNum">     136 </span>            : {</a>
<a name="137"><span class="lineNum">     137 </span>            :         int blkd_state = (rnp-&gt;gp_tasks ? RCU_GP_TASKS : 0) +</a>
<a name="138"><span class="lineNum">     138 </span>            :                          (rnp-&gt;exp_tasks ? RCU_EXP_TASKS : 0) +</a>
<a name="139"><span class="lineNum">     139 </span>            :                          (rnp-&gt;qsmask &amp; rdp-&gt;grpmask ? RCU_GP_BLKD : 0) +</a>
<a name="140"><span class="lineNum">     140 </span>            :                          (rnp-&gt;expmask &amp; rdp-&gt;grpmask ? RCU_EXP_BLKD : 0);</a>
<a name="141"><span class="lineNum">     141 </span>            :         struct task_struct *t = current;</a>
<a name="142"><span class="lineNum">     142 </span>            : </a>
<a name="143"><span class="lineNum">     143 </span>            :         raw_lockdep_assert_held_rcu_node(rnp);</a>
<a name="144"><span class="lineNum">     144 </span>            :         WARN_ON_ONCE(rdp-&gt;mynode != rnp);</a>
<a name="145"><span class="lineNum">     145 </span>            :         WARN_ON_ONCE(!rcu_is_leaf_node(rnp));</a>
<a name="146"><span class="lineNum">     146 </span>            :         /* RCU better not be waiting on newly onlined CPUs! */</a>
<a name="147"><span class="lineNum">     147 </span>            :         WARN_ON_ONCE(rnp-&gt;qsmaskinitnext &amp; ~rnp-&gt;qsmaskinit &amp; rnp-&gt;qsmask &amp;</a>
<a name="148"><span class="lineNum">     148 </span>            :                      rdp-&gt;grpmask);</a>
<a name="149"><span class="lineNum">     149 </span>            : </a>
<a name="150"><span class="lineNum">     150 </span>            :         /*</a>
<a name="151"><span class="lineNum">     151 </span>            :          * Decide where to queue the newly blocked task.  In theory,</a>
<a name="152"><span class="lineNum">     152 </span>            :          * this could be an if-statement.  In practice, when I tried</a>
<a name="153"><span class="lineNum">     153 </span>            :          * that, it was quite messy.</a>
<a name="154"><span class="lineNum">     154 </span>            :          */</a>
<a name="155"><span class="lineNum">     155 </span>            :         switch (blkd_state) {</a>
<a name="156"><span class="lineNum">     156 </span>            :         case 0:</a>
<a name="157"><span class="lineNum">     157 </span>            :         case                RCU_EXP_TASKS:</a>
<a name="158"><span class="lineNum">     158 </span>            :         case                RCU_EXP_TASKS + RCU_GP_BLKD:</a>
<a name="159"><span class="lineNum">     159 </span>            :         case RCU_GP_TASKS:</a>
<a name="160"><span class="lineNum">     160 </span>            :         case RCU_GP_TASKS + RCU_EXP_TASKS:</a>
<a name="161"><span class="lineNum">     161 </span>            : </a>
<a name="162"><span class="lineNum">     162 </span>            :                 /*</a>
<a name="163"><span class="lineNum">     163 </span>            :                  * Blocking neither GP, or first task blocking the normal</a>
<a name="164"><span class="lineNum">     164 </span>            :                  * GP but not blocking the already-waiting expedited GP.</a>
<a name="165"><span class="lineNum">     165 </span>            :                  * Queue at the head of the list to avoid unnecessarily</a>
<a name="166"><span class="lineNum">     166 </span>            :                  * blocking the already-waiting GPs.</a>
<a name="167"><span class="lineNum">     167 </span>            :                  */</a>
<a name="168"><span class="lineNum">     168 </span>            :                 list_add(&amp;t-&gt;rcu_node_entry, &amp;rnp-&gt;blkd_tasks);</a>
<a name="169"><span class="lineNum">     169 </span>            :                 break;</a>
<a name="170"><span class="lineNum">     170 </span>            : </a>
<a name="171"><span class="lineNum">     171 </span>            :         case                                              RCU_EXP_BLKD:</a>
<a name="172"><span class="lineNum">     172 </span>            :         case                                RCU_GP_BLKD:</a>
<a name="173"><span class="lineNum">     173 </span>            :         case                                RCU_GP_BLKD + RCU_EXP_BLKD:</a>
<a name="174"><span class="lineNum">     174 </span>            :         case RCU_GP_TASKS +                               RCU_EXP_BLKD:</a>
<a name="175"><span class="lineNum">     175 </span>            :         case RCU_GP_TASKS +                 RCU_GP_BLKD + RCU_EXP_BLKD:</a>
<a name="176"><span class="lineNum">     176 </span>            :         case RCU_GP_TASKS + RCU_EXP_TASKS + RCU_GP_BLKD + RCU_EXP_BLKD:</a>
<a name="177"><span class="lineNum">     177 </span>            : </a>
<a name="178"><span class="lineNum">     178 </span>            :                 /*</a>
<a name="179"><span class="lineNum">     179 </span>            :                  * First task arriving that blocks either GP, or first task</a>
<a name="180"><span class="lineNum">     180 </span>            :                  * arriving that blocks the expedited GP (with the normal</a>
<a name="181"><span class="lineNum">     181 </span>            :                  * GP already waiting), or a task arriving that blocks</a>
<a name="182"><span class="lineNum">     182 </span>            :                  * both GPs with both GPs already waiting.  Queue at the</a>
<a name="183"><span class="lineNum">     183 </span>            :                  * tail of the list to avoid any GP waiting on any of the</a>
<a name="184"><span class="lineNum">     184 </span>            :                  * already queued tasks that are not blocking it.</a>
<a name="185"><span class="lineNum">     185 </span>            :                  */</a>
<a name="186"><span class="lineNum">     186 </span>            :                 list_add_tail(&amp;t-&gt;rcu_node_entry, &amp;rnp-&gt;blkd_tasks);</a>
<a name="187"><span class="lineNum">     187 </span>            :                 break;</a>
<a name="188"><span class="lineNum">     188 </span>            : </a>
<a name="189"><span class="lineNum">     189 </span>            :         case                RCU_EXP_TASKS +               RCU_EXP_BLKD:</a>
<a name="190"><span class="lineNum">     190 </span>            :         case                RCU_EXP_TASKS + RCU_GP_BLKD + RCU_EXP_BLKD:</a>
<a name="191"><span class="lineNum">     191 </span>            :         case RCU_GP_TASKS + RCU_EXP_TASKS +               RCU_EXP_BLKD:</a>
<a name="192"><span class="lineNum">     192 </span>            : </a>
<a name="193"><span class="lineNum">     193 </span>            :                 /*</a>
<a name="194"><span class="lineNum">     194 </span>            :                  * Second or subsequent task blocking the expedited GP.</a>
<a name="195"><span class="lineNum">     195 </span>            :                  * The task either does not block the normal GP, or is the</a>
<a name="196"><span class="lineNum">     196 </span>            :                  * first task blocking the normal GP.  Queue just after</a>
<a name="197"><span class="lineNum">     197 </span>            :                  * the first task blocking the expedited GP.</a>
<a name="198"><span class="lineNum">     198 </span>            :                  */</a>
<a name="199"><span class="lineNum">     199 </span>            :                 list_add(&amp;t-&gt;rcu_node_entry, rnp-&gt;exp_tasks);</a>
<a name="200"><span class="lineNum">     200 </span>            :                 break;</a>
<a name="201"><span class="lineNum">     201 </span>            : </a>
<a name="202"><span class="lineNum">     202 </span>            :         case RCU_GP_TASKS +                 RCU_GP_BLKD:</a>
<a name="203"><span class="lineNum">     203 </span>            :         case RCU_GP_TASKS + RCU_EXP_TASKS + RCU_GP_BLKD:</a>
<a name="204"><span class="lineNum">     204 </span>            : </a>
<a name="205"><span class="lineNum">     205 </span>            :                 /*</a>
<a name="206"><span class="lineNum">     206 </span>            :                  * Second or subsequent task blocking the normal GP.</a>
<a name="207"><span class="lineNum">     207 </span>            :                  * The task does not block the expedited GP. Queue just</a>
<a name="208"><span class="lineNum">     208 </span>            :                  * after the first task blocking the normal GP.</a>
<a name="209"><span class="lineNum">     209 </span>            :                  */</a>
<a name="210"><span class="lineNum">     210 </span>            :                 list_add(&amp;t-&gt;rcu_node_entry, rnp-&gt;gp_tasks);</a>
<a name="211"><span class="lineNum">     211 </span>            :                 break;</a>
<a name="212"><span class="lineNum">     212 </span>            : </a>
<a name="213"><span class="lineNum">     213 </span>            :         default:</a>
<a name="214"><span class="lineNum">     214 </span>            : </a>
<a name="215"><span class="lineNum">     215 </span>            :                 /* Yet another exercise in excessive paranoia. */</a>
<a name="216"><span class="lineNum">     216 </span>            :                 WARN_ON_ONCE(1);</a>
<a name="217"><span class="lineNum">     217 </span>            :                 break;</a>
<a name="218"><span class="lineNum">     218 </span>            :         }</a>
<a name="219"><span class="lineNum">     219 </span>            : </a>
<a name="220"><span class="lineNum">     220 </span>            :         /*</a>
<a name="221"><span class="lineNum">     221 </span>            :          * We have now queued the task.  If it was the first one to</a>
<a name="222"><span class="lineNum">     222 </span>            :          * block either grace period, update the -&gt;gp_tasks and/or</a>
<a name="223"><span class="lineNum">     223 </span>            :          * -&gt;exp_tasks pointers, respectively, to reference the newly</a>
<a name="224"><span class="lineNum">     224 </span>            :          * blocked tasks.</a>
<a name="225"><span class="lineNum">     225 </span>            :          */</a>
<a name="226"><span class="lineNum">     226 </span>            :         if (!rnp-&gt;gp_tasks &amp;&amp; (blkd_state &amp; RCU_GP_BLKD)) {</a>
<a name="227"><span class="lineNum">     227 </span>            :                 WRITE_ONCE(rnp-&gt;gp_tasks, &amp;t-&gt;rcu_node_entry);</a>
<a name="228"><span class="lineNum">     228 </span>            :                 WARN_ON_ONCE(rnp-&gt;completedqs == rnp-&gt;gp_seq);</a>
<a name="229"><span class="lineNum">     229 </span>            :         }</a>
<a name="230"><span class="lineNum">     230 </span>            :         if (!rnp-&gt;exp_tasks &amp;&amp; (blkd_state &amp; RCU_EXP_BLKD))</a>
<a name="231"><span class="lineNum">     231 </span>            :                 WRITE_ONCE(rnp-&gt;exp_tasks, &amp;t-&gt;rcu_node_entry);</a>
<a name="232"><span class="lineNum">     232 </span>            :         WARN_ON_ONCE(!(blkd_state &amp; RCU_GP_BLKD) !=</a>
<a name="233"><span class="lineNum">     233 </span>            :                      !(rnp-&gt;qsmask &amp; rdp-&gt;grpmask));</a>
<a name="234"><span class="lineNum">     234 </span>            :         WARN_ON_ONCE(!(blkd_state &amp; RCU_EXP_BLKD) !=</a>
<a name="235"><span class="lineNum">     235 </span>            :                      !(rnp-&gt;expmask &amp; rdp-&gt;grpmask));</a>
<a name="236"><span class="lineNum">     236 </span>            :         raw_spin_unlock_rcu_node(rnp); /* interrupts remain disabled. */</a>
<a name="237"><span class="lineNum">     237 </span>            : </a>
<a name="238"><span class="lineNum">     238 </span>            :         /*</a>
<a name="239"><span class="lineNum">     239 </span>            :          * Report the quiescent state for the expedited GP.  This expedited</a>
<a name="240"><span class="lineNum">     240 </span>            :          * GP should not be able to end until we report, so there should be</a>
<a name="241"><span class="lineNum">     241 </span>            :          * no need to check for a subsequent expedited GP.  (Though we are</a>
<a name="242"><span class="lineNum">     242 </span>            :          * still in a quiescent state in any case.)</a>
<a name="243"><span class="lineNum">     243 </span>            :          */</a>
<a name="244"><span class="lineNum">     244 </span>            :         if (blkd_state &amp; RCU_EXP_BLKD &amp;&amp; rdp-&gt;exp_deferred_qs)</a>
<a name="245"><span class="lineNum">     245 </span>            :                 rcu_report_exp_rdp(rdp);</a>
<a name="246"><span class="lineNum">     246 </span>            :         else</a>
<a name="247"><span class="lineNum">     247 </span>            :                 WARN_ON_ONCE(rdp-&gt;exp_deferred_qs);</a>
<a name="248"><span class="lineNum">     248 </span>            : }</a>
<a name="249"><span class="lineNum">     249 </span>            : </a>
<a name="250"><span class="lineNum">     250 </span>            : /*</a>
<a name="251"><span class="lineNum">     251 </span>            :  * Record a preemptible-RCU quiescent state for the specified CPU.</a>
<a name="252"><span class="lineNum">     252 </span>            :  * Note that this does not necessarily mean that the task currently running</a>
<a name="253"><span class="lineNum">     253 </span>            :  * on the CPU is in a quiescent state:  Instead, it means that the current</a>
<a name="254"><span class="lineNum">     254 </span>            :  * grace period need not wait on any RCU read-side critical section that</a>
<a name="255"><span class="lineNum">     255 </span>            :  * starts later on this CPU.  It also means that if the current task is</a>
<a name="256"><span class="lineNum">     256 </span>            :  * in an RCU read-side critical section, it has already added itself to</a>
<a name="257"><span class="lineNum">     257 </span>            :  * some leaf rcu_node structure's -&gt;blkd_tasks list.  In addition to the</a>
<a name="258"><span class="lineNum">     258 </span>            :  * current task, there might be any number of other tasks blocked while</a>
<a name="259"><span class="lineNum">     259 </span>            :  * in an RCU read-side critical section.</a>
<a name="260"><span class="lineNum">     260 </span>            :  *</a>
<a name="261"><span class="lineNum">     261 </span>            :  * Callers to this function must disable preemption.</a>
<a name="262"><span class="lineNum">     262 </span>            :  */</a>
<a name="263"><span class="lineNum">     263 </span>            : static void rcu_qs(void)</a>
<a name="264"><span class="lineNum">     264 </span>            : {</a>
<a name="265"><span class="lineNum">     265 </span>            :         RCU_LOCKDEP_WARN(preemptible(), &quot;rcu_qs() invoked with preemption enabled!!!\n&quot;);</a>
<a name="266"><span class="lineNum">     266 </span>            :         if (__this_cpu_read(rcu_data.cpu_no_qs.s)) {</a>
<a name="267"><span class="lineNum">     267 </span>            :                 trace_rcu_grace_period(TPS(&quot;rcu_preempt&quot;),</a>
<a name="268"><span class="lineNum">     268 </span>            :                                        __this_cpu_read(rcu_data.gp_seq),</a>
<a name="269"><span class="lineNum">     269 </span>            :                                        TPS(&quot;cpuqs&quot;));</a>
<a name="270"><span class="lineNum">     270 </span>            :                 __this_cpu_write(rcu_data.cpu_no_qs.b.norm, false);</a>
<a name="271"><span class="lineNum">     271 </span>            :                 barrier(); /* Coordinate with rcu_flavor_sched_clock_irq(). */</a>
<a name="272"><span class="lineNum">     272 </span>            :                 WRITE_ONCE(current-&gt;rcu_read_unlock_special.b.need_qs, false);</a>
<a name="273"><span class="lineNum">     273 </span>            :         }</a>
<a name="274"><span class="lineNum">     274 </span>            : }</a>
<a name="275"><span class="lineNum">     275 </span>            : </a>
<a name="276"><span class="lineNum">     276 </span>            : /*</a>
<a name="277"><span class="lineNum">     277 </span>            :  * We have entered the scheduler, and the current task might soon be</a>
<a name="278"><span class="lineNum">     278 </span>            :  * context-switched away from.  If this task is in an RCU read-side</a>
<a name="279"><span class="lineNum">     279 </span>            :  * critical section, we will no longer be able to rely on the CPU to</a>
<a name="280"><span class="lineNum">     280 </span>            :  * record that fact, so we enqueue the task on the blkd_tasks list.</a>
<a name="281"><span class="lineNum">     281 </span>            :  * The task will dequeue itself when it exits the outermost enclosing</a>
<a name="282"><span class="lineNum">     282 </span>            :  * RCU read-side critical section.  Therefore, the current grace period</a>
<a name="283"><span class="lineNum">     283 </span>            :  * cannot be permitted to complete until the blkd_tasks list entries</a>
<a name="284"><span class="lineNum">     284 </span>            :  * predating the current grace period drain, in other words, until</a>
<a name="285"><span class="lineNum">     285 </span>            :  * rnp-&gt;gp_tasks becomes NULL.</a>
<a name="286"><span class="lineNum">     286 </span>            :  *</a>
<a name="287"><span class="lineNum">     287 </span>            :  * Caller must disable interrupts.</a>
<a name="288"><span class="lineNum">     288 </span>            :  */</a>
<a name="289"><span class="lineNum">     289 </span>            : void rcu_note_context_switch(bool preempt)</a>
<a name="290"><span class="lineNum">     290 </span>            : {</a>
<a name="291"><span class="lineNum">     291 </span>            :         struct task_struct *t = current;</a>
<a name="292"><span class="lineNum">     292 </span>            :         struct rcu_data *rdp = this_cpu_ptr(&amp;rcu_data);</a>
<a name="293"><span class="lineNum">     293 </span>            :         struct rcu_node *rnp;</a>
<a name="294"><span class="lineNum">     294 </span>            : </a>
<a name="295"><span class="lineNum">     295 </span>            :         trace_rcu_utilization(TPS(&quot;Start context switch&quot;));</a>
<a name="296"><span class="lineNum">     296 </span>            :         lockdep_assert_irqs_disabled();</a>
<a name="297"><span class="lineNum">     297 </span>            :         WARN_ON_ONCE(!preempt &amp;&amp; rcu_preempt_depth() &gt; 0);</a>
<a name="298"><span class="lineNum">     298 </span>            :         if (rcu_preempt_depth() &gt; 0 &amp;&amp;</a>
<a name="299"><span class="lineNum">     299 </span>            :             !t-&gt;rcu_read_unlock_special.b.blocked) {</a>
<a name="300"><span class="lineNum">     300 </span>            : </a>
<a name="301"><span class="lineNum">     301 </span>            :                 /* Possibly blocking in an RCU read-side critical section. */</a>
<a name="302"><span class="lineNum">     302 </span>            :                 rnp = rdp-&gt;mynode;</a>
<a name="303"><span class="lineNum">     303 </span>            :                 raw_spin_lock_rcu_node(rnp);</a>
<a name="304"><span class="lineNum">     304 </span>            :                 t-&gt;rcu_read_unlock_special.b.blocked = true;</a>
<a name="305"><span class="lineNum">     305 </span>            :                 t-&gt;rcu_blocked_node = rnp;</a>
<a name="306"><span class="lineNum">     306 </span>            : </a>
<a name="307"><span class="lineNum">     307 </span>            :                 /*</a>
<a name="308"><span class="lineNum">     308 </span>            :                  * Verify the CPU's sanity, trace the preemption, and</a>
<a name="309"><span class="lineNum">     309 </span>            :                  * then queue the task as required based on the states</a>
<a name="310"><span class="lineNum">     310 </span>            :                  * of any ongoing and expedited grace periods.</a>
<a name="311"><span class="lineNum">     311 </span>            :                  */</a>
<a name="312"><span class="lineNum">     312 </span>            :                 WARN_ON_ONCE((rdp-&gt;grpmask &amp; rcu_rnp_online_cpus(rnp)) == 0);</a>
<a name="313"><span class="lineNum">     313 </span>            :                 WARN_ON_ONCE(!list_empty(&amp;t-&gt;rcu_node_entry));</a>
<a name="314"><span class="lineNum">     314 </span>            :                 trace_rcu_preempt_task(rcu_state.name,</a>
<a name="315"><span class="lineNum">     315 </span>            :                                        t-&gt;pid,</a>
<a name="316"><span class="lineNum">     316 </span>            :                                        (rnp-&gt;qsmask &amp; rdp-&gt;grpmask)</a>
<a name="317"><span class="lineNum">     317 </span>            :                                        ? rnp-&gt;gp_seq</a>
<a name="318"><span class="lineNum">     318 </span>            :                                        : rcu_seq_snap(&amp;rnp-&gt;gp_seq));</a>
<a name="319"><span class="lineNum">     319 </span>            :                 rcu_preempt_ctxt_queue(rnp, rdp);</a>
<a name="320"><span class="lineNum">     320 </span>            :         } else {</a>
<a name="321"><span class="lineNum">     321 </span>            :                 rcu_preempt_deferred_qs(t);</a>
<a name="322"><span class="lineNum">     322 </span>            :         }</a>
<a name="323"><span class="lineNum">     323 </span>            : </a>
<a name="324"><span class="lineNum">     324 </span>            :         /*</a>
<a name="325"><span class="lineNum">     325 </span>            :          * Either we were not in an RCU read-side critical section to</a>
<a name="326"><span class="lineNum">     326 </span>            :          * begin with, or we have now recorded that critical section</a>
<a name="327"><span class="lineNum">     327 </span>            :          * globally.  Either way, we can now note a quiescent state</a>
<a name="328"><span class="lineNum">     328 </span>            :          * for this CPU.  Again, if we were in an RCU read-side critical</a>
<a name="329"><span class="lineNum">     329 </span>            :          * section, and if that critical section was blocking the current</a>
<a name="330"><span class="lineNum">     330 </span>            :          * grace period, then the fact that the task has been enqueued</a>
<a name="331"><span class="lineNum">     331 </span>            :          * means that we continue to block the current grace period.</a>
<a name="332"><span class="lineNum">     332 </span>            :          */</a>
<a name="333"><span class="lineNum">     333 </span>            :         rcu_qs();</a>
<a name="334"><span class="lineNum">     334 </span>            :         if (rdp-&gt;exp_deferred_qs)</a>
<a name="335"><span class="lineNum">     335 </span>            :                 rcu_report_exp_rdp(rdp);</a>
<a name="336"><span class="lineNum">     336 </span>            :         rcu_tasks_qs(current, preempt);</a>
<a name="337"><span class="lineNum">     337 </span>            :         trace_rcu_utilization(TPS(&quot;End context switch&quot;));</a>
<a name="338"><span class="lineNum">     338 </span>            : }</a>
<a name="339"><span class="lineNum">     339 </span>            : EXPORT_SYMBOL_GPL(rcu_note_context_switch);</a>
<a name="340"><span class="lineNum">     340 </span>            : </a>
<a name="341"><span class="lineNum">     341 </span>            : /*</a>
<a name="342"><span class="lineNum">     342 </span>            :  * Check for preempted RCU readers blocking the current grace period</a>
<a name="343"><span class="lineNum">     343 </span>            :  * for the specified rcu_node structure.  If the caller needs a reliable</a>
<a name="344"><span class="lineNum">     344 </span>            :  * answer, it must hold the rcu_node's -&gt;lock.</a>
<a name="345"><span class="lineNum">     345 </span>            :  */</a>
<a name="346"><span class="lineNum">     346 </span>            : static int rcu_preempt_blocked_readers_cgp(struct rcu_node *rnp)</a>
<a name="347"><span class="lineNum">     347 </span>            : {</a>
<a name="348"><span class="lineNum">     348 </span>            :         return READ_ONCE(rnp-&gt;gp_tasks) != NULL;</a>
<a name="349"><span class="lineNum">     349 </span>            : }</a>
<a name="350"><span class="lineNum">     350 </span>            : </a>
<a name="351"><span class="lineNum">     351 </span>            : /* limit value for -&gt;rcu_read_lock_nesting. */</a>
<a name="352"><span class="lineNum">     352 </span>            : #define RCU_NEST_PMAX (INT_MAX / 2)</a>
<a name="353"><span class="lineNum">     353 </span>            : </a>
<a name="354"><span class="lineNum">     354 </span>            : static void rcu_preempt_read_enter(void)</a>
<a name="355"><span class="lineNum">     355 </span>            : {</a>
<a name="356"><span class="lineNum">     356 </span>            :         current-&gt;rcu_read_lock_nesting++;</a>
<a name="357"><span class="lineNum">     357 </span>            : }</a>
<a name="358"><span class="lineNum">     358 </span>            : </a>
<a name="359"><span class="lineNum">     359 </span>            : static int rcu_preempt_read_exit(void)</a>
<a name="360"><span class="lineNum">     360 </span>            : {</a>
<a name="361"><span class="lineNum">     361 </span>            :         return --current-&gt;rcu_read_lock_nesting;</a>
<a name="362"><span class="lineNum">     362 </span>            : }</a>
<a name="363"><span class="lineNum">     363 </span>            : </a>
<a name="364"><span class="lineNum">     364 </span>            : static void rcu_preempt_depth_set(int val)</a>
<a name="365"><span class="lineNum">     365 </span>            : {</a>
<a name="366"><span class="lineNum">     366 </span>            :         current-&gt;rcu_read_lock_nesting = val;</a>
<a name="367"><span class="lineNum">     367 </span>            : }</a>
<a name="368"><span class="lineNum">     368 </span>            : </a>
<a name="369"><span class="lineNum">     369 </span>            : /*</a>
<a name="370"><span class="lineNum">     370 </span>            :  * Preemptible RCU implementation for rcu_read_lock().</a>
<a name="371"><span class="lineNum">     371 </span>            :  * Just increment -&gt;rcu_read_lock_nesting, shared state will be updated</a>
<a name="372"><span class="lineNum">     372 </span>            :  * if we block.</a>
<a name="373"><span class="lineNum">     373 </span>            :  */</a>
<a name="374"><span class="lineNum">     374 </span>            : void __rcu_read_lock(void)</a>
<a name="375"><span class="lineNum">     375 </span>            : {</a>
<a name="376"><span class="lineNum">     376 </span>            :         rcu_preempt_read_enter();</a>
<a name="377"><span class="lineNum">     377 </span>            :         if (IS_ENABLED(CONFIG_PROVE_LOCKING))</a>
<a name="378"><span class="lineNum">     378 </span>            :                 WARN_ON_ONCE(rcu_preempt_depth() &gt; RCU_NEST_PMAX);</a>
<a name="379"><span class="lineNum">     379 </span>            :         if (IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD) &amp;&amp; rcu_state.gp_kthread)</a>
<a name="380"><span class="lineNum">     380 </span>            :                 WRITE_ONCE(current-&gt;rcu_read_unlock_special.b.need_qs, true);</a>
<a name="381"><span class="lineNum">     381 </span>            :         barrier();  /* critical section after entry code. */</a>
<a name="382"><span class="lineNum">     382 </span>            : }</a>
<a name="383"><span class="lineNum">     383 </span>            : EXPORT_SYMBOL_GPL(__rcu_read_lock);</a>
<a name="384"><span class="lineNum">     384 </span>            : </a>
<a name="385"><span class="lineNum">     385 </span>            : /*</a>
<a name="386"><span class="lineNum">     386 </span>            :  * Preemptible RCU implementation for rcu_read_unlock().</a>
<a name="387"><span class="lineNum">     387 </span>            :  * Decrement -&gt;rcu_read_lock_nesting.  If the result is zero (outermost</a>
<a name="388"><span class="lineNum">     388 </span>            :  * rcu_read_unlock()) and -&gt;rcu_read_unlock_special is non-zero, then</a>
<a name="389"><span class="lineNum">     389 </span>            :  * invoke rcu_read_unlock_special() to clean up after a context switch</a>
<a name="390"><span class="lineNum">     390 </span>            :  * in an RCU read-side critical section and other special cases.</a>
<a name="391"><span class="lineNum">     391 </span>            :  */</a>
<a name="392"><span class="lineNum">     392 </span>            : void __rcu_read_unlock(void)</a>
<a name="393"><span class="lineNum">     393 </span>            : {</a>
<a name="394"><span class="lineNum">     394 </span>            :         struct task_struct *t = current;</a>
<a name="395"><span class="lineNum">     395 </span>            : </a>
<a name="396"><span class="lineNum">     396 </span>            :         if (rcu_preempt_read_exit() == 0) {</a>
<a name="397"><span class="lineNum">     397 </span>            :                 barrier();  /* critical section before exit code. */</a>
<a name="398"><span class="lineNum">     398 </span>            :                 if (unlikely(READ_ONCE(t-&gt;rcu_read_unlock_special.s)))</a>
<a name="399"><span class="lineNum">     399 </span>            :                         rcu_read_unlock_special(t);</a>
<a name="400"><span class="lineNum">     400 </span>            :         }</a>
<a name="401"><span class="lineNum">     401 </span>            :         if (IS_ENABLED(CONFIG_PROVE_LOCKING)) {</a>
<a name="402"><span class="lineNum">     402 </span>            :                 int rrln = rcu_preempt_depth();</a>
<a name="403"><span class="lineNum">     403 </span>            : </a>
<a name="404"><span class="lineNum">     404 </span>            :                 WARN_ON_ONCE(rrln &lt; 0 || rrln &gt; RCU_NEST_PMAX);</a>
<a name="405"><span class="lineNum">     405 </span>            :         }</a>
<a name="406"><span class="lineNum">     406 </span>            : }</a>
<a name="407"><span class="lineNum">     407 </span>            : EXPORT_SYMBOL_GPL(__rcu_read_unlock);</a>
<a name="408"><span class="lineNum">     408 </span>            : </a>
<a name="409"><span class="lineNum">     409 </span>            : /*</a>
<a name="410"><span class="lineNum">     410 </span>            :  * Advance a -&gt;blkd_tasks-list pointer to the next entry, instead</a>
<a name="411"><span class="lineNum">     411 </span>            :  * returning NULL if at the end of the list.</a>
<a name="412"><span class="lineNum">     412 </span>            :  */</a>
<a name="413"><span class="lineNum">     413 </span>            : static struct list_head *rcu_next_node_entry(struct task_struct *t,</a>
<a name="414"><span class="lineNum">     414 </span>            :                                              struct rcu_node *rnp)</a>
<a name="415"><span class="lineNum">     415 </span>            : {</a>
<a name="416"><span class="lineNum">     416 </span>            :         struct list_head *np;</a>
<a name="417"><span class="lineNum">     417 </span>            : </a>
<a name="418"><span class="lineNum">     418 </span>            :         np = t-&gt;rcu_node_entry.next;</a>
<a name="419"><span class="lineNum">     419 </span>            :         if (np == &amp;rnp-&gt;blkd_tasks)</a>
<a name="420"><span class="lineNum">     420 </span>            :                 np = NULL;</a>
<a name="421"><span class="lineNum">     421 </span>            :         return np;</a>
<a name="422"><span class="lineNum">     422 </span>            : }</a>
<a name="423"><span class="lineNum">     423 </span>            : </a>
<a name="424"><span class="lineNum">     424 </span>            : /*</a>
<a name="425"><span class="lineNum">     425 </span>            :  * Return true if the specified rcu_node structure has tasks that were</a>
<a name="426"><span class="lineNum">     426 </span>            :  * preempted within an RCU read-side critical section.</a>
<a name="427"><span class="lineNum">     427 </span>            :  */</a>
<a name="428"><span class="lineNum">     428 </span>            : static bool rcu_preempt_has_tasks(struct rcu_node *rnp)</a>
<a name="429"><span class="lineNum">     429 </span>            : {</a>
<a name="430"><span class="lineNum">     430 </span>            :         return !list_empty(&amp;rnp-&gt;blkd_tasks);</a>
<a name="431"><span class="lineNum">     431 </span>            : }</a>
<a name="432"><span class="lineNum">     432 </span>            : </a>
<a name="433"><span class="lineNum">     433 </span>            : /*</a>
<a name="434"><span class="lineNum">     434 </span>            :  * Report deferred quiescent states.  The deferral time can</a>
<a name="435"><span class="lineNum">     435 </span>            :  * be quite short, for example, in the case of the call from</a>
<a name="436"><span class="lineNum">     436 </span>            :  * rcu_read_unlock_special().</a>
<a name="437"><span class="lineNum">     437 </span>            :  */</a>
<a name="438"><span class="lineNum">     438 </span>            : static void</a>
<a name="439"><span class="lineNum">     439 </span>            : rcu_preempt_deferred_qs_irqrestore(struct task_struct *t, unsigned long flags)</a>
<a name="440"><span class="lineNum">     440 </span>            : {</a>
<a name="441"><span class="lineNum">     441 </span>            :         bool empty_exp;</a>
<a name="442"><span class="lineNum">     442 </span>            :         bool empty_norm;</a>
<a name="443"><span class="lineNum">     443 </span>            :         bool empty_exp_now;</a>
<a name="444"><span class="lineNum">     444 </span>            :         struct list_head *np;</a>
<a name="445"><span class="lineNum">     445 </span>            :         bool drop_boost_mutex = false;</a>
<a name="446"><span class="lineNum">     446 </span>            :         struct rcu_data *rdp;</a>
<a name="447"><span class="lineNum">     447 </span>            :         struct rcu_node *rnp;</a>
<a name="448"><span class="lineNum">     448 </span>            :         union rcu_special special;</a>
<a name="449"><span class="lineNum">     449 </span>            : </a>
<a name="450"><span class="lineNum">     450 </span>            :         /*</a>
<a name="451"><span class="lineNum">     451 </span>            :          * If RCU core is waiting for this CPU to exit its critical section,</a>
<a name="452"><span class="lineNum">     452 </span>            :          * report the fact that it has exited.  Because irqs are disabled,</a>
<a name="453"><span class="lineNum">     453 </span>            :          * t-&gt;rcu_read_unlock_special cannot change.</a>
<a name="454"><span class="lineNum">     454 </span>            :          */</a>
<a name="455"><span class="lineNum">     455 </span>            :         special = t-&gt;rcu_read_unlock_special;</a>
<a name="456"><span class="lineNum">     456 </span>            :         rdp = this_cpu_ptr(&amp;rcu_data);</a>
<a name="457"><span class="lineNum">     457 </span>            :         if (!special.s &amp;&amp; !rdp-&gt;exp_deferred_qs) {</a>
<a name="458"><span class="lineNum">     458 </span>            :                 local_irq_restore(flags);</a>
<a name="459"><span class="lineNum">     459 </span>            :                 return;</a>
<a name="460"><span class="lineNum">     460 </span>            :         }</a>
<a name="461"><span class="lineNum">     461 </span>            :         t-&gt;rcu_read_unlock_special.s = 0;</a>
<a name="462"><span class="lineNum">     462 </span>            :         if (special.b.need_qs) {</a>
<a name="463"><span class="lineNum">     463 </span>            :                 if (IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD)) {</a>
<a name="464"><span class="lineNum">     464 </span>            :                         rcu_report_qs_rdp(rdp);</a>
<a name="465"><span class="lineNum">     465 </span>            :                         udelay(rcu_unlock_delay);</a>
<a name="466"><span class="lineNum">     466 </span>            :                 } else {</a>
<a name="467"><span class="lineNum">     467 </span>            :                         rcu_qs();</a>
<a name="468"><span class="lineNum">     468 </span>            :                 }</a>
<a name="469"><span class="lineNum">     469 </span>            :         }</a>
<a name="470"><span class="lineNum">     470 </span>            : </a>
<a name="471"><span class="lineNum">     471 </span>            :         /*</a>
<a name="472"><span class="lineNum">     472 </span>            :          * Respond to a request by an expedited grace period for a</a>
<a name="473"><span class="lineNum">     473 </span>            :          * quiescent state from this CPU.  Note that requests from</a>
<a name="474"><span class="lineNum">     474 </span>            :          * tasks are handled when removing the task from the</a>
<a name="475"><span class="lineNum">     475 </span>            :          * blocked-tasks list below.</a>
<a name="476"><span class="lineNum">     476 </span>            :          */</a>
<a name="477"><span class="lineNum">     477 </span>            :         if (rdp-&gt;exp_deferred_qs)</a>
<a name="478"><span class="lineNum">     478 </span>            :                 rcu_report_exp_rdp(rdp);</a>
<a name="479"><span class="lineNum">     479 </span>            : </a>
<a name="480"><span class="lineNum">     480 </span>            :         /* Clean up if blocked during RCU read-side critical section. */</a>
<a name="481"><span class="lineNum">     481 </span>            :         if (special.b.blocked) {</a>
<a name="482"><span class="lineNum">     482 </span>            : </a>
<a name="483"><span class="lineNum">     483 </span>            :                 /*</a>
<a name="484"><span class="lineNum">     484 </span>            :                  * Remove this task from the list it blocked on.  The task</a>
<a name="485"><span class="lineNum">     485 </span>            :                  * now remains queued on the rcu_node corresponding to the</a>
<a name="486"><span class="lineNum">     486 </span>            :                  * CPU it first blocked on, so there is no longer any need</a>
<a name="487"><span class="lineNum">     487 </span>            :                  * to loop.  Retain a WARN_ON_ONCE() out of sheer paranoia.</a>
<a name="488"><span class="lineNum">     488 </span>            :                  */</a>
<a name="489"><span class="lineNum">     489 </span>            :                 rnp = t-&gt;rcu_blocked_node;</a>
<a name="490"><span class="lineNum">     490 </span>            :                 raw_spin_lock_rcu_node(rnp); /* irqs already disabled. */</a>
<a name="491"><span class="lineNum">     491 </span>            :                 WARN_ON_ONCE(rnp != t-&gt;rcu_blocked_node);</a>
<a name="492"><span class="lineNum">     492 </span>            :                 WARN_ON_ONCE(!rcu_is_leaf_node(rnp));</a>
<a name="493"><span class="lineNum">     493 </span>            :                 empty_norm = !rcu_preempt_blocked_readers_cgp(rnp);</a>
<a name="494"><span class="lineNum">     494 </span>            :                 WARN_ON_ONCE(rnp-&gt;completedqs == rnp-&gt;gp_seq &amp;&amp;</a>
<a name="495"><span class="lineNum">     495 </span>            :                              (!empty_norm || rnp-&gt;qsmask));</a>
<a name="496"><span class="lineNum">     496 </span>            :                 empty_exp = sync_rcu_exp_done(rnp);</a>
<a name="497"><span class="lineNum">     497 </span>            :                 smp_mb(); /* ensure expedited fastpath sees end of RCU c-s. */</a>
<a name="498"><span class="lineNum">     498 </span>            :                 np = rcu_next_node_entry(t, rnp);</a>
<a name="499"><span class="lineNum">     499 </span>            :                 list_del_init(&amp;t-&gt;rcu_node_entry);</a>
<a name="500"><span class="lineNum">     500 </span>            :                 t-&gt;rcu_blocked_node = NULL;</a>
<a name="501"><span class="lineNum">     501 </span>            :                 trace_rcu_unlock_preempted_task(TPS(&quot;rcu_preempt&quot;),</a>
<a name="502"><span class="lineNum">     502 </span>            :                                                 rnp-&gt;gp_seq, t-&gt;pid);</a>
<a name="503"><span class="lineNum">     503 </span>            :                 if (&amp;t-&gt;rcu_node_entry == rnp-&gt;gp_tasks)</a>
<a name="504"><span class="lineNum">     504 </span>            :                         WRITE_ONCE(rnp-&gt;gp_tasks, np);</a>
<a name="505"><span class="lineNum">     505 </span>            :                 if (&amp;t-&gt;rcu_node_entry == rnp-&gt;exp_tasks)</a>
<a name="506"><span class="lineNum">     506 </span>            :                         WRITE_ONCE(rnp-&gt;exp_tasks, np);</a>
<a name="507"><span class="lineNum">     507 </span>            :                 if (IS_ENABLED(CONFIG_RCU_BOOST)) {</a>
<a name="508"><span class="lineNum">     508 </span>            :                         /* Snapshot -&gt;boost_mtx ownership w/rnp-&gt;lock held. */</a>
<a name="509"><span class="lineNum">     509 </span>            :                         drop_boost_mutex = rt_mutex_owner(&amp;rnp-&gt;boost_mtx) == t;</a>
<a name="510"><span class="lineNum">     510 </span>            :                         if (&amp;t-&gt;rcu_node_entry == rnp-&gt;boost_tasks)</a>
<a name="511"><span class="lineNum">     511 </span>            :                                 WRITE_ONCE(rnp-&gt;boost_tasks, np);</a>
<a name="512"><span class="lineNum">     512 </span>            :                 }</a>
<a name="513"><span class="lineNum">     513 </span>            : </a>
<a name="514"><span class="lineNum">     514 </span>            :                 /*</a>
<a name="515"><span class="lineNum">     515 </span>            :                  * If this was the last task on the current list, and if</a>
<a name="516"><span class="lineNum">     516 </span>            :                  * we aren't waiting on any CPUs, report the quiescent state.</a>
<a name="517"><span class="lineNum">     517 </span>            :                  * Note that rcu_report_unblock_qs_rnp() releases rnp-&gt;lock,</a>
<a name="518"><span class="lineNum">     518 </span>            :                  * so we must take a snapshot of the expedited state.</a>
<a name="519"><span class="lineNum">     519 </span>            :                  */</a>
<a name="520"><span class="lineNum">     520 </span>            :                 empty_exp_now = sync_rcu_exp_done(rnp);</a>
<a name="521"><span class="lineNum">     521 </span>            :                 if (!empty_norm &amp;&amp; !rcu_preempt_blocked_readers_cgp(rnp)) {</a>
<a name="522"><span class="lineNum">     522 </span>            :                         trace_rcu_quiescent_state_report(TPS(&quot;preempt_rcu&quot;),</a>
<a name="523"><span class="lineNum">     523 </span>            :                                                          rnp-&gt;gp_seq,</a>
<a name="524"><span class="lineNum">     524 </span>            :                                                          0, rnp-&gt;qsmask,</a>
<a name="525"><span class="lineNum">     525 </span>            :                                                          rnp-&gt;level,</a>
<a name="526"><span class="lineNum">     526 </span>            :                                                          rnp-&gt;grplo,</a>
<a name="527"><span class="lineNum">     527 </span>            :                                                          rnp-&gt;grphi,</a>
<a name="528"><span class="lineNum">     528 </span>            :                                                          !!rnp-&gt;gp_tasks);</a>
<a name="529"><span class="lineNum">     529 </span>            :                         rcu_report_unblock_qs_rnp(rnp, flags);</a>
<a name="530"><span class="lineNum">     530 </span>            :                 } else {</a>
<a name="531"><span class="lineNum">     531 </span>            :                         raw_spin_unlock_irqrestore_rcu_node(rnp, flags);</a>
<a name="532"><span class="lineNum">     532 </span>            :                 }</a>
<a name="533"><span class="lineNum">     533 </span>            : </a>
<a name="534"><span class="lineNum">     534 </span>            :                 /* Unboost if we were boosted. */</a>
<a name="535"><span class="lineNum">     535 </span>            :                 if (IS_ENABLED(CONFIG_RCU_BOOST) &amp;&amp; drop_boost_mutex)</a>
<a name="536"><span class="lineNum">     536 </span>            :                         rt_mutex_futex_unlock(&amp;rnp-&gt;boost_mtx);</a>
<a name="537"><span class="lineNum">     537 </span>            : </a>
<a name="538"><span class="lineNum">     538 </span>            :                 /*</a>
<a name="539"><span class="lineNum">     539 </span>            :                  * If this was the last task on the expedited lists,</a>
<a name="540"><span class="lineNum">     540 </span>            :                  * then we need to report up the rcu_node hierarchy.</a>
<a name="541"><span class="lineNum">     541 </span>            :                  */</a>
<a name="542"><span class="lineNum">     542 </span>            :                 if (!empty_exp &amp;&amp; empty_exp_now)</a>
<a name="543"><span class="lineNum">     543 </span>            :                         rcu_report_exp_rnp(rnp, true);</a>
<a name="544"><span class="lineNum">     544 </span>            :         } else {</a>
<a name="545"><span class="lineNum">     545 </span>            :                 local_irq_restore(flags);</a>
<a name="546"><span class="lineNum">     546 </span>            :         }</a>
<a name="547"><span class="lineNum">     547 </span>            : }</a>
<a name="548"><span class="lineNum">     548 </span>            : </a>
<a name="549"><span class="lineNum">     549 </span>            : /*</a>
<a name="550"><span class="lineNum">     550 </span>            :  * Is a deferred quiescent-state pending, and are we also not in</a>
<a name="551"><span class="lineNum">     551 </span>            :  * an RCU read-side critical section?  It is the caller's responsibility</a>
<a name="552"><span class="lineNum">     552 </span>            :  * to ensure it is otherwise safe to report any deferred quiescent</a>
<a name="553"><span class="lineNum">     553 </span>            :  * states.  The reason for this is that it is safe to report a</a>
<a name="554"><span class="lineNum">     554 </span>            :  * quiescent state during context switch even though preemption</a>
<a name="555"><span class="lineNum">     555 </span>            :  * is disabled.  This function cannot be expected to understand these</a>
<a name="556"><span class="lineNum">     556 </span>            :  * nuances, so the caller must handle them.</a>
<a name="557"><span class="lineNum">     557 </span>            :  */</a>
<a name="558"><span class="lineNum">     558 </span>            : static bool rcu_preempt_need_deferred_qs(struct task_struct *t)</a>
<a name="559"><span class="lineNum">     559 </span>            : {</a>
<a name="560"><span class="lineNum">     560 </span>            :         return (__this_cpu_read(rcu_data.exp_deferred_qs) ||</a>
<a name="561"><span class="lineNum">     561 </span>            :                 READ_ONCE(t-&gt;rcu_read_unlock_special.s)) &amp;&amp;</a>
<a name="562"><span class="lineNum">     562 </span>            :                rcu_preempt_depth() == 0;</a>
<a name="563"><span class="lineNum">     563 </span>            : }</a>
<a name="564"><span class="lineNum">     564 </span>            : </a>
<a name="565"><span class="lineNum">     565 </span>            : /*</a>
<a name="566"><span class="lineNum">     566 </span>            :  * Report a deferred quiescent state if needed and safe to do so.</a>
<a name="567"><span class="lineNum">     567 </span>            :  * As with rcu_preempt_need_deferred_qs(), &quot;safe&quot; involves only</a>
<a name="568"><span class="lineNum">     568 </span>            :  * not being in an RCU read-side critical section.  The caller must</a>
<a name="569"><span class="lineNum">     569 </span>            :  * evaluate safety in terms of interrupt, softirq, and preemption</a>
<a name="570"><span class="lineNum">     570 </span>            :  * disabling.</a>
<a name="571"><span class="lineNum">     571 </span>            :  */</a>
<a name="572"><span class="lineNum">     572 </span>            : static void rcu_preempt_deferred_qs(struct task_struct *t)</a>
<a name="573"><span class="lineNum">     573 </span>            : {</a>
<a name="574"><span class="lineNum">     574 </span>            :         unsigned long flags;</a>
<a name="575"><span class="lineNum">     575 </span>            : </a>
<a name="576"><span class="lineNum">     576 </span>            :         if (!rcu_preempt_need_deferred_qs(t))</a>
<a name="577"><span class="lineNum">     577 </span>            :                 return;</a>
<a name="578"><span class="lineNum">     578 </span>            :         local_irq_save(flags);</a>
<a name="579"><span class="lineNum">     579 </span>            :         rcu_preempt_deferred_qs_irqrestore(t, flags);</a>
<a name="580"><span class="lineNum">     580 </span>            : }</a>
<a name="581"><span class="lineNum">     581 </span>            : </a>
<a name="582"><span class="lineNum">     582 </span>            : /*</a>
<a name="583"><span class="lineNum">     583 </span>            :  * Minimal handler to give the scheduler a chance to re-evaluate.</a>
<a name="584"><span class="lineNum">     584 </span>            :  */</a>
<a name="585"><span class="lineNum">     585 </span>            : static void rcu_preempt_deferred_qs_handler(struct irq_work *iwp)</a>
<a name="586"><span class="lineNum">     586 </span>            : {</a>
<a name="587"><span class="lineNum">     587 </span>            :         struct rcu_data *rdp;</a>
<a name="588"><span class="lineNum">     588 </span>            : </a>
<a name="589"><span class="lineNum">     589 </span>            :         rdp = container_of(iwp, struct rcu_data, defer_qs_iw);</a>
<a name="590"><span class="lineNum">     590 </span>            :         rdp-&gt;defer_qs_iw_pending = false;</a>
<a name="591"><span class="lineNum">     591 </span>            : }</a>
<a name="592"><span class="lineNum">     592 </span>            : </a>
<a name="593"><span class="lineNum">     593 </span>            : /*</a>
<a name="594"><span class="lineNum">     594 </span>            :  * Handle special cases during rcu_read_unlock(), such as needing to</a>
<a name="595"><span class="lineNum">     595 </span>            :  * notify RCU core processing or task having blocked during the RCU</a>
<a name="596"><span class="lineNum">     596 </span>            :  * read-side critical section.</a>
<a name="597"><span class="lineNum">     597 </span>            :  */</a>
<a name="598"><span class="lineNum">     598 </span>            : static void rcu_read_unlock_special(struct task_struct *t)</a>
<a name="599"><span class="lineNum">     599 </span>            : {</a>
<a name="600"><span class="lineNum">     600 </span>            :         unsigned long flags;</a>
<a name="601"><span class="lineNum">     601 </span>            :         bool preempt_bh_were_disabled =</a>
<a name="602"><span class="lineNum">     602 </span>            :                         !!(preempt_count() &amp; (PREEMPT_MASK | SOFTIRQ_MASK));</a>
<a name="603"><span class="lineNum">     603 </span>            :         bool irqs_were_disabled;</a>
<a name="604"><span class="lineNum">     604 </span>            : </a>
<a name="605"><span class="lineNum">     605 </span>            :         /* NMI handlers cannot block and cannot safely manipulate state. */</a>
<a name="606"><span class="lineNum">     606 </span>            :         if (in_nmi())</a>
<a name="607"><span class="lineNum">     607 </span>            :                 return;</a>
<a name="608"><span class="lineNum">     608 </span>            : </a>
<a name="609"><span class="lineNum">     609 </span>            :         local_irq_save(flags);</a>
<a name="610"><span class="lineNum">     610 </span>            :         irqs_were_disabled = irqs_disabled_flags(flags);</a>
<a name="611"><span class="lineNum">     611 </span>            :         if (preempt_bh_were_disabled || irqs_were_disabled) {</a>
<a name="612"><span class="lineNum">     612 </span>            :                 bool exp;</a>
<a name="613"><span class="lineNum">     613 </span>            :                 struct rcu_data *rdp = this_cpu_ptr(&amp;rcu_data);</a>
<a name="614"><span class="lineNum">     614 </span>            :                 struct rcu_node *rnp = rdp-&gt;mynode;</a>
<a name="615"><span class="lineNum">     615 </span>            : </a>
<a name="616"><span class="lineNum">     616 </span>            :                 exp = (t-&gt;rcu_blocked_node &amp;&amp;</a>
<a name="617"><span class="lineNum">     617 </span>            :                        READ_ONCE(t-&gt;rcu_blocked_node-&gt;exp_tasks)) ||</a>
<a name="618"><span class="lineNum">     618 </span>            :                       (rdp-&gt;grpmask &amp; READ_ONCE(rnp-&gt;expmask));</a>
<a name="619"><span class="lineNum">     619 </span>            :                 // Need to defer quiescent state until everything is enabled.</a>
<a name="620"><span class="lineNum">     620 </span>            :                 if (use_softirq &amp;&amp; (in_irq() || (exp &amp;&amp; !irqs_were_disabled))) {</a>
<a name="621"><span class="lineNum">     621 </span>            :                         // Using softirq, safe to awaken, and either the</a>
<a name="622"><span class="lineNum">     622 </span>            :                         // wakeup is free or there is an expedited GP.</a>
<a name="623"><span class="lineNum">     623 </span>            :                         raise_softirq_irqoff(RCU_SOFTIRQ);</a>
<a name="624"><span class="lineNum">     624 </span>            :                 } else {</a>
<a name="625"><span class="lineNum">     625 </span>            :                         // Enabling BH or preempt does reschedule, so...</a>
<a name="626"><span class="lineNum">     626 </span>            :                         // Also if no expediting, slow is OK.</a>
<a name="627"><span class="lineNum">     627 </span>            :                         // Plus nohz_full CPUs eventually get tick enabled.</a>
<a name="628"><span class="lineNum">     628 </span>            :                         set_tsk_need_resched(current);</a>
<a name="629"><span class="lineNum">     629 </span>            :                         set_preempt_need_resched();</a>
<a name="630"><span class="lineNum">     630 </span>            :                         if (IS_ENABLED(CONFIG_IRQ_WORK) &amp;&amp; irqs_were_disabled &amp;&amp;</a>
<a name="631"><span class="lineNum">     631 </span>            :                             !rdp-&gt;defer_qs_iw_pending &amp;&amp; exp &amp;&amp; cpu_online(rdp-&gt;cpu)) {</a>
<a name="632"><span class="lineNum">     632 </span>            :                                 // Get scheduler to re-evaluate and call hooks.</a>
<a name="633"><span class="lineNum">     633 </span>            :                                 // If !IRQ_WORK, FQS scan will eventually IPI.</a>
<a name="634"><span class="lineNum">     634 </span>            :                                 init_irq_work(&amp;rdp-&gt;defer_qs_iw,</a>
<a name="635"><span class="lineNum">     635 </span>            :                                               rcu_preempt_deferred_qs_handler);</a>
<a name="636"><span class="lineNum">     636 </span>            :                                 rdp-&gt;defer_qs_iw_pending = true;</a>
<a name="637"><span class="lineNum">     637 </span>            :                                 irq_work_queue_on(&amp;rdp-&gt;defer_qs_iw, rdp-&gt;cpu);</a>
<a name="638"><span class="lineNum">     638 </span>            :                         }</a>
<a name="639"><span class="lineNum">     639 </span>            :                 }</a>
<a name="640"><span class="lineNum">     640 </span>            :                 local_irq_restore(flags);</a>
<a name="641"><span class="lineNum">     641 </span>            :                 return;</a>
<a name="642"><span class="lineNum">     642 </span>            :         }</a>
<a name="643"><span class="lineNum">     643 </span>            :         rcu_preempt_deferred_qs_irqrestore(t, flags);</a>
<a name="644"><span class="lineNum">     644 </span>            : }</a>
<a name="645"><span class="lineNum">     645 </span>            : </a>
<a name="646"><span class="lineNum">     646 </span>            : /*</a>
<a name="647"><span class="lineNum">     647 </span>            :  * Check that the list of blocked tasks for the newly completed grace</a>
<a name="648"><span class="lineNum">     648 </span>            :  * period is in fact empty.  It is a serious bug to complete a grace</a>
<a name="649"><span class="lineNum">     649 </span>            :  * period that still has RCU readers blocked!  This function must be</a>
<a name="650"><span class="lineNum">     650 </span>            :  * invoked -before- updating this rnp's -&gt;gp_seq.</a>
<a name="651"><span class="lineNum">     651 </span>            :  *</a>
<a name="652"><span class="lineNum">     652 </span>            :  * Also, if there are blocked tasks on the list, they automatically</a>
<a name="653"><span class="lineNum">     653 </span>            :  * block the newly created grace period, so set up -&gt;gp_tasks accordingly.</a>
<a name="654"><span class="lineNum">     654 </span>            :  */</a>
<a name="655"><span class="lineNum">     655 </span>            : static void rcu_preempt_check_blocked_tasks(struct rcu_node *rnp)</a>
<a name="656"><span class="lineNum">     656 </span>            : {</a>
<a name="657"><span class="lineNum">     657 </span>            :         struct task_struct *t;</a>
<a name="658"><span class="lineNum">     658 </span>            : </a>
<a name="659"><span class="lineNum">     659 </span>            :         RCU_LOCKDEP_WARN(preemptible(), &quot;rcu_preempt_check_blocked_tasks() invoked with preemption enabled!!!\n&quot;);</a>
<a name="660"><span class="lineNum">     660 </span>            :         raw_lockdep_assert_held_rcu_node(rnp);</a>
<a name="661"><span class="lineNum">     661 </span>            :         if (WARN_ON_ONCE(rcu_preempt_blocked_readers_cgp(rnp)))</a>
<a name="662"><span class="lineNum">     662 </span>            :                 dump_blkd_tasks(rnp, 10);</a>
<a name="663"><span class="lineNum">     663 </span>            :         if (rcu_preempt_has_tasks(rnp) &amp;&amp;</a>
<a name="664"><span class="lineNum">     664 </span>            :             (rnp-&gt;qsmaskinit || rnp-&gt;wait_blkd_tasks)) {</a>
<a name="665"><span class="lineNum">     665 </span>            :                 WRITE_ONCE(rnp-&gt;gp_tasks, rnp-&gt;blkd_tasks.next);</a>
<a name="666"><span class="lineNum">     666 </span>            :                 t = container_of(rnp-&gt;gp_tasks, struct task_struct,</a>
<a name="667"><span class="lineNum">     667 </span>            :                                  rcu_node_entry);</a>
<a name="668"><span class="lineNum">     668 </span>            :                 trace_rcu_unlock_preempted_task(TPS(&quot;rcu_preempt-GPS&quot;),</a>
<a name="669"><span class="lineNum">     669 </span>            :                                                 rnp-&gt;gp_seq, t-&gt;pid);</a>
<a name="670"><span class="lineNum">     670 </span>            :         }</a>
<a name="671"><span class="lineNum">     671 </span>            :         WARN_ON_ONCE(rnp-&gt;qsmask);</a>
<a name="672"><span class="lineNum">     672 </span>            : }</a>
<a name="673"><span class="lineNum">     673 </span>            : </a>
<a name="674"><span class="lineNum">     674 </span>            : /*</a>
<a name="675"><span class="lineNum">     675 </span>            :  * Check for a quiescent state from the current CPU, including voluntary</a>
<a name="676"><span class="lineNum">     676 </span>            :  * context switches for Tasks RCU.  When a task blocks, the task is</a>
<a name="677"><span class="lineNum">     677 </span>            :  * recorded in the corresponding CPU's rcu_node structure, which is checked</a>
<a name="678"><span class="lineNum">     678 </span>            :  * elsewhere, hence this function need only check for quiescent states</a>
<a name="679"><span class="lineNum">     679 </span>            :  * related to the current CPU, not to those related to tasks.</a>
<a name="680"><span class="lineNum">     680 </span>            :  */</a>
<a name="681"><span class="lineNum">     681 </span>            : static void rcu_flavor_sched_clock_irq(int user)</a>
<a name="682"><span class="lineNum">     682 </span>            : {</a>
<a name="683"><span class="lineNum">     683 </span>            :         struct task_struct *t = current;</a>
<a name="684"><span class="lineNum">     684 </span>            : </a>
<a name="685"><span class="lineNum">     685 </span>            :         lockdep_assert_irqs_disabled();</a>
<a name="686"><span class="lineNum">     686 </span>            :         if (user || rcu_is_cpu_rrupt_from_idle()) {</a>
<a name="687"><span class="lineNum">     687 </span>            :                 rcu_note_voluntary_context_switch(current);</a>
<a name="688"><span class="lineNum">     688 </span>            :         }</a>
<a name="689"><span class="lineNum">     689 </span>            :         if (rcu_preempt_depth() &gt; 0 ||</a>
<a name="690"><span class="lineNum">     690 </span>            :             (preempt_count() &amp; (PREEMPT_MASK | SOFTIRQ_MASK))) {</a>
<a name="691"><span class="lineNum">     691 </span>            :                 /* No QS, force context switch if deferred. */</a>
<a name="692"><span class="lineNum">     692 </span>            :                 if (rcu_preempt_need_deferred_qs(t)) {</a>
<a name="693"><span class="lineNum">     693 </span>            :                         set_tsk_need_resched(t);</a>
<a name="694"><span class="lineNum">     694 </span>            :                         set_preempt_need_resched();</a>
<a name="695"><span class="lineNum">     695 </span>            :                 }</a>
<a name="696"><span class="lineNum">     696 </span>            :         } else if (rcu_preempt_need_deferred_qs(t)) {</a>
<a name="697"><span class="lineNum">     697 </span>            :                 rcu_preempt_deferred_qs(t); /* Report deferred QS. */</a>
<a name="698"><span class="lineNum">     698 </span>            :                 return;</a>
<a name="699"><span class="lineNum">     699 </span>            :         } else if (!WARN_ON_ONCE(rcu_preempt_depth())) {</a>
<a name="700"><span class="lineNum">     700 </span>            :                 rcu_qs(); /* Report immediate QS. */</a>
<a name="701"><span class="lineNum">     701 </span>            :                 return;</a>
<a name="702"><span class="lineNum">     702 </span>            :         }</a>
<a name="703"><span class="lineNum">     703 </span>            : </a>
<a name="704"><span class="lineNum">     704 </span>            :         /* If GP is oldish, ask for help from rcu_read_unlock_special(). */</a>
<a name="705"><span class="lineNum">     705 </span>            :         if (rcu_preempt_depth() &gt; 0 &amp;&amp;</a>
<a name="706"><span class="lineNum">     706 </span>            :             __this_cpu_read(rcu_data.core_needs_qs) &amp;&amp;</a>
<a name="707"><span class="lineNum">     707 </span>            :             __this_cpu_read(rcu_data.cpu_no_qs.b.norm) &amp;&amp;</a>
<a name="708"><span class="lineNum">     708 </span>            :             !t-&gt;rcu_read_unlock_special.b.need_qs &amp;&amp;</a>
<a name="709"><span class="lineNum">     709 </span>            :             time_after(jiffies, rcu_state.gp_start + HZ))</a>
<a name="710"><span class="lineNum">     710 </span>            :                 t-&gt;rcu_read_unlock_special.b.need_qs = true;</a>
<a name="711"><span class="lineNum">     711 </span>            : }</a>
<a name="712"><span class="lineNum">     712 </span>            : </a>
<a name="713"><span class="lineNum">     713 </span>            : /*</a>
<a name="714"><span class="lineNum">     714 </span>            :  * Check for a task exiting while in a preemptible-RCU read-side</a>
<a name="715"><span class="lineNum">     715 </span>            :  * critical section, clean up if so.  No need to issue warnings, as</a>
<a name="716"><span class="lineNum">     716 </span>            :  * debug_check_no_locks_held() already does this if lockdep is enabled.</a>
<a name="717"><span class="lineNum">     717 </span>            :  * Besides, if this function does anything other than just immediately</a>
<a name="718"><span class="lineNum">     718 </span>            :  * return, there was a bug of some sort.  Spewing warnings from this</a>
<a name="719"><span class="lineNum">     719 </span>            :  * function is like as not to simply obscure important prior warnings.</a>
<a name="720"><span class="lineNum">     720 </span>            :  */</a>
<a name="721"><span class="lineNum">     721 </span>            : void exit_rcu(void)</a>
<a name="722"><span class="lineNum">     722 </span>            : {</a>
<a name="723"><span class="lineNum">     723 </span>            :         struct task_struct *t = current;</a>
<a name="724"><span class="lineNum">     724 </span>            : </a>
<a name="725"><span class="lineNum">     725 </span>            :         if (unlikely(!list_empty(&amp;current-&gt;rcu_node_entry))) {</a>
<a name="726"><span class="lineNum">     726 </span>            :                 rcu_preempt_depth_set(1);</a>
<a name="727"><span class="lineNum">     727 </span>            :                 barrier();</a>
<a name="728"><span class="lineNum">     728 </span>            :                 WRITE_ONCE(t-&gt;rcu_read_unlock_special.b.blocked, true);</a>
<a name="729"><span class="lineNum">     729 </span>            :         } else if (unlikely(rcu_preempt_depth())) {</a>
<a name="730"><span class="lineNum">     730 </span>            :                 rcu_preempt_depth_set(1);</a>
<a name="731"><span class="lineNum">     731 </span>            :         } else {</a>
<a name="732"><span class="lineNum">     732 </span>            :                 return;</a>
<a name="733"><span class="lineNum">     733 </span>            :         }</a>
<a name="734"><span class="lineNum">     734 </span>            :         __rcu_read_unlock();</a>
<a name="735"><span class="lineNum">     735 </span>            :         rcu_preempt_deferred_qs(current);</a>
<a name="736"><span class="lineNum">     736 </span>            : }</a>
<a name="737"><span class="lineNum">     737 </span>            : </a>
<a name="738"><span class="lineNum">     738 </span>            : /*</a>
<a name="739"><span class="lineNum">     739 </span>            :  * Dump the blocked-tasks state, but limit the list dump to the</a>
<a name="740"><span class="lineNum">     740 </span>            :  * specified number of elements.</a>
<a name="741"><span class="lineNum">     741 </span>            :  */</a>
<a name="742"><span class="lineNum">     742 </span>            : static void</a>
<a name="743"><span class="lineNum">     743 </span>            : dump_blkd_tasks(struct rcu_node *rnp, int ncheck)</a>
<a name="744"><span class="lineNum">     744 </span>            : {</a>
<a name="745"><span class="lineNum">     745 </span>            :         int cpu;</a>
<a name="746"><span class="lineNum">     746 </span>            :         int i;</a>
<a name="747"><span class="lineNum">     747 </span>            :         struct list_head *lhp;</a>
<a name="748"><span class="lineNum">     748 </span>            :         bool onl;</a>
<a name="749"><span class="lineNum">     749 </span>            :         struct rcu_data *rdp;</a>
<a name="750"><span class="lineNum">     750 </span>            :         struct rcu_node *rnp1;</a>
<a name="751"><span class="lineNum">     751 </span>            : </a>
<a name="752"><span class="lineNum">     752 </span>            :         raw_lockdep_assert_held_rcu_node(rnp);</a>
<a name="753"><span class="lineNum">     753 </span>            :         pr_info(&quot;%s: grp: %d-%d level: %d -&gt;gp_seq %ld -&gt;completedqs %ld\n&quot;,</a>
<a name="754"><span class="lineNum">     754 </span>            :                 __func__, rnp-&gt;grplo, rnp-&gt;grphi, rnp-&gt;level,</a>
<a name="755"><span class="lineNum">     755 </span>            :                 (long)READ_ONCE(rnp-&gt;gp_seq), (long)rnp-&gt;completedqs);</a>
<a name="756"><span class="lineNum">     756 </span>            :         for (rnp1 = rnp; rnp1; rnp1 = rnp1-&gt;parent)</a>
<a name="757"><span class="lineNum">     757 </span>            :                 pr_info(&quot;%s: %d:%d -&gt;qsmask %#lx -&gt;qsmaskinit %#lx -&gt;qsmaskinitnext %#lx\n&quot;,</a>
<a name="758"><span class="lineNum">     758 </span>            :                         __func__, rnp1-&gt;grplo, rnp1-&gt;grphi, rnp1-&gt;qsmask, rnp1-&gt;qsmaskinit, rnp1-&gt;qsmaskinitnext);</a>
<a name="759"><span class="lineNum">     759 </span>            :         pr_info(&quot;%s: -&gt;gp_tasks %p -&gt;boost_tasks %p -&gt;exp_tasks %p\n&quot;,</a>
<a name="760"><span class="lineNum">     760 </span>            :                 __func__, READ_ONCE(rnp-&gt;gp_tasks), data_race(rnp-&gt;boost_tasks),</a>
<a name="761"><span class="lineNum">     761 </span>            :                 READ_ONCE(rnp-&gt;exp_tasks));</a>
<a name="762"><span class="lineNum">     762 </span>            :         pr_info(&quot;%s: -&gt;blkd_tasks&quot;, __func__);</a>
<a name="763"><span class="lineNum">     763 </span>            :         i = 0;</a>
<a name="764"><span class="lineNum">     764 </span>            :         list_for_each(lhp, &amp;rnp-&gt;blkd_tasks) {</a>
<a name="765"><span class="lineNum">     765 </span>            :                 pr_cont(&quot; %p&quot;, lhp);</a>
<a name="766"><span class="lineNum">     766 </span>            :                 if (++i &gt;= ncheck)</a>
<a name="767"><span class="lineNum">     767 </span>            :                         break;</a>
<a name="768"><span class="lineNum">     768 </span>            :         }</a>
<a name="769"><span class="lineNum">     769 </span>            :         pr_cont(&quot;\n&quot;);</a>
<a name="770"><span class="lineNum">     770 </span>            :         for (cpu = rnp-&gt;grplo; cpu &lt;= rnp-&gt;grphi; cpu++) {</a>
<a name="771"><span class="lineNum">     771 </span>            :                 rdp = per_cpu_ptr(&amp;rcu_data, cpu);</a>
<a name="772"><span class="lineNum">     772 </span>            :                 onl = !!(rdp-&gt;grpmask &amp; rcu_rnp_online_cpus(rnp));</a>
<a name="773"><span class="lineNum">     773 </span>            :                 pr_info(&quot;\t%d: %c online: %ld(%d) offline: %ld(%d)\n&quot;,</a>
<a name="774"><span class="lineNum">     774 </span>            :                         cpu, &quot;.o&quot;[onl],</a>
<a name="775"><span class="lineNum">     775 </span>            :                         (long)rdp-&gt;rcu_onl_gp_seq, rdp-&gt;rcu_onl_gp_flags,</a>
<a name="776"><span class="lineNum">     776 </span>            :                         (long)rdp-&gt;rcu_ofl_gp_seq, rdp-&gt;rcu_ofl_gp_flags);</a>
<a name="777"><span class="lineNum">     777 </span>            :         }</a>
<a name="778"><span class="lineNum">     778 </span>            : }</a>
<a name="779"><span class="lineNum">     779 </span>            : </a>
<a name="780"><span class="lineNum">     780 </span>            : #else /* #ifdef CONFIG_PREEMPT_RCU */</a>
<a name="781"><span class="lineNum">     781 </span>            : </a>
<a name="782"><span class="lineNum">     782 </span>            : /*</a>
<a name="783"><span class="lineNum">     783 </span>            :  * If strict grace periods are enabled, and if the calling</a>
<a name="784"><span class="lineNum">     784 </span>            :  * __rcu_read_unlock() marks the beginning of a quiescent state, immediately</a>
<a name="785"><span class="lineNum">     785 </span>            :  * report that quiescent state and, if requested, spin for a bit.</a>
<a name="786"><span class="lineNum">     786 </span>            :  */</a>
<a name="787"><span class="lineNum">     787 </span><span class="lineCov">    1156446 : void rcu_read_unlock_strict(void)</span></a>
<a name="788"><span class="lineNum">     788 </span>            : {</a>
<a name="789"><span class="lineNum">     789 </span><span class="lineCov">    1156446 :         struct rcu_data *rdp;</span></a>
<a name="790"><span class="lineNum">     790 </span>            : </a>
<a name="791"><span class="lineNum">     791 </span><span class="lineCov">    1156446 :         if (!IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD) ||</span></a>
<a name="792"><span class="lineNum">     792 </span>            :            irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)</a>
<a name="793"><span class="lineNum">     793 </span><span class="lineNoCov">          0 :                 return;</span></a>
<a name="794"><span class="lineNum">     794 </span>            :         rdp = this_cpu_ptr(&amp;rcu_data);</a>
<a name="795"><span class="lineNum">     795 </span>            :         rcu_report_qs_rdp(rdp);</a>
<a name="796"><span class="lineNum">     796 </span>            :         udelay(rcu_unlock_delay);</a>
<a name="797"><span class="lineNum">     797 </span>            : }</a>
<a name="798"><span class="lineNum">     798 </span>            : EXPORT_SYMBOL_GPL(rcu_read_unlock_strict);</a>
<a name="799"><span class="lineNum">     799 </span>            : </a>
<a name="800"><span class="lineNum">     800 </span>            : /*</a>
<a name="801"><span class="lineNum">     801 </span>            :  * Tell them what RCU they are running.</a>
<a name="802"><span class="lineNum">     802 </span>            :  */</a>
<a name="803"><span class="lineNum">     803 </span><span class="lineCov">          1 : static void __init rcu_bootup_announce(void)</span></a>
<a name="804"><span class="lineNum">     804 </span>            : {</a>
<a name="805"><span class="lineNum">     805 </span><span class="lineCov">          1 :         pr_info(&quot;Hierarchical RCU implementation.\n&quot;);</span></a>
<a name="806"><span class="lineNum">     806 </span><span class="lineCov">          1 :         rcu_bootup_announce_oddness();</span></a>
<a name="807"><span class="lineNum">     807 </span><span class="lineCov">          1 : }</span></a>
<a name="808"><span class="lineNum">     808 </span>            : </a>
<a name="809"><span class="lineNum">     809 </span>            : /*</a>
<a name="810"><span class="lineNum">     810 </span>            :  * Note a quiescent state for PREEMPTION=n.  Because we do not need to know</a>
<a name="811"><span class="lineNum">     811 </span>            :  * how many quiescent states passed, just if there was at least one since</a>
<a name="812"><span class="lineNum">     812 </span>            :  * the start of the grace period, this just sets a flag.  The caller must</a>
<a name="813"><span class="lineNum">     813 </span>            :  * have disabled preemption.</a>
<a name="814"><span class="lineNum">     814 </span>            :  */</a>
<a name="815"><span class="lineNum">     815 </span><span class="lineCov">      74752 : static void rcu_qs(void)</span></a>
<a name="816"><span class="lineNum">     816 </span>            : {</a>
<a name="817"><span class="lineNum">     817 </span><span class="lineCov">      74752 :         RCU_LOCKDEP_WARN(preemptible(), &quot;rcu_qs() invoked with preemption enabled!!!&quot;);</span></a>
<a name="818"><span class="lineNum">     818 </span><span class="lineCov">      75032 :         if (!__this_cpu_read(rcu_data.cpu_no_qs.s))</span></a>
<a name="819"><span class="lineNum">     819 </span>            :                 return;</a>
<a name="820"><span class="lineNum">     820 </span><span class="lineCov">       7820 :         trace_rcu_grace_period(TPS(&quot;rcu_sched&quot;),</span></a>
<a name="821"><span class="lineNum">     821 </span><span class="lineCov">       7820 :                                __this_cpu_read(rcu_data.gp_seq), TPS(&quot;cpuqs&quot;));</span></a>
<a name="822"><span class="lineNum">     822 </span><span class="lineCov">       7820 :         __this_cpu_write(rcu_data.cpu_no_qs.b.norm, false);</span></a>
<a name="823"><span class="lineNum">     823 </span><span class="lineCov">       7820 :         if (!__this_cpu_read(rcu_data.cpu_no_qs.b.exp))</span></a>
<a name="824"><span class="lineNum">     824 </span>            :                 return;</a>
<a name="825"><span class="lineNum">     825 </span><span class="lineCov">        303 :         __this_cpu_write(rcu_data.cpu_no_qs.b.exp, false);</span></a>
<a name="826"><span class="lineNum">     826 </span><span class="lineCov">        303 :         rcu_report_exp_rdp(this_cpu_ptr(&amp;rcu_data));</span></a>
<a name="827"><span class="lineNum">     827 </span>            : }</a>
<a name="828"><span class="lineNum">     828 </span>            : </a>
<a name="829"><span class="lineNum">     829 </span>            : /*</a>
<a name="830"><span class="lineNum">     830 </span>            :  * Register an urgently needed quiescent state.  If there is an</a>
<a name="831"><span class="lineNum">     831 </span>            :  * emergency, invoke rcu_momentary_dyntick_idle() to do a heavy-weight</a>
<a name="832"><span class="lineNum">     832 </span>            :  * dyntick-idle quiescent state visible to other CPUs, which will in</a>
<a name="833"><span class="lineNum">     833 </span>            :  * some cases serve for expedited as well as normal grace periods.</a>
<a name="834"><span class="lineNum">     834 </span>            :  * Either way, register a lightweight quiescent state.</a>
<a name="835"><span class="lineNum">     835 </span>            :  */</a>
<a name="836"><span class="lineNum">     836 </span><span class="lineCov">     539554 : void rcu_all_qs(void)</span></a>
<a name="837"><span class="lineNum">     837 </span>            : {</a>
<a name="838"><span class="lineNum">     838 </span><span class="lineCov">     539554 :         unsigned long flags;</span></a>
<a name="839"><span class="lineNum">     839 </span>            : </a>
<a name="840"><span class="lineNum">     840 </span><span class="lineCov">     539554 :         if (!raw_cpu_read(rcu_data.rcu_urgent_qs))</span></a>
<a name="841"><span class="lineNum">     841 </span>            :                 return;</a>
<a name="842"><span class="lineNum">     842 </span><span class="lineCov">          6 :         preempt_disable();</span></a>
<a name="843"><span class="lineNum">     843 </span>            :         /* Load rcu_urgent_qs before other flags. */</a>
<a name="844"><span class="lineNum">     844 </span><span class="lineCov">          6 :         if (!smp_load_acquire(this_cpu_ptr(&amp;rcu_data.rcu_urgent_qs))) {</span></a>
<a name="845"><span class="lineNum">     845 </span><span class="lineNoCov">          0 :                 preempt_enable();</span></a>
<a name="846"><span class="lineNum">     846 </span><span class="lineNoCov">          0 :                 return;</span></a>
<a name="847"><span class="lineNum">     847 </span>            :         }</a>
<a name="848"><span class="lineNum">     848 </span><span class="lineCov">          6 :         this_cpu_write(rcu_data.rcu_urgent_qs, false);</span></a>
<a name="849"><span class="lineNum">     849 </span><span class="lineCov">          6 :         if (unlikely(raw_cpu_read(rcu_data.rcu_need_heavy_qs))) {</span></a>
<a name="850"><span class="lineNum">     850 </span><span class="lineNoCov">          0 :                 local_irq_save(flags);</span></a>
<a name="851"><span class="lineNum">     851 </span><span class="lineNoCov">          0 :                 rcu_momentary_dyntick_idle();</span></a>
<a name="852"><span class="lineNum">     852 </span><span class="lineNoCov">          0 :                 local_irq_restore(flags);</span></a>
<a name="853"><span class="lineNum">     853 </span>            :         }</a>
<a name="854"><span class="lineNum">     854 </span><span class="lineCov">          6 :         rcu_qs();</span></a>
<a name="855"><span class="lineNum">     855 </span><span class="lineCov">          6 :         preempt_enable();</span></a>
<a name="856"><span class="lineNum">     856 </span>            : }</a>
<a name="857"><span class="lineNum">     857 </span>            : EXPORT_SYMBOL_GPL(rcu_all_qs);</a>
<a name="858"><span class="lineNum">     858 </span>            : </a>
<a name="859"><span class="lineNum">     859 </span>            : /*</a>
<a name="860"><span class="lineNum">     860 </span>            :  * Note a PREEMPTION=n context switch. The caller must have disabled interrupts.</a>
<a name="861"><span class="lineNum">     861 </span>            :  */</a>
<a name="862"><span class="lineNum">     862 </span><span class="lineCov">      29816 : void rcu_note_context_switch(bool preempt)</span></a>
<a name="863"><span class="lineNum">     863 </span>            : {</a>
<a name="864"><span class="lineNum">     864 </span><span class="lineCov">      29816 :         trace_rcu_utilization(TPS(&quot;Start context switch&quot;));</span></a>
<a name="865"><span class="lineNum">     865 </span><span class="lineCov">      29818 :         rcu_qs();</span></a>
<a name="866"><span class="lineNum">     866 </span>            :         /* Load rcu_urgent_qs before other flags. */</a>
<a name="867"><span class="lineNum">     867 </span><span class="lineCov">      29815 :         if (!smp_load_acquire(this_cpu_ptr(&amp;rcu_data.rcu_urgent_qs)))</span></a>
<a name="868"><span class="lineNum">     868 </span><span class="lineCov">      29521 :                 goto out;</span></a>
<a name="869"><span class="lineNum">     869 </span><span class="lineCov">        294 :         this_cpu_write(rcu_data.rcu_urgent_qs, false);</span></a>
<a name="870"><span class="lineNum">     870 </span><span class="lineCov">        294 :         if (unlikely(raw_cpu_read(rcu_data.rcu_need_heavy_qs)))</span></a>
<a name="871"><span class="lineNum">     871 </span><span class="lineNoCov">          0 :                 rcu_momentary_dyntick_idle();</span></a>
<a name="872"><span class="lineNum">     872 </span><span class="lineCov">      29815 :         rcu_tasks_qs(current, preempt);</span></a>
<a name="873"><span class="lineNum">     873 </span><span class="lineCov">        294 : out:</span></a>
<a name="874"><span class="lineNum">     874 </span><span class="lineCov">      29815 :         trace_rcu_utilization(TPS(&quot;End context switch&quot;));</span></a>
<a name="875"><span class="lineNum">     875 </span><span class="lineCov">      29818 : }</span></a>
<a name="876"><span class="lineNum">     876 </span>            : EXPORT_SYMBOL_GPL(rcu_note_context_switch);</a>
<a name="877"><span class="lineNum">     877 </span>            : </a>
<a name="878"><span class="lineNum">     878 </span>            : /*</a>
<a name="879"><span class="lineNum">     879 </span>            :  * Because preemptible RCU does not exist, there are never any preempted</a>
<a name="880"><span class="lineNum">     880 </span>            :  * RCU readers.</a>
<a name="881"><span class="lineNum">     881 </span>            :  */</a>
<a name="882"><span class="lineNum">     882 </span><span class="lineCov">       6411 : static int rcu_preempt_blocked_readers_cgp(struct rcu_node *rnp)</span></a>
<a name="883"><span class="lineNum">     883 </span>            : {</a>
<a name="884"><span class="lineNum">     884 </span><span class="lineCov">       4392 :         return 0;</span></a>
<a name="885"><span class="lineNum">     885 </span>            : }</a>
<a name="886"><span class="lineNum">     886 </span>            : </a>
<a name="887"><span class="lineNum">     887 </span>            : /*</a>
<a name="888"><span class="lineNum">     888 </span>            :  * Because there is no preemptible RCU, there can be no readers blocked.</a>
<a name="889"><span class="lineNum">     889 </span>            :  */</a>
<a name="890"><span class="lineNum">     890 </span><span class="lineCov">        161 : static bool rcu_preempt_has_tasks(struct rcu_node *rnp)</span></a>
<a name="891"><span class="lineNum">     891 </span>            : {</a>
<a name="892"><span class="lineNum">     892 </span><span class="lineCov">        161 :         return false;</span></a>
<a name="893"><span class="lineNum">     893 </span>            : }</a>
<a name="894"><span class="lineNum">     894 </span>            : </a>
<a name="895"><span class="lineNum">     895 </span>            : /*</a>
<a name="896"><span class="lineNum">     896 </span>            :  * Because there is no preemptible RCU, there can be no deferred quiescent</a>
<a name="897"><span class="lineNum">     897 </span>            :  * states.</a>
<a name="898"><span class="lineNum">     898 </span>            :  */</a>
<a name="899"><span class="lineNum">     899 </span><span class="lineCov">      15322 : static bool rcu_preempt_need_deferred_qs(struct task_struct *t)</span></a>
<a name="900"><span class="lineNum">     900 </span>            : {</a>
<a name="901"><span class="lineNum">     901 </span><span class="lineCov">      15322 :         return false;</span></a>
<a name="902"><span class="lineNum">     902 </span>            : }</a>
<a name="903"><span class="lineNum">     903 </span><span class="lineCov">      38831 : static void rcu_preempt_deferred_qs(struct task_struct *t) { }</span></a>
<a name="904"><span class="lineNum">     904 </span>            : </a>
<a name="905"><span class="lineNum">     905 </span>            : /*</a>
<a name="906"><span class="lineNum">     906 </span>            :  * Because there is no preemptible RCU, there can be no readers blocked,</a>
<a name="907"><span class="lineNum">     907 </span>            :  * so there is no need to check for blocked tasks.  So check only for</a>
<a name="908"><span class="lineNum">     908 </span>            :  * bogus qsmask values.</a>
<a name="909"><span class="lineNum">     909 </span>            :  */</a>
<a name="910"><span class="lineNum">     910 </span><span class="lineCov">       2020 : static void rcu_preempt_check_blocked_tasks(struct rcu_node *rnp)</span></a>
<a name="911"><span class="lineNum">     911 </span>            : {</a>
<a name="912"><span class="lineNum">     912 </span><span class="lineCov">       2020 :         WARN_ON_ONCE(rnp-&gt;qsmask);</span></a>
<a name="913"><span class="lineNum">     913 </span><span class="lineCov">       2020 : }</span></a>
<a name="914"><span class="lineNum">     914 </span>            : </a>
<a name="915"><span class="lineNum">     915 </span>            : /*</a>
<a name="916"><span class="lineNum">     916 </span>            :  * Check to see if this CPU is in a non-context-switch quiescent state,</a>
<a name="917"><span class="lineNum">     917 </span>            :  * namely user mode and idle loop.</a>
<a name="918"><span class="lineNum">     918 </span>            :  */</a>
<a name="919"><span class="lineNum">     919 </span><span class="lineCov">      27394 : static void rcu_flavor_sched_clock_irq(int user)</span></a>
<a name="920"><span class="lineNum">     920 </span>            : {</a>
<a name="921"><span class="lineNum">     921 </span><span class="lineCov">      27394 :         if (user || rcu_is_cpu_rrupt_from_idle()) {</span></a>
<a name="922"><span class="lineNum">     922 </span>            : </a>
<a name="923"><span class="lineNum">     923 </span>            :                 /*</a>
<a name="924"><span class="lineNum">     924 </span>            :                  * Get here if this CPU took its interrupt from user</a>
<a name="925"><span class="lineNum">     925 </span>            :                  * mode or from the idle loop, and if this is not a</a>
<a name="926"><span class="lineNum">     926 </span>            :                  * nested interrupt.  In this case, the CPU is in</a>
<a name="927"><span class="lineNum">     927 </span>            :                  * a quiescent state, so note it.</a>
<a name="928"><span class="lineNum">     928 </span>            :                  *</a>
<a name="929"><span class="lineNum">     929 </span>            :                  * No memory barrier is required here because rcu_qs()</a>
<a name="930"><span class="lineNum">     930 </span>            :                  * references only CPU-local variables that other CPUs</a>
<a name="931"><span class="lineNum">     931 </span>            :                  * neither access nor modify, at least not while the</a>
<a name="932"><span class="lineNum">     932 </span>            :                  * corresponding CPU is online.</a>
<a name="933"><span class="lineNum">     933 </span>            :                  */</a>
<a name="934"><span class="lineNum">     934 </span>            : </a>
<a name="935"><span class="lineNum">     935 </span><span class="lineCov">      12051 :                 rcu_qs();</span></a>
<a name="936"><span class="lineNum">     936 </span>            :         }</a>
<a name="937"><span class="lineNum">     937 </span><span class="lineCov">      28014 : }</span></a>
<a name="938"><span class="lineNum">     938 </span>            : </a>
<a name="939"><span class="lineNum">     939 </span>            : /*</a>
<a name="940"><span class="lineNum">     940 </span>            :  * Because preemptible RCU does not exist, tasks cannot possibly exit</a>
<a name="941"><span class="lineNum">     941 </span>            :  * while in preemptible RCU read-side critical sections.</a>
<a name="942"><span class="lineNum">     942 </span>            :  */</a>
<a name="943"><span class="lineNum">     943 </span><span class="lineCov">       1013 : void exit_rcu(void)</span></a>
<a name="944"><span class="lineNum">     944 </span>            : {</a>
<a name="945"><span class="lineNum">     945 </span><span class="lineCov">       1013 : }</span></a>
<a name="946"><span class="lineNum">     946 </span>            : </a>
<a name="947"><span class="lineNum">     947 </span>            : /*</a>
<a name="948"><span class="lineNum">     948 </span>            :  * Dump the guaranteed-empty blocked-tasks state.  Trust but verify.</a>
<a name="949"><span class="lineNum">     949 </span>            :  */</a>
<a name="950"><span class="lineNum">     950 </span>            : static void</a>
<a name="951"><span class="lineNum">     951 </span>            : dump_blkd_tasks(struct rcu_node *rnp, int ncheck)</a>
<a name="952"><span class="lineNum">     952 </span>            : {</a>
<a name="953"><span class="lineNum">     953 </span>            :         WARN_ON_ONCE(!list_empty(&amp;rnp-&gt;blkd_tasks));</a>
<a name="954"><span class="lineNum">     954 </span>            : }</a>
<a name="955"><span class="lineNum">     955 </span>            : </a>
<a name="956"><span class="lineNum">     956 </span>            : #endif /* #else #ifdef CONFIG_PREEMPT_RCU */</a>
<a name="957"><span class="lineNum">     957 </span>            : </a>
<a name="958"><span class="lineNum">     958 </span>            : /*</a>
<a name="959"><span class="lineNum">     959 </span>            :  * If boosting, set rcuc kthreads to realtime priority.</a>
<a name="960"><span class="lineNum">     960 </span>            :  */</a>
<a name="961"><span class="lineNum">     961 </span><span class="lineNoCov">          0 : static void rcu_cpu_kthread_setup(unsigned int cpu)</span></a>
<a name="962"><span class="lineNum">     962 </span>            : {</a>
<a name="963"><span class="lineNum">     963 </span>            : #ifdef CONFIG_RCU_BOOST</a>
<a name="964"><span class="lineNum">     964 </span>            :         struct sched_param sp;</a>
<a name="965"><span class="lineNum">     965 </span>            : </a>
<a name="966"><span class="lineNum">     966 </span>            :         sp.sched_priority = kthread_prio;</a>
<a name="967"><span class="lineNum">     967 </span>            :         sched_setscheduler_nocheck(current, SCHED_FIFO, &amp;sp);</a>
<a name="968"><span class="lineNum">     968 </span>            : #endif /* #ifdef CONFIG_RCU_BOOST */</a>
<a name="969"><span class="lineNum">     969 </span><span class="lineNoCov">          0 : }</span></a>
<a name="970"><span class="lineNum">     970 </span>            : </a>
<a name="971"><span class="lineNum">     971 </span>            : #ifdef CONFIG_RCU_BOOST</a>
<a name="972"><span class="lineNum">     972 </span>            : </a>
<a name="973"><span class="lineNum">     973 </span>            : /*</a>
<a name="974"><span class="lineNum">     974 </span>            :  * Carry out RCU priority boosting on the task indicated by -&gt;exp_tasks</a>
<a name="975"><span class="lineNum">     975 </span>            :  * or -&gt;boost_tasks, advancing the pointer to the next task in the</a>
<a name="976"><span class="lineNum">     976 </span>            :  * -&gt;blkd_tasks list.</a>
<a name="977"><span class="lineNum">     977 </span>            :  *</a>
<a name="978"><span class="lineNum">     978 </span>            :  * Note that irqs must be enabled: boosting the task can block.</a>
<a name="979"><span class="lineNum">     979 </span>            :  * Returns 1 if there are more tasks needing to be boosted.</a>
<a name="980"><span class="lineNum">     980 </span>            :  */</a>
<a name="981"><span class="lineNum">     981 </span>            : static int rcu_boost(struct rcu_node *rnp)</a>
<a name="982"><span class="lineNum">     982 </span>            : {</a>
<a name="983"><span class="lineNum">     983 </span>            :         unsigned long flags;</a>
<a name="984"><span class="lineNum">     984 </span>            :         struct task_struct *t;</a>
<a name="985"><span class="lineNum">     985 </span>            :         struct list_head *tb;</a>
<a name="986"><span class="lineNum">     986 </span>            : </a>
<a name="987"><span class="lineNum">     987 </span>            :         if (READ_ONCE(rnp-&gt;exp_tasks) == NULL &amp;&amp;</a>
<a name="988"><span class="lineNum">     988 </span>            :             READ_ONCE(rnp-&gt;boost_tasks) == NULL)</a>
<a name="989"><span class="lineNum">     989 </span>            :                 return 0;  /* Nothing left to boost. */</a>
<a name="990"><span class="lineNum">     990 </span>            : </a>
<a name="991"><span class="lineNum">     991 </span>            :         raw_spin_lock_irqsave_rcu_node(rnp, flags);</a>
<a name="992"><span class="lineNum">     992 </span>            : </a>
<a name="993"><span class="lineNum">     993 </span>            :         /*</a>
<a name="994"><span class="lineNum">     994 </span>            :          * Recheck under the lock: all tasks in need of boosting</a>
<a name="995"><span class="lineNum">     995 </span>            :          * might exit their RCU read-side critical sections on their own.</a>
<a name="996"><span class="lineNum">     996 </span>            :          */</a>
<a name="997"><span class="lineNum">     997 </span>            :         if (rnp-&gt;exp_tasks == NULL &amp;&amp; rnp-&gt;boost_tasks == NULL) {</a>
<a name="998"><span class="lineNum">     998 </span>            :                 raw_spin_unlock_irqrestore_rcu_node(rnp, flags);</a>
<a name="999"><span class="lineNum">     999 </span>            :                 return 0;</a>
<a name="1000"><span class="lineNum">    1000 </span>            :         }</a>
<a name="1001"><span class="lineNum">    1001 </span>            : </a>
<a name="1002"><span class="lineNum">    1002 </span>            :         /*</a>
<a name="1003"><span class="lineNum">    1003 </span>            :          * Preferentially boost tasks blocking expedited grace periods.</a>
<a name="1004"><span class="lineNum">    1004 </span>            :          * This cannot starve the normal grace periods because a second</a>
<a name="1005"><span class="lineNum">    1005 </span>            :          * expedited grace period must boost all blocked tasks, including</a>
<a name="1006"><span class="lineNum">    1006 </span>            :          * those blocking the pre-existing normal grace period.</a>
<a name="1007"><span class="lineNum">    1007 </span>            :          */</a>
<a name="1008"><span class="lineNum">    1008 </span>            :         if (rnp-&gt;exp_tasks != NULL)</a>
<a name="1009"><span class="lineNum">    1009 </span>            :                 tb = rnp-&gt;exp_tasks;</a>
<a name="1010"><span class="lineNum">    1010 </span>            :         else</a>
<a name="1011"><span class="lineNum">    1011 </span>            :                 tb = rnp-&gt;boost_tasks;</a>
<a name="1012"><span class="lineNum">    1012 </span>            : </a>
<a name="1013"><span class="lineNum">    1013 </span>            :         /*</a>
<a name="1014"><span class="lineNum">    1014 </span>            :          * We boost task t by manufacturing an rt_mutex that appears to</a>
<a name="1015"><span class="lineNum">    1015 </span>            :          * be held by task t.  We leave a pointer to that rt_mutex where</a>
<a name="1016"><span class="lineNum">    1016 </span>            :          * task t can find it, and task t will release the mutex when it</a>
<a name="1017"><span class="lineNum">    1017 </span>            :          * exits its outermost RCU read-side critical section.  Then</a>
<a name="1018"><span class="lineNum">    1018 </span>            :          * simply acquiring this artificial rt_mutex will boost task</a>
<a name="1019"><span class="lineNum">    1019 </span>            :          * t's priority.  (Thanks to tglx for suggesting this approach!)</a>
<a name="1020"><span class="lineNum">    1020 </span>            :          *</a>
<a name="1021"><span class="lineNum">    1021 </span>            :          * Note that task t must acquire rnp-&gt;lock to remove itself from</a>
<a name="1022"><span class="lineNum">    1022 </span>            :          * the -&gt;blkd_tasks list, which it will do from exit() if from</a>
<a name="1023"><span class="lineNum">    1023 </span>            :          * nowhere else.  We therefore are guaranteed that task t will</a>
<a name="1024"><span class="lineNum">    1024 </span>            :          * stay around at least until we drop rnp-&gt;lock.  Note that</a>
<a name="1025"><span class="lineNum">    1025 </span>            :          * rnp-&gt;lock also resolves races between our priority boosting</a>
<a name="1026"><span class="lineNum">    1026 </span>            :          * and task t's exiting its outermost RCU read-side critical</a>
<a name="1027"><span class="lineNum">    1027 </span>            :          * section.</a>
<a name="1028"><span class="lineNum">    1028 </span>            :          */</a>
<a name="1029"><span class="lineNum">    1029 </span>            :         t = container_of(tb, struct task_struct, rcu_node_entry);</a>
<a name="1030"><span class="lineNum">    1030 </span>            :         rt_mutex_init_proxy_locked(&amp;rnp-&gt;boost_mtx, t);</a>
<a name="1031"><span class="lineNum">    1031 </span>            :         raw_spin_unlock_irqrestore_rcu_node(rnp, flags);</a>
<a name="1032"><span class="lineNum">    1032 </span>            :         /* Lock only for side effect: boosts task t's priority. */</a>
<a name="1033"><span class="lineNum">    1033 </span>            :         rt_mutex_lock(&amp;rnp-&gt;boost_mtx);</a>
<a name="1034"><span class="lineNum">    1034 </span>            :         rt_mutex_unlock(&amp;rnp-&gt;boost_mtx);  /* Then keep lockdep happy. */</a>
<a name="1035"><span class="lineNum">    1035 </span>            : </a>
<a name="1036"><span class="lineNum">    1036 </span>            :         return READ_ONCE(rnp-&gt;exp_tasks) != NULL ||</a>
<a name="1037"><span class="lineNum">    1037 </span>            :                READ_ONCE(rnp-&gt;boost_tasks) != NULL;</a>
<a name="1038"><span class="lineNum">    1038 </span>            : }</a>
<a name="1039"><span class="lineNum">    1039 </span>            : </a>
<a name="1040"><span class="lineNum">    1040 </span>            : /*</a>
<a name="1041"><span class="lineNum">    1041 </span>            :  * Priority-boosting kthread, one per leaf rcu_node.</a>
<a name="1042"><span class="lineNum">    1042 </span>            :  */</a>
<a name="1043"><span class="lineNum">    1043 </span>            : static int rcu_boost_kthread(void *arg)</a>
<a name="1044"><span class="lineNum">    1044 </span>            : {</a>
<a name="1045"><span class="lineNum">    1045 </span>            :         struct rcu_node *rnp = (struct rcu_node *)arg;</a>
<a name="1046"><span class="lineNum">    1046 </span>            :         int spincnt = 0;</a>
<a name="1047"><span class="lineNum">    1047 </span>            :         int more2boost;</a>
<a name="1048"><span class="lineNum">    1048 </span>            : </a>
<a name="1049"><span class="lineNum">    1049 </span>            :         trace_rcu_utilization(TPS(&quot;Start boost kthread@init&quot;));</a>
<a name="1050"><span class="lineNum">    1050 </span>            :         for (;;) {</a>
<a name="1051"><span class="lineNum">    1051 </span>            :                 WRITE_ONCE(rnp-&gt;boost_kthread_status, RCU_KTHREAD_WAITING);</a>
<a name="1052"><span class="lineNum">    1052 </span>            :                 trace_rcu_utilization(TPS(&quot;End boost kthread@rcu_wait&quot;));</a>
<a name="1053"><span class="lineNum">    1053 </span>            :                 rcu_wait(READ_ONCE(rnp-&gt;boost_tasks) ||</a>
<a name="1054"><span class="lineNum">    1054 </span>            :                          READ_ONCE(rnp-&gt;exp_tasks));</a>
<a name="1055"><span class="lineNum">    1055 </span>            :                 trace_rcu_utilization(TPS(&quot;Start boost kthread@rcu_wait&quot;));</a>
<a name="1056"><span class="lineNum">    1056 </span>            :                 WRITE_ONCE(rnp-&gt;boost_kthread_status, RCU_KTHREAD_RUNNING);</a>
<a name="1057"><span class="lineNum">    1057 </span>            :                 more2boost = rcu_boost(rnp);</a>
<a name="1058"><span class="lineNum">    1058 </span>            :                 if (more2boost)</a>
<a name="1059"><span class="lineNum">    1059 </span>            :                         spincnt++;</a>
<a name="1060"><span class="lineNum">    1060 </span>            :                 else</a>
<a name="1061"><span class="lineNum">    1061 </span>            :                         spincnt = 0;</a>
<a name="1062"><span class="lineNum">    1062 </span>            :                 if (spincnt &gt; 10) {</a>
<a name="1063"><span class="lineNum">    1063 </span>            :                         WRITE_ONCE(rnp-&gt;boost_kthread_status, RCU_KTHREAD_YIELDING);</a>
<a name="1064"><span class="lineNum">    1064 </span>            :                         trace_rcu_utilization(TPS(&quot;End boost kthread@rcu_yield&quot;));</a>
<a name="1065"><span class="lineNum">    1065 </span>            :                         schedule_timeout_idle(2);</a>
<a name="1066"><span class="lineNum">    1066 </span>            :                         trace_rcu_utilization(TPS(&quot;Start boost kthread@rcu_yield&quot;));</a>
<a name="1067"><span class="lineNum">    1067 </span>            :                         spincnt = 0;</a>
<a name="1068"><span class="lineNum">    1068 </span>            :                 }</a>
<a name="1069"><span class="lineNum">    1069 </span>            :         }</a>
<a name="1070"><span class="lineNum">    1070 </span>            :         /* NOTREACHED */</a>
<a name="1071"><span class="lineNum">    1071 </span>            :         trace_rcu_utilization(TPS(&quot;End boost kthread@notreached&quot;));</a>
<a name="1072"><span class="lineNum">    1072 </span>            :         return 0;</a>
<a name="1073"><span class="lineNum">    1073 </span>            : }</a>
<a name="1074"><span class="lineNum">    1074 </span>            : </a>
<a name="1075"><span class="lineNum">    1075 </span>            : /*</a>
<a name="1076"><span class="lineNum">    1076 </span>            :  * Check to see if it is time to start boosting RCU readers that are</a>
<a name="1077"><span class="lineNum">    1077 </span>            :  * blocking the current grace period, and, if so, tell the per-rcu_node</a>
<a name="1078"><span class="lineNum">    1078 </span>            :  * kthread to start boosting them.  If there is an expedited grace</a>
<a name="1079"><span class="lineNum">    1079 </span>            :  * period in progress, it is always time to boost.</a>
<a name="1080"><span class="lineNum">    1080 </span>            :  *</a>
<a name="1081"><span class="lineNum">    1081 </span>            :  * The caller must hold rnp-&gt;lock, which this function releases.</a>
<a name="1082"><span class="lineNum">    1082 </span>            :  * The -&gt;boost_kthread_task is immortal, so we don't need to worry</a>
<a name="1083"><span class="lineNum">    1083 </span>            :  * about it going away.</a>
<a name="1084"><span class="lineNum">    1084 </span>            :  */</a>
<a name="1085"><span class="lineNum">    1085 </span>            : static void rcu_initiate_boost(struct rcu_node *rnp, unsigned long flags)</a>
<a name="1086"><span class="lineNum">    1086 </span>            :         __releases(rnp-&gt;lock)</a>
<a name="1087"><span class="lineNum">    1087 </span>            : {</a>
<a name="1088"><span class="lineNum">    1088 </span>            :         raw_lockdep_assert_held_rcu_node(rnp);</a>
<a name="1089"><span class="lineNum">    1089 </span>            :         if (!rcu_preempt_blocked_readers_cgp(rnp) &amp;&amp; rnp-&gt;exp_tasks == NULL) {</a>
<a name="1090"><span class="lineNum">    1090 </span>            :                 raw_spin_unlock_irqrestore_rcu_node(rnp, flags);</a>
<a name="1091"><span class="lineNum">    1091 </span>            :                 return;</a>
<a name="1092"><span class="lineNum">    1092 </span>            :         }</a>
<a name="1093"><span class="lineNum">    1093 </span>            :         if (rnp-&gt;exp_tasks != NULL ||</a>
<a name="1094"><span class="lineNum">    1094 </span>            :             (rnp-&gt;gp_tasks != NULL &amp;&amp;</a>
<a name="1095"><span class="lineNum">    1095 </span>            :              rnp-&gt;boost_tasks == NULL &amp;&amp;</a>
<a name="1096"><span class="lineNum">    1096 </span>            :              rnp-&gt;qsmask == 0 &amp;&amp;</a>
<a name="1097"><span class="lineNum">    1097 </span>            :              (!time_after(rnp-&gt;boost_time, jiffies) || rcu_state.cbovld))) {</a>
<a name="1098"><span class="lineNum">    1098 </span>            :                 if (rnp-&gt;exp_tasks == NULL)</a>
<a name="1099"><span class="lineNum">    1099 </span>            :                         WRITE_ONCE(rnp-&gt;boost_tasks, rnp-&gt;gp_tasks);</a>
<a name="1100"><span class="lineNum">    1100 </span>            :                 raw_spin_unlock_irqrestore_rcu_node(rnp, flags);</a>
<a name="1101"><span class="lineNum">    1101 </span>            :                 rcu_wake_cond(rnp-&gt;boost_kthread_task,</a>
<a name="1102"><span class="lineNum">    1102 </span>            :                               READ_ONCE(rnp-&gt;boost_kthread_status));</a>
<a name="1103"><span class="lineNum">    1103 </span>            :         } else {</a>
<a name="1104"><span class="lineNum">    1104 </span>            :                 raw_spin_unlock_irqrestore_rcu_node(rnp, flags);</a>
<a name="1105"><span class="lineNum">    1105 </span>            :         }</a>
<a name="1106"><span class="lineNum">    1106 </span>            : }</a>
<a name="1107"><span class="lineNum">    1107 </span>            : </a>
<a name="1108"><span class="lineNum">    1108 </span>            : /*</a>
<a name="1109"><span class="lineNum">    1109 </span>            :  * Is the current CPU running the RCU-callbacks kthread?</a>
<a name="1110"><span class="lineNum">    1110 </span>            :  * Caller must have preemption disabled.</a>
<a name="1111"><span class="lineNum">    1111 </span>            :  */</a>
<a name="1112"><span class="lineNum">    1112 </span>            : static bool rcu_is_callbacks_kthread(void)</a>
<a name="1113"><span class="lineNum">    1113 </span>            : {</a>
<a name="1114"><span class="lineNum">    1114 </span>            :         return __this_cpu_read(rcu_data.rcu_cpu_kthread_task) == current;</a>
<a name="1115"><span class="lineNum">    1115 </span>            : }</a>
<a name="1116"><span class="lineNum">    1116 </span>            : </a>
<a name="1117"><span class="lineNum">    1117 </span>            : #define RCU_BOOST_DELAY_JIFFIES DIV_ROUND_UP(CONFIG_RCU_BOOST_DELAY * HZ, 1000)</a>
<a name="1118"><span class="lineNum">    1118 </span>            : </a>
<a name="1119"><span class="lineNum">    1119 </span>            : /*</a>
<a name="1120"><span class="lineNum">    1120 </span>            :  * Do priority-boost accounting for the start of a new grace period.</a>
<a name="1121"><span class="lineNum">    1121 </span>            :  */</a>
<a name="1122"><span class="lineNum">    1122 </span>            : static void rcu_preempt_boost_start_gp(struct rcu_node *rnp)</a>
<a name="1123"><span class="lineNum">    1123 </span>            : {</a>
<a name="1124"><span class="lineNum">    1124 </span>            :         rnp-&gt;boost_time = jiffies + RCU_BOOST_DELAY_JIFFIES;</a>
<a name="1125"><span class="lineNum">    1125 </span>            : }</a>
<a name="1126"><span class="lineNum">    1126 </span>            : </a>
<a name="1127"><span class="lineNum">    1127 </span>            : /*</a>
<a name="1128"><span class="lineNum">    1128 </span>            :  * Create an RCU-boost kthread for the specified node if one does not</a>
<a name="1129"><span class="lineNum">    1129 </span>            :  * already exist.  We only create this kthread for preemptible RCU.</a>
<a name="1130"><span class="lineNum">    1130 </span>            :  * Returns zero if all is well, a negated errno otherwise.</a>
<a name="1131"><span class="lineNum">    1131 </span>            :  */</a>
<a name="1132"><span class="lineNum">    1132 </span>            : static void rcu_spawn_one_boost_kthread(struct rcu_node *rnp)</a>
<a name="1133"><span class="lineNum">    1133 </span>            : {</a>
<a name="1134"><span class="lineNum">    1134 </span>            :         int rnp_index = rnp - rcu_get_root();</a>
<a name="1135"><span class="lineNum">    1135 </span>            :         unsigned long flags;</a>
<a name="1136"><span class="lineNum">    1136 </span>            :         struct sched_param sp;</a>
<a name="1137"><span class="lineNum">    1137 </span>            :         struct task_struct *t;</a>
<a name="1138"><span class="lineNum">    1138 </span>            : </a>
<a name="1139"><span class="lineNum">    1139 </span>            :         if (!IS_ENABLED(CONFIG_PREEMPT_RCU))</a>
<a name="1140"><span class="lineNum">    1140 </span>            :                 return;</a>
<a name="1141"><span class="lineNum">    1141 </span>            : </a>
<a name="1142"><span class="lineNum">    1142 </span>            :         if (!rcu_scheduler_fully_active || rcu_rnp_online_cpus(rnp) == 0)</a>
<a name="1143"><span class="lineNum">    1143 </span>            :                 return;</a>
<a name="1144"><span class="lineNum">    1144 </span>            : </a>
<a name="1145"><span class="lineNum">    1145 </span>            :         rcu_state.boost = 1;</a>
<a name="1146"><span class="lineNum">    1146 </span>            : </a>
<a name="1147"><span class="lineNum">    1147 </span>            :         if (rnp-&gt;boost_kthread_task != NULL)</a>
<a name="1148"><span class="lineNum">    1148 </span>            :                 return;</a>
<a name="1149"><span class="lineNum">    1149 </span>            : </a>
<a name="1150"><span class="lineNum">    1150 </span>            :         t = kthread_create(rcu_boost_kthread, (void *)rnp,</a>
<a name="1151"><span class="lineNum">    1151 </span>            :                            &quot;rcub/%d&quot;, rnp_index);</a>
<a name="1152"><span class="lineNum">    1152 </span>            :         if (WARN_ON_ONCE(IS_ERR(t)))</a>
<a name="1153"><span class="lineNum">    1153 </span>            :                 return;</a>
<a name="1154"><span class="lineNum">    1154 </span>            : </a>
<a name="1155"><span class="lineNum">    1155 </span>            :         raw_spin_lock_irqsave_rcu_node(rnp, flags);</a>
<a name="1156"><span class="lineNum">    1156 </span>            :         rnp-&gt;boost_kthread_task = t;</a>
<a name="1157"><span class="lineNum">    1157 </span>            :         raw_spin_unlock_irqrestore_rcu_node(rnp, flags);</a>
<a name="1158"><span class="lineNum">    1158 </span>            :         sp.sched_priority = kthread_prio;</a>
<a name="1159"><span class="lineNum">    1159 </span>            :         sched_setscheduler_nocheck(t, SCHED_FIFO, &amp;sp);</a>
<a name="1160"><span class="lineNum">    1160 </span>            :         wake_up_process(t); /* get to TASK_INTERRUPTIBLE quickly. */</a>
<a name="1161"><span class="lineNum">    1161 </span>            : }</a>
<a name="1162"><span class="lineNum">    1162 </span>            : </a>
<a name="1163"><span class="lineNum">    1163 </span>            : /*</a>
<a name="1164"><span class="lineNum">    1164 </span>            :  * Set the per-rcu_node kthread's affinity to cover all CPUs that are</a>
<a name="1165"><span class="lineNum">    1165 </span>            :  * served by the rcu_node in question.  The CPU hotplug lock is still</a>
<a name="1166"><span class="lineNum">    1166 </span>            :  * held, so the value of rnp-&gt;qsmaskinit will be stable.</a>
<a name="1167"><span class="lineNum">    1167 </span>            :  *</a>
<a name="1168"><span class="lineNum">    1168 </span>            :  * We don't include outgoingcpu in the affinity set, use -1 if there is</a>
<a name="1169"><span class="lineNum">    1169 </span>            :  * no outgoing CPU.  If there are no CPUs left in the affinity set,</a>
<a name="1170"><span class="lineNum">    1170 </span>            :  * this function allows the kthread to execute on any CPU.</a>
<a name="1171"><span class="lineNum">    1171 </span>            :  */</a>
<a name="1172"><span class="lineNum">    1172 </span>            : static void rcu_boost_kthread_setaffinity(struct rcu_node *rnp, int outgoingcpu)</a>
<a name="1173"><span class="lineNum">    1173 </span>            : {</a>
<a name="1174"><span class="lineNum">    1174 </span>            :         struct task_struct *t = rnp-&gt;boost_kthread_task;</a>
<a name="1175"><span class="lineNum">    1175 </span>            :         unsigned long mask = rcu_rnp_online_cpus(rnp);</a>
<a name="1176"><span class="lineNum">    1176 </span>            :         cpumask_var_t cm;</a>
<a name="1177"><span class="lineNum">    1177 </span>            :         int cpu;</a>
<a name="1178"><span class="lineNum">    1178 </span>            : </a>
<a name="1179"><span class="lineNum">    1179 </span>            :         if (!t)</a>
<a name="1180"><span class="lineNum">    1180 </span>            :                 return;</a>
<a name="1181"><span class="lineNum">    1181 </span>            :         if (!zalloc_cpumask_var(&amp;cm, GFP_KERNEL))</a>
<a name="1182"><span class="lineNum">    1182 </span>            :                 return;</a>
<a name="1183"><span class="lineNum">    1183 </span>            :         for_each_leaf_node_possible_cpu(rnp, cpu)</a>
<a name="1184"><span class="lineNum">    1184 </span>            :                 if ((mask &amp; leaf_node_cpu_bit(rnp, cpu)) &amp;&amp;</a>
<a name="1185"><span class="lineNum">    1185 </span>            :                     cpu != outgoingcpu)</a>
<a name="1186"><span class="lineNum">    1186 </span>            :                         cpumask_set_cpu(cpu, cm);</a>
<a name="1187"><span class="lineNum">    1187 </span>            :         if (cpumask_weight(cm) == 0)</a>
<a name="1188"><span class="lineNum">    1188 </span>            :                 cpumask_setall(cm);</a>
<a name="1189"><span class="lineNum">    1189 </span>            :         set_cpus_allowed_ptr(t, cm);</a>
<a name="1190"><span class="lineNum">    1190 </span>            :         free_cpumask_var(cm);</a>
<a name="1191"><span class="lineNum">    1191 </span>            : }</a>
<a name="1192"><span class="lineNum">    1192 </span>            : </a>
<a name="1193"><span class="lineNum">    1193 </span>            : /*</a>
<a name="1194"><span class="lineNum">    1194 </span>            :  * Spawn boost kthreads -- called as soon as the scheduler is running.</a>
<a name="1195"><span class="lineNum">    1195 </span>            :  */</a>
<a name="1196"><span class="lineNum">    1196 </span>            : static void __init rcu_spawn_boost_kthreads(void)</a>
<a name="1197"><span class="lineNum">    1197 </span>            : {</a>
<a name="1198"><span class="lineNum">    1198 </span>            :         struct rcu_node *rnp;</a>
<a name="1199"><span class="lineNum">    1199 </span>            : </a>
<a name="1200"><span class="lineNum">    1200 </span>            :         rcu_for_each_leaf_node(rnp)</a>
<a name="1201"><span class="lineNum">    1201 </span>            :                 rcu_spawn_one_boost_kthread(rnp);</a>
<a name="1202"><span class="lineNum">    1202 </span>            : }</a>
<a name="1203"><span class="lineNum">    1203 </span>            : </a>
<a name="1204"><span class="lineNum">    1204 </span>            : static void rcu_prepare_kthreads(int cpu)</a>
<a name="1205"><span class="lineNum">    1205 </span>            : {</a>
<a name="1206"><span class="lineNum">    1206 </span>            :         struct rcu_data *rdp = per_cpu_ptr(&amp;rcu_data, cpu);</a>
<a name="1207"><span class="lineNum">    1207 </span>            :         struct rcu_node *rnp = rdp-&gt;mynode;</a>
<a name="1208"><span class="lineNum">    1208 </span>            : </a>
<a name="1209"><span class="lineNum">    1209 </span>            :         /* Fire up the incoming CPU's kthread and leaf rcu_node kthread. */</a>
<a name="1210"><span class="lineNum">    1210 </span>            :         if (rcu_scheduler_fully_active)</a>
<a name="1211"><span class="lineNum">    1211 </span>            :                 rcu_spawn_one_boost_kthread(rnp);</a>
<a name="1212"><span class="lineNum">    1212 </span>            : }</a>
<a name="1213"><span class="lineNum">    1213 </span>            : </a>
<a name="1214"><span class="lineNum">    1214 </span>            : #else /* #ifdef CONFIG_RCU_BOOST */</a>
<a name="1215"><span class="lineNum">    1215 </span>            : </a>
<a name="1216"><span class="lineNum">    1216 </span><span class="lineNoCov">          0 : static void rcu_initiate_boost(struct rcu_node *rnp, unsigned long flags)</span></a>
<a name="1217"><span class="lineNum">    1217 </span>            :         __releases(rnp-&gt;lock)</a>
<a name="1218"><span class="lineNum">    1218 </span>            : {</a>
<a name="1219"><span class="lineNum">    1219 </span><span class="lineNoCov">          0 :         raw_spin_unlock_irqrestore_rcu_node(rnp, flags);</span></a>
<a name="1220"><span class="lineNum">    1220 </span><span class="lineNoCov">          0 : }</span></a>
<a name="1221"><span class="lineNum">    1221 </span>            : </a>
<a name="1222"><span class="lineNum">    1222 </span><span class="lineCov">      48764 : static bool rcu_is_callbacks_kthread(void)</span></a>
<a name="1223"><span class="lineNum">    1223 </span>            : {</a>
<a name="1224"><span class="lineNum">    1224 </span><span class="lineCov">      48764 :         return false;</span></a>
<a name="1225"><span class="lineNum">    1225 </span>            : }</a>
<a name="1226"><span class="lineNum">    1226 </span>            : </a>
<a name="1227"><span class="lineNum">    1227 </span><span class="lineCov">       2020 : static void rcu_preempt_boost_start_gp(struct rcu_node *rnp)</span></a>
<a name="1228"><span class="lineNum">    1228 </span>            : {</a>
<a name="1229"><span class="lineNum">    1229 </span><span class="lineCov">       2020 : }</span></a>
<a name="1230"><span class="lineNum">    1230 </span>            : </a>
<a name="1231"><span class="lineNum">    1231 </span><span class="lineCov">          3 : static void rcu_boost_kthread_setaffinity(struct rcu_node *rnp, int outgoingcpu)</span></a>
<a name="1232"><span class="lineNum">    1232 </span>            : {</a>
<a name="1233"><span class="lineNum">    1233 </span><span class="lineCov">          3 : }</span></a>
<a name="1234"><span class="lineNum">    1234 </span>            : </a>
<a name="1235"><span class="lineNum">    1235 </span><span class="lineCov">          1 : static void __init rcu_spawn_boost_kthreads(void)</span></a>
<a name="1236"><span class="lineNum">    1236 </span>            : {</a>
<a name="1237"><span class="lineNum">    1237 </span><span class="lineCov">          1 : }</span></a>
<a name="1238"><span class="lineNum">    1238 </span>            : </a>
<a name="1239"><span class="lineNum">    1239 </span><span class="lineCov">          4 : static void rcu_prepare_kthreads(int cpu)</span></a>
<a name="1240"><span class="lineNum">    1240 </span>            : {</a>
<a name="1241"><span class="lineNum">    1241 </span><span class="lineCov">          4 : }</span></a>
<a name="1242"><span class="lineNum">    1242 </span>            : </a>
<a name="1243"><span class="lineNum">    1243 </span>            : #endif /* #else #ifdef CONFIG_RCU_BOOST */</a>
<a name="1244"><span class="lineNum">    1244 </span>            : </a>
<a name="1245"><span class="lineNum">    1245 </span>            : #if !defined(CONFIG_RCU_FAST_NO_HZ)</a>
<a name="1246"><span class="lineNum">    1246 </span>            : </a>
<a name="1247"><span class="lineNum">    1247 </span>            : /*</a>
<a name="1248"><span class="lineNum">    1248 </span>            :  * Check to see if any future non-offloaded RCU-related work will need</a>
<a name="1249"><span class="lineNum">    1249 </span>            :  * to be done by the current CPU, even if none need be done immediately,</a>
<a name="1250"><span class="lineNum">    1250 </span>            :  * returning 1 if so.  This function is part of the RCU implementation;</a>
<a name="1251"><span class="lineNum">    1251 </span>            :  * it is -not- an exported member of the RCU API.</a>
<a name="1252"><span class="lineNum">    1252 </span>            :  *</a>
<a name="1253"><span class="lineNum">    1253 </span>            :  * Because we not have RCU_FAST_NO_HZ, just check whether or not this</a>
<a name="1254"><span class="lineNum">    1254 </span>            :  * CPU has RCU callbacks queued.</a>
<a name="1255"><span class="lineNum">    1255 </span>            :  */</a>
<a name="1256"><span class="lineNum">    1256 </span><span class="lineCov">      17225 : int rcu_needs_cpu(u64 basemono, u64 *nextevt)</span></a>
<a name="1257"><span class="lineNum">    1257 </span>            : {</a>
<a name="1258"><span class="lineNum">    1258 </span><span class="lineCov">      17225 :         *nextevt = KTIME_MAX;</span></a>
<a name="1259"><span class="lineNum">    1259 </span><span class="lineCov">      17225 :         return !rcu_segcblist_empty(&amp;this_cpu_ptr(&amp;rcu_data)-&gt;cblist) &amp;&amp;</span></a>
<a name="1260"><span class="lineNum">    1260 </span><span class="lineCov">      16103 :                !rcu_segcblist_is_offloaded(&amp;this_cpu_ptr(&amp;rcu_data)-&gt;cblist);</span></a>
<a name="1261"><span class="lineNum">    1261 </span>            : }</a>
<a name="1262"><span class="lineNum">    1262 </span>            : </a>
<a name="1263"><span class="lineNum">    1263 </span>            : /*</a>
<a name="1264"><span class="lineNum">    1264 </span>            :  * Because we do not have RCU_FAST_NO_HZ, don't bother cleaning up</a>
<a name="1265"><span class="lineNum">    1265 </span>            :  * after it.</a>
<a name="1266"><span class="lineNum">    1266 </span>            :  */</a>
<a name="1267"><span class="lineNum">    1267 </span>            : static void rcu_cleanup_after_idle(void)</a>
<a name="1268"><span class="lineNum">    1268 </span>            : {</a>
<a name="1269"><span class="lineNum">    1269 </span>            : }</a>
<a name="1270"><span class="lineNum">    1270 </span>            : </a>
<a name="1271"><span class="lineNum">    1271 </span>            : /*</a>
<a name="1272"><span class="lineNum">    1272 </span>            :  * Do the idle-entry grace-period work, which, because CONFIG_RCU_FAST_NO_HZ=n,</a>
<a name="1273"><span class="lineNum">    1273 </span>            :  * is nothing.</a>
<a name="1274"><span class="lineNum">    1274 </span>            :  */</a>
<a name="1275"><span class="lineNum">    1275 </span>            : static void rcu_prepare_for_idle(void)</a>
<a name="1276"><span class="lineNum">    1276 </span>            : {</a>
<a name="1277"><span class="lineNum">    1277 </span>            : }</a>
<a name="1278"><span class="lineNum">    1278 </span>            : </a>
<a name="1279"><span class="lineNum">    1279 </span>            : #else /* #if !defined(CONFIG_RCU_FAST_NO_HZ) */</a>
<a name="1280"><span class="lineNum">    1280 </span>            : </a>
<a name="1281"><span class="lineNum">    1281 </span>            : /*</a>
<a name="1282"><span class="lineNum">    1282 </span>            :  * This code is invoked when a CPU goes idle, at which point we want</a>
<a name="1283"><span class="lineNum">    1283 </span>            :  * to have the CPU do everything required for RCU so that it can enter</a>
<a name="1284"><span class="lineNum">    1284 </span>            :  * the energy-efficient dyntick-idle mode.</a>
<a name="1285"><span class="lineNum">    1285 </span>            :  *</a>
<a name="1286"><span class="lineNum">    1286 </span>            :  * The following preprocessor symbol controls this:</a>
<a name="1287"><span class="lineNum">    1287 </span>            :  *</a>
<a name="1288"><span class="lineNum">    1288 </span>            :  * RCU_IDLE_GP_DELAY gives the number of jiffies that a CPU is permitted</a>
<a name="1289"><span class="lineNum">    1289 </span>            :  *      to sleep in dyntick-idle mode with RCU callbacks pending.  This</a>
<a name="1290"><span class="lineNum">    1290 </span>            :  *      is sized to be roughly one RCU grace period.  Those energy-efficiency</a>
<a name="1291"><span class="lineNum">    1291 </span>            :  *      benchmarkers who might otherwise be tempted to set this to a large</a>
<a name="1292"><span class="lineNum">    1292 </span>            :  *      number, be warned: Setting RCU_IDLE_GP_DELAY too high can hang your</a>
<a name="1293"><span class="lineNum">    1293 </span>            :  *      system.  And if you are -that- concerned about energy efficiency,</a>
<a name="1294"><span class="lineNum">    1294 </span>            :  *      just power the system down and be done with it!</a>
<a name="1295"><span class="lineNum">    1295 </span>            :  *</a>
<a name="1296"><span class="lineNum">    1296 </span>            :  * The value below works well in practice.  If future workloads require</a>
<a name="1297"><span class="lineNum">    1297 </span>            :  * adjustment, they can be converted into kernel config parameters, though</a>
<a name="1298"><span class="lineNum">    1298 </span>            :  * making the state machine smarter might be a better option.</a>
<a name="1299"><span class="lineNum">    1299 </span>            :  */</a>
<a name="1300"><span class="lineNum">    1300 </span>            : #define RCU_IDLE_GP_DELAY 4             /* Roughly one grace period. */</a>
<a name="1301"><span class="lineNum">    1301 </span>            : </a>
<a name="1302"><span class="lineNum">    1302 </span>            : static int rcu_idle_gp_delay = RCU_IDLE_GP_DELAY;</a>
<a name="1303"><span class="lineNum">    1303 </span>            : module_param(rcu_idle_gp_delay, int, 0644);</a>
<a name="1304"><span class="lineNum">    1304 </span>            : </a>
<a name="1305"><span class="lineNum">    1305 </span>            : /*</a>
<a name="1306"><span class="lineNum">    1306 </span>            :  * Try to advance callbacks on the current CPU, but only if it has been</a>
<a name="1307"><span class="lineNum">    1307 </span>            :  * awhile since the last time we did so.  Afterwards, if there are any</a>
<a name="1308"><span class="lineNum">    1308 </span>            :  * callbacks ready for immediate invocation, return true.</a>
<a name="1309"><span class="lineNum">    1309 </span>            :  */</a>
<a name="1310"><span class="lineNum">    1310 </span>            : static bool __maybe_unused rcu_try_advance_all_cbs(void)</a>
<a name="1311"><span class="lineNum">    1311 </span>            : {</a>
<a name="1312"><span class="lineNum">    1312 </span>            :         bool cbs_ready = false;</a>
<a name="1313"><span class="lineNum">    1313 </span>            :         struct rcu_data *rdp = this_cpu_ptr(&amp;rcu_data);</a>
<a name="1314"><span class="lineNum">    1314 </span>            :         struct rcu_node *rnp;</a>
<a name="1315"><span class="lineNum">    1315 </span>            : </a>
<a name="1316"><span class="lineNum">    1316 </span>            :         /* Exit early if we advanced recently. */</a>
<a name="1317"><span class="lineNum">    1317 </span>            :         if (jiffies == rdp-&gt;last_advance_all)</a>
<a name="1318"><span class="lineNum">    1318 </span>            :                 return false;</a>
<a name="1319"><span class="lineNum">    1319 </span>            :         rdp-&gt;last_advance_all = jiffies;</a>
<a name="1320"><span class="lineNum">    1320 </span>            : </a>
<a name="1321"><span class="lineNum">    1321 </span>            :         rnp = rdp-&gt;mynode;</a>
<a name="1322"><span class="lineNum">    1322 </span>            : </a>
<a name="1323"><span class="lineNum">    1323 </span>            :         /*</a>
<a name="1324"><span class="lineNum">    1324 </span>            :          * Don't bother checking unless a grace period has</a>
<a name="1325"><span class="lineNum">    1325 </span>            :          * completed since we last checked and there are</a>
<a name="1326"><span class="lineNum">    1326 </span>            :          * callbacks not yet ready to invoke.</a>
<a name="1327"><span class="lineNum">    1327 </span>            :          */</a>
<a name="1328"><span class="lineNum">    1328 </span>            :         if ((rcu_seq_completed_gp(rdp-&gt;gp_seq,</a>
<a name="1329"><span class="lineNum">    1329 </span>            :                                   rcu_seq_current(&amp;rnp-&gt;gp_seq)) ||</a>
<a name="1330"><span class="lineNum">    1330 </span>            :              unlikely(READ_ONCE(rdp-&gt;gpwrap))) &amp;&amp;</a>
<a name="1331"><span class="lineNum">    1331 </span>            :             rcu_segcblist_pend_cbs(&amp;rdp-&gt;cblist))</a>
<a name="1332"><span class="lineNum">    1332 </span>            :                 note_gp_changes(rdp);</a>
<a name="1333"><span class="lineNum">    1333 </span>            : </a>
<a name="1334"><span class="lineNum">    1334 </span>            :         if (rcu_segcblist_ready_cbs(&amp;rdp-&gt;cblist))</a>
<a name="1335"><span class="lineNum">    1335 </span>            :                 cbs_ready = true;</a>
<a name="1336"><span class="lineNum">    1336 </span>            :         return cbs_ready;</a>
<a name="1337"><span class="lineNum">    1337 </span>            : }</a>
<a name="1338"><span class="lineNum">    1338 </span>            : </a>
<a name="1339"><span class="lineNum">    1339 </span>            : /*</a>
<a name="1340"><span class="lineNum">    1340 </span>            :  * Allow the CPU to enter dyntick-idle mode unless it has callbacks ready</a>
<a name="1341"><span class="lineNum">    1341 </span>            :  * to invoke.  If the CPU has callbacks, try to advance them.  Tell the</a>
<a name="1342"><span class="lineNum">    1342 </span>            :  * caller about what to set the timeout.</a>
<a name="1343"><span class="lineNum">    1343 </span>            :  *</a>
<a name="1344"><span class="lineNum">    1344 </span>            :  * The caller must have disabled interrupts.</a>
<a name="1345"><span class="lineNum">    1345 </span>            :  */</a>
<a name="1346"><span class="lineNum">    1346 </span>            : int rcu_needs_cpu(u64 basemono, u64 *nextevt)</a>
<a name="1347"><span class="lineNum">    1347 </span>            : {</a>
<a name="1348"><span class="lineNum">    1348 </span>            :         struct rcu_data *rdp = this_cpu_ptr(&amp;rcu_data);</a>
<a name="1349"><span class="lineNum">    1349 </span>            :         unsigned long dj;</a>
<a name="1350"><span class="lineNum">    1350 </span>            : </a>
<a name="1351"><span class="lineNum">    1351 </span>            :         lockdep_assert_irqs_disabled();</a>
<a name="1352"><span class="lineNum">    1352 </span>            : </a>
<a name="1353"><span class="lineNum">    1353 </span>            :         /* If no non-offloaded callbacks, RCU doesn't need the CPU. */</a>
<a name="1354"><span class="lineNum">    1354 </span>            :         if (rcu_segcblist_empty(&amp;rdp-&gt;cblist) ||</a>
<a name="1355"><span class="lineNum">    1355 </span>            :             rcu_segcblist_is_offloaded(&amp;this_cpu_ptr(&amp;rcu_data)-&gt;cblist)) {</a>
<a name="1356"><span class="lineNum">    1356 </span>            :                 *nextevt = KTIME_MAX;</a>
<a name="1357"><span class="lineNum">    1357 </span>            :                 return 0;</a>
<a name="1358"><span class="lineNum">    1358 </span>            :         }</a>
<a name="1359"><span class="lineNum">    1359 </span>            : </a>
<a name="1360"><span class="lineNum">    1360 </span>            :         /* Attempt to advance callbacks. */</a>
<a name="1361"><span class="lineNum">    1361 </span>            :         if (rcu_try_advance_all_cbs()) {</a>
<a name="1362"><span class="lineNum">    1362 </span>            :                 /* Some ready to invoke, so initiate later invocation. */</a>
<a name="1363"><span class="lineNum">    1363 </span>            :                 invoke_rcu_core();</a>
<a name="1364"><span class="lineNum">    1364 </span>            :                 return 1;</a>
<a name="1365"><span class="lineNum">    1365 </span>            :         }</a>
<a name="1366"><span class="lineNum">    1366 </span>            :         rdp-&gt;last_accelerate = jiffies;</a>
<a name="1367"><span class="lineNum">    1367 </span>            : </a>
<a name="1368"><span class="lineNum">    1368 </span>            :         /* Request timer and round. */</a>
<a name="1369"><span class="lineNum">    1369 </span>            :         dj = round_up(rcu_idle_gp_delay + jiffies, rcu_idle_gp_delay) - jiffies;</a>
<a name="1370"><span class="lineNum">    1370 </span>            : </a>
<a name="1371"><span class="lineNum">    1371 </span>            :         *nextevt = basemono + dj * TICK_NSEC;</a>
<a name="1372"><span class="lineNum">    1372 </span>            :         return 0;</a>
<a name="1373"><span class="lineNum">    1373 </span>            : }</a>
<a name="1374"><span class="lineNum">    1374 </span>            : </a>
<a name="1375"><span class="lineNum">    1375 </span>            : /*</a>
<a name="1376"><span class="lineNum">    1376 </span>            :  * Prepare a CPU for idle from an RCU perspective.  The first major task is to</a>
<a name="1377"><span class="lineNum">    1377 </span>            :  * sense whether nohz mode has been enabled or disabled via sysfs.  The second</a>
<a name="1378"><span class="lineNum">    1378 </span>            :  * major task is to accelerate (that is, assign grace-period numbers to) any</a>
<a name="1379"><span class="lineNum">    1379 </span>            :  * recently arrived callbacks.</a>
<a name="1380"><span class="lineNum">    1380 </span>            :  *</a>
<a name="1381"><span class="lineNum">    1381 </span>            :  * The caller must have disabled interrupts.</a>
<a name="1382"><span class="lineNum">    1382 </span>            :  */</a>
<a name="1383"><span class="lineNum">    1383 </span>            : static void rcu_prepare_for_idle(void)</a>
<a name="1384"><span class="lineNum">    1384 </span>            : {</a>
<a name="1385"><span class="lineNum">    1385 </span>            :         bool needwake;</a>
<a name="1386"><span class="lineNum">    1386 </span>            :         struct rcu_data *rdp = this_cpu_ptr(&amp;rcu_data);</a>
<a name="1387"><span class="lineNum">    1387 </span>            :         struct rcu_node *rnp;</a>
<a name="1388"><span class="lineNum">    1388 </span>            :         int tne;</a>
<a name="1389"><span class="lineNum">    1389 </span>            : </a>
<a name="1390"><span class="lineNum">    1390 </span>            :         lockdep_assert_irqs_disabled();</a>
<a name="1391"><span class="lineNum">    1391 </span>            :         if (rcu_segcblist_is_offloaded(&amp;rdp-&gt;cblist))</a>
<a name="1392"><span class="lineNum">    1392 </span>            :                 return;</a>
<a name="1393"><span class="lineNum">    1393 </span>            : </a>
<a name="1394"><span class="lineNum">    1394 </span>            :         /* Handle nohz enablement switches conservatively. */</a>
<a name="1395"><span class="lineNum">    1395 </span>            :         tne = READ_ONCE(tick_nohz_active);</a>
<a name="1396"><span class="lineNum">    1396 </span>            :         if (tne != rdp-&gt;tick_nohz_enabled_snap) {</a>
<a name="1397"><span class="lineNum">    1397 </span>            :                 if (!rcu_segcblist_empty(&amp;rdp-&gt;cblist))</a>
<a name="1398"><span class="lineNum">    1398 </span>            :                         invoke_rcu_core(); /* force nohz to see update. */</a>
<a name="1399"><span class="lineNum">    1399 </span>            :                 rdp-&gt;tick_nohz_enabled_snap = tne;</a>
<a name="1400"><span class="lineNum">    1400 </span>            :                 return;</a>
<a name="1401"><span class="lineNum">    1401 </span>            :         }</a>
<a name="1402"><span class="lineNum">    1402 </span>            :         if (!tne)</a>
<a name="1403"><span class="lineNum">    1403 </span>            :                 return;</a>
<a name="1404"><span class="lineNum">    1404 </span>            : </a>
<a name="1405"><span class="lineNum">    1405 </span>            :         /*</a>
<a name="1406"><span class="lineNum">    1406 </span>            :          * If we have not yet accelerated this jiffy, accelerate all</a>
<a name="1407"><span class="lineNum">    1407 </span>            :          * callbacks on this CPU.</a>
<a name="1408"><span class="lineNum">    1408 </span>            :          */</a>
<a name="1409"><span class="lineNum">    1409 </span>            :         if (rdp-&gt;last_accelerate == jiffies)</a>
<a name="1410"><span class="lineNum">    1410 </span>            :                 return;</a>
<a name="1411"><span class="lineNum">    1411 </span>            :         rdp-&gt;last_accelerate = jiffies;</a>
<a name="1412"><span class="lineNum">    1412 </span>            :         if (rcu_segcblist_pend_cbs(&amp;rdp-&gt;cblist)) {</a>
<a name="1413"><span class="lineNum">    1413 </span>            :                 rnp = rdp-&gt;mynode;</a>
<a name="1414"><span class="lineNum">    1414 </span>            :                 raw_spin_lock_rcu_node(rnp); /* irqs already disabled. */</a>
<a name="1415"><span class="lineNum">    1415 </span>            :                 needwake = rcu_accelerate_cbs(rnp, rdp);</a>
<a name="1416"><span class="lineNum">    1416 </span>            :                 raw_spin_unlock_rcu_node(rnp); /* irqs remain disabled. */</a>
<a name="1417"><span class="lineNum">    1417 </span>            :                 if (needwake)</a>
<a name="1418"><span class="lineNum">    1418 </span>            :                         rcu_gp_kthread_wake();</a>
<a name="1419"><span class="lineNum">    1419 </span>            :         }</a>
<a name="1420"><span class="lineNum">    1420 </span>            : }</a>
<a name="1421"><span class="lineNum">    1421 </span>            : </a>
<a name="1422"><span class="lineNum">    1422 </span>            : /*</a>
<a name="1423"><span class="lineNum">    1423 </span>            :  * Clean up for exit from idle.  Attempt to advance callbacks based on</a>
<a name="1424"><span class="lineNum">    1424 </span>            :  * any grace periods that elapsed while the CPU was idle, and if any</a>
<a name="1425"><span class="lineNum">    1425 </span>            :  * callbacks are now ready to invoke, initiate invocation.</a>
<a name="1426"><span class="lineNum">    1426 </span>            :  */</a>
<a name="1427"><span class="lineNum">    1427 </span>            : static void rcu_cleanup_after_idle(void)</a>
<a name="1428"><span class="lineNum">    1428 </span>            : {</a>
<a name="1429"><span class="lineNum">    1429 </span>            :         struct rcu_data *rdp = this_cpu_ptr(&amp;rcu_data);</a>
<a name="1430"><span class="lineNum">    1430 </span>            : </a>
<a name="1431"><span class="lineNum">    1431 </span>            :         lockdep_assert_irqs_disabled();</a>
<a name="1432"><span class="lineNum">    1432 </span>            :         if (rcu_segcblist_is_offloaded(&amp;rdp-&gt;cblist))</a>
<a name="1433"><span class="lineNum">    1433 </span>            :                 return;</a>
<a name="1434"><span class="lineNum">    1434 </span>            :         if (rcu_try_advance_all_cbs())</a>
<a name="1435"><span class="lineNum">    1435 </span>            :                 invoke_rcu_core();</a>
<a name="1436"><span class="lineNum">    1436 </span>            : }</a>
<a name="1437"><span class="lineNum">    1437 </span>            : </a>
<a name="1438"><span class="lineNum">    1438 </span>            : #endif /* #else #if !defined(CONFIG_RCU_FAST_NO_HZ) */</a>
<a name="1439"><span class="lineNum">    1439 </span>            : </a>
<a name="1440"><span class="lineNum">    1440 </span>            : #ifdef CONFIG_RCU_NOCB_CPU</a>
<a name="1441"><span class="lineNum">    1441 </span>            : </a>
<a name="1442"><span class="lineNum">    1442 </span>            : /*</a>
<a name="1443"><span class="lineNum">    1443 </span>            :  * Offload callback processing from the boot-time-specified set of CPUs</a>
<a name="1444"><span class="lineNum">    1444 </span>            :  * specified by rcu_nocb_mask.  For the CPUs in the set, there are kthreads</a>
<a name="1445"><span class="lineNum">    1445 </span>            :  * created that pull the callbacks from the corresponding CPU, wait for</a>
<a name="1446"><span class="lineNum">    1446 </span>            :  * a grace period to elapse, and invoke the callbacks.  These kthreads</a>
<a name="1447"><span class="lineNum">    1447 </span>            :  * are organized into GP kthreads, which manage incoming callbacks, wait for</a>
<a name="1448"><span class="lineNum">    1448 </span>            :  * grace periods, and awaken CB kthreads, and the CB kthreads, which only</a>
<a name="1449"><span class="lineNum">    1449 </span>            :  * invoke callbacks.  Each GP kthread invokes its own CBs.  The no-CBs CPUs</a>
<a name="1450"><span class="lineNum">    1450 </span>            :  * do a wake_up() on their GP kthread when they insert a callback into any</a>
<a name="1451"><span class="lineNum">    1451 </span>            :  * empty list, unless the rcu_nocb_poll boot parameter has been specified,</a>
<a name="1452"><span class="lineNum">    1452 </span>            :  * in which case each kthread actively polls its CPU.  (Which isn't so great</a>
<a name="1453"><span class="lineNum">    1453 </span>            :  * for energy efficiency, but which does reduce RCU's overhead on that CPU.)</a>
<a name="1454"><span class="lineNum">    1454 </span>            :  *</a>
<a name="1455"><span class="lineNum">    1455 </span>            :  * This is intended to be used in conjunction with Frederic Weisbecker's</a>
<a name="1456"><span class="lineNum">    1456 </span>            :  * adaptive-idle work, which would seriously reduce OS jitter on CPUs</a>
<a name="1457"><span class="lineNum">    1457 </span>            :  * running CPU-bound user-mode computations.</a>
<a name="1458"><span class="lineNum">    1458 </span>            :  *</a>
<a name="1459"><span class="lineNum">    1459 </span>            :  * Offloading of callbacks can also be used as an energy-efficiency</a>
<a name="1460"><span class="lineNum">    1460 </span>            :  * measure because CPUs with no RCU callbacks queued are more aggressive</a>
<a name="1461"><span class="lineNum">    1461 </span>            :  * about entering dyntick-idle mode.</a>
<a name="1462"><span class="lineNum">    1462 </span>            :  */</a>
<a name="1463"><span class="lineNum">    1463 </span>            : </a>
<a name="1464"><span class="lineNum">    1464 </span>            : </a>
<a name="1465"><span class="lineNum">    1465 </span>            : /*</a>
<a name="1466"><span class="lineNum">    1466 </span>            :  * Parse the boot-time rcu_nocb_mask CPU list from the kernel parameters.</a>
<a name="1467"><span class="lineNum">    1467 </span>            :  * The string after the &quot;rcu_nocbs=&quot; is either &quot;all&quot; for all CPUs, or a</a>
<a name="1468"><span class="lineNum">    1468 </span>            :  * comma-separated list of CPUs and/or CPU ranges.  If an invalid list is</a>
<a name="1469"><span class="lineNum">    1469 </span>            :  * given, a warning is emitted and all CPUs are offloaded.</a>
<a name="1470"><span class="lineNum">    1470 </span>            :  */</a>
<a name="1471"><span class="lineNum">    1471 </span>            : static int __init rcu_nocb_setup(char *str)</a>
<a name="1472"><span class="lineNum">    1472 </span>            : {</a>
<a name="1473"><span class="lineNum">    1473 </span>            :         alloc_bootmem_cpumask_var(&amp;rcu_nocb_mask);</a>
<a name="1474"><span class="lineNum">    1474 </span>            :         if (!strcasecmp(str, &quot;all&quot;))</a>
<a name="1475"><span class="lineNum">    1475 </span>            :                 cpumask_setall(rcu_nocb_mask);</a>
<a name="1476"><span class="lineNum">    1476 </span>            :         else</a>
<a name="1477"><span class="lineNum">    1477 </span>            :                 if (cpulist_parse(str, rcu_nocb_mask)) {</a>
<a name="1478"><span class="lineNum">    1478 </span>            :                         pr_warn(&quot;rcu_nocbs= bad CPU range, all CPUs set\n&quot;);</a>
<a name="1479"><span class="lineNum">    1479 </span>            :                         cpumask_setall(rcu_nocb_mask);</a>
<a name="1480"><span class="lineNum">    1480 </span>            :                 }</a>
<a name="1481"><span class="lineNum">    1481 </span>            :         return 1;</a>
<a name="1482"><span class="lineNum">    1482 </span>            : }</a>
<a name="1483"><span class="lineNum">    1483 </span>            : __setup(&quot;rcu_nocbs=&quot;, rcu_nocb_setup);</a>
<a name="1484"><span class="lineNum">    1484 </span>            : </a>
<a name="1485"><span class="lineNum">    1485 </span>            : static int __init parse_rcu_nocb_poll(char *arg)</a>
<a name="1486"><span class="lineNum">    1486 </span>            : {</a>
<a name="1487"><span class="lineNum">    1487 </span>            :         rcu_nocb_poll = true;</a>
<a name="1488"><span class="lineNum">    1488 </span>            :         return 0;</a>
<a name="1489"><span class="lineNum">    1489 </span>            : }</a>
<a name="1490"><span class="lineNum">    1490 </span>            : early_param(&quot;rcu_nocb_poll&quot;, parse_rcu_nocb_poll);</a>
<a name="1491"><span class="lineNum">    1491 </span>            : </a>
<a name="1492"><span class="lineNum">    1492 </span>            : /*</a>
<a name="1493"><span class="lineNum">    1493 </span>            :  * Don't bother bypassing -&gt;cblist if the call_rcu() rate is low.</a>
<a name="1494"><span class="lineNum">    1494 </span>            :  * After all, the main point of bypassing is to avoid lock contention</a>
<a name="1495"><span class="lineNum">    1495 </span>            :  * on -&gt;nocb_lock, which only can happen at high call_rcu() rates.</a>
<a name="1496"><span class="lineNum">    1496 </span>            :  */</a>
<a name="1497"><span class="lineNum">    1497 </span>            : int nocb_nobypass_lim_per_jiffy = 16 * 1000 / HZ;</a>
<a name="1498"><span class="lineNum">    1498 </span>            : module_param(nocb_nobypass_lim_per_jiffy, int, 0);</a>
<a name="1499"><span class="lineNum">    1499 </span>            : </a>
<a name="1500"><span class="lineNum">    1500 </span>            : /*</a>
<a name="1501"><span class="lineNum">    1501 </span>            :  * Acquire the specified rcu_data structure's -&gt;nocb_bypass_lock.  If the</a>
<a name="1502"><span class="lineNum">    1502 </span>            :  * lock isn't immediately available, increment -&gt;nocb_lock_contended to</a>
<a name="1503"><span class="lineNum">    1503 </span>            :  * flag the contention.</a>
<a name="1504"><span class="lineNum">    1504 </span>            :  */</a>
<a name="1505"><span class="lineNum">    1505 </span>            : static void rcu_nocb_bypass_lock(struct rcu_data *rdp)</a>
<a name="1506"><span class="lineNum">    1506 </span>            :         __acquires(&amp;rdp-&gt;nocb_bypass_lock)</a>
<a name="1507"><span class="lineNum">    1507 </span>            : {</a>
<a name="1508"><span class="lineNum">    1508 </span>            :         lockdep_assert_irqs_disabled();</a>
<a name="1509"><span class="lineNum">    1509 </span>            :         if (raw_spin_trylock(&amp;rdp-&gt;nocb_bypass_lock))</a>
<a name="1510"><span class="lineNum">    1510 </span>            :                 return;</a>
<a name="1511"><span class="lineNum">    1511 </span>            :         atomic_inc(&amp;rdp-&gt;nocb_lock_contended);</a>
<a name="1512"><span class="lineNum">    1512 </span>            :         WARN_ON_ONCE(smp_processor_id() != rdp-&gt;cpu);</a>
<a name="1513"><span class="lineNum">    1513 </span>            :         smp_mb__after_atomic(); /* atomic_inc() before lock. */</a>
<a name="1514"><span class="lineNum">    1514 </span>            :         raw_spin_lock(&amp;rdp-&gt;nocb_bypass_lock);</a>
<a name="1515"><span class="lineNum">    1515 </span>            :         smp_mb__before_atomic(); /* atomic_dec() after lock. */</a>
<a name="1516"><span class="lineNum">    1516 </span>            :         atomic_dec(&amp;rdp-&gt;nocb_lock_contended);</a>
<a name="1517"><span class="lineNum">    1517 </span>            : }</a>
<a name="1518"><span class="lineNum">    1518 </span>            : </a>
<a name="1519"><span class="lineNum">    1519 </span>            : /*</a>
<a name="1520"><span class="lineNum">    1520 </span>            :  * Spinwait until the specified rcu_data structure's -&gt;nocb_lock is</a>
<a name="1521"><span class="lineNum">    1521 </span>            :  * not contended.  Please note that this is extremely special-purpose,</a>
<a name="1522"><span class="lineNum">    1522 </span>            :  * relying on the fact that at most two kthreads and one CPU contend for</a>
<a name="1523"><span class="lineNum">    1523 </span>            :  * this lock, and also that the two kthreads are guaranteed to have frequent</a>
<a name="1524"><span class="lineNum">    1524 </span>            :  * grace-period-duration time intervals between successive acquisitions</a>
<a name="1525"><span class="lineNum">    1525 </span>            :  * of the lock.  This allows us to use an extremely simple throttling</a>
<a name="1526"><span class="lineNum">    1526 </span>            :  * mechanism, and further to apply it only to the CPU doing floods of</a>
<a name="1527"><span class="lineNum">    1527 </span>            :  * call_rcu() invocations.  Don't try this at home!</a>
<a name="1528"><span class="lineNum">    1528 </span>            :  */</a>
<a name="1529"><span class="lineNum">    1529 </span>            : static void rcu_nocb_wait_contended(struct rcu_data *rdp)</a>
<a name="1530"><span class="lineNum">    1530 </span>            : {</a>
<a name="1531"><span class="lineNum">    1531 </span>            :         WARN_ON_ONCE(smp_processor_id() != rdp-&gt;cpu);</a>
<a name="1532"><span class="lineNum">    1532 </span>            :         while (WARN_ON_ONCE(atomic_read(&amp;rdp-&gt;nocb_lock_contended)))</a>
<a name="1533"><span class="lineNum">    1533 </span>            :                 cpu_relax();</a>
<a name="1534"><span class="lineNum">    1534 </span>            : }</a>
<a name="1535"><span class="lineNum">    1535 </span>            : </a>
<a name="1536"><span class="lineNum">    1536 </span>            : /*</a>
<a name="1537"><span class="lineNum">    1537 </span>            :  * Conditionally acquire the specified rcu_data structure's</a>
<a name="1538"><span class="lineNum">    1538 </span>            :  * -&gt;nocb_bypass_lock.</a>
<a name="1539"><span class="lineNum">    1539 </span>            :  */</a>
<a name="1540"><span class="lineNum">    1540 </span>            : static bool rcu_nocb_bypass_trylock(struct rcu_data *rdp)</a>
<a name="1541"><span class="lineNum">    1541 </span>            : {</a>
<a name="1542"><span class="lineNum">    1542 </span>            :         lockdep_assert_irqs_disabled();</a>
<a name="1543"><span class="lineNum">    1543 </span>            :         return raw_spin_trylock(&amp;rdp-&gt;nocb_bypass_lock);</a>
<a name="1544"><span class="lineNum">    1544 </span>            : }</a>
<a name="1545"><span class="lineNum">    1545 </span>            : </a>
<a name="1546"><span class="lineNum">    1546 </span>            : /*</a>
<a name="1547"><span class="lineNum">    1547 </span>            :  * Release the specified rcu_data structure's -&gt;nocb_bypass_lock.</a>
<a name="1548"><span class="lineNum">    1548 </span>            :  */</a>
<a name="1549"><span class="lineNum">    1549 </span>            : static void rcu_nocb_bypass_unlock(struct rcu_data *rdp)</a>
<a name="1550"><span class="lineNum">    1550 </span>            :         __releases(&amp;rdp-&gt;nocb_bypass_lock)</a>
<a name="1551"><span class="lineNum">    1551 </span>            : {</a>
<a name="1552"><span class="lineNum">    1552 </span>            :         lockdep_assert_irqs_disabled();</a>
<a name="1553"><span class="lineNum">    1553 </span>            :         raw_spin_unlock(&amp;rdp-&gt;nocb_bypass_lock);</a>
<a name="1554"><span class="lineNum">    1554 </span>            : }</a>
<a name="1555"><span class="lineNum">    1555 </span>            : </a>
<a name="1556"><span class="lineNum">    1556 </span>            : /*</a>
<a name="1557"><span class="lineNum">    1557 </span>            :  * Acquire the specified rcu_data structure's -&gt;nocb_lock, but only</a>
<a name="1558"><span class="lineNum">    1558 </span>            :  * if it corresponds to a no-CBs CPU.</a>
<a name="1559"><span class="lineNum">    1559 </span>            :  */</a>
<a name="1560"><span class="lineNum">    1560 </span>            : static void rcu_nocb_lock(struct rcu_data *rdp)</a>
<a name="1561"><span class="lineNum">    1561 </span>            : {</a>
<a name="1562"><span class="lineNum">    1562 </span>            :         lockdep_assert_irqs_disabled();</a>
<a name="1563"><span class="lineNum">    1563 </span>            :         if (!rcu_segcblist_is_offloaded(&amp;rdp-&gt;cblist))</a>
<a name="1564"><span class="lineNum">    1564 </span>            :                 return;</a>
<a name="1565"><span class="lineNum">    1565 </span>            :         raw_spin_lock(&amp;rdp-&gt;nocb_lock);</a>
<a name="1566"><span class="lineNum">    1566 </span>            : }</a>
<a name="1567"><span class="lineNum">    1567 </span>            : </a>
<a name="1568"><span class="lineNum">    1568 </span>            : /*</a>
<a name="1569"><span class="lineNum">    1569 </span>            :  * Release the specified rcu_data structure's -&gt;nocb_lock, but only</a>
<a name="1570"><span class="lineNum">    1570 </span>            :  * if it corresponds to a no-CBs CPU.</a>
<a name="1571"><span class="lineNum">    1571 </span>            :  */</a>
<a name="1572"><span class="lineNum">    1572 </span>            : static void rcu_nocb_unlock(struct rcu_data *rdp)</a>
<a name="1573"><span class="lineNum">    1573 </span>            : {</a>
<a name="1574"><span class="lineNum">    1574 </span>            :         if (rcu_segcblist_is_offloaded(&amp;rdp-&gt;cblist)) {</a>
<a name="1575"><span class="lineNum">    1575 </span>            :                 lockdep_assert_irqs_disabled();</a>
<a name="1576"><span class="lineNum">    1576 </span>            :                 raw_spin_unlock(&amp;rdp-&gt;nocb_lock);</a>
<a name="1577"><span class="lineNum">    1577 </span>            :         }</a>
<a name="1578"><span class="lineNum">    1578 </span>            : }</a>
<a name="1579"><span class="lineNum">    1579 </span>            : </a>
<a name="1580"><span class="lineNum">    1580 </span>            : /*</a>
<a name="1581"><span class="lineNum">    1581 </span>            :  * Release the specified rcu_data structure's -&gt;nocb_lock and restore</a>
<a name="1582"><span class="lineNum">    1582 </span>            :  * interrupts, but only if it corresponds to a no-CBs CPU.</a>
<a name="1583"><span class="lineNum">    1583 </span>            :  */</a>
<a name="1584"><span class="lineNum">    1584 </span>            : static void rcu_nocb_unlock_irqrestore(struct rcu_data *rdp,</a>
<a name="1585"><span class="lineNum">    1585 </span>            :                                        unsigned long flags)</a>
<a name="1586"><span class="lineNum">    1586 </span>            : {</a>
<a name="1587"><span class="lineNum">    1587 </span>            :         if (rcu_segcblist_is_offloaded(&amp;rdp-&gt;cblist)) {</a>
<a name="1588"><span class="lineNum">    1588 </span>            :                 lockdep_assert_irqs_disabled();</a>
<a name="1589"><span class="lineNum">    1589 </span>            :                 raw_spin_unlock_irqrestore(&amp;rdp-&gt;nocb_lock, flags);</a>
<a name="1590"><span class="lineNum">    1590 </span>            :         } else {</a>
<a name="1591"><span class="lineNum">    1591 </span>            :                 local_irq_restore(flags);</a>
<a name="1592"><span class="lineNum">    1592 </span>            :         }</a>
<a name="1593"><span class="lineNum">    1593 </span>            : }</a>
<a name="1594"><span class="lineNum">    1594 </span>            : </a>
<a name="1595"><span class="lineNum">    1595 </span>            : /* Lockdep check that -&gt;cblist may be safely accessed. */</a>
<a name="1596"><span class="lineNum">    1596 </span>            : static void rcu_lockdep_assert_cblist_protected(struct rcu_data *rdp)</a>
<a name="1597"><span class="lineNum">    1597 </span>            : {</a>
<a name="1598"><span class="lineNum">    1598 </span>            :         lockdep_assert_irqs_disabled();</a>
<a name="1599"><span class="lineNum">    1599 </span>            :         if (rcu_segcblist_is_offloaded(&amp;rdp-&gt;cblist))</a>
<a name="1600"><span class="lineNum">    1600 </span>            :                 lockdep_assert_held(&amp;rdp-&gt;nocb_lock);</a>
<a name="1601"><span class="lineNum">    1601 </span>            : }</a>
<a name="1602"><span class="lineNum">    1602 </span>            : </a>
<a name="1603"><span class="lineNum">    1603 </span>            : /*</a>
<a name="1604"><span class="lineNum">    1604 </span>            :  * Wake up any no-CBs CPUs' kthreads that were waiting on the just-ended</a>
<a name="1605"><span class="lineNum">    1605 </span>            :  * grace period.</a>
<a name="1606"><span class="lineNum">    1606 </span>            :  */</a>
<a name="1607"><span class="lineNum">    1607 </span>            : static void rcu_nocb_gp_cleanup(struct swait_queue_head *sq)</a>
<a name="1608"><span class="lineNum">    1608 </span>            : {</a>
<a name="1609"><span class="lineNum">    1609 </span>            :         swake_up_all(sq);</a>
<a name="1610"><span class="lineNum">    1610 </span>            : }</a>
<a name="1611"><span class="lineNum">    1611 </span>            : </a>
<a name="1612"><span class="lineNum">    1612 </span>            : static struct swait_queue_head *rcu_nocb_gp_get(struct rcu_node *rnp)</a>
<a name="1613"><span class="lineNum">    1613 </span>            : {</a>
<a name="1614"><span class="lineNum">    1614 </span>            :         return &amp;rnp-&gt;nocb_gp_wq[rcu_seq_ctr(rnp-&gt;gp_seq) &amp; 0x1];</a>
<a name="1615"><span class="lineNum">    1615 </span>            : }</a>
<a name="1616"><span class="lineNum">    1616 </span>            : </a>
<a name="1617"><span class="lineNum">    1617 </span>            : static void rcu_init_one_nocb(struct rcu_node *rnp)</a>
<a name="1618"><span class="lineNum">    1618 </span>            : {</a>
<a name="1619"><span class="lineNum">    1619 </span>            :         init_swait_queue_head(&amp;rnp-&gt;nocb_gp_wq[0]);</a>
<a name="1620"><span class="lineNum">    1620 </span>            :         init_swait_queue_head(&amp;rnp-&gt;nocb_gp_wq[1]);</a>
<a name="1621"><span class="lineNum">    1621 </span>            : }</a>
<a name="1622"><span class="lineNum">    1622 </span>            : </a>
<a name="1623"><span class="lineNum">    1623 </span>            : /* Is the specified CPU a no-CBs CPU? */</a>
<a name="1624"><span class="lineNum">    1624 </span>            : bool rcu_is_nocb_cpu(int cpu)</a>
<a name="1625"><span class="lineNum">    1625 </span>            : {</a>
<a name="1626"><span class="lineNum">    1626 </span>            :         if (cpumask_available(rcu_nocb_mask))</a>
<a name="1627"><span class="lineNum">    1627 </span>            :                 return cpumask_test_cpu(cpu, rcu_nocb_mask);</a>
<a name="1628"><span class="lineNum">    1628 </span>            :         return false;</a>
<a name="1629"><span class="lineNum">    1629 </span>            : }</a>
<a name="1630"><span class="lineNum">    1630 </span>            : </a>
<a name="1631"><span class="lineNum">    1631 </span>            : /*</a>
<a name="1632"><span class="lineNum">    1632 </span>            :  * Kick the GP kthread for this NOCB group.  Caller holds -&gt;nocb_lock</a>
<a name="1633"><span class="lineNum">    1633 </span>            :  * and this function releases it.</a>
<a name="1634"><span class="lineNum">    1634 </span>            :  */</a>
<a name="1635"><span class="lineNum">    1635 </span>            : static bool wake_nocb_gp(struct rcu_data *rdp, bool force,</a>
<a name="1636"><span class="lineNum">    1636 </span>            :                          unsigned long flags)</a>
<a name="1637"><span class="lineNum">    1637 </span>            :         __releases(rdp-&gt;nocb_lock)</a>
<a name="1638"><span class="lineNum">    1638 </span>            : {</a>
<a name="1639"><span class="lineNum">    1639 </span>            :         bool needwake = false;</a>
<a name="1640"><span class="lineNum">    1640 </span>            :         struct rcu_data *rdp_gp = rdp-&gt;nocb_gp_rdp;</a>
<a name="1641"><span class="lineNum">    1641 </span>            : </a>
<a name="1642"><span class="lineNum">    1642 </span>            :         lockdep_assert_held(&amp;rdp-&gt;nocb_lock);</a>
<a name="1643"><span class="lineNum">    1643 </span>            :         if (!READ_ONCE(rdp_gp-&gt;nocb_gp_kthread)) {</a>
<a name="1644"><span class="lineNum">    1644 </span>            :                 trace_rcu_nocb_wake(rcu_state.name, rdp-&gt;cpu,</a>
<a name="1645"><span class="lineNum">    1645 </span>            :                                     TPS(&quot;AlreadyAwake&quot;));</a>
<a name="1646"><span class="lineNum">    1646 </span>            :                 rcu_nocb_unlock_irqrestore(rdp, flags);</a>
<a name="1647"><span class="lineNum">    1647 </span>            :                 return false;</a>
<a name="1648"><span class="lineNum">    1648 </span>            :         }</a>
<a name="1649"><span class="lineNum">    1649 </span>            :         del_timer(&amp;rdp-&gt;nocb_timer);</a>
<a name="1650"><span class="lineNum">    1650 </span>            :         rcu_nocb_unlock_irqrestore(rdp, flags);</a>
<a name="1651"><span class="lineNum">    1651 </span>            :         raw_spin_lock_irqsave(&amp;rdp_gp-&gt;nocb_gp_lock, flags);</a>
<a name="1652"><span class="lineNum">    1652 </span>            :         if (force || READ_ONCE(rdp_gp-&gt;nocb_gp_sleep)) {</a>
<a name="1653"><span class="lineNum">    1653 </span>            :                 WRITE_ONCE(rdp_gp-&gt;nocb_gp_sleep, false);</a>
<a name="1654"><span class="lineNum">    1654 </span>            :                 needwake = true;</a>
<a name="1655"><span class="lineNum">    1655 </span>            :                 trace_rcu_nocb_wake(rcu_state.name, rdp-&gt;cpu, TPS(&quot;DoWake&quot;));</a>
<a name="1656"><span class="lineNum">    1656 </span>            :         }</a>
<a name="1657"><span class="lineNum">    1657 </span>            :         raw_spin_unlock_irqrestore(&amp;rdp_gp-&gt;nocb_gp_lock, flags);</a>
<a name="1658"><span class="lineNum">    1658 </span>            :         if (needwake)</a>
<a name="1659"><span class="lineNum">    1659 </span>            :                 wake_up_process(rdp_gp-&gt;nocb_gp_kthread);</a>
<a name="1660"><span class="lineNum">    1660 </span>            : </a>
<a name="1661"><span class="lineNum">    1661 </span>            :         return needwake;</a>
<a name="1662"><span class="lineNum">    1662 </span>            : }</a>
<a name="1663"><span class="lineNum">    1663 </span>            : </a>
<a name="1664"><span class="lineNum">    1664 </span>            : /*</a>
<a name="1665"><span class="lineNum">    1665 </span>            :  * Arrange to wake the GP kthread for this NOCB group at some future</a>
<a name="1666"><span class="lineNum">    1666 </span>            :  * time when it is safe to do so.</a>
<a name="1667"><span class="lineNum">    1667 </span>            :  */</a>
<a name="1668"><span class="lineNum">    1668 </span>            : static void wake_nocb_gp_defer(struct rcu_data *rdp, int waketype,</a>
<a name="1669"><span class="lineNum">    1669 </span>            :                                const char *reason)</a>
<a name="1670"><span class="lineNum">    1670 </span>            : {</a>
<a name="1671"><span class="lineNum">    1671 </span>            :         if (rdp-&gt;nocb_defer_wakeup == RCU_NOCB_WAKE_OFF)</a>
<a name="1672"><span class="lineNum">    1672 </span>            :                 return;</a>
<a name="1673"><span class="lineNum">    1673 </span>            :         if (rdp-&gt;nocb_defer_wakeup == RCU_NOCB_WAKE_NOT)</a>
<a name="1674"><span class="lineNum">    1674 </span>            :                 mod_timer(&amp;rdp-&gt;nocb_timer, jiffies + 1);</a>
<a name="1675"><span class="lineNum">    1675 </span>            :         if (rdp-&gt;nocb_defer_wakeup &lt; waketype)</a>
<a name="1676"><span class="lineNum">    1676 </span>            :                 WRITE_ONCE(rdp-&gt;nocb_defer_wakeup, waketype);</a>
<a name="1677"><span class="lineNum">    1677 </span>            :         trace_rcu_nocb_wake(rcu_state.name, rdp-&gt;cpu, reason);</a>
<a name="1678"><span class="lineNum">    1678 </span>            : }</a>
<a name="1679"><span class="lineNum">    1679 </span>            : </a>
<a name="1680"><span class="lineNum">    1680 </span>            : /*</a>
<a name="1681"><span class="lineNum">    1681 </span>            :  * Flush the -&gt;nocb_bypass queue into -&gt;cblist, enqueuing rhp if non-NULL.</a>
<a name="1682"><span class="lineNum">    1682 </span>            :  * However, if there is a callback to be enqueued and if -&gt;nocb_bypass</a>
<a name="1683"><span class="lineNum">    1683 </span>            :  * proves to be initially empty, just return false because the no-CB GP</a>
<a name="1684"><span class="lineNum">    1684 </span>            :  * kthread may need to be awakened in this case.</a>
<a name="1685"><span class="lineNum">    1685 </span>            :  *</a>
<a name="1686"><span class="lineNum">    1686 </span>            :  * Note that this function always returns true if rhp is NULL.</a>
<a name="1687"><span class="lineNum">    1687 </span>            :  */</a>
<a name="1688"><span class="lineNum">    1688 </span>            : static bool rcu_nocb_do_flush_bypass(struct rcu_data *rdp, struct rcu_head *rhp,</a>
<a name="1689"><span class="lineNum">    1689 </span>            :                                      unsigned long j)</a>
<a name="1690"><span class="lineNum">    1690 </span>            : {</a>
<a name="1691"><span class="lineNum">    1691 </span>            :         struct rcu_cblist rcl;</a>
<a name="1692"><span class="lineNum">    1692 </span>            : </a>
<a name="1693"><span class="lineNum">    1693 </span>            :         WARN_ON_ONCE(!rcu_segcblist_is_offloaded(&amp;rdp-&gt;cblist));</a>
<a name="1694"><span class="lineNum">    1694 </span>            :         rcu_lockdep_assert_cblist_protected(rdp);</a>
<a name="1695"><span class="lineNum">    1695 </span>            :         lockdep_assert_held(&amp;rdp-&gt;nocb_bypass_lock);</a>
<a name="1696"><span class="lineNum">    1696 </span>            :         if (rhp &amp;&amp; !rcu_cblist_n_cbs(&amp;rdp-&gt;nocb_bypass)) {</a>
<a name="1697"><span class="lineNum">    1697 </span>            :                 raw_spin_unlock(&amp;rdp-&gt;nocb_bypass_lock);</a>
<a name="1698"><span class="lineNum">    1698 </span>            :                 return false;</a>
<a name="1699"><span class="lineNum">    1699 </span>            :         }</a>
<a name="1700"><span class="lineNum">    1700 </span>            :         /* Note: -&gt;cblist.len already accounts for -&gt;nocb_bypass contents. */</a>
<a name="1701"><span class="lineNum">    1701 </span>            :         if (rhp)</a>
<a name="1702"><span class="lineNum">    1702 </span>            :                 rcu_segcblist_inc_len(&amp;rdp-&gt;cblist); /* Must precede enqueue. */</a>
<a name="1703"><span class="lineNum">    1703 </span>            :         rcu_cblist_flush_enqueue(&amp;rcl, &amp;rdp-&gt;nocb_bypass, rhp);</a>
<a name="1704"><span class="lineNum">    1704 </span>            :         rcu_segcblist_insert_pend_cbs(&amp;rdp-&gt;cblist, &amp;rcl);</a>
<a name="1705"><span class="lineNum">    1705 </span>            :         WRITE_ONCE(rdp-&gt;nocb_bypass_first, j);</a>
<a name="1706"><span class="lineNum">    1706 </span>            :         rcu_nocb_bypass_unlock(rdp);</a>
<a name="1707"><span class="lineNum">    1707 </span>            :         return true;</a>
<a name="1708"><span class="lineNum">    1708 </span>            : }</a>
<a name="1709"><span class="lineNum">    1709 </span>            : </a>
<a name="1710"><span class="lineNum">    1710 </span>            : /*</a>
<a name="1711"><span class="lineNum">    1711 </span>            :  * Flush the -&gt;nocb_bypass queue into -&gt;cblist, enqueuing rhp if non-NULL.</a>
<a name="1712"><span class="lineNum">    1712 </span>            :  * However, if there is a callback to be enqueued and if -&gt;nocb_bypass</a>
<a name="1713"><span class="lineNum">    1713 </span>            :  * proves to be initially empty, just return false because the no-CB GP</a>
<a name="1714"><span class="lineNum">    1714 </span>            :  * kthread may need to be awakened in this case.</a>
<a name="1715"><span class="lineNum">    1715 </span>            :  *</a>
<a name="1716"><span class="lineNum">    1716 </span>            :  * Note that this function always returns true if rhp is NULL.</a>
<a name="1717"><span class="lineNum">    1717 </span>            :  */</a>
<a name="1718"><span class="lineNum">    1718 </span>            : static bool rcu_nocb_flush_bypass(struct rcu_data *rdp, struct rcu_head *rhp,</a>
<a name="1719"><span class="lineNum">    1719 </span>            :                                   unsigned long j)</a>
<a name="1720"><span class="lineNum">    1720 </span>            : {</a>
<a name="1721"><span class="lineNum">    1721 </span>            :         if (!rcu_segcblist_is_offloaded(&amp;rdp-&gt;cblist))</a>
<a name="1722"><span class="lineNum">    1722 </span>            :                 return true;</a>
<a name="1723"><span class="lineNum">    1723 </span>            :         rcu_lockdep_assert_cblist_protected(rdp);</a>
<a name="1724"><span class="lineNum">    1724 </span>            :         rcu_nocb_bypass_lock(rdp);</a>
<a name="1725"><span class="lineNum">    1725 </span>            :         return rcu_nocb_do_flush_bypass(rdp, rhp, j);</a>
<a name="1726"><span class="lineNum">    1726 </span>            : }</a>
<a name="1727"><span class="lineNum">    1727 </span>            : </a>
<a name="1728"><span class="lineNum">    1728 </span>            : /*</a>
<a name="1729"><span class="lineNum">    1729 </span>            :  * If the -&gt;nocb_bypass_lock is immediately available, flush the</a>
<a name="1730"><span class="lineNum">    1730 </span>            :  * -&gt;nocb_bypass queue into -&gt;cblist.</a>
<a name="1731"><span class="lineNum">    1731 </span>            :  */</a>
<a name="1732"><span class="lineNum">    1732 </span>            : static void rcu_nocb_try_flush_bypass(struct rcu_data *rdp, unsigned long j)</a>
<a name="1733"><span class="lineNum">    1733 </span>            : {</a>
<a name="1734"><span class="lineNum">    1734 </span>            :         rcu_lockdep_assert_cblist_protected(rdp);</a>
<a name="1735"><span class="lineNum">    1735 </span>            :         if (!rcu_segcblist_is_offloaded(&amp;rdp-&gt;cblist) ||</a>
<a name="1736"><span class="lineNum">    1736 </span>            :             !rcu_nocb_bypass_trylock(rdp))</a>
<a name="1737"><span class="lineNum">    1737 </span>            :                 return;</a>
<a name="1738"><span class="lineNum">    1738 </span>            :         WARN_ON_ONCE(!rcu_nocb_do_flush_bypass(rdp, NULL, j));</a>
<a name="1739"><span class="lineNum">    1739 </span>            : }</a>
<a name="1740"><span class="lineNum">    1740 </span>            : </a>
<a name="1741"><span class="lineNum">    1741 </span>            : /*</a>
<a name="1742"><span class="lineNum">    1742 </span>            :  * See whether it is appropriate to use the -&gt;nocb_bypass list in order</a>
<a name="1743"><span class="lineNum">    1743 </span>            :  * to control contention on -&gt;nocb_lock.  A limited number of direct</a>
<a name="1744"><span class="lineNum">    1744 </span>            :  * enqueues are permitted into -&gt;cblist per jiffy.  If -&gt;nocb_bypass</a>
<a name="1745"><span class="lineNum">    1745 </span>            :  * is non-empty, further callbacks must be placed into -&gt;nocb_bypass,</a>
<a name="1746"><span class="lineNum">    1746 </span>            :  * otherwise rcu_barrier() breaks.  Use rcu_nocb_flush_bypass() to switch</a>
<a name="1747"><span class="lineNum">    1747 </span>            :  * back to direct use of -&gt;cblist.  However, -&gt;nocb_bypass should not be</a>
<a name="1748"><span class="lineNum">    1748 </span>            :  * used if -&gt;cblist is empty, because otherwise callbacks can be stranded</a>
<a name="1749"><span class="lineNum">    1749 </span>            :  * on -&gt;nocb_bypass because we cannot count on the current CPU ever again</a>
<a name="1750"><span class="lineNum">    1750 </span>            :  * invoking call_rcu().  The general rule is that if -&gt;nocb_bypass is</a>
<a name="1751"><span class="lineNum">    1751 </span>            :  * non-empty, the corresponding no-CBs grace-period kthread must not be</a>
<a name="1752"><span class="lineNum">    1752 </span>            :  * in an indefinite sleep state.</a>
<a name="1753"><span class="lineNum">    1753 </span>            :  *</a>
<a name="1754"><span class="lineNum">    1754 </span>            :  * Finally, it is not permitted to use the bypass during early boot,</a>
<a name="1755"><span class="lineNum">    1755 </span>            :  * as doing so would confuse the auto-initialization code.  Besides</a>
<a name="1756"><span class="lineNum">    1756 </span>            :  * which, there is no point in worrying about lock contention while</a>
<a name="1757"><span class="lineNum">    1757 </span>            :  * there is only one CPU in operation.</a>
<a name="1758"><span class="lineNum">    1758 </span>            :  */</a>
<a name="1759"><span class="lineNum">    1759 </span>            : static bool rcu_nocb_try_bypass(struct rcu_data *rdp, struct rcu_head *rhp,</a>
<a name="1760"><span class="lineNum">    1760 </span>            :                                 bool *was_alldone, unsigned long flags)</a>
<a name="1761"><span class="lineNum">    1761 </span>            : {</a>
<a name="1762"><span class="lineNum">    1762 </span>            :         unsigned long c;</a>
<a name="1763"><span class="lineNum">    1763 </span>            :         unsigned long cur_gp_seq;</a>
<a name="1764"><span class="lineNum">    1764 </span>            :         unsigned long j = jiffies;</a>
<a name="1765"><span class="lineNum">    1765 </span>            :         long ncbs = rcu_cblist_n_cbs(&amp;rdp-&gt;nocb_bypass);</a>
<a name="1766"><span class="lineNum">    1766 </span>            : </a>
<a name="1767"><span class="lineNum">    1767 </span>            :         if (!rcu_segcblist_is_offloaded(&amp;rdp-&gt;cblist)) {</a>
<a name="1768"><span class="lineNum">    1768 </span>            :                 *was_alldone = !rcu_segcblist_pend_cbs(&amp;rdp-&gt;cblist);</a>
<a name="1769"><span class="lineNum">    1769 </span>            :                 return false; /* Not offloaded, no bypassing. */</a>
<a name="1770"><span class="lineNum">    1770 </span>            :         }</a>
<a name="1771"><span class="lineNum">    1771 </span>            :         lockdep_assert_irqs_disabled();</a>
<a name="1772"><span class="lineNum">    1772 </span>            : </a>
<a name="1773"><span class="lineNum">    1773 </span>            :         // Don't use -&gt;nocb_bypass during early boot.</a>
<a name="1774"><span class="lineNum">    1774 </span>            :         if (rcu_scheduler_active != RCU_SCHEDULER_RUNNING) {</a>
<a name="1775"><span class="lineNum">    1775 </span>            :                 rcu_nocb_lock(rdp);</a>
<a name="1776"><span class="lineNum">    1776 </span>            :                 WARN_ON_ONCE(rcu_cblist_n_cbs(&amp;rdp-&gt;nocb_bypass));</a>
<a name="1777"><span class="lineNum">    1777 </span>            :                 *was_alldone = !rcu_segcblist_pend_cbs(&amp;rdp-&gt;cblist);</a>
<a name="1778"><span class="lineNum">    1778 </span>            :                 return false;</a>
<a name="1779"><span class="lineNum">    1779 </span>            :         }</a>
<a name="1780"><span class="lineNum">    1780 </span>            : </a>
<a name="1781"><span class="lineNum">    1781 </span>            :         // If we have advanced to a new jiffy, reset counts to allow</a>
<a name="1782"><span class="lineNum">    1782 </span>            :         // moving back from -&gt;nocb_bypass to -&gt;cblist.</a>
<a name="1783"><span class="lineNum">    1783 </span>            :         if (j == rdp-&gt;nocb_nobypass_last) {</a>
<a name="1784"><span class="lineNum">    1784 </span>            :                 c = rdp-&gt;nocb_nobypass_count + 1;</a>
<a name="1785"><span class="lineNum">    1785 </span>            :         } else {</a>
<a name="1786"><span class="lineNum">    1786 </span>            :                 WRITE_ONCE(rdp-&gt;nocb_nobypass_last, j);</a>
<a name="1787"><span class="lineNum">    1787 </span>            :                 c = rdp-&gt;nocb_nobypass_count - nocb_nobypass_lim_per_jiffy;</a>
<a name="1788"><span class="lineNum">    1788 </span>            :                 if (ULONG_CMP_LT(rdp-&gt;nocb_nobypass_count,</a>
<a name="1789"><span class="lineNum">    1789 </span>            :                                  nocb_nobypass_lim_per_jiffy))</a>
<a name="1790"><span class="lineNum">    1790 </span>            :                         c = 0;</a>
<a name="1791"><span class="lineNum">    1791 </span>            :                 else if (c &gt; nocb_nobypass_lim_per_jiffy)</a>
<a name="1792"><span class="lineNum">    1792 </span>            :                         c = nocb_nobypass_lim_per_jiffy;</a>
<a name="1793"><span class="lineNum">    1793 </span>            :         }</a>
<a name="1794"><span class="lineNum">    1794 </span>            :         WRITE_ONCE(rdp-&gt;nocb_nobypass_count, c);</a>
<a name="1795"><span class="lineNum">    1795 </span>            : </a>
<a name="1796"><span class="lineNum">    1796 </span>            :         // If there hasn't yet been all that many -&gt;cblist enqueues</a>
<a name="1797"><span class="lineNum">    1797 </span>            :         // this jiffy, tell the caller to enqueue onto -&gt;cblist.  But flush</a>
<a name="1798"><span class="lineNum">    1798 </span>            :         // -&gt;nocb_bypass first.</a>
<a name="1799"><span class="lineNum">    1799 </span>            :         if (rdp-&gt;nocb_nobypass_count &lt; nocb_nobypass_lim_per_jiffy) {</a>
<a name="1800"><span class="lineNum">    1800 </span>            :                 rcu_nocb_lock(rdp);</a>
<a name="1801"><span class="lineNum">    1801 </span>            :                 *was_alldone = !rcu_segcblist_pend_cbs(&amp;rdp-&gt;cblist);</a>
<a name="1802"><span class="lineNum">    1802 </span>            :                 if (*was_alldone)</a>
<a name="1803"><span class="lineNum">    1803 </span>            :                         trace_rcu_nocb_wake(rcu_state.name, rdp-&gt;cpu,</a>
<a name="1804"><span class="lineNum">    1804 </span>            :                                             TPS(&quot;FirstQ&quot;));</a>
<a name="1805"><span class="lineNum">    1805 </span>            :                 WARN_ON_ONCE(!rcu_nocb_flush_bypass(rdp, NULL, j));</a>
<a name="1806"><span class="lineNum">    1806 </span>            :                 WARN_ON_ONCE(rcu_cblist_n_cbs(&amp;rdp-&gt;nocb_bypass));</a>
<a name="1807"><span class="lineNum">    1807 </span>            :                 return false; // Caller must enqueue the callback.</a>
<a name="1808"><span class="lineNum">    1808 </span>            :         }</a>
<a name="1809"><span class="lineNum">    1809 </span>            : </a>
<a name="1810"><span class="lineNum">    1810 </span>            :         // If -&gt;nocb_bypass has been used too long or is too full,</a>
<a name="1811"><span class="lineNum">    1811 </span>            :         // flush -&gt;nocb_bypass to -&gt;cblist.</a>
<a name="1812"><span class="lineNum">    1812 </span>            :         if ((ncbs &amp;&amp; j != READ_ONCE(rdp-&gt;nocb_bypass_first)) ||</a>
<a name="1813"><span class="lineNum">    1813 </span>            :             ncbs &gt;= qhimark) {</a>
<a name="1814"><span class="lineNum">    1814 </span>            :                 rcu_nocb_lock(rdp);</a>
<a name="1815"><span class="lineNum">    1815 </span>            :                 if (!rcu_nocb_flush_bypass(rdp, rhp, j)) {</a>
<a name="1816"><span class="lineNum">    1816 </span>            :                         *was_alldone = !rcu_segcblist_pend_cbs(&amp;rdp-&gt;cblist);</a>
<a name="1817"><span class="lineNum">    1817 </span>            :                         if (*was_alldone)</a>
<a name="1818"><span class="lineNum">    1818 </span>            :                                 trace_rcu_nocb_wake(rcu_state.name, rdp-&gt;cpu,</a>
<a name="1819"><span class="lineNum">    1819 </span>            :                                                     TPS(&quot;FirstQ&quot;));</a>
<a name="1820"><span class="lineNum">    1820 </span>            :                         WARN_ON_ONCE(rcu_cblist_n_cbs(&amp;rdp-&gt;nocb_bypass));</a>
<a name="1821"><span class="lineNum">    1821 </span>            :                         return false; // Caller must enqueue the callback.</a>
<a name="1822"><span class="lineNum">    1822 </span>            :                 }</a>
<a name="1823"><span class="lineNum">    1823 </span>            :                 if (j != rdp-&gt;nocb_gp_adv_time &amp;&amp;</a>
<a name="1824"><span class="lineNum">    1824 </span>            :                     rcu_segcblist_nextgp(&amp;rdp-&gt;cblist, &amp;cur_gp_seq) &amp;&amp;</a>
<a name="1825"><span class="lineNum">    1825 </span>            :                     rcu_seq_done(&amp;rdp-&gt;mynode-&gt;gp_seq, cur_gp_seq)) {</a>
<a name="1826"><span class="lineNum">    1826 </span>            :                         rcu_advance_cbs_nowake(rdp-&gt;mynode, rdp);</a>
<a name="1827"><span class="lineNum">    1827 </span>            :                         rdp-&gt;nocb_gp_adv_time = j;</a>
<a name="1828"><span class="lineNum">    1828 </span>            :                 }</a>
<a name="1829"><span class="lineNum">    1829 </span>            :                 rcu_nocb_unlock_irqrestore(rdp, flags);</a>
<a name="1830"><span class="lineNum">    1830 </span>            :                 return true; // Callback already enqueued.</a>
<a name="1831"><span class="lineNum">    1831 </span>            :         }</a>
<a name="1832"><span class="lineNum">    1832 </span>            : </a>
<a name="1833"><span class="lineNum">    1833 </span>            :         // We need to use the bypass.</a>
<a name="1834"><span class="lineNum">    1834 </span>            :         rcu_nocb_wait_contended(rdp);</a>
<a name="1835"><span class="lineNum">    1835 </span>            :         rcu_nocb_bypass_lock(rdp);</a>
<a name="1836"><span class="lineNum">    1836 </span>            :         ncbs = rcu_cblist_n_cbs(&amp;rdp-&gt;nocb_bypass);</a>
<a name="1837"><span class="lineNum">    1837 </span>            :         rcu_segcblist_inc_len(&amp;rdp-&gt;cblist); /* Must precede enqueue. */</a>
<a name="1838"><span class="lineNum">    1838 </span>            :         rcu_cblist_enqueue(&amp;rdp-&gt;nocb_bypass, rhp);</a>
<a name="1839"><span class="lineNum">    1839 </span>            :         if (!ncbs) {</a>
<a name="1840"><span class="lineNum">    1840 </span>            :                 WRITE_ONCE(rdp-&gt;nocb_bypass_first, j);</a>
<a name="1841"><span class="lineNum">    1841 </span>            :                 trace_rcu_nocb_wake(rcu_state.name, rdp-&gt;cpu, TPS(&quot;FirstBQ&quot;));</a>
<a name="1842"><span class="lineNum">    1842 </span>            :         }</a>
<a name="1843"><span class="lineNum">    1843 </span>            :         rcu_nocb_bypass_unlock(rdp);</a>
<a name="1844"><span class="lineNum">    1844 </span>            :         smp_mb(); /* Order enqueue before wake. */</a>
<a name="1845"><span class="lineNum">    1845 </span>            :         if (ncbs) {</a>
<a name="1846"><span class="lineNum">    1846 </span>            :                 local_irq_restore(flags);</a>
<a name="1847"><span class="lineNum">    1847 </span>            :         } else {</a>
<a name="1848"><span class="lineNum">    1848 </span>            :                 // No-CBs GP kthread might be indefinitely asleep, if so, wake.</a>
<a name="1849"><span class="lineNum">    1849 </span>            :                 rcu_nocb_lock(rdp); // Rare during call_rcu() flood.</a>
<a name="1850"><span class="lineNum">    1850 </span>            :                 if (!rcu_segcblist_pend_cbs(&amp;rdp-&gt;cblist)) {</a>
<a name="1851"><span class="lineNum">    1851 </span>            :                         trace_rcu_nocb_wake(rcu_state.name, rdp-&gt;cpu,</a>
<a name="1852"><span class="lineNum">    1852 </span>            :                                             TPS(&quot;FirstBQwake&quot;));</a>
<a name="1853"><span class="lineNum">    1853 </span>            :                         __call_rcu_nocb_wake(rdp, true, flags);</a>
<a name="1854"><span class="lineNum">    1854 </span>            :                 } else {</a>
<a name="1855"><span class="lineNum">    1855 </span>            :                         trace_rcu_nocb_wake(rcu_state.name, rdp-&gt;cpu,</a>
<a name="1856"><span class="lineNum">    1856 </span>            :                                             TPS(&quot;FirstBQnoWake&quot;));</a>
<a name="1857"><span class="lineNum">    1857 </span>            :                         rcu_nocb_unlock_irqrestore(rdp, flags);</a>
<a name="1858"><span class="lineNum">    1858 </span>            :                 }</a>
<a name="1859"><span class="lineNum">    1859 </span>            :         }</a>
<a name="1860"><span class="lineNum">    1860 </span>            :         return true; // Callback already enqueued.</a>
<a name="1861"><span class="lineNum">    1861 </span>            : }</a>
<a name="1862"><span class="lineNum">    1862 </span>            : </a>
<a name="1863"><span class="lineNum">    1863 </span>            : /*</a>
<a name="1864"><span class="lineNum">    1864 </span>            :  * Awaken the no-CBs grace-period kthead if needed, either due to it</a>
<a name="1865"><span class="lineNum">    1865 </span>            :  * legitimately being asleep or due to overload conditions.</a>
<a name="1866"><span class="lineNum">    1866 </span>            :  *</a>
<a name="1867"><span class="lineNum">    1867 </span>            :  * If warranted, also wake up the kthread servicing this CPUs queues.</a>
<a name="1868"><span class="lineNum">    1868 </span>            :  */</a>
<a name="1869"><span class="lineNum">    1869 </span>            : static void __call_rcu_nocb_wake(struct rcu_data *rdp, bool was_alldone,</a>
<a name="1870"><span class="lineNum">    1870 </span>            :                                  unsigned long flags)</a>
<a name="1871"><span class="lineNum">    1871 </span>            :                                  __releases(rdp-&gt;nocb_lock)</a>
<a name="1872"><span class="lineNum">    1872 </span>            : {</a>
<a name="1873"><span class="lineNum">    1873 </span>            :         unsigned long cur_gp_seq;</a>
<a name="1874"><span class="lineNum">    1874 </span>            :         unsigned long j;</a>
<a name="1875"><span class="lineNum">    1875 </span>            :         long len;</a>
<a name="1876"><span class="lineNum">    1876 </span>            :         struct task_struct *t;</a>
<a name="1877"><span class="lineNum">    1877 </span>            : </a>
<a name="1878"><span class="lineNum">    1878 </span>            :         // If we are being polled or there is no kthread, just leave.</a>
<a name="1879"><span class="lineNum">    1879 </span>            :         t = READ_ONCE(rdp-&gt;nocb_gp_kthread);</a>
<a name="1880"><span class="lineNum">    1880 </span>            :         if (rcu_nocb_poll || !t) {</a>
<a name="1881"><span class="lineNum">    1881 </span>            :                 trace_rcu_nocb_wake(rcu_state.name, rdp-&gt;cpu,</a>
<a name="1882"><span class="lineNum">    1882 </span>            :                                     TPS(&quot;WakeNotPoll&quot;));</a>
<a name="1883"><span class="lineNum">    1883 </span>            :                 rcu_nocb_unlock_irqrestore(rdp, flags);</a>
<a name="1884"><span class="lineNum">    1884 </span>            :                 return;</a>
<a name="1885"><span class="lineNum">    1885 </span>            :         }</a>
<a name="1886"><span class="lineNum">    1886 </span>            :         // Need to actually to a wakeup.</a>
<a name="1887"><span class="lineNum">    1887 </span>            :         len = rcu_segcblist_n_cbs(&amp;rdp-&gt;cblist);</a>
<a name="1888"><span class="lineNum">    1888 </span>            :         if (was_alldone) {</a>
<a name="1889"><span class="lineNum">    1889 </span>            :                 rdp-&gt;qlen_last_fqs_check = len;</a>
<a name="1890"><span class="lineNum">    1890 </span>            :                 if (!irqs_disabled_flags(flags)) {</a>
<a name="1891"><span class="lineNum">    1891 </span>            :                         /* ... if queue was empty ... */</a>
<a name="1892"><span class="lineNum">    1892 </span>            :                         wake_nocb_gp(rdp, false, flags);</a>
<a name="1893"><span class="lineNum">    1893 </span>            :                         trace_rcu_nocb_wake(rcu_state.name, rdp-&gt;cpu,</a>
<a name="1894"><span class="lineNum">    1894 </span>            :                                             TPS(&quot;WakeEmpty&quot;));</a>
<a name="1895"><span class="lineNum">    1895 </span>            :                 } else {</a>
<a name="1896"><span class="lineNum">    1896 </span>            :                         wake_nocb_gp_defer(rdp, RCU_NOCB_WAKE,</a>
<a name="1897"><span class="lineNum">    1897 </span>            :                                            TPS(&quot;WakeEmptyIsDeferred&quot;));</a>
<a name="1898"><span class="lineNum">    1898 </span>            :                         rcu_nocb_unlock_irqrestore(rdp, flags);</a>
<a name="1899"><span class="lineNum">    1899 </span>            :                 }</a>
<a name="1900"><span class="lineNum">    1900 </span>            :         } else if (len &gt; rdp-&gt;qlen_last_fqs_check + qhimark) {</a>
<a name="1901"><span class="lineNum">    1901 </span>            :                 /* ... or if many callbacks queued. */</a>
<a name="1902"><span class="lineNum">    1902 </span>            :                 rdp-&gt;qlen_last_fqs_check = len;</a>
<a name="1903"><span class="lineNum">    1903 </span>            :                 j = jiffies;</a>
<a name="1904"><span class="lineNum">    1904 </span>            :                 if (j != rdp-&gt;nocb_gp_adv_time &amp;&amp;</a>
<a name="1905"><span class="lineNum">    1905 </span>            :                     rcu_segcblist_nextgp(&amp;rdp-&gt;cblist, &amp;cur_gp_seq) &amp;&amp;</a>
<a name="1906"><span class="lineNum">    1906 </span>            :                     rcu_seq_done(&amp;rdp-&gt;mynode-&gt;gp_seq, cur_gp_seq)) {</a>
<a name="1907"><span class="lineNum">    1907 </span>            :                         rcu_advance_cbs_nowake(rdp-&gt;mynode, rdp);</a>
<a name="1908"><span class="lineNum">    1908 </span>            :                         rdp-&gt;nocb_gp_adv_time = j;</a>
<a name="1909"><span class="lineNum">    1909 </span>            :                 }</a>
<a name="1910"><span class="lineNum">    1910 </span>            :                 smp_mb(); /* Enqueue before timer_pending(). */</a>
<a name="1911"><span class="lineNum">    1911 </span>            :                 if ((rdp-&gt;nocb_cb_sleep ||</a>
<a name="1912"><span class="lineNum">    1912 </span>            :                      !rcu_segcblist_ready_cbs(&amp;rdp-&gt;cblist)) &amp;&amp;</a>
<a name="1913"><span class="lineNum">    1913 </span>            :                     !timer_pending(&amp;rdp-&gt;nocb_bypass_timer))</a>
<a name="1914"><span class="lineNum">    1914 </span>            :                         wake_nocb_gp_defer(rdp, RCU_NOCB_WAKE_FORCE,</a>
<a name="1915"><span class="lineNum">    1915 </span>            :                                            TPS(&quot;WakeOvfIsDeferred&quot;));</a>
<a name="1916"><span class="lineNum">    1916 </span>            :                 rcu_nocb_unlock_irqrestore(rdp, flags);</a>
<a name="1917"><span class="lineNum">    1917 </span>            :         } else {</a>
<a name="1918"><span class="lineNum">    1918 </span>            :                 trace_rcu_nocb_wake(rcu_state.name, rdp-&gt;cpu, TPS(&quot;WakeNot&quot;));</a>
<a name="1919"><span class="lineNum">    1919 </span>            :                 rcu_nocb_unlock_irqrestore(rdp, flags);</a>
<a name="1920"><span class="lineNum">    1920 </span>            :         }</a>
<a name="1921"><span class="lineNum">    1921 </span>            :         return;</a>
<a name="1922"><span class="lineNum">    1922 </span>            : }</a>
<a name="1923"><span class="lineNum">    1923 </span>            : </a>
<a name="1924"><span class="lineNum">    1924 </span>            : /* Wake up the no-CBs GP kthread to flush -&gt;nocb_bypass. */</a>
<a name="1925"><span class="lineNum">    1925 </span>            : static void do_nocb_bypass_wakeup_timer(struct timer_list *t)</a>
<a name="1926"><span class="lineNum">    1926 </span>            : {</a>
<a name="1927"><span class="lineNum">    1927 </span>            :         unsigned long flags;</a>
<a name="1928"><span class="lineNum">    1928 </span>            :         struct rcu_data *rdp = from_timer(rdp, t, nocb_bypass_timer);</a>
<a name="1929"><span class="lineNum">    1929 </span>            : </a>
<a name="1930"><span class="lineNum">    1930 </span>            :         trace_rcu_nocb_wake(rcu_state.name, rdp-&gt;cpu, TPS(&quot;Timer&quot;));</a>
<a name="1931"><span class="lineNum">    1931 </span>            :         rcu_nocb_lock_irqsave(rdp, flags);</a>
<a name="1932"><span class="lineNum">    1932 </span>            :         smp_mb__after_spinlock(); /* Timer expire before wakeup. */</a>
<a name="1933"><span class="lineNum">    1933 </span>            :         __call_rcu_nocb_wake(rdp, true, flags);</a>
<a name="1934"><span class="lineNum">    1934 </span>            : }</a>
<a name="1935"><span class="lineNum">    1935 </span>            : </a>
<a name="1936"><span class="lineNum">    1936 </span>            : /*</a>
<a name="1937"><span class="lineNum">    1937 </span>            :  * Check if we ignore this rdp.</a>
<a name="1938"><span class="lineNum">    1938 </span>            :  *</a>
<a name="1939"><span class="lineNum">    1939 </span>            :  * We check that without holding the nocb lock but</a>
<a name="1940"><span class="lineNum">    1940 </span>            :  * we make sure not to miss a freshly offloaded rdp</a>
<a name="1941"><span class="lineNum">    1941 </span>            :  * with the current ordering:</a>
<a name="1942"><span class="lineNum">    1942 </span>            :  *</a>
<a name="1943"><span class="lineNum">    1943 </span>            :  *  rdp_offload_toggle()        nocb_gp_enabled_cb()</a>
<a name="1944"><span class="lineNum">    1944 </span>            :  * -------------------------   ----------------------------</a>
<a name="1945"><span class="lineNum">    1945 </span>            :  *    WRITE flags                 LOCK nocb_gp_lock</a>
<a name="1946"><span class="lineNum">    1946 </span>            :  *    LOCK nocb_gp_lock           READ/WRITE nocb_gp_sleep</a>
<a name="1947"><span class="lineNum">    1947 </span>            :  *    READ/WRITE nocb_gp_sleep    UNLOCK nocb_gp_lock</a>
<a name="1948"><span class="lineNum">    1948 </span>            :  *    UNLOCK nocb_gp_lock         READ flags</a>
<a name="1949"><span class="lineNum">    1949 </span>            :  */</a>
<a name="1950"><span class="lineNum">    1950 </span>            : static inline bool nocb_gp_enabled_cb(struct rcu_data *rdp)</a>
<a name="1951"><span class="lineNum">    1951 </span>            : {</a>
<a name="1952"><span class="lineNum">    1952 </span>            :         u8 flags = SEGCBLIST_OFFLOADED | SEGCBLIST_KTHREAD_GP;</a>
<a name="1953"><span class="lineNum">    1953 </span>            : </a>
<a name="1954"><span class="lineNum">    1954 </span>            :         return rcu_segcblist_test_flags(&amp;rdp-&gt;cblist, flags);</a>
<a name="1955"><span class="lineNum">    1955 </span>            : }</a>
<a name="1956"><span class="lineNum">    1956 </span>            : </a>
<a name="1957"><span class="lineNum">    1957 </span>            : static inline bool nocb_gp_update_state(struct rcu_data *rdp, bool *needwake_state)</a>
<a name="1958"><span class="lineNum">    1958 </span>            : {</a>
<a name="1959"><span class="lineNum">    1959 </span>            :         struct rcu_segcblist *cblist = &amp;rdp-&gt;cblist;</a>
<a name="1960"><span class="lineNum">    1960 </span>            : </a>
<a name="1961"><span class="lineNum">    1961 </span>            :         if (rcu_segcblist_test_flags(cblist, SEGCBLIST_OFFLOADED)) {</a>
<a name="1962"><span class="lineNum">    1962 </span>            :                 if (!rcu_segcblist_test_flags(cblist, SEGCBLIST_KTHREAD_GP)) {</a>
<a name="1963"><span class="lineNum">    1963 </span>            :                         rcu_segcblist_set_flags(cblist, SEGCBLIST_KTHREAD_GP);</a>
<a name="1964"><span class="lineNum">    1964 </span>            :                         if (rcu_segcblist_test_flags(cblist, SEGCBLIST_KTHREAD_CB))</a>
<a name="1965"><span class="lineNum">    1965 </span>            :                                 *needwake_state = true;</a>
<a name="1966"><span class="lineNum">    1966 </span>            :                 }</a>
<a name="1967"><span class="lineNum">    1967 </span>            :                 return true;</a>
<a name="1968"><span class="lineNum">    1968 </span>            :         }</a>
<a name="1969"><span class="lineNum">    1969 </span>            : </a>
<a name="1970"><span class="lineNum">    1970 </span>            :         /*</a>
<a name="1971"><span class="lineNum">    1971 </span>            :          * De-offloading. Clear our flag and notify the de-offload worker.</a>
<a name="1972"><span class="lineNum">    1972 </span>            :          * We will ignore this rdp until it ever gets re-offloaded.</a>
<a name="1973"><span class="lineNum">    1973 </span>            :          */</a>
<a name="1974"><span class="lineNum">    1974 </span>            :         WARN_ON_ONCE(!rcu_segcblist_test_flags(cblist, SEGCBLIST_KTHREAD_GP));</a>
<a name="1975"><span class="lineNum">    1975 </span>            :         rcu_segcblist_clear_flags(cblist, SEGCBLIST_KTHREAD_GP);</a>
<a name="1976"><span class="lineNum">    1976 </span>            :         if (!rcu_segcblist_test_flags(cblist, SEGCBLIST_KTHREAD_CB))</a>
<a name="1977"><span class="lineNum">    1977 </span>            :                 *needwake_state = true;</a>
<a name="1978"><span class="lineNum">    1978 </span>            :         return false;</a>
<a name="1979"><span class="lineNum">    1979 </span>            : }</a>
<a name="1980"><span class="lineNum">    1980 </span>            : </a>
<a name="1981"><span class="lineNum">    1981 </span>            : </a>
<a name="1982"><span class="lineNum">    1982 </span>            : /*</a>
<a name="1983"><span class="lineNum">    1983 </span>            :  * No-CBs GP kthreads come here to wait for additional callbacks to show up</a>
<a name="1984"><span class="lineNum">    1984 </span>            :  * or for grace periods to end.</a>
<a name="1985"><span class="lineNum">    1985 </span>            :  */</a>
<a name="1986"><span class="lineNum">    1986 </span>            : static void nocb_gp_wait(struct rcu_data *my_rdp)</a>
<a name="1987"><span class="lineNum">    1987 </span>            : {</a>
<a name="1988"><span class="lineNum">    1988 </span>            :         bool bypass = false;</a>
<a name="1989"><span class="lineNum">    1989 </span>            :         long bypass_ncbs;</a>
<a name="1990"><span class="lineNum">    1990 </span>            :         int __maybe_unused cpu = my_rdp-&gt;cpu;</a>
<a name="1991"><span class="lineNum">    1991 </span>            :         unsigned long cur_gp_seq;</a>
<a name="1992"><span class="lineNum">    1992 </span>            :         unsigned long flags;</a>
<a name="1993"><span class="lineNum">    1993 </span>            :         bool gotcbs = false;</a>
<a name="1994"><span class="lineNum">    1994 </span>            :         unsigned long j = jiffies;</a>
<a name="1995"><span class="lineNum">    1995 </span>            :         bool needwait_gp = false; // This prevents actual uninitialized use.</a>
<a name="1996"><span class="lineNum">    1996 </span>            :         bool needwake;</a>
<a name="1997"><span class="lineNum">    1997 </span>            :         bool needwake_gp;</a>
<a name="1998"><span class="lineNum">    1998 </span>            :         struct rcu_data *rdp;</a>
<a name="1999"><span class="lineNum">    1999 </span>            :         struct rcu_node *rnp;</a>
<a name="2000"><span class="lineNum">    2000 </span>            :         unsigned long wait_gp_seq = 0; // Suppress &quot;use uninitialized&quot; warning.</a>
<a name="2001"><span class="lineNum">    2001 </span>            :         bool wasempty = false;</a>
<a name="2002"><span class="lineNum">    2002 </span>            : </a>
<a name="2003"><span class="lineNum">    2003 </span>            :         /*</a>
<a name="2004"><span class="lineNum">    2004 </span>            :          * Each pass through the following loop checks for CBs and for the</a>
<a name="2005"><span class="lineNum">    2005 </span>            :          * nearest grace period (if any) to wait for next.  The CB kthreads</a>
<a name="2006"><span class="lineNum">    2006 </span>            :          * and the global grace-period kthread are awakened if needed.</a>
<a name="2007"><span class="lineNum">    2007 </span>            :          */</a>
<a name="2008"><span class="lineNum">    2008 </span>            :         WARN_ON_ONCE(my_rdp-&gt;nocb_gp_rdp != my_rdp);</a>
<a name="2009"><span class="lineNum">    2009 </span>            :         for (rdp = my_rdp; rdp; rdp = rdp-&gt;nocb_next_cb_rdp) {</a>
<a name="2010"><span class="lineNum">    2010 </span>            :                 bool needwake_state = false;</a>
<a name="2011"><span class="lineNum">    2011 </span>            : </a>
<a name="2012"><span class="lineNum">    2012 </span>            :                 if (!nocb_gp_enabled_cb(rdp))</a>
<a name="2013"><span class="lineNum">    2013 </span>            :                         continue;</a>
<a name="2014"><span class="lineNum">    2014 </span>            :                 trace_rcu_nocb_wake(rcu_state.name, rdp-&gt;cpu, TPS(&quot;Check&quot;));</a>
<a name="2015"><span class="lineNum">    2015 </span>            :                 rcu_nocb_lock_irqsave(rdp, flags);</a>
<a name="2016"><span class="lineNum">    2016 </span>            :                 if (!nocb_gp_update_state(rdp, &amp;needwake_state)) {</a>
<a name="2017"><span class="lineNum">    2017 </span>            :                         rcu_nocb_unlock_irqrestore(rdp, flags);</a>
<a name="2018"><span class="lineNum">    2018 </span>            :                         if (needwake_state)</a>
<a name="2019"><span class="lineNum">    2019 </span>            :                                 swake_up_one(&amp;rdp-&gt;nocb_state_wq);</a>
<a name="2020"><span class="lineNum">    2020 </span>            :                         continue;</a>
<a name="2021"><span class="lineNum">    2021 </span>            :                 }</a>
<a name="2022"><span class="lineNum">    2022 </span>            :                 bypass_ncbs = rcu_cblist_n_cbs(&amp;rdp-&gt;nocb_bypass);</a>
<a name="2023"><span class="lineNum">    2023 </span>            :                 if (bypass_ncbs &amp;&amp;</a>
<a name="2024"><span class="lineNum">    2024 </span>            :                     (time_after(j, READ_ONCE(rdp-&gt;nocb_bypass_first) + 1) ||</a>
<a name="2025"><span class="lineNum">    2025 </span>            :                      bypass_ncbs &gt; 2 * qhimark)) {</a>
<a name="2026"><span class="lineNum">    2026 </span>            :                         // Bypass full or old, so flush it.</a>
<a name="2027"><span class="lineNum">    2027 </span>            :                         (void)rcu_nocb_try_flush_bypass(rdp, j);</a>
<a name="2028"><span class="lineNum">    2028 </span>            :                         bypass_ncbs = rcu_cblist_n_cbs(&amp;rdp-&gt;nocb_bypass);</a>
<a name="2029"><span class="lineNum">    2029 </span>            :                 } else if (!bypass_ncbs &amp;&amp; rcu_segcblist_empty(&amp;rdp-&gt;cblist)) {</a>
<a name="2030"><span class="lineNum">    2030 </span>            :                         rcu_nocb_unlock_irqrestore(rdp, flags);</a>
<a name="2031"><span class="lineNum">    2031 </span>            :                         if (needwake_state)</a>
<a name="2032"><span class="lineNum">    2032 </span>            :                                 swake_up_one(&amp;rdp-&gt;nocb_state_wq);</a>
<a name="2033"><span class="lineNum">    2033 </span>            :                         continue; /* No callbacks here, try next. */</a>
<a name="2034"><span class="lineNum">    2034 </span>            :                 }</a>
<a name="2035"><span class="lineNum">    2035 </span>            :                 if (bypass_ncbs) {</a>
<a name="2036"><span class="lineNum">    2036 </span>            :                         trace_rcu_nocb_wake(rcu_state.name, rdp-&gt;cpu,</a>
<a name="2037"><span class="lineNum">    2037 </span>            :                                             TPS(&quot;Bypass&quot;));</a>
<a name="2038"><span class="lineNum">    2038 </span>            :                         bypass = true;</a>
<a name="2039"><span class="lineNum">    2039 </span>            :                 }</a>
<a name="2040"><span class="lineNum">    2040 </span>            :                 rnp = rdp-&gt;mynode;</a>
<a name="2041"><span class="lineNum">    2041 </span>            :                 if (bypass) {  // Avoid race with first bypass CB.</a>
<a name="2042"><span class="lineNum">    2042 </span>            :                         WRITE_ONCE(my_rdp-&gt;nocb_defer_wakeup,</a>
<a name="2043"><span class="lineNum">    2043 </span>            :                                    RCU_NOCB_WAKE_NOT);</a>
<a name="2044"><span class="lineNum">    2044 </span>            :                         del_timer(&amp;my_rdp-&gt;nocb_timer);</a>
<a name="2045"><span class="lineNum">    2045 </span>            :                 }</a>
<a name="2046"><span class="lineNum">    2046 </span>            :                 // Advance callbacks if helpful and low contention.</a>
<a name="2047"><span class="lineNum">    2047 </span>            :                 needwake_gp = false;</a>
<a name="2048"><span class="lineNum">    2048 </span>            :                 if (!rcu_segcblist_restempty(&amp;rdp-&gt;cblist,</a>
<a name="2049"><span class="lineNum">    2049 </span>            :                                              RCU_NEXT_READY_TAIL) ||</a>
<a name="2050"><span class="lineNum">    2050 </span>            :                     (rcu_segcblist_nextgp(&amp;rdp-&gt;cblist, &amp;cur_gp_seq) &amp;&amp;</a>
<a name="2051"><span class="lineNum">    2051 </span>            :                      rcu_seq_done(&amp;rnp-&gt;gp_seq, cur_gp_seq))) {</a>
<a name="2052"><span class="lineNum">    2052 </span>            :                         raw_spin_lock_rcu_node(rnp); /* irqs disabled. */</a>
<a name="2053"><span class="lineNum">    2053 </span>            :                         needwake_gp = rcu_advance_cbs(rnp, rdp);</a>
<a name="2054"><span class="lineNum">    2054 </span>            :                         wasempty = rcu_segcblist_restempty(&amp;rdp-&gt;cblist,</a>
<a name="2055"><span class="lineNum">    2055 </span>            :                                                            RCU_NEXT_READY_TAIL);</a>
<a name="2056"><span class="lineNum">    2056 </span>            :                         raw_spin_unlock_rcu_node(rnp); /* irqs disabled. */</a>
<a name="2057"><span class="lineNum">    2057 </span>            :                 }</a>
<a name="2058"><span class="lineNum">    2058 </span>            :                 // Need to wait on some grace period?</a>
<a name="2059"><span class="lineNum">    2059 </span>            :                 WARN_ON_ONCE(wasempty &amp;&amp;</a>
<a name="2060"><span class="lineNum">    2060 </span>            :                              !rcu_segcblist_restempty(&amp;rdp-&gt;cblist,</a>
<a name="2061"><span class="lineNum">    2061 </span>            :                                                       RCU_NEXT_READY_TAIL));</a>
<a name="2062"><span class="lineNum">    2062 </span>            :                 if (rcu_segcblist_nextgp(&amp;rdp-&gt;cblist, &amp;cur_gp_seq)) {</a>
<a name="2063"><span class="lineNum">    2063 </span>            :                         if (!needwait_gp ||</a>
<a name="2064"><span class="lineNum">    2064 </span>            :                             ULONG_CMP_LT(cur_gp_seq, wait_gp_seq))</a>
<a name="2065"><span class="lineNum">    2065 </span>            :                                 wait_gp_seq = cur_gp_seq;</a>
<a name="2066"><span class="lineNum">    2066 </span>            :                         needwait_gp = true;</a>
<a name="2067"><span class="lineNum">    2067 </span>            :                         trace_rcu_nocb_wake(rcu_state.name, rdp-&gt;cpu,</a>
<a name="2068"><span class="lineNum">    2068 </span>            :                                             TPS(&quot;NeedWaitGP&quot;));</a>
<a name="2069"><span class="lineNum">    2069 </span>            :                 }</a>
<a name="2070"><span class="lineNum">    2070 </span>            :                 if (rcu_segcblist_ready_cbs(&amp;rdp-&gt;cblist)) {</a>
<a name="2071"><span class="lineNum">    2071 </span>            :                         needwake = rdp-&gt;nocb_cb_sleep;</a>
<a name="2072"><span class="lineNum">    2072 </span>            :                         WRITE_ONCE(rdp-&gt;nocb_cb_sleep, false);</a>
<a name="2073"><span class="lineNum">    2073 </span>            :                         smp_mb(); /* CB invocation -after- GP end. */</a>
<a name="2074"><span class="lineNum">    2074 </span>            :                 } else {</a>
<a name="2075"><span class="lineNum">    2075 </span>            :                         needwake = false;</a>
<a name="2076"><span class="lineNum">    2076 </span>            :                 }</a>
<a name="2077"><span class="lineNum">    2077 </span>            :                 rcu_nocb_unlock_irqrestore(rdp, flags);</a>
<a name="2078"><span class="lineNum">    2078 </span>            :                 if (needwake) {</a>
<a name="2079"><span class="lineNum">    2079 </span>            :                         swake_up_one(&amp;rdp-&gt;nocb_cb_wq);</a>
<a name="2080"><span class="lineNum">    2080 </span>            :                         gotcbs = true;</a>
<a name="2081"><span class="lineNum">    2081 </span>            :                 }</a>
<a name="2082"><span class="lineNum">    2082 </span>            :                 if (needwake_gp)</a>
<a name="2083"><span class="lineNum">    2083 </span>            :                         rcu_gp_kthread_wake();</a>
<a name="2084"><span class="lineNum">    2084 </span>            :                 if (needwake_state)</a>
<a name="2085"><span class="lineNum">    2085 </span>            :                         swake_up_one(&amp;rdp-&gt;nocb_state_wq);</a>
<a name="2086"><span class="lineNum">    2086 </span>            :         }</a>
<a name="2087"><span class="lineNum">    2087 </span>            : </a>
<a name="2088"><span class="lineNum">    2088 </span>            :         my_rdp-&gt;nocb_gp_bypass = bypass;</a>
<a name="2089"><span class="lineNum">    2089 </span>            :         my_rdp-&gt;nocb_gp_gp = needwait_gp;</a>
<a name="2090"><span class="lineNum">    2090 </span>            :         my_rdp-&gt;nocb_gp_seq = needwait_gp ? wait_gp_seq : 0;</a>
<a name="2091"><span class="lineNum">    2091 </span>            :         if (bypass &amp;&amp; !rcu_nocb_poll) {</a>
<a name="2092"><span class="lineNum">    2092 </span>            :                 // At least one child with non-empty -&gt;nocb_bypass, so set</a>
<a name="2093"><span class="lineNum">    2093 </span>            :                 // timer in order to avoid stranding its callbacks.</a>
<a name="2094"><span class="lineNum">    2094 </span>            :                 raw_spin_lock_irqsave(&amp;my_rdp-&gt;nocb_gp_lock, flags);</a>
<a name="2095"><span class="lineNum">    2095 </span>            :                 mod_timer(&amp;my_rdp-&gt;nocb_bypass_timer, j + 2);</a>
<a name="2096"><span class="lineNum">    2096 </span>            :                 raw_spin_unlock_irqrestore(&amp;my_rdp-&gt;nocb_gp_lock, flags);</a>
<a name="2097"><span class="lineNum">    2097 </span>            :         }</a>
<a name="2098"><span class="lineNum">    2098 </span>            :         if (rcu_nocb_poll) {</a>
<a name="2099"><span class="lineNum">    2099 </span>            :                 /* Polling, so trace if first poll in the series. */</a>
<a name="2100"><span class="lineNum">    2100 </span>            :                 if (gotcbs)</a>
<a name="2101"><span class="lineNum">    2101 </span>            :                         trace_rcu_nocb_wake(rcu_state.name, cpu, TPS(&quot;Poll&quot;));</a>
<a name="2102"><span class="lineNum">    2102 </span>            :                 schedule_timeout_idle(1);</a>
<a name="2103"><span class="lineNum">    2103 </span>            :         } else if (!needwait_gp) {</a>
<a name="2104"><span class="lineNum">    2104 </span>            :                 /* Wait for callbacks to appear. */</a>
<a name="2105"><span class="lineNum">    2105 </span>            :                 trace_rcu_nocb_wake(rcu_state.name, cpu, TPS(&quot;Sleep&quot;));</a>
<a name="2106"><span class="lineNum">    2106 </span>            :                 swait_event_interruptible_exclusive(my_rdp-&gt;nocb_gp_wq,</a>
<a name="2107"><span class="lineNum">    2107 </span>            :                                 !READ_ONCE(my_rdp-&gt;nocb_gp_sleep));</a>
<a name="2108"><span class="lineNum">    2108 </span>            :                 trace_rcu_nocb_wake(rcu_state.name, cpu, TPS(&quot;EndSleep&quot;));</a>
<a name="2109"><span class="lineNum">    2109 </span>            :         } else {</a>
<a name="2110"><span class="lineNum">    2110 </span>            :                 rnp = my_rdp-&gt;mynode;</a>
<a name="2111"><span class="lineNum">    2111 </span>            :                 trace_rcu_this_gp(rnp, my_rdp, wait_gp_seq, TPS(&quot;StartWait&quot;));</a>
<a name="2112"><span class="lineNum">    2112 </span>            :                 swait_event_interruptible_exclusive(</a>
<a name="2113"><span class="lineNum">    2113 </span>            :                         rnp-&gt;nocb_gp_wq[rcu_seq_ctr(wait_gp_seq) &amp; 0x1],</a>
<a name="2114"><span class="lineNum">    2114 </span>            :                         rcu_seq_done(&amp;rnp-&gt;gp_seq, wait_gp_seq) ||</a>
<a name="2115"><span class="lineNum">    2115 </span>            :                         !READ_ONCE(my_rdp-&gt;nocb_gp_sleep));</a>
<a name="2116"><span class="lineNum">    2116 </span>            :                 trace_rcu_this_gp(rnp, my_rdp, wait_gp_seq, TPS(&quot;EndWait&quot;));</a>
<a name="2117"><span class="lineNum">    2117 </span>            :         }</a>
<a name="2118"><span class="lineNum">    2118 </span>            :         if (!rcu_nocb_poll) {</a>
<a name="2119"><span class="lineNum">    2119 </span>            :                 raw_spin_lock_irqsave(&amp;my_rdp-&gt;nocb_gp_lock, flags);</a>
<a name="2120"><span class="lineNum">    2120 </span>            :                 if (bypass)</a>
<a name="2121"><span class="lineNum">    2121 </span>            :                         del_timer(&amp;my_rdp-&gt;nocb_bypass_timer);</a>
<a name="2122"><span class="lineNum">    2122 </span>            :                 WRITE_ONCE(my_rdp-&gt;nocb_gp_sleep, true);</a>
<a name="2123"><span class="lineNum">    2123 </span>            :                 raw_spin_unlock_irqrestore(&amp;my_rdp-&gt;nocb_gp_lock, flags);</a>
<a name="2124"><span class="lineNum">    2124 </span>            :         }</a>
<a name="2125"><span class="lineNum">    2125 </span>            :         my_rdp-&gt;nocb_gp_seq = -1;</a>
<a name="2126"><span class="lineNum">    2126 </span>            :         WARN_ON(signal_pending(current));</a>
<a name="2127"><span class="lineNum">    2127 </span>            : }</a>
<a name="2128"><span class="lineNum">    2128 </span>            : </a>
<a name="2129"><span class="lineNum">    2129 </span>            : /*</a>
<a name="2130"><span class="lineNum">    2130 </span>            :  * No-CBs grace-period-wait kthread.  There is one of these per group</a>
<a name="2131"><span class="lineNum">    2131 </span>            :  * of CPUs, but only once at least one CPU in that group has come online</a>
<a name="2132"><span class="lineNum">    2132 </span>            :  * at least once since boot.  This kthread checks for newly posted</a>
<a name="2133"><span class="lineNum">    2133 </span>            :  * callbacks from any of the CPUs it is responsible for, waits for a</a>
<a name="2134"><span class="lineNum">    2134 </span>            :  * grace period, then awakens all of the rcu_nocb_cb_kthread() instances</a>
<a name="2135"><span class="lineNum">    2135 </span>            :  * that then have callback-invocation work to do.</a>
<a name="2136"><span class="lineNum">    2136 </span>            :  */</a>
<a name="2137"><span class="lineNum">    2137 </span>            : static int rcu_nocb_gp_kthread(void *arg)</a>
<a name="2138"><span class="lineNum">    2138 </span>            : {</a>
<a name="2139"><span class="lineNum">    2139 </span>            :         struct rcu_data *rdp = arg;</a>
<a name="2140"><span class="lineNum">    2140 </span>            : </a>
<a name="2141"><span class="lineNum">    2141 </span>            :         for (;;) {</a>
<a name="2142"><span class="lineNum">    2142 </span>            :                 WRITE_ONCE(rdp-&gt;nocb_gp_loops, rdp-&gt;nocb_gp_loops + 1);</a>
<a name="2143"><span class="lineNum">    2143 </span>            :                 nocb_gp_wait(rdp);</a>
<a name="2144"><span class="lineNum">    2144 </span>            :                 cond_resched_tasks_rcu_qs();</a>
<a name="2145"><span class="lineNum">    2145 </span>            :         }</a>
<a name="2146"><span class="lineNum">    2146 </span>            :         return 0;</a>
<a name="2147"><span class="lineNum">    2147 </span>            : }</a>
<a name="2148"><span class="lineNum">    2148 </span>            : </a>
<a name="2149"><span class="lineNum">    2149 </span>            : static inline bool nocb_cb_can_run(struct rcu_data *rdp)</a>
<a name="2150"><span class="lineNum">    2150 </span>            : {</a>
<a name="2151"><span class="lineNum">    2151 </span>            :         u8 flags = SEGCBLIST_OFFLOADED | SEGCBLIST_KTHREAD_CB;</a>
<a name="2152"><span class="lineNum">    2152 </span>            :         return rcu_segcblist_test_flags(&amp;rdp-&gt;cblist, flags);</a>
<a name="2153"><span class="lineNum">    2153 </span>            : }</a>
<a name="2154"><span class="lineNum">    2154 </span>            : </a>
<a name="2155"><span class="lineNum">    2155 </span>            : static inline bool nocb_cb_wait_cond(struct rcu_data *rdp)</a>
<a name="2156"><span class="lineNum">    2156 </span>            : {</a>
<a name="2157"><span class="lineNum">    2157 </span>            :         return nocb_cb_can_run(rdp) &amp;&amp; !READ_ONCE(rdp-&gt;nocb_cb_sleep);</a>
<a name="2158"><span class="lineNum">    2158 </span>            : }</a>
<a name="2159"><span class="lineNum">    2159 </span>            : </a>
<a name="2160"><span class="lineNum">    2160 </span>            : /*</a>
<a name="2161"><span class="lineNum">    2161 </span>            :  * Invoke any ready callbacks from the corresponding no-CBs CPU,</a>
<a name="2162"><span class="lineNum">    2162 </span>            :  * then, if there are no more, wait for more to appear.</a>
<a name="2163"><span class="lineNum">    2163 </span>            :  */</a>
<a name="2164"><span class="lineNum">    2164 </span>            : static void nocb_cb_wait(struct rcu_data *rdp)</a>
<a name="2165"><span class="lineNum">    2165 </span>            : {</a>
<a name="2166"><span class="lineNum">    2166 </span>            :         struct rcu_segcblist *cblist = &amp;rdp-&gt;cblist;</a>
<a name="2167"><span class="lineNum">    2167 </span>            :         unsigned long cur_gp_seq;</a>
<a name="2168"><span class="lineNum">    2168 </span>            :         unsigned long flags;</a>
<a name="2169"><span class="lineNum">    2169 </span>            :         bool needwake_state = false;</a>
<a name="2170"><span class="lineNum">    2170 </span>            :         bool needwake_gp = false;</a>
<a name="2171"><span class="lineNum">    2171 </span>            :         struct rcu_node *rnp = rdp-&gt;mynode;</a>
<a name="2172"><span class="lineNum">    2172 </span>            : </a>
<a name="2173"><span class="lineNum">    2173 </span>            :         local_irq_save(flags);</a>
<a name="2174"><span class="lineNum">    2174 </span>            :         rcu_momentary_dyntick_idle();</a>
<a name="2175"><span class="lineNum">    2175 </span>            :         local_irq_restore(flags);</a>
<a name="2176"><span class="lineNum">    2176 </span>            :         local_bh_disable();</a>
<a name="2177"><span class="lineNum">    2177 </span>            :         rcu_do_batch(rdp);</a>
<a name="2178"><span class="lineNum">    2178 </span>            :         local_bh_enable();</a>
<a name="2179"><span class="lineNum">    2179 </span>            :         lockdep_assert_irqs_enabled();</a>
<a name="2180"><span class="lineNum">    2180 </span>            :         rcu_nocb_lock_irqsave(rdp, flags);</a>
<a name="2181"><span class="lineNum">    2181 </span>            :         if (rcu_segcblist_nextgp(cblist, &amp;cur_gp_seq) &amp;&amp;</a>
<a name="2182"><span class="lineNum">    2182 </span>            :             rcu_seq_done(&amp;rnp-&gt;gp_seq, cur_gp_seq) &amp;&amp;</a>
<a name="2183"><span class="lineNum">    2183 </span>            :             raw_spin_trylock_rcu_node(rnp)) { /* irqs already disabled. */</a>
<a name="2184"><span class="lineNum">    2184 </span>            :                 needwake_gp = rcu_advance_cbs(rdp-&gt;mynode, rdp);</a>
<a name="2185"><span class="lineNum">    2185 </span>            :                 raw_spin_unlock_rcu_node(rnp); /* irqs remain disabled. */</a>
<a name="2186"><span class="lineNum">    2186 </span>            :         }</a>
<a name="2187"><span class="lineNum">    2187 </span>            : </a>
<a name="2188"><span class="lineNum">    2188 </span>            :         WRITE_ONCE(rdp-&gt;nocb_cb_sleep, true);</a>
<a name="2189"><span class="lineNum">    2189 </span>            : </a>
<a name="2190"><span class="lineNum">    2190 </span>            :         if (rcu_segcblist_test_flags(cblist, SEGCBLIST_OFFLOADED)) {</a>
<a name="2191"><span class="lineNum">    2191 </span>            :                 if (!rcu_segcblist_test_flags(cblist, SEGCBLIST_KTHREAD_CB)) {</a>
<a name="2192"><span class="lineNum">    2192 </span>            :                         rcu_segcblist_set_flags(cblist, SEGCBLIST_KTHREAD_CB);</a>
<a name="2193"><span class="lineNum">    2193 </span>            :                         if (rcu_segcblist_test_flags(cblist, SEGCBLIST_KTHREAD_GP))</a>
<a name="2194"><span class="lineNum">    2194 </span>            :                                 needwake_state = true;</a>
<a name="2195"><span class="lineNum">    2195 </span>            :                 }</a>
<a name="2196"><span class="lineNum">    2196 </span>            :                 if (rcu_segcblist_ready_cbs(cblist))</a>
<a name="2197"><span class="lineNum">    2197 </span>            :                         WRITE_ONCE(rdp-&gt;nocb_cb_sleep, false);</a>
<a name="2198"><span class="lineNum">    2198 </span>            :         } else {</a>
<a name="2199"><span class="lineNum">    2199 </span>            :                 /*</a>
<a name="2200"><span class="lineNum">    2200 </span>            :                  * De-offloading. Clear our flag and notify the de-offload worker.</a>
<a name="2201"><span class="lineNum">    2201 </span>            :                  * We won't touch the callbacks and keep sleeping until we ever</a>
<a name="2202"><span class="lineNum">    2202 </span>            :                  * get re-offloaded.</a>
<a name="2203"><span class="lineNum">    2203 </span>            :                  */</a>
<a name="2204"><span class="lineNum">    2204 </span>            :                 WARN_ON_ONCE(!rcu_segcblist_test_flags(cblist, SEGCBLIST_KTHREAD_CB));</a>
<a name="2205"><span class="lineNum">    2205 </span>            :                 rcu_segcblist_clear_flags(cblist, SEGCBLIST_KTHREAD_CB);</a>
<a name="2206"><span class="lineNum">    2206 </span>            :                 if (!rcu_segcblist_test_flags(cblist, SEGCBLIST_KTHREAD_GP))</a>
<a name="2207"><span class="lineNum">    2207 </span>            :                         needwake_state = true;</a>
<a name="2208"><span class="lineNum">    2208 </span>            :         }</a>
<a name="2209"><span class="lineNum">    2209 </span>            : </a>
<a name="2210"><span class="lineNum">    2210 </span>            :         if (rdp-&gt;nocb_cb_sleep)</a>
<a name="2211"><span class="lineNum">    2211 </span>            :                 trace_rcu_nocb_wake(rcu_state.name, rdp-&gt;cpu, TPS(&quot;CBSleep&quot;));</a>
<a name="2212"><span class="lineNum">    2212 </span>            : </a>
<a name="2213"><span class="lineNum">    2213 </span>            :         rcu_nocb_unlock_irqrestore(rdp, flags);</a>
<a name="2214"><span class="lineNum">    2214 </span>            :         if (needwake_gp)</a>
<a name="2215"><span class="lineNum">    2215 </span>            :                 rcu_gp_kthread_wake();</a>
<a name="2216"><span class="lineNum">    2216 </span>            : </a>
<a name="2217"><span class="lineNum">    2217 </span>            :         if (needwake_state)</a>
<a name="2218"><span class="lineNum">    2218 </span>            :                 swake_up_one(&amp;rdp-&gt;nocb_state_wq);</a>
<a name="2219"><span class="lineNum">    2219 </span>            : </a>
<a name="2220"><span class="lineNum">    2220 </span>            :         do {</a>
<a name="2221"><span class="lineNum">    2221 </span>            :                 swait_event_interruptible_exclusive(rdp-&gt;nocb_cb_wq,</a>
<a name="2222"><span class="lineNum">    2222 </span>            :                                                     nocb_cb_wait_cond(rdp));</a>
<a name="2223"><span class="lineNum">    2223 </span>            : </a>
<a name="2224"><span class="lineNum">    2224 </span>            :                 // VVV Ensure CB invocation follows _sleep test.</a>
<a name="2225"><span class="lineNum">    2225 </span>            :                 if (smp_load_acquire(&amp;rdp-&gt;nocb_cb_sleep)) { // ^^^</a>
<a name="2226"><span class="lineNum">    2226 </span>            :                         WARN_ON(signal_pending(current));</a>
<a name="2227"><span class="lineNum">    2227 </span>            :                         trace_rcu_nocb_wake(rcu_state.name, rdp-&gt;cpu, TPS(&quot;WokeEmpty&quot;));</a>
<a name="2228"><span class="lineNum">    2228 </span>            :                 }</a>
<a name="2229"><span class="lineNum">    2229 </span>            :         } while (!nocb_cb_can_run(rdp));</a>
<a name="2230"><span class="lineNum">    2230 </span>            : }</a>
<a name="2231"><span class="lineNum">    2231 </span>            : </a>
<a name="2232"><span class="lineNum">    2232 </span>            : /*</a>
<a name="2233"><span class="lineNum">    2233 </span>            :  * Per-rcu_data kthread, but only for no-CBs CPUs.  Repeatedly invoke</a>
<a name="2234"><span class="lineNum">    2234 </span>            :  * nocb_cb_wait() to do the dirty work.</a>
<a name="2235"><span class="lineNum">    2235 </span>            :  */</a>
<a name="2236"><span class="lineNum">    2236 </span>            : static int rcu_nocb_cb_kthread(void *arg)</a>
<a name="2237"><span class="lineNum">    2237 </span>            : {</a>
<a name="2238"><span class="lineNum">    2238 </span>            :         struct rcu_data *rdp = arg;</a>
<a name="2239"><span class="lineNum">    2239 </span>            : </a>
<a name="2240"><span class="lineNum">    2240 </span>            :         // Each pass through this loop does one callback batch, and,</a>
<a name="2241"><span class="lineNum">    2241 </span>            :         // if there are no more ready callbacks, waits for them.</a>
<a name="2242"><span class="lineNum">    2242 </span>            :         for (;;) {</a>
<a name="2243"><span class="lineNum">    2243 </span>            :                 nocb_cb_wait(rdp);</a>
<a name="2244"><span class="lineNum">    2244 </span>            :                 cond_resched_tasks_rcu_qs();</a>
<a name="2245"><span class="lineNum">    2245 </span>            :         }</a>
<a name="2246"><span class="lineNum">    2246 </span>            :         return 0;</a>
<a name="2247"><span class="lineNum">    2247 </span>            : }</a>
<a name="2248"><span class="lineNum">    2248 </span>            : </a>
<a name="2249"><span class="lineNum">    2249 </span>            : /* Is a deferred wakeup of rcu_nocb_kthread() required? */</a>
<a name="2250"><span class="lineNum">    2250 </span>            : static int rcu_nocb_need_deferred_wakeup(struct rcu_data *rdp)</a>
<a name="2251"><span class="lineNum">    2251 </span>            : {</a>
<a name="2252"><span class="lineNum">    2252 </span>            :         return READ_ONCE(rdp-&gt;nocb_defer_wakeup) &gt; RCU_NOCB_WAKE_NOT;</a>
<a name="2253"><span class="lineNum">    2253 </span>            : }</a>
<a name="2254"><span class="lineNum">    2254 </span>            : </a>
<a name="2255"><span class="lineNum">    2255 </span>            : /* Do a deferred wakeup of rcu_nocb_kthread(). */</a>
<a name="2256"><span class="lineNum">    2256 </span>            : static bool do_nocb_deferred_wakeup_common(struct rcu_data *rdp)</a>
<a name="2257"><span class="lineNum">    2257 </span>            : {</a>
<a name="2258"><span class="lineNum">    2258 </span>            :         unsigned long flags;</a>
<a name="2259"><span class="lineNum">    2259 </span>            :         int ndw;</a>
<a name="2260"><span class="lineNum">    2260 </span>            :         int ret;</a>
<a name="2261"><span class="lineNum">    2261 </span>            : </a>
<a name="2262"><span class="lineNum">    2262 </span>            :         rcu_nocb_lock_irqsave(rdp, flags);</a>
<a name="2263"><span class="lineNum">    2263 </span>            :         if (!rcu_nocb_need_deferred_wakeup(rdp)) {</a>
<a name="2264"><span class="lineNum">    2264 </span>            :                 rcu_nocb_unlock_irqrestore(rdp, flags);</a>
<a name="2265"><span class="lineNum">    2265 </span>            :                 return false;</a>
<a name="2266"><span class="lineNum">    2266 </span>            :         }</a>
<a name="2267"><span class="lineNum">    2267 </span>            :         ndw = READ_ONCE(rdp-&gt;nocb_defer_wakeup);</a>
<a name="2268"><span class="lineNum">    2268 </span>            :         WRITE_ONCE(rdp-&gt;nocb_defer_wakeup, RCU_NOCB_WAKE_NOT);</a>
<a name="2269"><span class="lineNum">    2269 </span>            :         ret = wake_nocb_gp(rdp, ndw == RCU_NOCB_WAKE_FORCE, flags);</a>
<a name="2270"><span class="lineNum">    2270 </span>            :         trace_rcu_nocb_wake(rcu_state.name, rdp-&gt;cpu, TPS(&quot;DeferredWake&quot;));</a>
<a name="2271"><span class="lineNum">    2271 </span>            : </a>
<a name="2272"><span class="lineNum">    2272 </span>            :         return ret;</a>
<a name="2273"><span class="lineNum">    2273 </span>            : }</a>
<a name="2274"><span class="lineNum">    2274 </span>            : </a>
<a name="2275"><span class="lineNum">    2275 </span>            : /* Do a deferred wakeup of rcu_nocb_kthread() from a timer handler. */</a>
<a name="2276"><span class="lineNum">    2276 </span>            : static void do_nocb_deferred_wakeup_timer(struct timer_list *t)</a>
<a name="2277"><span class="lineNum">    2277 </span>            : {</a>
<a name="2278"><span class="lineNum">    2278 </span>            :         struct rcu_data *rdp = from_timer(rdp, t, nocb_timer);</a>
<a name="2279"><span class="lineNum">    2279 </span>            : </a>
<a name="2280"><span class="lineNum">    2280 </span>            :         do_nocb_deferred_wakeup_common(rdp);</a>
<a name="2281"><span class="lineNum">    2281 </span>            : }</a>
<a name="2282"><span class="lineNum">    2282 </span>            : </a>
<a name="2283"><span class="lineNum">    2283 </span>            : /*</a>
<a name="2284"><span class="lineNum">    2284 </span>            :  * Do a deferred wakeup of rcu_nocb_kthread() from fastpath.</a>
<a name="2285"><span class="lineNum">    2285 </span>            :  * This means we do an inexact common-case check.  Note that if</a>
<a name="2286"><span class="lineNum">    2286 </span>            :  * we miss, -&gt;nocb_timer will eventually clean things up.</a>
<a name="2287"><span class="lineNum">    2287 </span>            :  */</a>
<a name="2288"><span class="lineNum">    2288 </span>            : static bool do_nocb_deferred_wakeup(struct rcu_data *rdp)</a>
<a name="2289"><span class="lineNum">    2289 </span>            : {</a>
<a name="2290"><span class="lineNum">    2290 </span>            :         if (rcu_nocb_need_deferred_wakeup(rdp))</a>
<a name="2291"><span class="lineNum">    2291 </span>            :                 return do_nocb_deferred_wakeup_common(rdp);</a>
<a name="2292"><span class="lineNum">    2292 </span>            :         return false;</a>
<a name="2293"><span class="lineNum">    2293 </span>            : }</a>
<a name="2294"><span class="lineNum">    2294 </span>            : </a>
<a name="2295"><span class="lineNum">    2295 </span>            : void rcu_nocb_flush_deferred_wakeup(void)</a>
<a name="2296"><span class="lineNum">    2296 </span>            : {</a>
<a name="2297"><span class="lineNum">    2297 </span>            :         do_nocb_deferred_wakeup(this_cpu_ptr(&amp;rcu_data));</a>
<a name="2298"><span class="lineNum">    2298 </span>            : }</a>
<a name="2299"><span class="lineNum">    2299 </span>            : EXPORT_SYMBOL_GPL(rcu_nocb_flush_deferred_wakeup);</a>
<a name="2300"><span class="lineNum">    2300 </span>            : </a>
<a name="2301"><span class="lineNum">    2301 </span>            : static int rdp_offload_toggle(struct rcu_data *rdp,</a>
<a name="2302"><span class="lineNum">    2302 </span>            :                                bool offload, unsigned long flags)</a>
<a name="2303"><span class="lineNum">    2303 </span>            :         __releases(rdp-&gt;nocb_lock)</a>
<a name="2304"><span class="lineNum">    2304 </span>            : {</a>
<a name="2305"><span class="lineNum">    2305 </span>            :         struct rcu_segcblist *cblist = &amp;rdp-&gt;cblist;</a>
<a name="2306"><span class="lineNum">    2306 </span>            :         struct rcu_data *rdp_gp = rdp-&gt;nocb_gp_rdp;</a>
<a name="2307"><span class="lineNum">    2307 </span>            :         bool wake_gp = false;</a>
<a name="2308"><span class="lineNum">    2308 </span>            : </a>
<a name="2309"><span class="lineNum">    2309 </span>            :         rcu_segcblist_offload(cblist, offload);</a>
<a name="2310"><span class="lineNum">    2310 </span>            : </a>
<a name="2311"><span class="lineNum">    2311 </span>            :         if (rdp-&gt;nocb_cb_sleep)</a>
<a name="2312"><span class="lineNum">    2312 </span>            :                 rdp-&gt;nocb_cb_sleep = false;</a>
<a name="2313"><span class="lineNum">    2313 </span>            :         rcu_nocb_unlock_irqrestore(rdp, flags);</a>
<a name="2314"><span class="lineNum">    2314 </span>            : </a>
<a name="2315"><span class="lineNum">    2315 </span>            :         /*</a>
<a name="2316"><span class="lineNum">    2316 </span>            :          * Ignore former value of nocb_cb_sleep and force wake up as it could</a>
<a name="2317"><span class="lineNum">    2317 </span>            :          * have been spuriously set to false already.</a>
<a name="2318"><span class="lineNum">    2318 </span>            :          */</a>
<a name="2319"><span class="lineNum">    2319 </span>            :         swake_up_one(&amp;rdp-&gt;nocb_cb_wq);</a>
<a name="2320"><span class="lineNum">    2320 </span>            : </a>
<a name="2321"><span class="lineNum">    2321 </span>            :         raw_spin_lock_irqsave(&amp;rdp_gp-&gt;nocb_gp_lock, flags);</a>
<a name="2322"><span class="lineNum">    2322 </span>            :         if (rdp_gp-&gt;nocb_gp_sleep) {</a>
<a name="2323"><span class="lineNum">    2323 </span>            :                 rdp_gp-&gt;nocb_gp_sleep = false;</a>
<a name="2324"><span class="lineNum">    2324 </span>            :                 wake_gp = true;</a>
<a name="2325"><span class="lineNum">    2325 </span>            :         }</a>
<a name="2326"><span class="lineNum">    2326 </span>            :         raw_spin_unlock_irqrestore(&amp;rdp_gp-&gt;nocb_gp_lock, flags);</a>
<a name="2327"><span class="lineNum">    2327 </span>            : </a>
<a name="2328"><span class="lineNum">    2328 </span>            :         if (wake_gp)</a>
<a name="2329"><span class="lineNum">    2329 </span>            :                 wake_up_process(rdp_gp-&gt;nocb_gp_kthread);</a>
<a name="2330"><span class="lineNum">    2330 </span>            : </a>
<a name="2331"><span class="lineNum">    2331 </span>            :         return 0;</a>
<a name="2332"><span class="lineNum">    2332 </span>            : }</a>
<a name="2333"><span class="lineNum">    2333 </span>            : </a>
<a name="2334"><span class="lineNum">    2334 </span>            : static int __rcu_nocb_rdp_deoffload(struct rcu_data *rdp)</a>
<a name="2335"><span class="lineNum">    2335 </span>            : {</a>
<a name="2336"><span class="lineNum">    2336 </span>            :         struct rcu_segcblist *cblist = &amp;rdp-&gt;cblist;</a>
<a name="2337"><span class="lineNum">    2337 </span>            :         unsigned long flags;</a>
<a name="2338"><span class="lineNum">    2338 </span>            :         int ret;</a>
<a name="2339"><span class="lineNum">    2339 </span>            : </a>
<a name="2340"><span class="lineNum">    2340 </span>            :         pr_info(&quot;De-offloading %d\n&quot;, rdp-&gt;cpu);</a>
<a name="2341"><span class="lineNum">    2341 </span>            : </a>
<a name="2342"><span class="lineNum">    2342 </span>            :         rcu_nocb_lock_irqsave(rdp, flags);</a>
<a name="2343"><span class="lineNum">    2343 </span>            :         /*</a>
<a name="2344"><span class="lineNum">    2344 </span>            :          * If there are still pending work offloaded, the offline</a>
<a name="2345"><span class="lineNum">    2345 </span>            :          * CPU won't help much handling them.</a>
<a name="2346"><span class="lineNum">    2346 </span>            :          */</a>
<a name="2347"><span class="lineNum">    2347 </span>            :         if (cpu_is_offline(rdp-&gt;cpu) &amp;&amp; !rcu_segcblist_empty(&amp;rdp-&gt;cblist)) {</a>
<a name="2348"><span class="lineNum">    2348 </span>            :                 rcu_nocb_unlock_irqrestore(rdp, flags);</a>
<a name="2349"><span class="lineNum">    2349 </span>            :                 return -EBUSY;</a>
<a name="2350"><span class="lineNum">    2350 </span>            :         }</a>
<a name="2351"><span class="lineNum">    2351 </span>            : </a>
<a name="2352"><span class="lineNum">    2352 </span>            :         ret = rdp_offload_toggle(rdp, false, flags);</a>
<a name="2353"><span class="lineNum">    2353 </span>            :         swait_event_exclusive(rdp-&gt;nocb_state_wq,</a>
<a name="2354"><span class="lineNum">    2354 </span>            :                               !rcu_segcblist_test_flags(cblist, SEGCBLIST_KTHREAD_CB |</a>
<a name="2355"><span class="lineNum">    2355 </span>            :                                                         SEGCBLIST_KTHREAD_GP));</a>
<a name="2356"><span class="lineNum">    2356 </span>            :         rcu_nocb_lock_irqsave(rdp, flags);</a>
<a name="2357"><span class="lineNum">    2357 </span>            :         /* Make sure nocb timer won't stay around */</a>
<a name="2358"><span class="lineNum">    2358 </span>            :         WRITE_ONCE(rdp-&gt;nocb_defer_wakeup, RCU_NOCB_WAKE_OFF);</a>
<a name="2359"><span class="lineNum">    2359 </span>            :         rcu_nocb_unlock_irqrestore(rdp, flags);</a>
<a name="2360"><span class="lineNum">    2360 </span>            :         del_timer_sync(&amp;rdp-&gt;nocb_timer);</a>
<a name="2361"><span class="lineNum">    2361 </span>            : </a>
<a name="2362"><span class="lineNum">    2362 </span>            :         /*</a>
<a name="2363"><span class="lineNum">    2363 </span>            :          * Flush bypass. While IRQs are disabled and once we set</a>
<a name="2364"><span class="lineNum">    2364 </span>            :          * SEGCBLIST_SOFTIRQ_ONLY, no callback is supposed to be</a>
<a name="2365"><span class="lineNum">    2365 </span>            :          * enqueued on bypass.</a>
<a name="2366"><span class="lineNum">    2366 </span>            :          */</a>
<a name="2367"><span class="lineNum">    2367 </span>            :         rcu_nocb_lock_irqsave(rdp, flags);</a>
<a name="2368"><span class="lineNum">    2368 </span>            :         rcu_nocb_flush_bypass(rdp, NULL, jiffies);</a>
<a name="2369"><span class="lineNum">    2369 </span>            :         rcu_segcblist_set_flags(cblist, SEGCBLIST_SOFTIRQ_ONLY);</a>
<a name="2370"><span class="lineNum">    2370 </span>            :         /*</a>
<a name="2371"><span class="lineNum">    2371 </span>            :          * With SEGCBLIST_SOFTIRQ_ONLY, we can't use</a>
<a name="2372"><span class="lineNum">    2372 </span>            :          * rcu_nocb_unlock_irqrestore() anymore. Theoretically we</a>
<a name="2373"><span class="lineNum">    2373 </span>            :          * could set SEGCBLIST_SOFTIRQ_ONLY with cb unlocked and IRQs</a>
<a name="2374"><span class="lineNum">    2374 </span>            :          * disabled now, but let's be paranoid.</a>
<a name="2375"><span class="lineNum">    2375 </span>            :          */</a>
<a name="2376"><span class="lineNum">    2376 </span>            :         raw_spin_unlock_irqrestore(&amp;rdp-&gt;nocb_lock, flags);</a>
<a name="2377"><span class="lineNum">    2377 </span>            : </a>
<a name="2378"><span class="lineNum">    2378 </span>            :         return ret;</a>
<a name="2379"><span class="lineNum">    2379 </span>            : }</a>
<a name="2380"><span class="lineNum">    2380 </span>            : </a>
<a name="2381"><span class="lineNum">    2381 </span>            : static long rcu_nocb_rdp_deoffload(void *arg)</a>
<a name="2382"><span class="lineNum">    2382 </span>            : {</a>
<a name="2383"><span class="lineNum">    2383 </span>            :         struct rcu_data *rdp = arg;</a>
<a name="2384"><span class="lineNum">    2384 </span>            : </a>
<a name="2385"><span class="lineNum">    2385 </span>            :         WARN_ON_ONCE(rdp-&gt;cpu != raw_smp_processor_id());</a>
<a name="2386"><span class="lineNum">    2386 </span>            :         return __rcu_nocb_rdp_deoffload(rdp);</a>
<a name="2387"><span class="lineNum">    2387 </span>            : }</a>
<a name="2388"><span class="lineNum">    2388 </span>            : </a>
<a name="2389"><span class="lineNum">    2389 </span>            : int rcu_nocb_cpu_deoffload(int cpu)</a>
<a name="2390"><span class="lineNum">    2390 </span>            : {</a>
<a name="2391"><span class="lineNum">    2391 </span>            :         struct rcu_data *rdp = per_cpu_ptr(&amp;rcu_data, cpu);</a>
<a name="2392"><span class="lineNum">    2392 </span>            :         int ret = 0;</a>
<a name="2393"><span class="lineNum">    2393 </span>            : </a>
<a name="2394"><span class="lineNum">    2394 </span>            :         if (rdp == rdp-&gt;nocb_gp_rdp) {</a>
<a name="2395"><span class="lineNum">    2395 </span>            :                 pr_info(&quot;Can't deoffload an rdp GP leader (yet)\n&quot;);</a>
<a name="2396"><span class="lineNum">    2396 </span>            :                 return -EINVAL;</a>
<a name="2397"><span class="lineNum">    2397 </span>            :         }</a>
<a name="2398"><span class="lineNum">    2398 </span>            :         mutex_lock(&amp;rcu_state.barrier_mutex);</a>
<a name="2399"><span class="lineNum">    2399 </span>            :         cpus_read_lock();</a>
<a name="2400"><span class="lineNum">    2400 </span>            :         if (rcu_segcblist_is_offloaded(&amp;rdp-&gt;cblist)) {</a>
<a name="2401"><span class="lineNum">    2401 </span>            :                 if (cpu_online(cpu))</a>
<a name="2402"><span class="lineNum">    2402 </span>            :                         ret = work_on_cpu(cpu, rcu_nocb_rdp_deoffload, rdp);</a>
<a name="2403"><span class="lineNum">    2403 </span>            :                 else</a>
<a name="2404"><span class="lineNum">    2404 </span>            :                         ret = __rcu_nocb_rdp_deoffload(rdp);</a>
<a name="2405"><span class="lineNum">    2405 </span>            :                 if (!ret)</a>
<a name="2406"><span class="lineNum">    2406 </span>            :                         cpumask_clear_cpu(cpu, rcu_nocb_mask);</a>
<a name="2407"><span class="lineNum">    2407 </span>            :         }</a>
<a name="2408"><span class="lineNum">    2408 </span>            :         cpus_read_unlock();</a>
<a name="2409"><span class="lineNum">    2409 </span>            :         mutex_unlock(&amp;rcu_state.barrier_mutex);</a>
<a name="2410"><span class="lineNum">    2410 </span>            : </a>
<a name="2411"><span class="lineNum">    2411 </span>            :         return ret;</a>
<a name="2412"><span class="lineNum">    2412 </span>            : }</a>
<a name="2413"><span class="lineNum">    2413 </span>            : EXPORT_SYMBOL_GPL(rcu_nocb_cpu_deoffload);</a>
<a name="2414"><span class="lineNum">    2414 </span>            : </a>
<a name="2415"><span class="lineNum">    2415 </span>            : static int __rcu_nocb_rdp_offload(struct rcu_data *rdp)</a>
<a name="2416"><span class="lineNum">    2416 </span>            : {</a>
<a name="2417"><span class="lineNum">    2417 </span>            :         struct rcu_segcblist *cblist = &amp;rdp-&gt;cblist;</a>
<a name="2418"><span class="lineNum">    2418 </span>            :         unsigned long flags;</a>
<a name="2419"><span class="lineNum">    2419 </span>            :         int ret;</a>
<a name="2420"><span class="lineNum">    2420 </span>            : </a>
<a name="2421"><span class="lineNum">    2421 </span>            :         /*</a>
<a name="2422"><span class="lineNum">    2422 </span>            :          * For now we only support re-offload, ie: the rdp must have been</a>
<a name="2423"><span class="lineNum">    2423 </span>            :          * offloaded on boot first.</a>
<a name="2424"><span class="lineNum">    2424 </span>            :          */</a>
<a name="2425"><span class="lineNum">    2425 </span>            :         if (!rdp-&gt;nocb_gp_rdp)</a>
<a name="2426"><span class="lineNum">    2426 </span>            :                 return -EINVAL;</a>
<a name="2427"><span class="lineNum">    2427 </span>            : </a>
<a name="2428"><span class="lineNum">    2428 </span>            :         pr_info(&quot;Offloading %d\n&quot;, rdp-&gt;cpu);</a>
<a name="2429"><span class="lineNum">    2429 </span>            :         /*</a>
<a name="2430"><span class="lineNum">    2430 </span>            :          * Can't use rcu_nocb_lock_irqsave() while we are in</a>
<a name="2431"><span class="lineNum">    2431 </span>            :          * SEGCBLIST_SOFTIRQ_ONLY mode.</a>
<a name="2432"><span class="lineNum">    2432 </span>            :          */</a>
<a name="2433"><span class="lineNum">    2433 </span>            :         raw_spin_lock_irqsave(&amp;rdp-&gt;nocb_lock, flags);</a>
<a name="2434"><span class="lineNum">    2434 </span>            :         /* Re-enable nocb timer */</a>
<a name="2435"><span class="lineNum">    2435 </span>            :         WRITE_ONCE(rdp-&gt;nocb_defer_wakeup, RCU_NOCB_WAKE_NOT);</a>
<a name="2436"><span class="lineNum">    2436 </span>            :         /*</a>
<a name="2437"><span class="lineNum">    2437 </span>            :          * We didn't take the nocb lock while working on the</a>
<a name="2438"><span class="lineNum">    2438 </span>            :          * rdp-&gt;cblist in SEGCBLIST_SOFTIRQ_ONLY mode.</a>
<a name="2439"><span class="lineNum">    2439 </span>            :          * Every modifications that have been done previously on</a>
<a name="2440"><span class="lineNum">    2440 </span>            :          * rdp-&gt;cblist must be visible remotely by the nocb kthreads</a>
<a name="2441"><span class="lineNum">    2441 </span>            :          * upon wake up after reading the cblist flags.</a>
<a name="2442"><span class="lineNum">    2442 </span>            :          *</a>
<a name="2443"><span class="lineNum">    2443 </span>            :          * The layout against nocb_lock enforces that ordering:</a>
<a name="2444"><span class="lineNum">    2444 </span>            :          *</a>
<a name="2445"><span class="lineNum">    2445 </span>            :          *  __rcu_nocb_rdp_offload()   nocb_cb_wait()/nocb_gp_wait()</a>
<a name="2446"><span class="lineNum">    2446 </span>            :          * -------------------------   ----------------------------</a>
<a name="2447"><span class="lineNum">    2447 </span>            :          *      WRITE callbacks           rcu_nocb_lock()</a>
<a name="2448"><span class="lineNum">    2448 </span>            :          *      rcu_nocb_lock()           READ flags</a>
<a name="2449"><span class="lineNum">    2449 </span>            :          *      WRITE flags               READ callbacks</a>
<a name="2450"><span class="lineNum">    2450 </span>            :          *      rcu_nocb_unlock()         rcu_nocb_unlock()</a>
<a name="2451"><span class="lineNum">    2451 </span>            :          */</a>
<a name="2452"><span class="lineNum">    2452 </span>            :         ret = rdp_offload_toggle(rdp, true, flags);</a>
<a name="2453"><span class="lineNum">    2453 </span>            :         swait_event_exclusive(rdp-&gt;nocb_state_wq,</a>
<a name="2454"><span class="lineNum">    2454 </span>            :                               rcu_segcblist_test_flags(cblist, SEGCBLIST_KTHREAD_CB) &amp;&amp;</a>
<a name="2455"><span class="lineNum">    2455 </span>            :                               rcu_segcblist_test_flags(cblist, SEGCBLIST_KTHREAD_GP));</a>
<a name="2456"><span class="lineNum">    2456 </span>            : </a>
<a name="2457"><span class="lineNum">    2457 </span>            :         return ret;</a>
<a name="2458"><span class="lineNum">    2458 </span>            : }</a>
<a name="2459"><span class="lineNum">    2459 </span>            : </a>
<a name="2460"><span class="lineNum">    2460 </span>            : static long rcu_nocb_rdp_offload(void *arg)</a>
<a name="2461"><span class="lineNum">    2461 </span>            : {</a>
<a name="2462"><span class="lineNum">    2462 </span>            :         struct rcu_data *rdp = arg;</a>
<a name="2463"><span class="lineNum">    2463 </span>            : </a>
<a name="2464"><span class="lineNum">    2464 </span>            :         WARN_ON_ONCE(rdp-&gt;cpu != raw_smp_processor_id());</a>
<a name="2465"><span class="lineNum">    2465 </span>            :         return __rcu_nocb_rdp_offload(rdp);</a>
<a name="2466"><span class="lineNum">    2466 </span>            : }</a>
<a name="2467"><span class="lineNum">    2467 </span>            : </a>
<a name="2468"><span class="lineNum">    2468 </span>            : int rcu_nocb_cpu_offload(int cpu)</a>
<a name="2469"><span class="lineNum">    2469 </span>            : {</a>
<a name="2470"><span class="lineNum">    2470 </span>            :         struct rcu_data *rdp = per_cpu_ptr(&amp;rcu_data, cpu);</a>
<a name="2471"><span class="lineNum">    2471 </span>            :         int ret = 0;</a>
<a name="2472"><span class="lineNum">    2472 </span>            : </a>
<a name="2473"><span class="lineNum">    2473 </span>            :         mutex_lock(&amp;rcu_state.barrier_mutex);</a>
<a name="2474"><span class="lineNum">    2474 </span>            :         cpus_read_lock();</a>
<a name="2475"><span class="lineNum">    2475 </span>            :         if (!rcu_segcblist_is_offloaded(&amp;rdp-&gt;cblist)) {</a>
<a name="2476"><span class="lineNum">    2476 </span>            :                 if (cpu_online(cpu))</a>
<a name="2477"><span class="lineNum">    2477 </span>            :                         ret = work_on_cpu(cpu, rcu_nocb_rdp_offload, rdp);</a>
<a name="2478"><span class="lineNum">    2478 </span>            :                 else</a>
<a name="2479"><span class="lineNum">    2479 </span>            :                         ret = __rcu_nocb_rdp_offload(rdp);</a>
<a name="2480"><span class="lineNum">    2480 </span>            :                 if (!ret)</a>
<a name="2481"><span class="lineNum">    2481 </span>            :                         cpumask_set_cpu(cpu, rcu_nocb_mask);</a>
<a name="2482"><span class="lineNum">    2482 </span>            :         }</a>
<a name="2483"><span class="lineNum">    2483 </span>            :         cpus_read_unlock();</a>
<a name="2484"><span class="lineNum">    2484 </span>            :         mutex_unlock(&amp;rcu_state.barrier_mutex);</a>
<a name="2485"><span class="lineNum">    2485 </span>            : </a>
<a name="2486"><span class="lineNum">    2486 </span>            :         return ret;</a>
<a name="2487"><span class="lineNum">    2487 </span>            : }</a>
<a name="2488"><span class="lineNum">    2488 </span>            : EXPORT_SYMBOL_GPL(rcu_nocb_cpu_offload);</a>
<a name="2489"><span class="lineNum">    2489 </span>            : </a>
<a name="2490"><span class="lineNum">    2490 </span>            : void __init rcu_init_nohz(void)</a>
<a name="2491"><span class="lineNum">    2491 </span>            : {</a>
<a name="2492"><span class="lineNum">    2492 </span>            :         int cpu;</a>
<a name="2493"><span class="lineNum">    2493 </span>            :         bool need_rcu_nocb_mask = false;</a>
<a name="2494"><span class="lineNum">    2494 </span>            :         struct rcu_data *rdp;</a>
<a name="2495"><span class="lineNum">    2495 </span>            : </a>
<a name="2496"><span class="lineNum">    2496 </span>            : #if defined(CONFIG_NO_HZ_FULL)</a>
<a name="2497"><span class="lineNum">    2497 </span>            :         if (tick_nohz_full_running &amp;&amp; cpumask_weight(tick_nohz_full_mask))</a>
<a name="2498"><span class="lineNum">    2498 </span>            :                 need_rcu_nocb_mask = true;</a>
<a name="2499"><span class="lineNum">    2499 </span>            : #endif /* #if defined(CONFIG_NO_HZ_FULL) */</a>
<a name="2500"><span class="lineNum">    2500 </span>            : </a>
<a name="2501"><span class="lineNum">    2501 </span>            :         if (!cpumask_available(rcu_nocb_mask) &amp;&amp; need_rcu_nocb_mask) {</a>
<a name="2502"><span class="lineNum">    2502 </span>            :                 if (!zalloc_cpumask_var(&amp;rcu_nocb_mask, GFP_KERNEL)) {</a>
<a name="2503"><span class="lineNum">    2503 </span>            :                         pr_info(&quot;rcu_nocb_mask allocation failed, callback offloading disabled.\n&quot;);</a>
<a name="2504"><span class="lineNum">    2504 </span>            :                         return;</a>
<a name="2505"><span class="lineNum">    2505 </span>            :                 }</a>
<a name="2506"><span class="lineNum">    2506 </span>            :         }</a>
<a name="2507"><span class="lineNum">    2507 </span>            :         if (!cpumask_available(rcu_nocb_mask))</a>
<a name="2508"><span class="lineNum">    2508 </span>            :                 return;</a>
<a name="2509"><span class="lineNum">    2509 </span>            : </a>
<a name="2510"><span class="lineNum">    2510 </span>            : #if defined(CONFIG_NO_HZ_FULL)</a>
<a name="2511"><span class="lineNum">    2511 </span>            :         if (tick_nohz_full_running)</a>
<a name="2512"><span class="lineNum">    2512 </span>            :                 cpumask_or(rcu_nocb_mask, rcu_nocb_mask, tick_nohz_full_mask);</a>
<a name="2513"><span class="lineNum">    2513 </span>            : #endif /* #if defined(CONFIG_NO_HZ_FULL) */</a>
<a name="2514"><span class="lineNum">    2514 </span>            : </a>
<a name="2515"><span class="lineNum">    2515 </span>            :         if (!cpumask_subset(rcu_nocb_mask, cpu_possible_mask)) {</a>
<a name="2516"><span class="lineNum">    2516 </span>            :                 pr_info(&quot;\tNote: kernel parameter 'rcu_nocbs=', 'nohz_full', or 'isolcpus=' contains nonexistent CPUs.\n&quot;);</a>
<a name="2517"><span class="lineNum">    2517 </span>            :                 cpumask_and(rcu_nocb_mask, cpu_possible_mask,</a>
<a name="2518"><span class="lineNum">    2518 </span>            :                             rcu_nocb_mask);</a>
<a name="2519"><span class="lineNum">    2519 </span>            :         }</a>
<a name="2520"><span class="lineNum">    2520 </span>            :         if (cpumask_empty(rcu_nocb_mask))</a>
<a name="2521"><span class="lineNum">    2521 </span>            :                 pr_info(&quot;\tOffload RCU callbacks from CPUs: (none).\n&quot;);</a>
<a name="2522"><span class="lineNum">    2522 </span>            :         else</a>
<a name="2523"><span class="lineNum">    2523 </span>            :                 pr_info(&quot;\tOffload RCU callbacks from CPUs: %*pbl.\n&quot;,</a>
<a name="2524"><span class="lineNum">    2524 </span>            :                         cpumask_pr_args(rcu_nocb_mask));</a>
<a name="2525"><span class="lineNum">    2525 </span>            :         if (rcu_nocb_poll)</a>
<a name="2526"><span class="lineNum">    2526 </span>            :                 pr_info(&quot;\tPoll for callbacks from no-CBs CPUs.\n&quot;);</a>
<a name="2527"><span class="lineNum">    2527 </span>            : </a>
<a name="2528"><span class="lineNum">    2528 </span>            :         for_each_cpu(cpu, rcu_nocb_mask) {</a>
<a name="2529"><span class="lineNum">    2529 </span>            :                 rdp = per_cpu_ptr(&amp;rcu_data, cpu);</a>
<a name="2530"><span class="lineNum">    2530 </span>            :                 if (rcu_segcblist_empty(&amp;rdp-&gt;cblist))</a>
<a name="2531"><span class="lineNum">    2531 </span>            :                         rcu_segcblist_init(&amp;rdp-&gt;cblist);</a>
<a name="2532"><span class="lineNum">    2532 </span>            :                 rcu_segcblist_offload(&amp;rdp-&gt;cblist, true);</a>
<a name="2533"><span class="lineNum">    2533 </span>            :                 rcu_segcblist_set_flags(&amp;rdp-&gt;cblist, SEGCBLIST_KTHREAD_CB);</a>
<a name="2534"><span class="lineNum">    2534 </span>            :                 rcu_segcblist_set_flags(&amp;rdp-&gt;cblist, SEGCBLIST_KTHREAD_GP);</a>
<a name="2535"><span class="lineNum">    2535 </span>            :         }</a>
<a name="2536"><span class="lineNum">    2536 </span>            :         rcu_organize_nocb_kthreads();</a>
<a name="2537"><span class="lineNum">    2537 </span>            : }</a>
<a name="2538"><span class="lineNum">    2538 </span>            : </a>
<a name="2539"><span class="lineNum">    2539 </span>            : /* Initialize per-rcu_data variables for no-CBs CPUs. */</a>
<a name="2540"><span class="lineNum">    2540 </span>            : static void __init rcu_boot_init_nocb_percpu_data(struct rcu_data *rdp)</a>
<a name="2541"><span class="lineNum">    2541 </span>            : {</a>
<a name="2542"><span class="lineNum">    2542 </span>            :         init_swait_queue_head(&amp;rdp-&gt;nocb_cb_wq);</a>
<a name="2543"><span class="lineNum">    2543 </span>            :         init_swait_queue_head(&amp;rdp-&gt;nocb_gp_wq);</a>
<a name="2544"><span class="lineNum">    2544 </span>            :         init_swait_queue_head(&amp;rdp-&gt;nocb_state_wq);</a>
<a name="2545"><span class="lineNum">    2545 </span>            :         raw_spin_lock_init(&amp;rdp-&gt;nocb_lock);</a>
<a name="2546"><span class="lineNum">    2546 </span>            :         raw_spin_lock_init(&amp;rdp-&gt;nocb_bypass_lock);</a>
<a name="2547"><span class="lineNum">    2547 </span>            :         raw_spin_lock_init(&amp;rdp-&gt;nocb_gp_lock);</a>
<a name="2548"><span class="lineNum">    2548 </span>            :         timer_setup(&amp;rdp-&gt;nocb_timer, do_nocb_deferred_wakeup_timer, 0);</a>
<a name="2549"><span class="lineNum">    2549 </span>            :         timer_setup(&amp;rdp-&gt;nocb_bypass_timer, do_nocb_bypass_wakeup_timer, 0);</a>
<a name="2550"><span class="lineNum">    2550 </span>            :         rcu_cblist_init(&amp;rdp-&gt;nocb_bypass);</a>
<a name="2551"><span class="lineNum">    2551 </span>            : }</a>
<a name="2552"><span class="lineNum">    2552 </span>            : </a>
<a name="2553"><span class="lineNum">    2553 </span>            : /*</a>
<a name="2554"><span class="lineNum">    2554 </span>            :  * If the specified CPU is a no-CBs CPU that does not already have its</a>
<a name="2555"><span class="lineNum">    2555 </span>            :  * rcuo CB kthread, spawn it.  Additionally, if the rcuo GP kthread</a>
<a name="2556"><span class="lineNum">    2556 </span>            :  * for this CPU's group has not yet been created, spawn it as well.</a>
<a name="2557"><span class="lineNum">    2557 </span>            :  */</a>
<a name="2558"><span class="lineNum">    2558 </span>            : static void rcu_spawn_one_nocb_kthread(int cpu)</a>
<a name="2559"><span class="lineNum">    2559 </span>            : {</a>
<a name="2560"><span class="lineNum">    2560 </span>            :         struct rcu_data *rdp = per_cpu_ptr(&amp;rcu_data, cpu);</a>
<a name="2561"><span class="lineNum">    2561 </span>            :         struct rcu_data *rdp_gp;</a>
<a name="2562"><span class="lineNum">    2562 </span>            :         struct task_struct *t;</a>
<a name="2563"><span class="lineNum">    2563 </span>            : </a>
<a name="2564"><span class="lineNum">    2564 </span>            :         /*</a>
<a name="2565"><span class="lineNum">    2565 </span>            :          * If this isn't a no-CBs CPU or if it already has an rcuo kthread,</a>
<a name="2566"><span class="lineNum">    2566 </span>            :          * then nothing to do.</a>
<a name="2567"><span class="lineNum">    2567 </span>            :          */</a>
<a name="2568"><span class="lineNum">    2568 </span>            :         if (!rcu_is_nocb_cpu(cpu) || rdp-&gt;nocb_cb_kthread)</a>
<a name="2569"><span class="lineNum">    2569 </span>            :                 return;</a>
<a name="2570"><span class="lineNum">    2570 </span>            : </a>
<a name="2571"><span class="lineNum">    2571 </span>            :         /* If we didn't spawn the GP kthread first, reorganize! */</a>
<a name="2572"><span class="lineNum">    2572 </span>            :         rdp_gp = rdp-&gt;nocb_gp_rdp;</a>
<a name="2573"><span class="lineNum">    2573 </span>            :         if (!rdp_gp-&gt;nocb_gp_kthread) {</a>
<a name="2574"><span class="lineNum">    2574 </span>            :                 t = kthread_run(rcu_nocb_gp_kthread, rdp_gp,</a>
<a name="2575"><span class="lineNum">    2575 </span>            :                                 &quot;rcuog/%d&quot;, rdp_gp-&gt;cpu);</a>
<a name="2576"><span class="lineNum">    2576 </span>            :                 if (WARN_ONCE(IS_ERR(t), &quot;%s: Could not start rcuo GP kthread, OOM is now expected behavior\n&quot;, __func__))</a>
<a name="2577"><span class="lineNum">    2577 </span>            :                         return;</a>
<a name="2578"><span class="lineNum">    2578 </span>            :                 WRITE_ONCE(rdp_gp-&gt;nocb_gp_kthread, t);</a>
<a name="2579"><span class="lineNum">    2579 </span>            :         }</a>
<a name="2580"><span class="lineNum">    2580 </span>            : </a>
<a name="2581"><span class="lineNum">    2581 </span>            :         /* Spawn the kthread for this CPU. */</a>
<a name="2582"><span class="lineNum">    2582 </span>            :         t = kthread_run(rcu_nocb_cb_kthread, rdp,</a>
<a name="2583"><span class="lineNum">    2583 </span>            :                         &quot;rcuo%c/%d&quot;, rcu_state.abbr, cpu);</a>
<a name="2584"><span class="lineNum">    2584 </span>            :         if (WARN_ONCE(IS_ERR(t), &quot;%s: Could not start rcuo CB kthread, OOM is now expected behavior\n&quot;, __func__))</a>
<a name="2585"><span class="lineNum">    2585 </span>            :                 return;</a>
<a name="2586"><span class="lineNum">    2586 </span>            :         WRITE_ONCE(rdp-&gt;nocb_cb_kthread, t);</a>
<a name="2587"><span class="lineNum">    2587 </span>            :         WRITE_ONCE(rdp-&gt;nocb_gp_kthread, rdp_gp-&gt;nocb_gp_kthread);</a>
<a name="2588"><span class="lineNum">    2588 </span>            : }</a>
<a name="2589"><span class="lineNum">    2589 </span>            : </a>
<a name="2590"><span class="lineNum">    2590 </span>            : /*</a>
<a name="2591"><span class="lineNum">    2591 </span>            :  * If the specified CPU is a no-CBs CPU that does not already have its</a>
<a name="2592"><span class="lineNum">    2592 </span>            :  * rcuo kthread, spawn it.</a>
<a name="2593"><span class="lineNum">    2593 </span>            :  */</a>
<a name="2594"><span class="lineNum">    2594 </span>            : static void rcu_spawn_cpu_nocb_kthread(int cpu)</a>
<a name="2595"><span class="lineNum">    2595 </span>            : {</a>
<a name="2596"><span class="lineNum">    2596 </span>            :         if (rcu_scheduler_fully_active)</a>
<a name="2597"><span class="lineNum">    2597 </span>            :                 rcu_spawn_one_nocb_kthread(cpu);</a>
<a name="2598"><span class="lineNum">    2598 </span>            : }</a>
<a name="2599"><span class="lineNum">    2599 </span>            : </a>
<a name="2600"><span class="lineNum">    2600 </span>            : /*</a>
<a name="2601"><span class="lineNum">    2601 </span>            :  * Once the scheduler is running, spawn rcuo kthreads for all online</a>
<a name="2602"><span class="lineNum">    2602 </span>            :  * no-CBs CPUs.  This assumes that the early_initcall()s happen before</a>
<a name="2603"><span class="lineNum">    2603 </span>            :  * non-boot CPUs come online -- if this changes, we will need to add</a>
<a name="2604"><span class="lineNum">    2604 </span>            :  * some mutual exclusion.</a>
<a name="2605"><span class="lineNum">    2605 </span>            :  */</a>
<a name="2606"><span class="lineNum">    2606 </span>            : static void __init rcu_spawn_nocb_kthreads(void)</a>
<a name="2607"><span class="lineNum">    2607 </span>            : {</a>
<a name="2608"><span class="lineNum">    2608 </span>            :         int cpu;</a>
<a name="2609"><span class="lineNum">    2609 </span>            : </a>
<a name="2610"><span class="lineNum">    2610 </span>            :         for_each_online_cpu(cpu)</a>
<a name="2611"><span class="lineNum">    2611 </span>            :                 rcu_spawn_cpu_nocb_kthread(cpu);</a>
<a name="2612"><span class="lineNum">    2612 </span>            : }</a>
<a name="2613"><span class="lineNum">    2613 </span>            : </a>
<a name="2614"><span class="lineNum">    2614 </span>            : /* How many CB CPU IDs per GP kthread?  Default of -1 for sqrt(nr_cpu_ids). */</a>
<a name="2615"><span class="lineNum">    2615 </span>            : static int rcu_nocb_gp_stride = -1;</a>
<a name="2616"><span class="lineNum">    2616 </span>            : module_param(rcu_nocb_gp_stride, int, 0444);</a>
<a name="2617"><span class="lineNum">    2617 </span>            : </a>
<a name="2618"><span class="lineNum">    2618 </span>            : /*</a>
<a name="2619"><span class="lineNum">    2619 </span>            :  * Initialize GP-CB relationships for all no-CBs CPU.</a>
<a name="2620"><span class="lineNum">    2620 </span>            :  */</a>
<a name="2621"><span class="lineNum">    2621 </span>            : static void __init rcu_organize_nocb_kthreads(void)</a>
<a name="2622"><span class="lineNum">    2622 </span>            : {</a>
<a name="2623"><span class="lineNum">    2623 </span>            :         int cpu;</a>
<a name="2624"><span class="lineNum">    2624 </span>            :         bool firsttime = true;</a>
<a name="2625"><span class="lineNum">    2625 </span>            :         bool gotnocbs = false;</a>
<a name="2626"><span class="lineNum">    2626 </span>            :         bool gotnocbscbs = true;</a>
<a name="2627"><span class="lineNum">    2627 </span>            :         int ls = rcu_nocb_gp_stride;</a>
<a name="2628"><span class="lineNum">    2628 </span>            :         int nl = 0;  /* Next GP kthread. */</a>
<a name="2629"><span class="lineNum">    2629 </span>            :         struct rcu_data *rdp;</a>
<a name="2630"><span class="lineNum">    2630 </span>            :         struct rcu_data *rdp_gp = NULL;  /* Suppress misguided gcc warn. */</a>
<a name="2631"><span class="lineNum">    2631 </span>            :         struct rcu_data *rdp_prev = NULL;</a>
<a name="2632"><span class="lineNum">    2632 </span>            : </a>
<a name="2633"><span class="lineNum">    2633 </span>            :         if (!cpumask_available(rcu_nocb_mask))</a>
<a name="2634"><span class="lineNum">    2634 </span>            :                 return;</a>
<a name="2635"><span class="lineNum">    2635 </span>            :         if (ls == -1) {</a>
<a name="2636"><span class="lineNum">    2636 </span>            :                 ls = nr_cpu_ids / int_sqrt(nr_cpu_ids);</a>
<a name="2637"><span class="lineNum">    2637 </span>            :                 rcu_nocb_gp_stride = ls;</a>
<a name="2638"><span class="lineNum">    2638 </span>            :         }</a>
<a name="2639"><span class="lineNum">    2639 </span>            : </a>
<a name="2640"><span class="lineNum">    2640 </span>            :         /*</a>
<a name="2641"><span class="lineNum">    2641 </span>            :          * Each pass through this loop sets up one rcu_data structure.</a>
<a name="2642"><span class="lineNum">    2642 </span>            :          * Should the corresponding CPU come online in the future, then</a>
<a name="2643"><span class="lineNum">    2643 </span>            :          * we will spawn the needed set of rcu_nocb_kthread() kthreads.</a>
<a name="2644"><span class="lineNum">    2644 </span>            :          */</a>
<a name="2645"><span class="lineNum">    2645 </span>            :         for_each_cpu(cpu, rcu_nocb_mask) {</a>
<a name="2646"><span class="lineNum">    2646 </span>            :                 rdp = per_cpu_ptr(&amp;rcu_data, cpu);</a>
<a name="2647"><span class="lineNum">    2647 </span>            :                 if (rdp-&gt;cpu &gt;= nl) {</a>
<a name="2648"><span class="lineNum">    2648 </span>            :                         /* New GP kthread, set up for CBs &amp; next GP. */</a>
<a name="2649"><span class="lineNum">    2649 </span>            :                         gotnocbs = true;</a>
<a name="2650"><span class="lineNum">    2650 </span>            :                         nl = DIV_ROUND_UP(rdp-&gt;cpu + 1, ls) * ls;</a>
<a name="2651"><span class="lineNum">    2651 </span>            :                         rdp-&gt;nocb_gp_rdp = rdp;</a>
<a name="2652"><span class="lineNum">    2652 </span>            :                         rdp_gp = rdp;</a>
<a name="2653"><span class="lineNum">    2653 </span>            :                         if (dump_tree) {</a>
<a name="2654"><span class="lineNum">    2654 </span>            :                                 if (!firsttime)</a>
<a name="2655"><span class="lineNum">    2655 </span>            :                                         pr_cont(&quot;%s\n&quot;, gotnocbscbs</a>
<a name="2656"><span class="lineNum">    2656 </span>            :                                                         ? &quot;&quot; : &quot; (self only)&quot;);</a>
<a name="2657"><span class="lineNum">    2657 </span>            :                                 gotnocbscbs = false;</a>
<a name="2658"><span class="lineNum">    2658 </span>            :                                 firsttime = false;</a>
<a name="2659"><span class="lineNum">    2659 </span>            :                                 pr_alert(&quot;%s: No-CB GP kthread CPU %d:&quot;,</a>
<a name="2660"><span class="lineNum">    2660 </span>            :                                          __func__, cpu);</a>
<a name="2661"><span class="lineNum">    2661 </span>            :                         }</a>
<a name="2662"><span class="lineNum">    2662 </span>            :                 } else {</a>
<a name="2663"><span class="lineNum">    2663 </span>            :                         /* Another CB kthread, link to previous GP kthread. */</a>
<a name="2664"><span class="lineNum">    2664 </span>            :                         gotnocbscbs = true;</a>
<a name="2665"><span class="lineNum">    2665 </span>            :                         rdp-&gt;nocb_gp_rdp = rdp_gp;</a>
<a name="2666"><span class="lineNum">    2666 </span>            :                         rdp_prev-&gt;nocb_next_cb_rdp = rdp;</a>
<a name="2667"><span class="lineNum">    2667 </span>            :                         if (dump_tree)</a>
<a name="2668"><span class="lineNum">    2668 </span>            :                                 pr_cont(&quot; %d&quot;, cpu);</a>
<a name="2669"><span class="lineNum">    2669 </span>            :                 }</a>
<a name="2670"><span class="lineNum">    2670 </span>            :                 rdp_prev = rdp;</a>
<a name="2671"><span class="lineNum">    2671 </span>            :         }</a>
<a name="2672"><span class="lineNum">    2672 </span>            :         if (gotnocbs &amp;&amp; dump_tree)</a>
<a name="2673"><span class="lineNum">    2673 </span>            :                 pr_cont(&quot;%s\n&quot;, gotnocbscbs ? &quot;&quot; : &quot; (self only)&quot;);</a>
<a name="2674"><span class="lineNum">    2674 </span>            : }</a>
<a name="2675"><span class="lineNum">    2675 </span>            : </a>
<a name="2676"><span class="lineNum">    2676 </span>            : /*</a>
<a name="2677"><span class="lineNum">    2677 </span>            :  * Bind the current task to the offloaded CPUs.  If there are no offloaded</a>
<a name="2678"><span class="lineNum">    2678 </span>            :  * CPUs, leave the task unbound.  Splat if the bind attempt fails.</a>
<a name="2679"><span class="lineNum">    2679 </span>            :  */</a>
<a name="2680"><span class="lineNum">    2680 </span>            : void rcu_bind_current_to_nocb(void)</a>
<a name="2681"><span class="lineNum">    2681 </span>            : {</a>
<a name="2682"><span class="lineNum">    2682 </span>            :         if (cpumask_available(rcu_nocb_mask) &amp;&amp; cpumask_weight(rcu_nocb_mask))</a>
<a name="2683"><span class="lineNum">    2683 </span>            :                 WARN_ON(sched_setaffinity(current-&gt;pid, rcu_nocb_mask));</a>
<a name="2684"><span class="lineNum">    2684 </span>            : }</a>
<a name="2685"><span class="lineNum">    2685 </span>            : EXPORT_SYMBOL_GPL(rcu_bind_current_to_nocb);</a>
<a name="2686"><span class="lineNum">    2686 </span>            : </a>
<a name="2687"><span class="lineNum">    2687 </span>            : // The -&gt;on_cpu field is available only in CONFIG_SMP=y, so...</a>
<a name="2688"><span class="lineNum">    2688 </span>            : #ifdef CONFIG_SMP</a>
<a name="2689"><span class="lineNum">    2689 </span>            : static char *show_rcu_should_be_on_cpu(struct task_struct *tsp)</a>
<a name="2690"><span class="lineNum">    2690 </span>            : {</a>
<a name="2691"><span class="lineNum">    2691 </span>            :         return tsp &amp;&amp; tsp-&gt;state == TASK_RUNNING &amp;&amp; !tsp-&gt;on_cpu ? &quot;!&quot; : &quot;&quot;;</a>
<a name="2692"><span class="lineNum">    2692 </span>            : }</a>
<a name="2693"><span class="lineNum">    2693 </span>            : #else // #ifdef CONFIG_SMP</a>
<a name="2694"><span class="lineNum">    2694 </span>            : static char *show_rcu_should_be_on_cpu(struct task_struct *tsp)</a>
<a name="2695"><span class="lineNum">    2695 </span>            : {</a>
<a name="2696"><span class="lineNum">    2696 </span>            :         return &quot;&quot;;</a>
<a name="2697"><span class="lineNum">    2697 </span>            : }</a>
<a name="2698"><span class="lineNum">    2698 </span>            : #endif // #else #ifdef CONFIG_SMP</a>
<a name="2699"><span class="lineNum">    2699 </span>            : </a>
<a name="2700"><span class="lineNum">    2700 </span>            : /*</a>
<a name="2701"><span class="lineNum">    2701 </span>            :  * Dump out nocb grace-period kthread state for the specified rcu_data</a>
<a name="2702"><span class="lineNum">    2702 </span>            :  * structure.</a>
<a name="2703"><span class="lineNum">    2703 </span>            :  */</a>
<a name="2704"><span class="lineNum">    2704 </span>            : static void show_rcu_nocb_gp_state(struct rcu_data *rdp)</a>
<a name="2705"><span class="lineNum">    2705 </span>            : {</a>
<a name="2706"><span class="lineNum">    2706 </span>            :         struct rcu_node *rnp = rdp-&gt;mynode;</a>
<a name="2707"><span class="lineNum">    2707 </span>            : </a>
<a name="2708"><span class="lineNum">    2708 </span>            :         pr_info(&quot;nocb GP %d %c%c%c%c%c%c %c[%c%c] %c%c:%ld rnp %d:%d %lu %c CPU %d%s\n&quot;,</a>
<a name="2709"><span class="lineNum">    2709 </span>            :                 rdp-&gt;cpu,</a>
<a name="2710"><span class="lineNum">    2710 </span>            :                 &quot;kK&quot;[!!rdp-&gt;nocb_gp_kthread],</a>
<a name="2711"><span class="lineNum">    2711 </span>            :                 &quot;lL&quot;[raw_spin_is_locked(&amp;rdp-&gt;nocb_gp_lock)],</a>
<a name="2712"><span class="lineNum">    2712 </span>            :                 &quot;dD&quot;[!!rdp-&gt;nocb_defer_wakeup],</a>
<a name="2713"><span class="lineNum">    2713 </span>            :                 &quot;tT&quot;[timer_pending(&amp;rdp-&gt;nocb_timer)],</a>
<a name="2714"><span class="lineNum">    2714 </span>            :                 &quot;bB&quot;[timer_pending(&amp;rdp-&gt;nocb_bypass_timer)],</a>
<a name="2715"><span class="lineNum">    2715 </span>            :                 &quot;sS&quot;[!!rdp-&gt;nocb_gp_sleep],</a>
<a name="2716"><span class="lineNum">    2716 </span>            :                 &quot;.W&quot;[swait_active(&amp;rdp-&gt;nocb_gp_wq)],</a>
<a name="2717"><span class="lineNum">    2717 </span>            :                 &quot;.W&quot;[swait_active(&amp;rnp-&gt;nocb_gp_wq[0])],</a>
<a name="2718"><span class="lineNum">    2718 </span>            :                 &quot;.W&quot;[swait_active(&amp;rnp-&gt;nocb_gp_wq[1])],</a>
<a name="2719"><span class="lineNum">    2719 </span>            :                 &quot;.B&quot;[!!rdp-&gt;nocb_gp_bypass],</a>
<a name="2720"><span class="lineNum">    2720 </span>            :                 &quot;.G&quot;[!!rdp-&gt;nocb_gp_gp],</a>
<a name="2721"><span class="lineNum">    2721 </span>            :                 (long)rdp-&gt;nocb_gp_seq,</a>
<a name="2722"><span class="lineNum">    2722 </span>            :                 rnp-&gt;grplo, rnp-&gt;grphi, READ_ONCE(rdp-&gt;nocb_gp_loops),</a>
<a name="2723"><span class="lineNum">    2723 </span>            :                 rdp-&gt;nocb_gp_kthread ? task_state_to_char(rdp-&gt;nocb_gp_kthread) : '.',</a>
<a name="2724"><span class="lineNum">    2724 </span>            :                 rdp-&gt;nocb_cb_kthread ? (int)task_cpu(rdp-&gt;nocb_gp_kthread) : -1,</a>
<a name="2725"><span class="lineNum">    2725 </span>            :                 show_rcu_should_be_on_cpu(rdp-&gt;nocb_cb_kthread));</a>
<a name="2726"><span class="lineNum">    2726 </span>            : }</a>
<a name="2727"><span class="lineNum">    2727 </span>            : </a>
<a name="2728"><span class="lineNum">    2728 </span>            : /* Dump out nocb kthread state for the specified rcu_data structure. */</a>
<a name="2729"><span class="lineNum">    2729 </span>            : static void show_rcu_nocb_state(struct rcu_data *rdp)</a>
<a name="2730"><span class="lineNum">    2730 </span>            : {</a>
<a name="2731"><span class="lineNum">    2731 </span>            :         char bufw[20];</a>
<a name="2732"><span class="lineNum">    2732 </span>            :         char bufr[20];</a>
<a name="2733"><span class="lineNum">    2733 </span>            :         struct rcu_segcblist *rsclp = &amp;rdp-&gt;cblist;</a>
<a name="2734"><span class="lineNum">    2734 </span>            :         bool waslocked;</a>
<a name="2735"><span class="lineNum">    2735 </span>            :         bool wastimer;</a>
<a name="2736"><span class="lineNum">    2736 </span>            :         bool wassleep;</a>
<a name="2737"><span class="lineNum">    2737 </span>            : </a>
<a name="2738"><span class="lineNum">    2738 </span>            :         if (rdp-&gt;nocb_gp_rdp == rdp)</a>
<a name="2739"><span class="lineNum">    2739 </span>            :                 show_rcu_nocb_gp_state(rdp);</a>
<a name="2740"><span class="lineNum">    2740 </span>            : </a>
<a name="2741"><span class="lineNum">    2741 </span>            :         sprintf(bufw, &quot;%ld&quot;, rsclp-&gt;gp_seq[RCU_WAIT_TAIL]);</a>
<a name="2742"><span class="lineNum">    2742 </span>            :         sprintf(bufr, &quot;%ld&quot;, rsclp-&gt;gp_seq[RCU_NEXT_READY_TAIL]);</a>
<a name="2743"><span class="lineNum">    2743 </span>            :         pr_info(&quot;   CB %d^%d-&gt;%d %c%c%c%c%c%c F%ld L%ld C%d %c%c%s%c%s%c%c q%ld %c CPU %d%s\n&quot;,</a>
<a name="2744"><span class="lineNum">    2744 </span>            :                 rdp-&gt;cpu, rdp-&gt;nocb_gp_rdp-&gt;cpu,</a>
<a name="2745"><span class="lineNum">    2745 </span>            :                 rdp-&gt;nocb_next_cb_rdp ? rdp-&gt;nocb_next_cb_rdp-&gt;cpu : -1,</a>
<a name="2746"><span class="lineNum">    2746 </span>            :                 &quot;kK&quot;[!!rdp-&gt;nocb_cb_kthread],</a>
<a name="2747"><span class="lineNum">    2747 </span>            :                 &quot;bB&quot;[raw_spin_is_locked(&amp;rdp-&gt;nocb_bypass_lock)],</a>
<a name="2748"><span class="lineNum">    2748 </span>            :                 &quot;cC&quot;[!!atomic_read(&amp;rdp-&gt;nocb_lock_contended)],</a>
<a name="2749"><span class="lineNum">    2749 </span>            :                 &quot;lL&quot;[raw_spin_is_locked(&amp;rdp-&gt;nocb_lock)],</a>
<a name="2750"><span class="lineNum">    2750 </span>            :                 &quot;sS&quot;[!!rdp-&gt;nocb_cb_sleep],</a>
<a name="2751"><span class="lineNum">    2751 </span>            :                 &quot;.W&quot;[swait_active(&amp;rdp-&gt;nocb_cb_wq)],</a>
<a name="2752"><span class="lineNum">    2752 </span>            :                 jiffies - rdp-&gt;nocb_bypass_first,</a>
<a name="2753"><span class="lineNum">    2753 </span>            :                 jiffies - rdp-&gt;nocb_nobypass_last,</a>
<a name="2754"><span class="lineNum">    2754 </span>            :                 rdp-&gt;nocb_nobypass_count,</a>
<a name="2755"><span class="lineNum">    2755 </span>            :                 &quot;.D&quot;[rcu_segcblist_ready_cbs(rsclp)],</a>
<a name="2756"><span class="lineNum">    2756 </span>            :                 &quot;.W&quot;[!rcu_segcblist_segempty(rsclp, RCU_WAIT_TAIL)],</a>
<a name="2757"><span class="lineNum">    2757 </span>            :                 rcu_segcblist_segempty(rsclp, RCU_WAIT_TAIL) ? &quot;&quot; : bufw,</a>
<a name="2758"><span class="lineNum">    2758 </span>            :                 &quot;.R&quot;[!rcu_segcblist_segempty(rsclp, RCU_NEXT_READY_TAIL)],</a>
<a name="2759"><span class="lineNum">    2759 </span>            :                 rcu_segcblist_segempty(rsclp, RCU_NEXT_READY_TAIL) ? &quot;&quot; : bufr,</a>
<a name="2760"><span class="lineNum">    2760 </span>            :                 &quot;.N&quot;[!rcu_segcblist_segempty(rsclp, RCU_NEXT_TAIL)],</a>
<a name="2761"><span class="lineNum">    2761 </span>            :                 &quot;.B&quot;[!!rcu_cblist_n_cbs(&amp;rdp-&gt;nocb_bypass)],</a>
<a name="2762"><span class="lineNum">    2762 </span>            :                 rcu_segcblist_n_cbs(&amp;rdp-&gt;cblist),</a>
<a name="2763"><span class="lineNum">    2763 </span>            :                 rdp-&gt;nocb_cb_kthread ? task_state_to_char(rdp-&gt;nocb_cb_kthread) : '.',</a>
<a name="2764"><span class="lineNum">    2764 </span>            :                 rdp-&gt;nocb_cb_kthread ? (int)task_cpu(rdp-&gt;nocb_gp_kthread) : -1,</a>
<a name="2765"><span class="lineNum">    2765 </span>            :                 show_rcu_should_be_on_cpu(rdp-&gt;nocb_cb_kthread));</a>
<a name="2766"><span class="lineNum">    2766 </span>            : </a>
<a name="2767"><span class="lineNum">    2767 </span>            :         /* It is OK for GP kthreads to have GP state. */</a>
<a name="2768"><span class="lineNum">    2768 </span>            :         if (rdp-&gt;nocb_gp_rdp == rdp)</a>
<a name="2769"><span class="lineNum">    2769 </span>            :                 return;</a>
<a name="2770"><span class="lineNum">    2770 </span>            : </a>
<a name="2771"><span class="lineNum">    2771 </span>            :         waslocked = raw_spin_is_locked(&amp;rdp-&gt;nocb_gp_lock);</a>
<a name="2772"><span class="lineNum">    2772 </span>            :         wastimer = timer_pending(&amp;rdp-&gt;nocb_bypass_timer);</a>
<a name="2773"><span class="lineNum">    2773 </span>            :         wassleep = swait_active(&amp;rdp-&gt;nocb_gp_wq);</a>
<a name="2774"><span class="lineNum">    2774 </span>            :         if (!rdp-&gt;nocb_gp_sleep &amp;&amp; !waslocked &amp;&amp; !wastimer &amp;&amp; !wassleep)</a>
<a name="2775"><span class="lineNum">    2775 </span>            :                 return;  /* Nothing untowards. */</a>
<a name="2776"><span class="lineNum">    2776 </span>            : </a>
<a name="2777"><span class="lineNum">    2777 </span>            :         pr_info(&quot;   nocb GP activity on CB-only CPU!!! %c%c%c%c %c\n&quot;,</a>
<a name="2778"><span class="lineNum">    2778 </span>            :                 &quot;lL&quot;[waslocked],</a>
<a name="2779"><span class="lineNum">    2779 </span>            :                 &quot;dD&quot;[!!rdp-&gt;nocb_defer_wakeup],</a>
<a name="2780"><span class="lineNum">    2780 </span>            :                 &quot;tT&quot;[wastimer],</a>
<a name="2781"><span class="lineNum">    2781 </span>            :                 &quot;sS&quot;[!!rdp-&gt;nocb_gp_sleep],</a>
<a name="2782"><span class="lineNum">    2782 </span>            :                 &quot;.W&quot;[wassleep]);</a>
<a name="2783"><span class="lineNum">    2783 </span>            : }</a>
<a name="2784"><span class="lineNum">    2784 </span>            : </a>
<a name="2785"><span class="lineNum">    2785 </span>            : #else /* #ifdef CONFIG_RCU_NOCB_CPU */</a>
<a name="2786"><span class="lineNum">    2786 </span>            : </a>
<a name="2787"><span class="lineNum">    2787 </span>            : /* No -&gt;nocb_lock to acquire.  */</a>
<a name="2788"><span class="lineNum">    2788 </span><span class="lineCov">      97537 : static void rcu_nocb_lock(struct rcu_data *rdp)</span></a>
<a name="2789"><span class="lineNum">    2789 </span>            : {</a>
<a name="2790"><span class="lineNum">    2790 </span><span class="lineCov">      97537 : }</span></a>
<a name="2791"><span class="lineNum">    2791 </span>            : </a>
<a name="2792"><span class="lineNum">    2792 </span>            : /* No -&gt;nocb_lock to release.  */</a>
<a name="2793"><span class="lineNum">    2793 </span><span class="lineCov">          6 : static void rcu_nocb_unlock(struct rcu_data *rdp)</span></a>
<a name="2794"><span class="lineNum">    2794 </span>            : {</a>
<a name="2795"><span class="lineNum">    2795 </span><span class="lineCov">          4 : }</span></a>
<a name="2796"><span class="lineNum">    2796 </span>            : </a>
<a name="2797"><span class="lineNum">    2797 </span>            : /* No -&gt;nocb_lock to release.  */</a>
<a name="2798"><span class="lineNum">    2798 </span><span class="lineCov">      97605 : static void rcu_nocb_unlock_irqrestore(struct rcu_data *rdp,</span></a>
<a name="2799"><span class="lineNum">    2799 </span>            :                                        unsigned long flags)</a>
<a name="2800"><span class="lineNum">    2800 </span>            : {</a>
<a name="2801"><span class="lineNum">    2801 </span><span class="lineCov">      97605 :         local_irq_restore(flags);</span></a>
<a name="2802"><span class="lineNum">    2802 </span><span class="lineCov">      97631 : }</span></a>
<a name="2803"><span class="lineNum">    2803 </span>            : </a>
<a name="2804"><span class="lineNum">    2804 </span>            : /* Lockdep check that -&gt;cblist may be safely accessed. */</a>
<a name="2805"><span class="lineNum">    2805 </span><span class="lineCov">      26320 : static void rcu_lockdep_assert_cblist_protected(struct rcu_data *rdp)</span></a>
<a name="2806"><span class="lineNum">    2806 </span>            : {</a>
<a name="2807"><span class="lineNum">    2807 </span><span class="lineCov">      52640 :         lockdep_assert_irqs_disabled();</span></a>
<a name="2808"><span class="lineNum">    2808 </span><span class="lineCov">      26320 : }</span></a>
<a name="2809"><span class="lineNum">    2809 </span>            : </a>
<a name="2810"><span class="lineNum">    2810 </span><span class="lineCov">       2019 : static void rcu_nocb_gp_cleanup(struct swait_queue_head *sq)</span></a>
<a name="2811"><span class="lineNum">    2811 </span>            : {</a>
<a name="2812"><span class="lineNum">    2812 </span><span class="lineCov">       2019 : }</span></a>
<a name="2813"><span class="lineNum">    2813 </span>            : </a>
<a name="2814"><span class="lineNum">    2814 </span><span class="lineCov">       2019 : static struct swait_queue_head *rcu_nocb_gp_get(struct rcu_node *rnp)</span></a>
<a name="2815"><span class="lineNum">    2815 </span>            : {</a>
<a name="2816"><span class="lineNum">    2816 </span><span class="lineCov">       2019 :         return NULL;</span></a>
<a name="2817"><span class="lineNum">    2817 </span>            : }</a>
<a name="2818"><span class="lineNum">    2818 </span>            : </a>
<a name="2819"><span class="lineNum">    2819 </span><span class="lineCov">          1 : static void rcu_init_one_nocb(struct rcu_node *rnp)</span></a>
<a name="2820"><span class="lineNum">    2820 </span>            : {</a>
<a name="2821"><span class="lineNum">    2821 </span><span class="lineCov">          1 : }</span></a>
<a name="2822"><span class="lineNum">    2822 </span>            : </a>
<a name="2823"><span class="lineNum">    2823 </span><span class="lineCov">          2 : static bool rcu_nocb_flush_bypass(struct rcu_data *rdp, struct rcu_head *rhp,</span></a>
<a name="2824"><span class="lineNum">    2824 </span>            :                                   unsigned long j)</a>
<a name="2825"><span class="lineNum">    2825 </span>            : {</a>
<a name="2826"><span class="lineNum">    2826 </span><span class="lineCov">          2 :         return true;</span></a>
<a name="2827"><span class="lineNum">    2827 </span>            : }</a>
<a name="2828"><span class="lineNum">    2828 </span>            : </a>
<a name="2829"><span class="lineNum">    2829 </span><span class="lineCov">     627326 : static bool rcu_nocb_try_bypass(struct rcu_data *rdp, struct rcu_head *rhp,</span></a>
<a name="2830"><span class="lineNum">    2830 </span>            :                                 bool *was_alldone, unsigned long flags)</a>
<a name="2831"><span class="lineNum">    2831 </span>            : {</a>
<a name="2832"><span class="lineNum">    2832 </span><span class="lineCov">     627326 :         return false;</span></a>
<a name="2833"><span class="lineNum">    2833 </span>            : }</a>
<a name="2834"><span class="lineNum">    2834 </span>            : </a>
<a name="2835"><span class="lineNum">    2835 </span>            : static void __call_rcu_nocb_wake(struct rcu_data *rdp, bool was_empty,</a>
<a name="2836"><span class="lineNum">    2836 </span>            :                                  unsigned long flags)</a>
<a name="2837"><span class="lineNum">    2837 </span>            : {</a>
<a name="2838"><span class="lineNum">    2838 </span>            :         WARN_ON_ONCE(1);  /* Should be dead code! */</a>
<a name="2839"><span class="lineNum">    2839 </span>            : }</a>
<a name="2840"><span class="lineNum">    2840 </span>            : </a>
<a name="2841"><span class="lineNum">    2841 </span><span class="lineCov">          4 : static void __init rcu_boot_init_nocb_percpu_data(struct rcu_data *rdp)</span></a>
<a name="2842"><span class="lineNum">    2842 </span>            : {</a>
<a name="2843"><span class="lineNum">    2843 </span><span class="lineCov">          4 : }</span></a>
<a name="2844"><span class="lineNum">    2844 </span>            : </a>
<a name="2845"><span class="lineNum">    2845 </span><span class="lineCov">      27740 : static int rcu_nocb_need_deferred_wakeup(struct rcu_data *rdp)</span></a>
<a name="2846"><span class="lineNum">    2846 </span>            : {</a>
<a name="2847"><span class="lineNum">    2847 </span><span class="lineCov">      27740 :         return false;</span></a>
<a name="2848"><span class="lineNum">    2848 </span>            : }</a>
<a name="2849"><span class="lineNum">    2849 </span>            : </a>
<a name="2850"><span class="lineNum">    2850 </span><span class="lineCov">      54197 : static bool do_nocb_deferred_wakeup(struct rcu_data *rdp)</span></a>
<a name="2851"><span class="lineNum">    2851 </span>            : {</a>
<a name="2852"><span class="lineNum">    2852 </span><span class="lineCov">      54197 :         return false;</span></a>
<a name="2853"><span class="lineNum">    2853 </span>            : }</a>
<a name="2854"><span class="lineNum">    2854 </span>            : </a>
<a name="2855"><span class="lineNum">    2855 </span><span class="lineCov">          4 : static void rcu_spawn_cpu_nocb_kthread(int cpu)</span></a>
<a name="2856"><span class="lineNum">    2856 </span>            : {</a>
<a name="2857"><span class="lineNum">    2857 </span><span class="lineCov">          4 : }</span></a>
<a name="2858"><span class="lineNum">    2858 </span>            : </a>
<a name="2859"><span class="lineNum">    2859 </span><span class="lineCov">          1 : static void __init rcu_spawn_nocb_kthreads(void)</span></a>
<a name="2860"><span class="lineNum">    2860 </span>            : {</a>
<a name="2861"><span class="lineNum">    2861 </span><span class="lineCov">          1 : }</span></a>
<a name="2862"><span class="lineNum">    2862 </span>            : </a>
<a name="2863"><span class="lineNum">    2863 </span>            : static void show_rcu_nocb_state(struct rcu_data *rdp)</a>
<a name="2864"><span class="lineNum">    2864 </span>            : {</a>
<a name="2865"><span class="lineNum">    2865 </span>            : }</a>
<a name="2866"><span class="lineNum">    2866 </span>            : </a>
<a name="2867"><span class="lineNum">    2867 </span>            : #endif /* #else #ifdef CONFIG_RCU_NOCB_CPU */</a>
<a name="2868"><span class="lineNum">    2868 </span>            : </a>
<a name="2869"><span class="lineNum">    2869 </span>            : /*</a>
<a name="2870"><span class="lineNum">    2870 </span>            :  * Is this CPU a NO_HZ_FULL CPU that should ignore RCU so that the</a>
<a name="2871"><span class="lineNum">    2871 </span>            :  * grace-period kthread will do force_quiescent_state() processing?</a>
<a name="2872"><span class="lineNum">    2872 </span>            :  * The idea is to avoid waking up RCU core processing on such a</a>
<a name="2873"><span class="lineNum">    2873 </span>            :  * CPU unless the grace period has extended for too long.</a>
<a name="2874"><span class="lineNum">    2874 </span>            :  *</a>
<a name="2875"><span class="lineNum">    2875 </span>            :  * This code relies on the fact that all NO_HZ_FULL CPUs are also</a>
<a name="2876"><span class="lineNum">    2876 </span>            :  * CONFIG_RCU_NOCB_CPU CPUs.</a>
<a name="2877"><span class="lineNum">    2877 </span>            :  */</a>
<a name="2878"><span class="lineNum">    2878 </span>            : static bool rcu_nohz_full_cpu(void)</a>
<a name="2879"><span class="lineNum">    2879 </span>            : {</a>
<a name="2880"><span class="lineNum">    2880 </span>            : #ifdef CONFIG_NO_HZ_FULL</a>
<a name="2881"><span class="lineNum">    2881 </span>            :         if (tick_nohz_full_cpu(smp_processor_id()) &amp;&amp;</a>
<a name="2882"><span class="lineNum">    2882 </span>            :             (!rcu_gp_in_progress() ||</a>
<a name="2883"><span class="lineNum">    2883 </span>            :              time_before(jiffies, READ_ONCE(rcu_state.gp_start) + HZ)))</a>
<a name="2884"><span class="lineNum">    2884 </span>            :                 return true;</a>
<a name="2885"><span class="lineNum">    2885 </span>            : #endif /* #ifdef CONFIG_NO_HZ_FULL */</a>
<a name="2886"><span class="lineNum">    2886 </span>            :         return false;</a>
<a name="2887"><span class="lineNum">    2887 </span>            : }</a>
<a name="2888"><span class="lineNum">    2888 </span>            : </a>
<a name="2889"><span class="lineNum">    2889 </span>            : /*</a>
<a name="2890"><span class="lineNum">    2890 </span>            :  * Bind the RCU grace-period kthreads to the housekeeping CPU.</a>
<a name="2891"><span class="lineNum">    2891 </span>            :  */</a>
<a name="2892"><span class="lineNum">    2892 </span><span class="lineCov">          1 : static void rcu_bind_gp_kthread(void)</span></a>
<a name="2893"><span class="lineNum">    2893 </span>            : {</a>
<a name="2894"><span class="lineNum">    2894 </span><span class="lineCov">          1 :         if (!tick_nohz_full_enabled())</span></a>
<a name="2895"><span class="lineNum">    2895 </span><span class="lineCov">          1 :                 return;</span></a>
<a name="2896"><span class="lineNum">    2896 </span><span class="lineCov">          1 :         housekeeping_affine(current, HK_FLAG_RCU);</span></a>
<a name="2897"><span class="lineNum">    2897 </span>            : }</a>
<a name="2898"><span class="lineNum">    2898 </span>            : </a>
<a name="2899"><span class="lineNum">    2899 </span>            : /* Record the current task on dyntick-idle entry. */</a>
<a name="2900"><span class="lineNum">    2900 </span>            : static void noinstr rcu_dynticks_task_enter(void)</a>
<a name="2901"><span class="lineNum">    2901 </span>            : {</a>
<a name="2902"><span class="lineNum">    2902 </span>            : #if defined(CONFIG_TASKS_RCU) &amp;&amp; defined(CONFIG_NO_HZ_FULL)</a>
<a name="2903"><span class="lineNum">    2903 </span>            :         WRITE_ONCE(current-&gt;rcu_tasks_idle_cpu, smp_processor_id());</a>
<a name="2904"><span class="lineNum">    2904 </span>            : #endif /* #if defined(CONFIG_TASKS_RCU) &amp;&amp; defined(CONFIG_NO_HZ_FULL) */</a>
<a name="2905"><span class="lineNum">    2905 </span>            : }</a>
<a name="2906"><span class="lineNum">    2906 </span>            : </a>
<a name="2907"><span class="lineNum">    2907 </span>            : /* Record no current task on dyntick-idle exit. */</a>
<a name="2908"><span class="lineNum">    2908 </span>            : static void noinstr rcu_dynticks_task_exit(void)</a>
<a name="2909"><span class="lineNum">    2909 </span>            : {</a>
<a name="2910"><span class="lineNum">    2910 </span>            : #if defined(CONFIG_TASKS_RCU) &amp;&amp; defined(CONFIG_NO_HZ_FULL)</a>
<a name="2911"><span class="lineNum">    2911 </span>            :         WRITE_ONCE(current-&gt;rcu_tasks_idle_cpu, -1);</a>
<a name="2912"><span class="lineNum">    2912 </span>            : #endif /* #if defined(CONFIG_TASKS_RCU) &amp;&amp; defined(CONFIG_NO_HZ_FULL) */</a>
<a name="2913"><span class="lineNum">    2913 </span>            : }</a>
<a name="2914"><span class="lineNum">    2914 </span>            : </a>
<a name="2915"><span class="lineNum">    2915 </span>            : /* Turn on heavyweight RCU tasks trace readers on idle/user entry. */</a>
<a name="2916"><span class="lineNum">    2916 </span>            : static void rcu_dynticks_task_trace_enter(void)</a>
<a name="2917"><span class="lineNum">    2917 </span>            : {</a>
<a name="2918"><span class="lineNum">    2918 </span>            : #ifdef CONFIG_TASKS_RCU_TRACE</a>
<a name="2919"><span class="lineNum">    2919 </span>            :         if (IS_ENABLED(CONFIG_TASKS_TRACE_RCU_READ_MB))</a>
<a name="2920"><span class="lineNum">    2920 </span>            :                 current-&gt;trc_reader_special.b.need_mb = true;</a>
<a name="2921"><span class="lineNum">    2921 </span>            : #endif /* #ifdef CONFIG_TASKS_RCU_TRACE */</a>
<a name="2922"><span class="lineNum">    2922 </span>            : }</a>
<a name="2923"><span class="lineNum">    2923 </span>            : </a>
<a name="2924"><span class="lineNum">    2924 </span>            : /* Turn off heavyweight RCU tasks trace readers on idle/user exit. */</a>
<a name="2925"><span class="lineNum">    2925 </span>            : static void rcu_dynticks_task_trace_exit(void)</a>
<a name="2926"><span class="lineNum">    2926 </span>            : {</a>
<a name="2927"><span class="lineNum">    2927 </span>            : #ifdef CONFIG_TASKS_RCU_TRACE</a>
<a name="2928"><span class="lineNum">    2928 </span>            :         if (IS_ENABLED(CONFIG_TASKS_TRACE_RCU_READ_MB))</a>
<a name="2929"><span class="lineNum">    2929 </span>            :                 current-&gt;trc_reader_special.b.need_mb = false;</a>
<a name="2930"><span class="lineNum">    2930 </span>            : #endif /* #ifdef CONFIG_TASKS_RCU_TRACE */</a>
<a name="2931"><span class="lineNum">    2931 </span>            : }</a>
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="http://ltp.sourceforge.net/coverage/lcov.php" target="_parent">LCOV version 1.14</a></td></tr>
  </table>
  <br>

</body>
</html>
